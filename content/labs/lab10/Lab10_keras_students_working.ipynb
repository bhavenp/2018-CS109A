{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS-109A Introduction to Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 10:  Neural Networks using `keras` \n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2018**<br/>\n",
    "**Instructors:** Pavlos Protopapas and Kevin Rader<br/>\n",
    "**Lab Instructor:** Eleni Kaxiras<br/>\n",
    "**Authors:** David Sondak, Eleni Kaxiras, and Pavlos Protopapas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "div.gc { \n",
       "\tbackground-color: #AEDE94;\n",
       "\tborder-color: #E9967A; \t \n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 12pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## RUN THIS CELL TO GET THE RIGHT FORMATTING \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get\\\n",
    "    (\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anatomy of an Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a previous lab we created our own neural network by writing some simple python functions.  We focused on a regression problem where we tried to learn a function. We practiced using the logistic activation function in a network with multiple nodes, but a single or two hidden layers.  Some of the key observations were:\n",
    "* Increasing the number of nodes allows us to represent more complicated functions  \n",
    "* The weights and biases have a very big impact on the solution\n",
    "* Finding the \"correct\" weights and biases is really hard to do manually\n",
    "* There must be a better method for determining the weights and biases automatically\n",
    "\n",
    "We also didn't assess the effects of different activation functions or different network depths. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 3 parts of an ANN\n",
    "\n",
    "- **Part 1: the input layer** (dimentions are determined from our dataset)\n",
    "- **Part 2: the internal architecture or hidden layers** (the number of layers, the activation functions, the learnable parameters and other hyperparameters)\n",
    "- **Part 3: the output layer** (what we want from the network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A word about .npy files\n",
    "\n",
    "Numpy arrays are faster than plain python lists, as we know. Numpy also offers a file format called .npy, which, when it comes to reading the same data multiple times from disk storage, is a lot faster than reading from a csv file. You can save any list or array into this format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/tmp/123', np.array([[1, 2, 3], [4, 5, 6]]))\n",
    "hello = np.load('/tmp/123.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hello"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Keras` Basics ![](figs/keras.png)\n",
    "https://keras.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning computations can be quite demanding. TensorFlow is a framework for representing complicated ML algorithms and executing them in any platform, from a phone to a distributed system using GPUs. Developed by Google Brain, TensorFlow is used very broadly today. \n",
    "\n",
    "**[`keras`](https://keras.io/)**, is a high-level API used for fast prototyping, advanced research, and production. We will use `tf.keras` which is TensorFlow's implementation of the `keras` API.\n",
    "\n",
    "### Models are assemblies of layers\n",
    "\n",
    "The core data structure of Keras is a **model**, a way to organize layers. A model is understood as a sequence or a graph of standalone, fully-configurable modules that can be plugged together with as few restrictions as possible. In particular, neural layers, cost functions, optimizers, initialization schemes, activation functions, regularization schemes are all standalone modules that you can combine to create new models.\n",
    "\n",
    "The simplest type of model is the **Sequential** model, a linear stack of layers. For more complex architectures, one can use the Keras **Functional** API, which allows to build arbitrary graphs of layers.\n",
    "\n",
    "https://keras.io/models/model/\n",
    "\n",
    "Everything you need to know about the Sequential model is here: https://keras.io/models/sequential/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Installation\n",
    "\n",
    "If you haven't already, install `Keras` using the instructions found at [https://keras.io/#installation](https://keras.io/#installation)\n",
    "\n",
    "Choose the TensorFlow installation instructions (found at [https://www.tensorflow.org/install/](https://www.tensorflow.org/install/) )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Approximating a Gaussian using keras\n",
    "Let's try to redo the problem from last week.  Recall that we had a function\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "f\\left(x\\right) = e^{-x^{2}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "and we wanted to use a neural network to approximate that function.  This week, we will use `keras` to do the true optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the necessary `keras` modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bhavenpatel/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n",
      "2.1.6-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "print(tf.VERSION)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456, 1242922902424397177)]\n"
     ]
    }
   ],
   "source": [
    "# Checking if our machine has GPUs. Mine does not..\n",
    "with tf.Session() as sess:\n",
    "    devices = sess.list_devices()\n",
    "    print(devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get started, we need to create some **data**.  We will generate data points from an underlying function (here the Guassian).  Then we will use the `sklearn` `train_test_split` method to split the dataset into training and testing portions.  Remember that we train a machine learning algorithm on the training set and then assess the algorithm's performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "n_samples = 1050 # set the number of samples to take for each dataset\n",
    "test_size = 0.3 # set the proportion of data to hold out for testing\n",
    "\n",
    "# define the function and add noise\n",
    "\n",
    "def f_gauss(x):\n",
    "    return np.exp(-x * x) + np.random.normal(loc=0, scale=.1, size = x.shape[0])\n",
    "\n",
    "X = np.random.permutation(np.linspace(-10, 10, n_samples)) # choose some points from the function\n",
    "Y = f_gauss(X)\n",
    "\n",
    "# create training and testing data from this set of points\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a2c588908>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameters are learned by the network. the hyperparameters are chosen by the user; can be tuned as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a keras network\n",
    "\n",
    "Now we will create a neural network model with keras. We're going to use a single layer and just 2 neurons in that layer. We will start with the sigmoid activation function. We also choose a linear output layer since we are doing regression. The loss function is selected to be the **mean squared error (MSE)**. In addition to these choices we must also specify our initial weights as well as the optimization method that will be used to minimize the loss function. The keras interface has many choises as to those hyperparameters.\n",
    "\n",
    "**Part 1:** First we start by defining the number of nodes in a layer and the input dimensions. If we have more than one layer we might need to define a value for the number of nodes (H) for each layer.\n",
    "\n",
    "`H = \n",
    "input_dim =`\n",
    "\n",
    "Then we instantiate the model\n",
    "\n",
    "`model = models.Sequential() `\n",
    "\n",
    "**Part 2:** Then we add the hidden layers. Adding layers and stacking them is done using `.add()`\n",
    "\n",
    "`model.add(layers.Dense(H, input_dim=input_dim,  \n",
    "                activation='sigmoid')) `\n",
    "\n",
    "**An alternative way** \n",
    "\n",
    "`model = Sequential([\n",
    "    Dense(200, input_shape=(X_train.shape[1],), activation='relu'),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(4, activation='linear')\n",
    "])`\n",
    "\n",
    "**Part 3:** We end with the final layer (output)\n",
    "\n",
    "`model.add(layers.Dense(1, \n",
    "                activation='linear')) `\n",
    "                \n",
    "Our model is not ready yet. We need to configure its learning process with .compile():\n",
    "\n",
    "`model.compile(loss='mean_squared_error', optimizer='sgd')`\n",
    "\n",
    "If you need to, you can further configure your optimizer. A core principle of Keras is to make things reasonably simple, while allowing the user to be fully in control when they need to (the ultimate control being the easy extensibility of the source code)\n",
    "\n",
    "`model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(lr=0.01))`\n",
    "              \n",
    "Our model is now ready to use. We haven't trained it yet, but we'll do that now using the fit method. Notice that we also need to specify the batch size for the stochastic gradient decent algorithm as well as the number of epochs to run.\n",
    "\n",
    "`model.fit(X_train, Y_train, batch_size=100, epochs=100)#, verbose=1)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 1:</b> </div>\n",
    "\n",
    "Build a NN with one hidden layer with **2 neurons**. Use the `tanh` activation function. Train the model using the X_train dataset from above (train the model in this case means run `.compile` and `.fit`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "735/735 [==============================] - 0s 374us/step - loss: 0.2427\n",
      "Epoch 2/100\n",
      "735/735 [==============================] - 0s 15us/step - loss: 0.2267\n",
      "Epoch 3/100\n",
      "735/735 [==============================] - 0s 18us/step - loss: 0.2110\n",
      "Epoch 4/100\n",
      "735/735 [==============================] - 0s 15us/step - loss: 0.1965\n",
      "Epoch 5/100\n",
      "735/735 [==============================] - 0s 17us/step - loss: 0.1826\n",
      "Epoch 6/100\n",
      "735/735 [==============================] - 0s 20us/step - loss: 0.1701\n",
      "Epoch 7/100\n",
      "735/735 [==============================] - 0s 17us/step - loss: 0.1584\n",
      "Epoch 8/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.1476\n",
      "Epoch 9/100\n",
      "735/735 [==============================] - 0s 17us/step - loss: 0.1377\n",
      "Epoch 10/100\n",
      "735/735 [==============================] - 0s 21us/step - loss: 0.1287\n",
      "Epoch 11/100\n",
      "735/735 [==============================] - 0s 17us/step - loss: 0.1203\n",
      "Epoch 12/100\n",
      "735/735 [==============================] - 0s 14us/step - loss: 0.1127\n",
      "Epoch 13/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.1058\n",
      "Epoch 14/100\n",
      "735/735 [==============================] - 0s 22us/step - loss: 0.0994\n",
      "Epoch 15/100\n",
      "735/735 [==============================] - 0s 15us/step - loss: 0.0937\n",
      "Epoch 16/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0885\n",
      "Epoch 17/100\n",
      "735/735 [==============================] - 0s 19us/step - loss: 0.0838\n",
      "Epoch 18/100\n",
      "735/735 [==============================] - 0s 15us/step - loss: 0.0796\n",
      "Epoch 19/100\n",
      "735/735 [==============================] - 0s 13us/step - loss: 0.0759\n",
      "Epoch 20/100\n",
      "735/735 [==============================] - 0s 14us/step - loss: 0.0724\n",
      "Epoch 21/100\n",
      "735/735 [==============================] - 0s 25us/step - loss: 0.0694\n",
      "Epoch 22/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0667\n",
      "Epoch 23/100\n",
      "735/735 [==============================] - 0s 15us/step - loss: 0.0643\n",
      "Epoch 24/100\n",
      "735/735 [==============================] - 0s 19us/step - loss: 0.0621\n",
      "Epoch 25/100\n",
      "735/735 [==============================] - 0s 14us/step - loss: 0.0601\n",
      "Epoch 26/100\n",
      "735/735 [==============================] - 0s 21us/step - loss: 0.0584\n",
      "Epoch 27/100\n",
      "735/735 [==============================] - 0s 18us/step - loss: 0.0568\n",
      "Epoch 28/100\n",
      "735/735 [==============================] - 0s 27us/step - loss: 0.0553\n",
      "Epoch 29/100\n",
      "735/735 [==============================] - 0s 22us/step - loss: 0.0540\n",
      "Epoch 30/100\n",
      "735/735 [==============================] - 0s 14us/step - loss: 0.0527\n",
      "Epoch 31/100\n",
      "735/735 [==============================] - 0s 19us/step - loss: 0.0515\n",
      "Epoch 32/100\n",
      "735/735 [==============================] - 0s 14us/step - loss: 0.0505\n",
      "Epoch 33/100\n",
      "735/735 [==============================] - 0s 14us/step - loss: 0.0495\n",
      "Epoch 34/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0485\n",
      "Epoch 35/100\n",
      "735/735 [==============================] - 0s 15us/step - loss: 0.0476\n",
      "Epoch 36/100\n",
      "735/735 [==============================] - 0s 20us/step - loss: 0.0467\n",
      "Epoch 37/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0459\n",
      "Epoch 38/100\n",
      "735/735 [==============================] - 0s 14us/step - loss: 0.0451\n",
      "Epoch 39/100\n",
      "735/735 [==============================] - 0s 13us/step - loss: 0.0444\n",
      "Epoch 40/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0437\n",
      "Epoch 41/100\n",
      "735/735 [==============================] - 0s 19us/step - loss: 0.0430\n",
      "Epoch 42/100\n",
      "735/735 [==============================] - 0s 15us/step - loss: 0.0423\n",
      "Epoch 43/100\n",
      "735/735 [==============================] - 0s 14us/step - loss: 0.0416\n",
      "Epoch 44/100\n",
      "735/735 [==============================] - 0s 14us/step - loss: 0.0410\n",
      "Epoch 45/100\n",
      "735/735 [==============================] - 0s 21us/step - loss: 0.0404\n",
      "Epoch 46/100\n",
      "735/735 [==============================] - 0s 24us/step - loss: 0.0398\n",
      "Epoch 47/100\n",
      "735/735 [==============================] - 0s 20us/step - loss: 0.0392\n",
      "Epoch 48/100\n",
      "735/735 [==============================] - 0s 18us/step - loss: 0.0386\n",
      "Epoch 49/100\n",
      "735/735 [==============================] - 0s 19us/step - loss: 0.0381\n",
      "Epoch 50/100\n",
      "735/735 [==============================] - 0s 23us/step - loss: 0.0376\n",
      "Epoch 51/100\n",
      "735/735 [==============================] - 0s 27us/step - loss: 0.0371\n",
      "Epoch 52/100\n",
      "735/735 [==============================] - 0s 20us/step - loss: 0.0366\n",
      "Epoch 53/100\n",
      "735/735 [==============================] - 0s 13us/step - loss: 0.0362\n",
      "Epoch 54/100\n",
      "735/735 [==============================] - 0s 19us/step - loss: 0.0357\n",
      "Epoch 55/100\n",
      "735/735 [==============================] - 0s 15us/step - loss: 0.0353\n",
      "Epoch 56/100\n",
      "735/735 [==============================] - 0s 14us/step - loss: 0.0349\n",
      "Epoch 57/100\n",
      "735/735 [==============================] - 0s 14us/step - loss: 0.0345\n",
      "Epoch 58/100\n",
      "735/735 [==============================] - 0s 17us/step - loss: 0.0341\n",
      "Epoch 59/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0338\n",
      "Epoch 60/100\n",
      "735/735 [==============================] - 0s 13us/step - loss: 0.0334\n",
      "Epoch 61/100\n",
      "735/735 [==============================] - 0s 15us/step - loss: 0.0330\n",
      "Epoch 62/100\n",
      "735/735 [==============================] - 0s 19us/step - loss: 0.0327\n",
      "Epoch 63/100\n",
      "735/735 [==============================] - 0s 21us/step - loss: 0.0324\n",
      "Epoch 64/100\n",
      "735/735 [==============================] - 0s 24us/step - loss: 0.0321\n",
      "Epoch 65/100\n",
      "735/735 [==============================] - 0s 17us/step - loss: 0.0317\n",
      "Epoch 66/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0314\n",
      "Epoch 67/100\n",
      "735/735 [==============================] - 0s 18us/step - loss: 0.0311\n",
      "Epoch 68/100\n",
      "735/735 [==============================] - 0s 18us/step - loss: 0.0309\n",
      "Epoch 69/100\n",
      "735/735 [==============================] - 0s 15us/step - loss: 0.0306\n",
      "Epoch 70/100\n",
      "735/735 [==============================] - 0s 20us/step - loss: 0.0303\n",
      "Epoch 71/100\n",
      "735/735 [==============================] - 0s 15us/step - loss: 0.0301\n",
      "Epoch 72/100\n",
      "735/735 [==============================] - 0s 20us/step - loss: 0.0298\n",
      "Epoch 73/100\n",
      "735/735 [==============================] - 0s 15us/step - loss: 0.0295\n",
      "Epoch 74/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0293\n",
      "Epoch 75/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0290\n",
      "Epoch 76/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0288\n",
      "Epoch 77/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0286\n",
      "Epoch 78/100\n",
      "735/735 [==============================] - 0s 14us/step - loss: 0.0284\n",
      "Epoch 79/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0281\n",
      "Epoch 80/100\n",
      "735/735 [==============================] - 0s 22us/step - loss: 0.0279\n",
      "Epoch 81/100\n",
      "735/735 [==============================] - 0s 15us/step - loss: 0.0277\n",
      "Epoch 82/100\n",
      "735/735 [==============================] - 0s 14us/step - loss: 0.0275\n",
      "Epoch 83/100\n",
      "735/735 [==============================] - 0s 17us/step - loss: 0.0273\n",
      "Epoch 84/100\n",
      "735/735 [==============================] - 0s 18us/step - loss: 0.0270\n",
      "Epoch 85/100\n",
      "735/735 [==============================] - 0s 19us/step - loss: 0.0268\n",
      "Epoch 86/100\n",
      "735/735 [==============================] - 0s 14us/step - loss: 0.0267\n",
      "Epoch 87/100\n",
      "735/735 [==============================] - 0s 14us/step - loss: 0.0264\n",
      "Epoch 88/100\n",
      "735/735 [==============================] - 0s 18us/step - loss: 0.0263\n",
      "Epoch 89/100\n",
      "735/735 [==============================] - 0s 19us/step - loss: 0.0260\n",
      "Epoch 90/100\n",
      "735/735 [==============================] - 0s 14us/step - loss: 0.0258\n",
      "Epoch 91/100\n",
      "735/735 [==============================] - 0s 19us/step - loss: 0.0257\n",
      "Epoch 92/100\n",
      "735/735 [==============================] - 0s 15us/step - loss: 0.0255\n",
      "Epoch 93/100\n",
      "735/735 [==============================] - 0s 14us/step - loss: 0.0253\n",
      "Epoch 94/100\n",
      "735/735 [==============================] - 0s 15us/step - loss: 0.0251\n",
      "Epoch 95/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0249\n",
      "Epoch 96/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0247\n",
      "Epoch 97/100\n",
      "735/735 [==============================] - 0s 15us/step - loss: 0.0246\n",
      "Epoch 98/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0244\n",
      "Epoch 99/100\n",
      "735/735 [==============================] - 0s 15us/step - loss: 0.0242\n",
      "Epoch 100/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0240\n"
     ]
    }
   ],
   "source": [
    "# %load solutions/NN_1_layer_2_nodes.py\n",
    "H = 2 # number of nodes in the layer\n",
    "input_dim = 1 # input dimension: just x\n",
    "\n",
    "model = models.Sequential() # create sequential multi-layer perceptron\n",
    "\n",
    "# our first hidden layer with two nodes\n",
    "model.add(layers.Dense(H, input_dim=input_dim, activation='tanh') );\n",
    "\n",
    "# add output layer\n",
    "model.add(layers.Dense(1, activation='linear') );\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# fit the model\n",
    "model_history = model.fit(X_train, Y_train, batch_size=100, epochs=100, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  We've trained a model.  Now it's time to explore the results.  Notice the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some constants for our plots\n",
    "FIG_SIZE = (10,5)\n",
    "FONT_SIZE = 10\n",
    "LABEL_SIZE = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use our model to predict in the range we want\n",
    "X_range = np.linspace(-10, 10, 1000)\n",
    "y_pred = model.predict(X_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the results\n",
    "fig, ax = plt.subplots(1, 1, figsize=FIG_SIZE)\n",
    "ax.scatter(X_train, Y_train, label='Training data')\n",
    "ax.plot(X_range, y_pred, lw=4, color='r', label=f'MLP with one hidden layer and {H} nodes')\n",
    "ax.set_xlabel(r'$X$', fontsize=FONT_SIZE)\n",
    "ax.set_ylabel(r'$Y$', fontsize=FONT_SIZE)\n",
    "ax.set_title(f'NN with {len(model_history.model.layers)-1} layers, {H} nodes in each layer', fontsize=LABEL_SIZE)\n",
    "ax.tick_params(labelsize=LABEL_SIZE)\n",
    "\n",
    "ax.legend(loc=0, fontsize=FONT_SIZE)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 2:</b></div>\n",
    "\n",
    "Change the number of neurons in the layer. Try changing the activation function to `reLU`.  Can you get better results?  What worked the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "735/735 [==============================] - 0s 375us/step - loss: 0.1996\n",
      "Epoch 2/100\n",
      "735/735 [==============================] - 0s 17us/step - loss: 0.0960\n",
      "Epoch 3/100\n",
      "735/735 [==============================] - 0s 24us/step - loss: 0.0744\n",
      "Epoch 4/100\n",
      "735/735 [==============================] - 0s 17us/step - loss: 0.0746\n",
      "Epoch 5/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0669\n",
      "Epoch 6/100\n",
      "735/735 [==============================] - 0s 21us/step - loss: 0.0623\n",
      "Epoch 7/100\n",
      "735/735 [==============================] - 0s 23us/step - loss: 0.0595\n",
      "Epoch 8/100\n",
      "735/735 [==============================] - 0s 17us/step - loss: 0.0563\n",
      "Epoch 9/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0540\n",
      "Epoch 10/100\n",
      "735/735 [==============================] - 0s 28us/step - loss: 0.0521\n",
      "Epoch 11/100\n",
      "735/735 [==============================] - 0s 22us/step - loss: 0.0504\n",
      "Epoch 12/100\n",
      "735/735 [==============================] - 0s 23us/step - loss: 0.0494\n",
      "Epoch 13/100\n",
      "735/735 [==============================] - 0s 22us/step - loss: 0.0472\n",
      "Epoch 14/100\n",
      "735/735 [==============================] - 0s 17us/step - loss: 0.0458\n",
      "Epoch 15/100\n",
      "735/735 [==============================] - 0s 22us/step - loss: 0.0447\n",
      "Epoch 16/100\n",
      "735/735 [==============================] - 0s 19us/step - loss: 0.0436\n",
      "Epoch 17/100\n",
      "735/735 [==============================] - 0s 20us/step - loss: 0.0427\n",
      "Epoch 18/100\n",
      "735/735 [==============================] - 0s 23us/step - loss: 0.0418\n",
      "Epoch 19/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0412\n",
      "Epoch 20/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0403\n",
      "Epoch 21/100\n",
      "735/735 [==============================] - 0s 19us/step - loss: 0.0397\n",
      "Epoch 22/100\n",
      "735/735 [==============================] - 0s 18us/step - loss: 0.0392\n",
      "Epoch 23/100\n",
      "735/735 [==============================] - 0s 18us/step - loss: 0.0386\n",
      "Epoch 24/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0381\n",
      "Epoch 25/100\n",
      "735/735 [==============================] - 0s 24us/step - loss: 0.0377\n",
      "Epoch 26/100\n",
      "735/735 [==============================] - 0s 17us/step - loss: 0.0372\n",
      "Epoch 27/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0370\n",
      "Epoch 28/100\n",
      "735/735 [==============================] - 0s 53us/step - loss: 0.0365\n",
      "Epoch 29/100\n",
      "735/735 [==============================] - 0s 15us/step - loss: 0.0360\n",
      "Epoch 30/100\n",
      "735/735 [==============================] - 0s 15us/step - loss: 0.0360\n",
      "Epoch 31/100\n",
      "735/735 [==============================] - 0s 26us/step - loss: 0.0356\n",
      "Epoch 32/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0355\n",
      "Epoch 33/100\n",
      "735/735 [==============================] - 0s 15us/step - loss: 0.0349\n",
      "Epoch 34/100\n",
      "735/735 [==============================] - 0s 19us/step - loss: 0.0346\n",
      "Epoch 35/100\n",
      "735/735 [==============================] - 0s 26us/step - loss: 0.0344\n",
      "Epoch 36/100\n",
      "735/735 [==============================] - 0s 18us/step - loss: 0.0341\n",
      "Epoch 37/100\n",
      "735/735 [==============================] - 0s 19us/step - loss: 0.0337\n",
      "Epoch 38/100\n",
      "735/735 [==============================] - 0s 19us/step - loss: 0.0334\n",
      "Epoch 39/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0332\n",
      "Epoch 40/100\n",
      "735/735 [==============================] - 0s 28us/step - loss: 0.0333\n",
      "Epoch 41/100\n",
      "735/735 [==============================] - 0s 24us/step - loss: 0.0326\n",
      "Epoch 42/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0327\n",
      "Epoch 43/100\n",
      "735/735 [==============================] - 0s 14us/step - loss: 0.0324\n",
      "Epoch 44/100\n",
      "735/735 [==============================] - 0s 23us/step - loss: 0.0321\n",
      "Epoch 45/100\n",
      "735/735 [==============================] - 0s 18us/step - loss: 0.0317\n",
      "Epoch 46/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0313\n",
      "Epoch 47/100\n",
      "735/735 [==============================] - 0s 20us/step - loss: 0.0311\n",
      "Epoch 48/100\n",
      "735/735 [==============================] - 0s 23us/step - loss: 0.0313\n",
      "Epoch 49/100\n",
      "735/735 [==============================] - 0s 17us/step - loss: 0.0308\n",
      "Epoch 50/100\n",
      "735/735 [==============================] - 0s 19us/step - loss: 0.0303\n",
      "Epoch 51/100\n",
      "735/735 [==============================] - 0s 25us/step - loss: 0.0300\n",
      "Epoch 52/100\n",
      "735/735 [==============================] - 0s 17us/step - loss: 0.0295\n",
      "Epoch 53/100\n",
      "735/735 [==============================] - 0s 18us/step - loss: 0.0294\n",
      "Epoch 54/100\n",
      "735/735 [==============================] - 0s 35us/step - loss: 0.0290\n",
      "Epoch 55/100\n",
      "735/735 [==============================] - 0s 30us/step - loss: 0.0287\n",
      "Epoch 56/100\n",
      "735/735 [==============================] - 0s 27us/step - loss: 0.0285\n",
      "Epoch 57/100\n",
      "735/735 [==============================] - 0s 18us/step - loss: 0.0282\n",
      "Epoch 58/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0279\n",
      "Epoch 59/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0275\n",
      "Epoch 60/100\n",
      "735/735 [==============================] - 0s 23us/step - loss: 0.0273\n",
      "Epoch 61/100\n",
      "735/735 [==============================] - 0s 21us/step - loss: 0.0270\n",
      "Epoch 62/100\n",
      "735/735 [==============================] - 0s 17us/step - loss: 0.0267\n",
      "Epoch 63/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0267\n",
      "Epoch 64/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0262\n",
      "Epoch 65/100\n",
      "735/735 [==============================] - 0s 21us/step - loss: 0.0260\n",
      "Epoch 66/100\n",
      "735/735 [==============================] - 0s 17us/step - loss: 0.0256\n",
      "Epoch 67/100\n",
      "735/735 [==============================] - 0s 15us/step - loss: 0.0256\n",
      "Epoch 68/100\n",
      "735/735 [==============================] - 0s 15us/step - loss: 0.0250\n",
      "Epoch 69/100\n",
      "735/735 [==============================] - 0s 20us/step - loss: 0.0249\n",
      "Epoch 70/100\n",
      "735/735 [==============================] - 0s 15us/step - loss: 0.0248\n",
      "Epoch 71/100\n",
      "735/735 [==============================] - 0s 14us/step - loss: 0.0246\n",
      "Epoch 72/100\n",
      "735/735 [==============================] - 0s 15us/step - loss: 0.0242\n",
      "Epoch 73/100\n",
      "735/735 [==============================] - 0s 22us/step - loss: 0.0238\n",
      "Epoch 74/100\n",
      "735/735 [==============================] - 0s 15us/step - loss: 0.0240\n",
      "Epoch 75/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0234\n",
      "Epoch 76/100\n",
      "735/735 [==============================] - 0s 22us/step - loss: 0.0230\n",
      "Epoch 77/100\n",
      "735/735 [==============================] - 0s 19us/step - loss: 0.0228\n",
      "Epoch 78/100\n",
      "735/735 [==============================] - 0s 14us/step - loss: 0.0225\n",
      "Epoch 79/100\n",
      "735/735 [==============================] - 0s 17us/step - loss: 0.0223\n",
      "Epoch 80/100\n",
      "735/735 [==============================] - 0s 17us/step - loss: 0.0220\n",
      "Epoch 81/100\n",
      "735/735 [==============================] - 0s 17us/step - loss: 0.0220\n",
      "Epoch 82/100\n",
      "735/735 [==============================] - 0s 22us/step - loss: 0.0219\n",
      "Epoch 83/100\n",
      "735/735 [==============================] - 0s 23us/step - loss: 0.0214\n",
      "Epoch 84/100\n",
      "735/735 [==============================] - 0s 15us/step - loss: 0.0213\n",
      "Epoch 85/100\n",
      "735/735 [==============================] - 0s 15us/step - loss: 0.0215\n",
      "Epoch 86/100\n",
      "735/735 [==============================] - 0s 20us/step - loss: 0.0217\n",
      "Epoch 87/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0216\n",
      "Epoch 88/100\n",
      "735/735 [==============================] - 0s 17us/step - loss: 0.0210\n",
      "Epoch 89/100\n",
      "735/735 [==============================] - 0s 22us/step - loss: 0.0203\n",
      "Epoch 90/100\n",
      "735/735 [==============================] - 0s 21us/step - loss: 0.0198\n",
      "Epoch 91/100\n",
      "735/735 [==============================] - 0s 18us/step - loss: 0.0199\n",
      "Epoch 92/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0198\n",
      "Epoch 93/100\n",
      "735/735 [==============================] - 0s 20us/step - loss: 0.0194\n",
      "Epoch 94/100\n",
      "735/735 [==============================] - 0s 22us/step - loss: 0.0191\n",
      "Epoch 95/100\n",
      "735/735 [==============================] - 0s 18us/step - loss: 0.0189\n",
      "Epoch 96/100\n",
      "735/735 [==============================] - 0s 18us/step - loss: 0.0189\n",
      "Epoch 97/100\n",
      "735/735 [==============================] - 0s 17us/step - loss: 0.0186\n",
      "Epoch 98/100\n",
      "735/735 [==============================] - 0s 18us/step - loss: 0.0183\n",
      "Epoch 99/100\n",
      "735/735 [==============================] - 0s 22us/step - loss: 0.0182\n",
      "Epoch 100/100\n",
      "735/735 [==============================] - 0s 20us/step - loss: 0.0181\n"
     ]
    }
   ],
   "source": [
    "H = 40 # number of nodes in the layer\n",
    "input_dim = 1 # input dimension: just x\n",
    "\n",
    "model16 = models.Sequential() # create sequential multi-layer perceptron\n",
    "\n",
    "# our first hidden layer with two nodes\n",
    "model16.add(layers.Dense(H, input_dim=input_dim, activation='relu') );\n",
    "\n",
    "# add output layer\n",
    "model16.add(layers.Dense(1, activation='linear') );\n",
    "\n",
    "# compile the model\n",
    "model16.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# fit the model\n",
    "model16_history = model16.fit(X_train, Y_train, batch_size=100, epochs=100, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 367 samples, validate on 368 samples\n",
      "Epoch 1/1200\n",
      "367/367 [==============================] - 0s 937us/step - loss: 0.0615 - val_loss: 0.0863\n",
      "Epoch 2/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0606 - val_loss: 0.0855\n",
      "Epoch 3/1200\n",
      "367/367 [==============================] - 0s 15us/step - loss: 0.0601 - val_loss: 0.0847\n",
      "Epoch 4/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0597 - val_loss: 0.0840\n",
      "Epoch 5/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0592 - val_loss: 0.0832\n",
      "Epoch 6/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0587 - val_loss: 0.0825\n",
      "Epoch 7/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0582 - val_loss: 0.0819\n",
      "Epoch 8/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0577 - val_loss: 0.0812\n",
      "Epoch 9/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0572 - val_loss: 0.0805\n",
      "Epoch 10/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0567 - val_loss: 0.0799\n",
      "Epoch 11/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0562 - val_loss: 0.0792\n",
      "Epoch 12/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0557 - val_loss: 0.0784\n",
      "Epoch 13/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0552 - val_loss: 0.0776\n",
      "Epoch 14/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0546 - val_loss: 0.0768\n",
      "Epoch 15/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0541 - val_loss: 0.0760\n",
      "Epoch 16/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0535 - val_loss: 0.0751\n",
      "Epoch 17/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0530 - val_loss: 0.0743\n",
      "Epoch 18/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0525 - val_loss: 0.0735\n",
      "Epoch 19/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0519 - val_loss: 0.0726\n",
      "Epoch 20/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0513 - val_loss: 0.0718\n",
      "Epoch 21/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0508 - val_loss: 0.0710\n",
      "Epoch 22/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0502 - val_loss: 0.0701\n",
      "Epoch 23/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0496 - val_loss: 0.0693\n",
      "Epoch 24/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0491 - val_loss: 0.0684\n",
      "Epoch 25/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0485 - val_loss: 0.0675\n",
      "Epoch 26/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0480 - val_loss: 0.0666\n",
      "Epoch 27/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0475 - val_loss: 0.0657\n",
      "Epoch 28/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0469 - val_loss: 0.0648\n",
      "Epoch 29/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0464 - val_loss: 0.0640\n",
      "Epoch 30/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0459 - val_loss: 0.0632\n",
      "Epoch 31/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0453 - val_loss: 0.0624\n",
      "Epoch 32/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0448 - val_loss: 0.0616\n",
      "Epoch 33/1200\n",
      "367/367 [==============================] - 0s 27us/step - loss: 0.0443 - val_loss: 0.0608\n",
      "Epoch 34/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0438 - val_loss: 0.0599\n",
      "Epoch 35/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0433 - val_loss: 0.0591\n",
      "Epoch 36/1200\n",
      "367/367 [==============================] - 0s 15us/step - loss: 0.0428 - val_loss: 0.0583\n",
      "Epoch 37/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0425 - val_loss: 0.0575\n",
      "Epoch 38/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0419 - val_loss: 0.0568\n",
      "Epoch 39/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0415 - val_loss: 0.0561\n",
      "Epoch 40/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0411 - val_loss: 0.0555\n",
      "Epoch 41/1200\n",
      "367/367 [==============================] - 0s 15us/step - loss: 0.0407 - val_loss: 0.0548\n",
      "Epoch 42/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0403 - val_loss: 0.0541\n",
      "Epoch 43/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0399 - val_loss: 0.0533\n",
      "Epoch 44/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0395 - val_loss: 0.0526\n",
      "Epoch 45/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0392 - val_loss: 0.0519\n",
      "Epoch 46/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0388 - val_loss: 0.0513\n",
      "Epoch 47/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0385 - val_loss: 0.0507\n",
      "Epoch 48/1200\n",
      "367/367 [==============================] - 0s 15us/step - loss: 0.0382 - val_loss: 0.0502\n",
      "Epoch 49/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0380 - val_loss: 0.0497\n",
      "Epoch 50/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0377 - val_loss: 0.0491\n",
      "Epoch 51/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0374 - val_loss: 0.0487\n",
      "Epoch 52/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0372 - val_loss: 0.0482\n",
      "Epoch 53/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0369 - val_loss: 0.0477\n",
      "Epoch 54/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0367 - val_loss: 0.0474\n",
      "Epoch 55/1200\n",
      "367/367 [==============================] - 0s 15us/step - loss: 0.0365 - val_loss: 0.0470\n",
      "Epoch 56/1200\n",
      "367/367 [==============================] - 0s 14us/step - loss: 0.0363 - val_loss: 0.0465\n",
      "Epoch 57/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0361 - val_loss: 0.0460\n",
      "Epoch 58/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0360 - val_loss: 0.0456\n",
      "Epoch 59/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0358 - val_loss: 0.0453\n",
      "Epoch 60/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0356 - val_loss: 0.0451\n",
      "Epoch 61/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0355 - val_loss: 0.0450\n",
      "Epoch 62/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0354 - val_loss: 0.0448\n",
      "Epoch 63/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0352 - val_loss: 0.0444\n",
      "Epoch 64/1200\n",
      "367/367 [==============================] - 0s 15us/step - loss: 0.0351 - val_loss: 0.0440\n",
      "Epoch 65/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0350 - val_loss: 0.0439\n",
      "Epoch 66/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0349 - val_loss: 0.0438\n",
      "Epoch 67/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0348 - val_loss: 0.0437\n",
      "Epoch 68/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0347 - val_loss: 0.0434\n",
      "Epoch 69/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0347 - val_loss: 0.0430\n",
      "Epoch 70/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0345 - val_loss: 0.0428\n",
      "Epoch 71/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0344 - val_loss: 0.0428\n",
      "Epoch 72/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0343 - val_loss: 0.0427\n",
      "Epoch 73/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0342 - val_loss: 0.0425\n",
      "Epoch 74/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0341 - val_loss: 0.0422\n",
      "Epoch 75/1200\n",
      "367/367 [==============================] - 0s 28us/step - loss: 0.0341 - val_loss: 0.0421\n",
      "Epoch 76/1200\n",
      "367/367 [==============================] - 0s 29us/step - loss: 0.0339 - val_loss: 0.0422\n",
      "Epoch 77/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0339 - val_loss: 0.0422\n",
      "Epoch 78/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0339 - val_loss: 0.0420\n",
      "Epoch 79/1200\n",
      "367/367 [==============================] - 0s 26us/step - loss: 0.0337 - val_loss: 0.0417\n",
      "Epoch 80/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0336 - val_loss: 0.0416\n",
      "Epoch 81/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0337 - val_loss: 0.0416\n",
      "Epoch 82/1200\n",
      "367/367 [==============================] - 0s 26us/step - loss: 0.0336 - val_loss: 0.0414\n",
      "Epoch 83/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0335 - val_loss: 0.0415\n",
      "Epoch 84/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0334 - val_loss: 0.0416\n",
      "Epoch 85/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0334 - val_loss: 0.0415\n",
      "Epoch 86/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0333 - val_loss: 0.0413\n",
      "Epoch 87/1200\n",
      "367/367 [==============================] - 0s 27us/step - loss: 0.0332 - val_loss: 0.0409\n",
      "Epoch 88/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0331 - val_loss: 0.0407\n",
      "Epoch 89/1200\n",
      "367/367 [==============================] - 0s 26us/step - loss: 0.0330 - val_loss: 0.0406\n",
      "Epoch 90/1200\n",
      "367/367 [==============================] - 0s 29us/step - loss: 0.0330 - val_loss: 0.0406\n",
      "Epoch 91/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0329 - val_loss: 0.0405\n",
      "Epoch 92/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0328 - val_loss: 0.0404\n",
      "Epoch 93/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0328 - val_loss: 0.0403\n",
      "Epoch 94/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0327 - val_loss: 0.0402\n",
      "Epoch 95/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0326 - val_loss: 0.0400\n",
      "Epoch 96/1200\n",
      "367/367 [==============================] - 0s 32us/step - loss: 0.0326 - val_loss: 0.0398\n",
      "Epoch 97/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0325 - val_loss: 0.0396\n",
      "Epoch 98/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0325 - val_loss: 0.0395\n",
      "Epoch 99/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0324 - val_loss: 0.0395\n",
      "Epoch 100/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0324 - val_loss: 0.0394\n",
      "Epoch 101/1200\n",
      "367/367 [==============================] - 0s 28us/step - loss: 0.0323 - val_loss: 0.0394\n",
      "Epoch 102/1200\n",
      "367/367 [==============================] - 0s 30us/step - loss: 0.0322 - val_loss: 0.0393\n",
      "Epoch 103/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0322 - val_loss: 0.0390\n",
      "Epoch 104/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0321 - val_loss: 0.0390\n",
      "Epoch 105/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0321 - val_loss: 0.0389\n",
      "Epoch 106/1200\n",
      "367/367 [==============================] - 0s 77us/step - loss: 0.0320 - val_loss: 0.0387\n",
      "Epoch 107/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0319 - val_loss: 0.0386\n",
      "Epoch 108/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0318 - val_loss: 0.0386\n",
      "Epoch 109/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0317 - val_loss: 0.0387\n",
      "Epoch 110/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0316 - val_loss: 0.0385\n",
      "Epoch 111/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0315 - val_loss: 0.0383\n",
      "Epoch 112/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0314 - val_loss: 0.0380\n",
      "Epoch 113/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0312 - val_loss: 0.0379\n",
      "Epoch 114/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0312 - val_loss: 0.0379\n",
      "Epoch 115/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0312 - val_loss: 0.0377\n",
      "Epoch 116/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0309 - val_loss: 0.0375\n",
      "Epoch 117/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0309 - val_loss: 0.0376\n",
      "Epoch 118/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0309 - val_loss: 0.0375\n",
      "Epoch 119/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0307 - val_loss: 0.0372\n",
      "Epoch 120/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0306 - val_loss: 0.0370\n",
      "Epoch 121/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0306 - val_loss: 0.0369\n",
      "Epoch 122/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0305 - val_loss: 0.0368\n",
      "Epoch 123/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0304 - val_loss: 0.0368\n",
      "Epoch 124/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0303 - val_loss: 0.0369\n",
      "Epoch 125/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0303 - val_loss: 0.0368\n",
      "Epoch 126/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0302 - val_loss: 0.0365\n",
      "Epoch 127/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0301 - val_loss: 0.0364\n",
      "Epoch 128/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0300 - val_loss: 0.0366\n",
      "Epoch 129/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0302 - val_loss: 0.0365\n",
      "Epoch 130/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0300 - val_loss: 0.0363\n",
      "Epoch 131/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0301 - val_loss: 0.0362\n",
      "Epoch 132/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0299 - val_loss: 0.0363\n",
      "Epoch 133/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0299 - val_loss: 0.0366\n",
      "Epoch 134/1200\n",
      "367/367 [==============================] - 0s 15us/step - loss: 0.0300 - val_loss: 0.0362\n",
      "Epoch 135/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0298 - val_loss: 0.0361\n",
      "Epoch 136/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0297 - val_loss: 0.0359\n",
      "Epoch 137/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0296 - val_loss: 0.0356\n",
      "Epoch 138/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0296 - val_loss: 0.0355\n",
      "Epoch 139/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0297 - val_loss: 0.0353\n",
      "Epoch 140/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0295 - val_loss: 0.0353\n",
      "Epoch 141/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0295 - val_loss: 0.0355\n",
      "Epoch 142/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0295 - val_loss: 0.0354\n",
      "Epoch 143/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0294 - val_loss: 0.0351\n",
      "Epoch 144/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0293 - val_loss: 0.0348\n",
      "Epoch 145/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0294 - val_loss: 0.0346\n",
      "Epoch 146/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0293 - val_loss: 0.0346\n",
      "Epoch 147/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0291 - val_loss: 0.0348\n",
      "Epoch 148/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0292 - val_loss: 0.0350\n",
      "Epoch 149/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0292 - val_loss: 0.0348\n",
      "Epoch 150/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0290 - val_loss: 0.0347\n",
      "Epoch 151/1200\n",
      "367/367 [==============================] - 0s 26us/step - loss: 0.0291 - val_loss: 0.0345\n",
      "Epoch 152/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0290 - val_loss: 0.0344\n",
      "Epoch 153/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0290 - val_loss: 0.0346\n",
      "Epoch 154/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0290 - val_loss: 0.0347\n",
      "Epoch 155/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0289 - val_loss: 0.0345\n",
      "Epoch 156/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0288 - val_loss: 0.0345\n",
      "Epoch 157/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 0s 15us/step - loss: 0.0289 - val_loss: 0.0343\n",
      "Epoch 158/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0287 - val_loss: 0.0342\n",
      "Epoch 159/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0287 - val_loss: 0.0342\n",
      "Epoch 160/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0287 - val_loss: 0.0340\n",
      "Epoch 161/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0286 - val_loss: 0.0340\n",
      "Epoch 162/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0287 - val_loss: 0.0340\n",
      "Epoch 163/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0286 - val_loss: 0.0339\n",
      "Epoch 164/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0285 - val_loss: 0.0339\n",
      "Epoch 165/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0284 - val_loss: 0.0339\n",
      "Epoch 166/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0284 - val_loss: 0.0338\n",
      "Epoch 167/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0284 - val_loss: 0.0336\n",
      "Epoch 168/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0284 - val_loss: 0.0334\n",
      "Epoch 169/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0283 - val_loss: 0.0335\n",
      "Epoch 170/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0282 - val_loss: 0.0337\n",
      "Epoch 171/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0283 - val_loss: 0.0338\n",
      "Epoch 172/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0283 - val_loss: 0.0335\n",
      "Epoch 173/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0282 - val_loss: 0.0332\n",
      "Epoch 174/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0282 - val_loss: 0.0331\n",
      "Epoch 175/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0281 - val_loss: 0.0332\n",
      "Epoch 176/1200\n",
      "367/367 [==============================] - 0s 15us/step - loss: 0.0280 - val_loss: 0.0333\n",
      "Epoch 177/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0280 - val_loss: 0.0333\n",
      "Epoch 178/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0280 - val_loss: 0.0332\n",
      "Epoch 179/1200\n",
      "367/367 [==============================] - 0s 26us/step - loss: 0.0279 - val_loss: 0.0329\n",
      "Epoch 180/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0280 - val_loss: 0.0328\n",
      "Epoch 181/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0278 - val_loss: 0.0328\n",
      "Epoch 182/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0278 - val_loss: 0.0328\n",
      "Epoch 183/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0278 - val_loss: 0.0328\n",
      "Epoch 184/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0277 - val_loss: 0.0327\n",
      "Epoch 185/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0278 - val_loss: 0.0325\n",
      "Epoch 186/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0277 - val_loss: 0.0325\n",
      "Epoch 187/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0276 - val_loss: 0.0326\n",
      "Epoch 188/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0276 - val_loss: 0.0326\n",
      "Epoch 189/1200\n",
      "367/367 [==============================] - 0s 15us/step - loss: 0.0276 - val_loss: 0.0326\n",
      "Epoch 190/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0278 - val_loss: 0.0324\n",
      "Epoch 191/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0274 - val_loss: 0.0326\n",
      "Epoch 192/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0277 - val_loss: 0.0325\n",
      "Epoch 193/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0277 - val_loss: 0.0322\n",
      "Epoch 194/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0274 - val_loss: 0.0323\n",
      "Epoch 195/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0274 - val_loss: 0.0324\n",
      "Epoch 196/1200\n",
      "367/367 [==============================] - 0s 14us/step - loss: 0.0274 - val_loss: 0.0324\n",
      "Epoch 197/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0274 - val_loss: 0.0322\n",
      "Epoch 198/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0273 - val_loss: 0.0318\n",
      "Epoch 199/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0273 - val_loss: 0.0318\n",
      "Epoch 200/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0272 - val_loss: 0.0318\n",
      "Epoch 201/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0272 - val_loss: 0.0318\n",
      "Epoch 202/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0271 - val_loss: 0.0318\n",
      "Epoch 203/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0271 - val_loss: 0.0319\n",
      "Epoch 204/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0271 - val_loss: 0.0317\n",
      "Epoch 205/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0270 - val_loss: 0.0315\n",
      "Epoch 206/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0270 - val_loss: 0.0314\n",
      "Epoch 207/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0270 - val_loss: 0.0315\n",
      "Epoch 208/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0268 - val_loss: 0.0316\n",
      "Epoch 209/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0270 - val_loss: 0.0317\n",
      "Epoch 210/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0269 - val_loss: 0.0314\n",
      "Epoch 211/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0268 - val_loss: 0.0312\n",
      "Epoch 212/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0268 - val_loss: 0.0312\n",
      "Epoch 213/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0271 - val_loss: 0.0313\n",
      "Epoch 214/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0268 - val_loss: 0.0317\n",
      "Epoch 215/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0268 - val_loss: 0.0317\n",
      "Epoch 216/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0268 - val_loss: 0.0312\n",
      "Epoch 217/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0266 - val_loss: 0.0310\n",
      "Epoch 218/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0267 - val_loss: 0.0309\n",
      "Epoch 219/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0266 - val_loss: 0.0309\n",
      "Epoch 220/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0266 - val_loss: 0.0310\n",
      "Epoch 221/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0265 - val_loss: 0.0310\n",
      "Epoch 222/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0265 - val_loss: 0.0311\n",
      "Epoch 223/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0266 - val_loss: 0.0308\n",
      "Epoch 224/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0264 - val_loss: 0.0308\n",
      "Epoch 225/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0263 - val_loss: 0.0309\n",
      "Epoch 226/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0263 - val_loss: 0.0307\n",
      "Epoch 227/1200\n",
      "367/367 [==============================] - 0s 14us/step - loss: 0.0262 - val_loss: 0.0307\n",
      "Epoch 228/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0263 - val_loss: 0.0306\n",
      "Epoch 229/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0262 - val_loss: 0.0304\n",
      "Epoch 230/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0262 - val_loss: 0.0305\n",
      "Epoch 231/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0261 - val_loss: 0.0307\n",
      "Epoch 232/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0261 - val_loss: 0.0307\n",
      "Epoch 233/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0261 - val_loss: 0.0305\n",
      "Epoch 234/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0260 - val_loss: 0.0303\n",
      "Epoch 235/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0260 - val_loss: 0.0303\n",
      "Epoch 236/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0259 - val_loss: 0.0303\n",
      "Epoch 237/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0259 - val_loss: 0.0302\n",
      "Epoch 238/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0258 - val_loss: 0.0303\n",
      "Epoch 239/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0259 - val_loss: 0.0303\n",
      "Epoch 240/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0259 - val_loss: 0.0302\n",
      "Epoch 241/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0258 - val_loss: 0.0301\n",
      "Epoch 242/1200\n",
      "367/367 [==============================] - 0s 27us/step - loss: 0.0258 - val_loss: 0.0301\n",
      "Epoch 243/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0257 - val_loss: 0.0303\n",
      "Epoch 244/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0257 - val_loss: 0.0302\n",
      "Epoch 245/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0256 - val_loss: 0.0299\n",
      "Epoch 246/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0256 - val_loss: 0.0299\n",
      "Epoch 247/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0256 - val_loss: 0.0299\n",
      "Epoch 248/1200\n",
      "367/367 [==============================] - 0s 27us/step - loss: 0.0256 - val_loss: 0.0301\n",
      "Epoch 249/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0256 - val_loss: 0.0302\n",
      "Epoch 250/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0255 - val_loss: 0.0299\n",
      "Epoch 251/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0255 - val_loss: 0.0297\n",
      "Epoch 252/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0254 - val_loss: 0.0297\n",
      "Epoch 253/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0254 - val_loss: 0.0298\n",
      "Epoch 254/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0253 - val_loss: 0.0296\n",
      "Epoch 255/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0253 - val_loss: 0.0294\n",
      "Epoch 256/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0253 - val_loss: 0.0293\n",
      "Epoch 257/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0253 - val_loss: 0.0292\n",
      "Epoch 258/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0253 - val_loss: 0.0291\n",
      "Epoch 259/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0252 - val_loss: 0.0291\n",
      "Epoch 260/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0252 - val_loss: 0.0292\n",
      "Epoch 261/1200\n",
      "367/367 [==============================] - 0s 27us/step - loss: 0.0252 - val_loss: 0.0292\n",
      "Epoch 262/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0251 - val_loss: 0.0293\n",
      "Epoch 263/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0251 - val_loss: 0.0293\n",
      "Epoch 264/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0250 - val_loss: 0.0291\n",
      "Epoch 265/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0250 - val_loss: 0.0291\n",
      "Epoch 266/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0250 - val_loss: 0.0291\n",
      "Epoch 267/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0250 - val_loss: 0.0292\n",
      "Epoch 268/1200\n",
      "367/367 [==============================] - 0s 14us/step - loss: 0.0249 - val_loss: 0.0290\n",
      "Epoch 269/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0249 - val_loss: 0.0289\n",
      "Epoch 270/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0249 - val_loss: 0.0289\n",
      "Epoch 271/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0249 - val_loss: 0.0291\n",
      "Epoch 272/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0249 - val_loss: 0.0291\n",
      "Epoch 273/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0248 - val_loss: 0.0288\n",
      "Epoch 274/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0248 - val_loss: 0.0288\n",
      "Epoch 275/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0248 - val_loss: 0.0289\n",
      "Epoch 276/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0247 - val_loss: 0.0288\n",
      "Epoch 277/1200\n",
      "367/367 [==============================] - 0s 15us/step - loss: 0.0247 - val_loss: 0.0286\n",
      "Epoch 278/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0246 - val_loss: 0.0286\n",
      "Epoch 279/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0246 - val_loss: 0.0289\n",
      "Epoch 280/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0246 - val_loss: 0.0288\n",
      "Epoch 281/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0246 - val_loss: 0.0287\n",
      "Epoch 282/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0244 - val_loss: 0.0285\n",
      "Epoch 283/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0247 - val_loss: 0.0285\n",
      "Epoch 284/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0245 - val_loss: 0.0286\n",
      "Epoch 285/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0244 - val_loss: 0.0289\n",
      "Epoch 286/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0246 - val_loss: 0.0286\n",
      "Epoch 287/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0244 - val_loss: 0.0284\n",
      "Epoch 288/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0244 - val_loss: 0.0282\n",
      "Epoch 289/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0243 - val_loss: 0.0283\n",
      "Epoch 290/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0244 - val_loss: 0.0285\n",
      "Epoch 291/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0243 - val_loss: 0.0283\n",
      "Epoch 292/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0242 - val_loss: 0.0283\n",
      "Epoch 293/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0243 - val_loss: 0.0280\n",
      "Epoch 294/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0241 - val_loss: 0.0279\n",
      "Epoch 295/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0242 - val_loss: 0.0280\n",
      "Epoch 296/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0243 - val_loss: 0.0279\n",
      "Epoch 297/1200\n",
      "367/367 [==============================] - 0s 29us/step - loss: 0.0240 - val_loss: 0.0279\n",
      "Epoch 298/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0240 - val_loss: 0.0278\n",
      "Epoch 299/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0240 - val_loss: 0.0278\n",
      "Epoch 300/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0239 - val_loss: 0.0278\n",
      "Epoch 301/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0239 - val_loss: 0.0277\n",
      "Epoch 302/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0239 - val_loss: 0.0277\n",
      "Epoch 303/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0238 - val_loss: 0.0275\n",
      "Epoch 304/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0238 - val_loss: 0.0276\n",
      "Epoch 305/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0237 - val_loss: 0.0277\n",
      "Epoch 306/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0237 - val_loss: 0.0276\n",
      "Epoch 307/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0237 - val_loss: 0.0275\n",
      "Epoch 308/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0237 - val_loss: 0.0275\n",
      "Epoch 309/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0236 - val_loss: 0.0275\n",
      "Epoch 310/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0236 - val_loss: 0.0274\n",
      "Epoch 311/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0236 - val_loss: 0.0273\n",
      "Epoch 312/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0236 - val_loss: 0.0273\n",
      "Epoch 313/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 0s 21us/step - loss: 0.0235 - val_loss: 0.0272\n",
      "Epoch 314/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0235 - val_loss: 0.0272\n",
      "Epoch 315/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0234 - val_loss: 0.0272\n",
      "Epoch 316/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0235 - val_loss: 0.0272\n",
      "Epoch 317/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0235 - val_loss: 0.0270\n",
      "Epoch 318/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0234 - val_loss: 0.0269\n",
      "Epoch 319/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0234 - val_loss: 0.0268\n",
      "Epoch 320/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0234 - val_loss: 0.0268\n",
      "Epoch 321/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0233 - val_loss: 0.0271\n",
      "Epoch 322/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0233 - val_loss: 0.0270\n",
      "Epoch 323/1200\n",
      "367/367 [==============================] - 0s 34us/step - loss: 0.0232 - val_loss: 0.0269\n",
      "Epoch 324/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0232 - val_loss: 0.0268\n",
      "Epoch 325/1200\n",
      "367/367 [==============================] - 0s 37us/step - loss: 0.0231 - val_loss: 0.0270\n",
      "Epoch 326/1200\n",
      "367/367 [==============================] - 0s 27us/step - loss: 0.0232 - val_loss: 0.0270\n",
      "Epoch 327/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0231 - val_loss: 0.0269\n",
      "Epoch 328/1200\n",
      "367/367 [==============================] - 0s 30us/step - loss: 0.0231 - val_loss: 0.0267\n",
      "Epoch 329/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0231 - val_loss: 0.0267\n",
      "Epoch 330/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0230 - val_loss: 0.0269\n",
      "Epoch 331/1200\n",
      "367/367 [==============================] - 0s 32us/step - loss: 0.0231 - val_loss: 0.0268\n",
      "Epoch 332/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0229 - val_loss: 0.0267\n",
      "Epoch 333/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0231 - val_loss: 0.0267\n",
      "Epoch 334/1200\n",
      "367/367 [==============================] - 0s 31us/step - loss: 0.0230 - val_loss: 0.0263\n",
      "Epoch 335/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0229 - val_loss: 0.0264\n",
      "Epoch 336/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0230 - val_loss: 0.0264\n",
      "Epoch 337/1200\n",
      "367/367 [==============================] - 0s 29us/step - loss: 0.0229 - val_loss: 0.0265\n",
      "Epoch 338/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0229 - val_loss: 0.0262\n",
      "Epoch 339/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0228 - val_loss: 0.0260\n",
      "Epoch 340/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0228 - val_loss: 0.0262\n",
      "Epoch 341/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0227 - val_loss: 0.0266\n",
      "Epoch 342/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0228 - val_loss: 0.0265\n",
      "Epoch 343/1200\n",
      "367/367 [==============================] - 0s 27us/step - loss: 0.0228 - val_loss: 0.0259\n",
      "Epoch 344/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0229 - val_loss: 0.0259\n",
      "Epoch 345/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0227 - val_loss: 0.0262\n",
      "Epoch 346/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0226 - val_loss: 0.0264\n",
      "Epoch 347/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0226 - val_loss: 0.0259\n",
      "Epoch 348/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0225 - val_loss: 0.0257\n",
      "Epoch 349/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0225 - val_loss: 0.0257\n",
      "Epoch 350/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0224 - val_loss: 0.0259\n",
      "Epoch 351/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0224 - val_loss: 0.0260\n",
      "Epoch 352/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0224 - val_loss: 0.0258\n",
      "Epoch 353/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0223 - val_loss: 0.0257\n",
      "Epoch 354/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0223 - val_loss: 0.0257\n",
      "Epoch 355/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0223 - val_loss: 0.0259\n",
      "Epoch 356/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0223 - val_loss: 0.0258\n",
      "Epoch 357/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0223 - val_loss: 0.0256\n",
      "Epoch 358/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0223 - val_loss: 0.0255\n",
      "Epoch 359/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0222 - val_loss: 0.0255\n",
      "Epoch 360/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0221 - val_loss: 0.0256\n",
      "Epoch 361/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0221 - val_loss: 0.0257\n",
      "Epoch 362/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0221 - val_loss: 0.0256\n",
      "Epoch 363/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0221 - val_loss: 0.0254\n",
      "Epoch 364/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0220 - val_loss: 0.0253\n",
      "Epoch 365/1200\n",
      "367/367 [==============================] - 0s 14us/step - loss: 0.0220 - val_loss: 0.0254\n",
      "Epoch 366/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0219 - val_loss: 0.0257\n",
      "Epoch 367/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0220 - val_loss: 0.0258\n",
      "Epoch 368/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0220 - val_loss: 0.0255\n",
      "Epoch 369/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0219 - val_loss: 0.0252\n",
      "Epoch 370/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0219 - val_loss: 0.0251\n",
      "Epoch 371/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0220 - val_loss: 0.0252\n",
      "Epoch 372/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0219 - val_loss: 0.0256\n",
      "Epoch 373/1200\n",
      "367/367 [==============================] - 0s 15us/step - loss: 0.0218 - val_loss: 0.0254\n",
      "Epoch 374/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0217 - val_loss: 0.0250\n",
      "Epoch 375/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0218 - val_loss: 0.0250\n",
      "Epoch 376/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0218 - val_loss: 0.0250\n",
      "Epoch 377/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0216 - val_loss: 0.0254\n",
      "Epoch 378/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0217 - val_loss: 0.0256\n",
      "Epoch 379/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0217 - val_loss: 0.0250\n",
      "Epoch 380/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0216 - val_loss: 0.0248\n",
      "Epoch 381/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0216 - val_loss: 0.0248\n",
      "Epoch 382/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0216 - val_loss: 0.0249\n",
      "Epoch 383/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0215 - val_loss: 0.0250\n",
      "Epoch 384/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0215 - val_loss: 0.0250\n",
      "Epoch 385/1200\n",
      "367/367 [==============================] - 0s 15us/step - loss: 0.0214 - val_loss: 0.0247\n",
      "Epoch 386/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0214 - val_loss: 0.0245\n",
      "Epoch 387/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0214 - val_loss: 0.0245\n",
      "Epoch 388/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0214 - val_loss: 0.0245\n",
      "Epoch 389/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0214 - val_loss: 0.0246\n",
      "Epoch 390/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0214 - val_loss: 0.0245\n",
      "Epoch 391/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0213 - val_loss: 0.0245\n",
      "Epoch 392/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0212 - val_loss: 0.0244\n",
      "Epoch 393/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0213 - val_loss: 0.0243\n",
      "Epoch 394/1200\n",
      "367/367 [==============================] - 0s 29us/step - loss: 0.0212 - val_loss: 0.0244\n",
      "Epoch 395/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0212 - val_loss: 0.0246\n",
      "Epoch 396/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0213 - val_loss: 0.0245\n",
      "Epoch 397/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0211 - val_loss: 0.0242\n",
      "Epoch 398/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0212 - val_loss: 0.0241\n",
      "Epoch 399/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0212 - val_loss: 0.0241\n",
      "Epoch 400/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0210 - val_loss: 0.0243\n",
      "Epoch 401/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0210 - val_loss: 0.0243\n",
      "Epoch 402/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0210 - val_loss: 0.0241\n",
      "Epoch 403/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0210 - val_loss: 0.0240\n",
      "Epoch 404/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0210 - val_loss: 0.0239\n",
      "Epoch 405/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0209 - val_loss: 0.0241\n",
      "Epoch 406/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0208 - val_loss: 0.0243\n",
      "Epoch 407/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0210 - val_loss: 0.0242\n",
      "Epoch 408/1200\n",
      "367/367 [==============================] - 0s 26us/step - loss: 0.0208 - val_loss: 0.0239\n",
      "Epoch 409/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0208 - val_loss: 0.0239\n",
      "Epoch 410/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0209 - val_loss: 0.0238\n",
      "Epoch 411/1200\n",
      "367/367 [==============================] - 0s 26us/step - loss: 0.0207 - val_loss: 0.0243\n",
      "Epoch 412/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0208 - val_loss: 0.0246\n",
      "Epoch 413/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0209 - val_loss: 0.0241\n",
      "Epoch 414/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0206 - val_loss: 0.0238\n",
      "Epoch 415/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0208 - val_loss: 0.0237\n",
      "Epoch 416/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0208 - val_loss: 0.0236\n",
      "Epoch 417/1200\n",
      "367/367 [==============================] - 0s 31us/step - loss: 0.0206 - val_loss: 0.0241\n",
      "Epoch 418/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0207 - val_loss: 0.0243\n",
      "Epoch 419/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0207 - val_loss: 0.0235\n",
      "Epoch 420/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0206 - val_loss: 0.0233\n",
      "Epoch 421/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0207 - val_loss: 0.0232\n",
      "Epoch 422/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0205 - val_loss: 0.0234\n",
      "Epoch 423/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0205 - val_loss: 0.0236\n",
      "Epoch 424/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0205 - val_loss: 0.0233\n",
      "Epoch 425/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0204 - val_loss: 0.0231\n",
      "Epoch 426/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0204 - val_loss: 0.0231\n",
      "Epoch 427/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0204 - val_loss: 0.0233\n",
      "Epoch 428/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0204 - val_loss: 0.0232\n",
      "Epoch 429/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0202 - val_loss: 0.0231\n",
      "Epoch 430/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0203 - val_loss: 0.0230\n",
      "Epoch 431/1200\n",
      "367/367 [==============================] - 0s 37us/step - loss: 0.0202 - val_loss: 0.0233\n",
      "Epoch 432/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0202 - val_loss: 0.0233\n",
      "Epoch 433/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0202 - val_loss: 0.0230\n",
      "Epoch 434/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0201 - val_loss: 0.0231\n",
      "Epoch 435/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0201 - val_loss: 0.0233\n",
      "Epoch 436/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0201 - val_loss: 0.0232\n",
      "Epoch 437/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0201 - val_loss: 0.0230\n",
      "Epoch 438/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0200 - val_loss: 0.0228\n",
      "Epoch 439/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0200 - val_loss: 0.0228\n",
      "Epoch 440/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0200 - val_loss: 0.0229\n",
      "Epoch 441/1200\n",
      "367/367 [==============================] - 0s 29us/step - loss: 0.0199 - val_loss: 0.0231\n",
      "Epoch 442/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0200 - val_loss: 0.0232\n",
      "Epoch 443/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0199 - val_loss: 0.0227\n",
      "Epoch 444/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0199 - val_loss: 0.0226\n",
      "Epoch 445/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0200 - val_loss: 0.0226\n",
      "Epoch 446/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0200 - val_loss: 0.0230\n",
      "Epoch 447/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0199 - val_loss: 0.0229\n",
      "Epoch 448/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0200 - val_loss: 0.0232\n",
      "Epoch 449/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0202 - val_loss: 0.0225\n",
      "Epoch 450/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0198 - val_loss: 0.0227\n",
      "Epoch 451/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0200 - val_loss: 0.0227\n",
      "Epoch 452/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0197 - val_loss: 0.0230\n",
      "Epoch 453/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0198 - val_loss: 0.0230\n",
      "Epoch 454/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0198 - val_loss: 0.0225\n",
      "Epoch 455/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0197 - val_loss: 0.0225\n",
      "Epoch 456/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0197 - val_loss: 0.0223\n",
      "Epoch 457/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0196 - val_loss: 0.0224\n",
      "Epoch 458/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0195 - val_loss: 0.0227\n",
      "Epoch 459/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0196 - val_loss: 0.0226\n",
      "Epoch 460/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0195 - val_loss: 0.0222\n",
      "Epoch 461/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0195 - val_loss: 0.0221\n",
      "Epoch 462/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0195 - val_loss: 0.0221\n",
      "Epoch 463/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0194 - val_loss: 0.0224\n",
      "Epoch 464/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0196 - val_loss: 0.0224\n",
      "Epoch 465/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0195 - val_loss: 0.0220\n",
      "Epoch 466/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0194 - val_loss: 0.0220\n",
      "Epoch 467/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0194 - val_loss: 0.0221\n",
      "Epoch 468/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0193 - val_loss: 0.0222\n",
      "Epoch 469/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 0s 20us/step - loss: 0.0193 - val_loss: 0.0222\n",
      "Epoch 470/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0193 - val_loss: 0.0221\n",
      "Epoch 471/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0193 - val_loss: 0.0219\n",
      "Epoch 472/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0193 - val_loss: 0.0218\n",
      "Epoch 473/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0192 - val_loss: 0.0221\n",
      "Epoch 474/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0192 - val_loss: 0.0223\n",
      "Epoch 475/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0192 - val_loss: 0.0221\n",
      "Epoch 476/1200\n",
      "367/367 [==============================] - 0s 40us/step - loss: 0.0191 - val_loss: 0.0220\n",
      "Epoch 477/1200\n",
      "367/367 [==============================] - 0s 34us/step - loss: 0.0191 - val_loss: 0.0219\n",
      "Epoch 478/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0191 - val_loss: 0.0219\n",
      "Epoch 479/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0191 - val_loss: 0.0220\n",
      "Epoch 480/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0190 - val_loss: 0.0222\n",
      "Epoch 481/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0191 - val_loss: 0.0222\n",
      "Epoch 482/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0190 - val_loss: 0.0219\n",
      "Epoch 483/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0190 - val_loss: 0.0218\n",
      "Epoch 484/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0189 - val_loss: 0.0219\n",
      "Epoch 485/1200\n",
      "367/367 [==============================] - 0s 26us/step - loss: 0.0189 - val_loss: 0.0219\n",
      "Epoch 486/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0189 - val_loss: 0.0216\n",
      "Epoch 487/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0189 - val_loss: 0.0214\n",
      "Epoch 488/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0189 - val_loss: 0.0215\n",
      "Epoch 489/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0189 - val_loss: 0.0216\n",
      "Epoch 490/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0188 - val_loss: 0.0215\n",
      "Epoch 491/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0188 - val_loss: 0.0214\n",
      "Epoch 492/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0188 - val_loss: 0.0212\n",
      "Epoch 493/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0188 - val_loss: 0.0213\n",
      "Epoch 494/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0188 - val_loss: 0.0212\n",
      "Epoch 495/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0187 - val_loss: 0.0212\n",
      "Epoch 496/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0187 - val_loss: 0.0212\n",
      "Epoch 497/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0186 - val_loss: 0.0213\n",
      "Epoch 498/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0186 - val_loss: 0.0213\n",
      "Epoch 499/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0186 - val_loss: 0.0213\n",
      "Epoch 500/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0185 - val_loss: 0.0213\n",
      "Epoch 501/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0185 - val_loss: 0.0213\n",
      "Epoch 502/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0186 - val_loss: 0.0213\n",
      "Epoch 503/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0185 - val_loss: 0.0213\n",
      "Epoch 504/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0185 - val_loss: 0.0213\n",
      "Epoch 505/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0185 - val_loss: 0.0213\n",
      "Epoch 506/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0184 - val_loss: 0.0212\n",
      "Epoch 507/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0184 - val_loss: 0.0210\n",
      "Epoch 508/1200\n",
      "367/367 [==============================] - 0s 26us/step - loss: 0.0183 - val_loss: 0.0211\n",
      "Epoch 509/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0186 - val_loss: 0.0209\n",
      "Epoch 510/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0187 - val_loss: 0.0209\n",
      "Epoch 511/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0184 - val_loss: 0.0212\n",
      "Epoch 512/1200\n",
      "367/367 [==============================] - 0s 27us/step - loss: 0.0184 - val_loss: 0.0213\n",
      "Epoch 513/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0184 - val_loss: 0.0207\n",
      "Epoch 514/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0183 - val_loss: 0.0206\n",
      "Epoch 515/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0183 - val_loss: 0.0207\n",
      "Epoch 516/1200\n",
      "367/367 [==============================] - 0s 29us/step - loss: 0.0183 - val_loss: 0.0209\n",
      "Epoch 517/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0183 - val_loss: 0.0207\n",
      "Epoch 518/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0181 - val_loss: 0.0205\n",
      "Epoch 519/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0182 - val_loss: 0.0205\n",
      "Epoch 520/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0181 - val_loss: 0.0207\n",
      "Epoch 521/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0181 - val_loss: 0.0208\n",
      "Epoch 522/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0181 - val_loss: 0.0205\n",
      "Epoch 523/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0180 - val_loss: 0.0204\n",
      "Epoch 524/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0180 - val_loss: 0.0204\n",
      "Epoch 525/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0180 - val_loss: 0.0205\n",
      "Epoch 526/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0180 - val_loss: 0.0205\n",
      "Epoch 527/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0180 - val_loss: 0.0205\n",
      "Epoch 528/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0179 - val_loss: 0.0204\n",
      "Epoch 529/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0179 - val_loss: 0.0202\n",
      "Epoch 530/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0180 - val_loss: 0.0202\n",
      "Epoch 531/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0180 - val_loss: 0.0204\n",
      "Epoch 532/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0179 - val_loss: 0.0205\n",
      "Epoch 533/1200\n",
      "367/367 [==============================] - 0s 15us/step - loss: 0.0179 - val_loss: 0.0203\n",
      "Epoch 534/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0178 - val_loss: 0.0201\n",
      "Epoch 535/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0178 - val_loss: 0.0201\n",
      "Epoch 536/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0178 - val_loss: 0.0202\n",
      "Epoch 537/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0177 - val_loss: 0.0204\n",
      "Epoch 538/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0178 - val_loss: 0.0205\n",
      "Epoch 539/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0178 - val_loss: 0.0201\n",
      "Epoch 540/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0177 - val_loss: 0.0200\n",
      "Epoch 541/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0177 - val_loss: 0.0200\n",
      "Epoch 542/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0176 - val_loss: 0.0204\n",
      "Epoch 543/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0177 - val_loss: 0.0203\n",
      "Epoch 544/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0176 - val_loss: 0.0199\n",
      "Epoch 545/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0176 - val_loss: 0.0199\n",
      "Epoch 546/1200\n",
      "367/367 [==============================] - 0s 29us/step - loss: 0.0176 - val_loss: 0.0200\n",
      "Epoch 547/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0175 - val_loss: 0.0202\n",
      "Epoch 548/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0176 - val_loss: 0.0202\n",
      "Epoch 549/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0175 - val_loss: 0.0199\n",
      "Epoch 550/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0175 - val_loss: 0.0198\n",
      "Epoch 551/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0175 - val_loss: 0.0199\n",
      "Epoch 552/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0175 - val_loss: 0.0200\n",
      "Epoch 553/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0174 - val_loss: 0.0199\n",
      "Epoch 554/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0174 - val_loss: 0.0199\n",
      "Epoch 555/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0175 - val_loss: 0.0197\n",
      "Epoch 556/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0173 - val_loss: 0.0196\n",
      "Epoch 557/1200\n",
      "367/367 [==============================] - 0s 31us/step - loss: 0.0174 - val_loss: 0.0196\n",
      "Epoch 558/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0174 - val_loss: 0.0197\n",
      "Epoch 559/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0173 - val_loss: 0.0198\n",
      "Epoch 560/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0173 - val_loss: 0.0197\n",
      "Epoch 561/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0174 - val_loss: 0.0195\n",
      "Epoch 562/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0172 - val_loss: 0.0197\n",
      "Epoch 563/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0172 - val_loss: 0.0199\n",
      "Epoch 564/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0173 - val_loss: 0.0197\n",
      "Epoch 565/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0172 - val_loss: 0.0195\n",
      "Epoch 566/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0172 - val_loss: 0.0194\n",
      "Epoch 567/1200\n",
      "367/367 [==============================] - 0s 28us/step - loss: 0.0172 - val_loss: 0.0194\n",
      "Epoch 568/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0171 - val_loss: 0.0196\n",
      "Epoch 569/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0172 - val_loss: 0.0195\n",
      "Epoch 570/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0171 - val_loss: 0.0195\n",
      "Epoch 571/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0172 - val_loss: 0.0192\n",
      "Epoch 572/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0171 - val_loss: 0.0191\n",
      "Epoch 573/1200\n",
      "367/367 [==============================] - 0s 28us/step - loss: 0.0172 - val_loss: 0.0194\n",
      "Epoch 574/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0171 - val_loss: 0.0194\n",
      "Epoch 575/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0171 - val_loss: 0.0194\n",
      "Epoch 576/1200\n",
      "367/367 [==============================] - 0s 26us/step - loss: 0.0171 - val_loss: 0.0189\n",
      "Epoch 577/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0170 - val_loss: 0.0193\n",
      "Epoch 578/1200\n",
      "367/367 [==============================] - 0s 26us/step - loss: 0.0175 - val_loss: 0.0190\n",
      "Epoch 579/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0170 - val_loss: 0.0199\n",
      "Epoch 580/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0174 - val_loss: 0.0193\n",
      "Epoch 581/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0170 - val_loss: 0.0190\n",
      "Epoch 582/1200\n",
      "367/367 [==============================] - 0s 26us/step - loss: 0.0170 - val_loss: 0.0189\n",
      "Epoch 583/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0170 - val_loss: 0.0190\n",
      "Epoch 584/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0168 - val_loss: 0.0191\n",
      "Epoch 585/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0169 - val_loss: 0.0189\n",
      "Epoch 586/1200\n",
      "367/367 [==============================] - 0s 30us/step - loss: 0.0167 - val_loss: 0.0189\n",
      "Epoch 587/1200\n",
      "367/367 [==============================] - 0s 14us/step - loss: 0.0168 - val_loss: 0.0189\n",
      "Epoch 588/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0168 - val_loss: 0.0188\n",
      "Epoch 589/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0168 - val_loss: 0.0188\n",
      "Epoch 590/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0168 - val_loss: 0.0187\n",
      "Epoch 591/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0167 - val_loss: 0.0187\n",
      "Epoch 592/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0168 - val_loss: 0.0187\n",
      "Epoch 593/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0168 - val_loss: 0.0189\n",
      "Epoch 594/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0166 - val_loss: 0.0187\n",
      "Epoch 595/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0166 - val_loss: 0.0187\n",
      "Epoch 596/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0167 - val_loss: 0.0187\n",
      "Epoch 597/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0166 - val_loss: 0.0190\n",
      "Epoch 598/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0167 - val_loss: 0.0188\n",
      "Epoch 599/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0165 - val_loss: 0.0185\n",
      "Epoch 600/1200\n",
      "367/367 [==============================] - 0s 26us/step - loss: 0.0165 - val_loss: 0.0185\n",
      "Epoch 601/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0166 - val_loss: 0.0184\n",
      "Epoch 602/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0166 - val_loss: 0.0185\n",
      "Epoch 603/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0165 - val_loss: 0.0186\n",
      "Epoch 604/1200\n",
      "367/367 [==============================] - 0s 14us/step - loss: 0.0164 - val_loss: 0.0185\n",
      "Epoch 605/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0164 - val_loss: 0.0185\n",
      "Epoch 606/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0164 - val_loss: 0.0184\n",
      "Epoch 607/1200\n",
      "367/367 [==============================] - 0s 15us/step - loss: 0.0164 - val_loss: 0.0183\n",
      "Epoch 608/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0164 - val_loss: 0.0184\n",
      "Epoch 609/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0164 - val_loss: 0.0185\n",
      "Epoch 610/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0164 - val_loss: 0.0185\n",
      "Epoch 611/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0164 - val_loss: 0.0185\n",
      "Epoch 612/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0163 - val_loss: 0.0185\n",
      "Epoch 613/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0163 - val_loss: 0.0183\n",
      "Epoch 614/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0163 - val_loss: 0.0183\n",
      "Epoch 615/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0163 - val_loss: 0.0184\n",
      "Epoch 616/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0162 - val_loss: 0.0185\n",
      "Epoch 617/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0162 - val_loss: 0.0185\n",
      "Epoch 618/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0162 - val_loss: 0.0182\n",
      "Epoch 619/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0161 - val_loss: 0.0182\n",
      "Epoch 620/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0162 - val_loss: 0.0182\n",
      "Epoch 621/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0161 - val_loss: 0.0184\n",
      "Epoch 622/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0162 - val_loss: 0.0183\n",
      "Epoch 623/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0162 - val_loss: 0.0181\n",
      "Epoch 624/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0162 - val_loss: 0.0179\n",
      "Epoch 625/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 0s 18us/step - loss: 0.0161 - val_loss: 0.0183\n",
      "Epoch 626/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0163 - val_loss: 0.0180\n",
      "Epoch 627/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0160 - val_loss: 0.0180\n",
      "Epoch 628/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0162 - val_loss: 0.0180\n",
      "Epoch 629/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0160 - val_loss: 0.0182\n",
      "Epoch 630/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0161 - val_loss: 0.0181\n",
      "Epoch 631/1200\n",
      "367/367 [==============================] - 0s 15us/step - loss: 0.0160 - val_loss: 0.0179\n",
      "Epoch 632/1200\n",
      "367/367 [==============================] - 0s 15us/step - loss: 0.0160 - val_loss: 0.0178\n",
      "Epoch 633/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0160 - val_loss: 0.0179\n",
      "Epoch 634/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0159 - val_loss: 0.0181\n",
      "Epoch 635/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0159 - val_loss: 0.0181\n",
      "Epoch 636/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0159 - val_loss: 0.0181\n",
      "Epoch 637/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0159 - val_loss: 0.0179\n",
      "Epoch 638/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0159 - val_loss: 0.0179\n",
      "Epoch 639/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0159 - val_loss: 0.0179\n",
      "Epoch 640/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0157 - val_loss: 0.0182\n",
      "Epoch 641/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0161 - val_loss: 0.0183\n",
      "Epoch 642/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0160 - val_loss: 0.0178\n",
      "Epoch 643/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0158 - val_loss: 0.0179\n",
      "Epoch 644/1200\n",
      "367/367 [==============================] - 0s 28us/step - loss: 0.0160 - val_loss: 0.0176\n",
      "Epoch 645/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0157 - val_loss: 0.0180\n",
      "Epoch 646/1200\n",
      "367/367 [==============================] - 0s 30us/step - loss: 0.0159 - val_loss: 0.0179\n",
      "Epoch 647/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0157 - val_loss: 0.0177\n",
      "Epoch 648/1200\n",
      "367/367 [==============================] - 0s 26us/step - loss: 0.0157 - val_loss: 0.0175\n",
      "Epoch 649/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0158 - val_loss: 0.0175\n",
      "Epoch 650/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0157 - val_loss: 0.0177\n",
      "Epoch 651/1200\n",
      "367/367 [==============================] - 0s 30us/step - loss: 0.0156 - val_loss: 0.0178\n",
      "Epoch 652/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0156 - val_loss: 0.0177\n",
      "Epoch 653/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0156 - val_loss: 0.0175\n",
      "Epoch 654/1200\n",
      "367/367 [==============================] - 0s 26us/step - loss: 0.0156 - val_loss: 0.0175\n",
      "Epoch 655/1200\n",
      "367/367 [==============================] - 0s 26us/step - loss: 0.0156 - val_loss: 0.0177\n",
      "Epoch 656/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0156 - val_loss: 0.0178\n",
      "Epoch 657/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0156 - val_loss: 0.0176\n",
      "Epoch 658/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0155 - val_loss: 0.0174\n",
      "Epoch 659/1200\n",
      "367/367 [==============================] - 0s 26us/step - loss: 0.0156 - val_loss: 0.0174\n",
      "Epoch 660/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0156 - val_loss: 0.0174\n",
      "Epoch 661/1200\n",
      "367/367 [==============================] - 0s 15us/step - loss: 0.0154 - val_loss: 0.0176\n",
      "Epoch 662/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0155 - val_loss: 0.0175\n",
      "Epoch 663/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0155 - val_loss: 0.0174\n",
      "Epoch 664/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0155 - val_loss: 0.0175\n",
      "Epoch 665/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0155 - val_loss: 0.0173\n",
      "Epoch 666/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0155 - val_loss: 0.0174\n",
      "Epoch 667/1200\n",
      "367/367 [==============================] - 0s 13us/step - loss: 0.0154 - val_loss: 0.0175\n",
      "Epoch 668/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0154 - val_loss: 0.0176\n",
      "Epoch 669/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0154 - val_loss: 0.0172\n",
      "Epoch 670/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0154 - val_loss: 0.0172\n",
      "Epoch 671/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0154 - val_loss: 0.0173\n",
      "Epoch 672/1200\n",
      "367/367 [==============================] - 0s 15us/step - loss: 0.0153 - val_loss: 0.0175\n",
      "Epoch 673/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0155 - val_loss: 0.0172\n",
      "Epoch 674/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0153 - val_loss: 0.0170\n",
      "Epoch 675/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0153 - val_loss: 0.0171\n",
      "Epoch 676/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0152 - val_loss: 0.0172\n",
      "Epoch 677/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0152 - val_loss: 0.0173\n",
      "Epoch 678/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0153 - val_loss: 0.0172\n",
      "Epoch 679/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0152 - val_loss: 0.0170\n",
      "Epoch 680/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0153 - val_loss: 0.0171\n",
      "Epoch 681/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0152 - val_loss: 0.0172\n",
      "Epoch 682/1200\n",
      "367/367 [==============================] - 0s 29us/step - loss: 0.0152 - val_loss: 0.0175\n",
      "Epoch 683/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0153 - val_loss: 0.0174\n",
      "Epoch 684/1200\n",
      "367/367 [==============================] - 0s 26us/step - loss: 0.0153 - val_loss: 0.0169\n",
      "Epoch 685/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0151 - val_loss: 0.0170\n",
      "Epoch 686/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0154 - val_loss: 0.0168\n",
      "Epoch 687/1200\n",
      "367/367 [==============================] - 0s 26us/step - loss: 0.0152 - val_loss: 0.0170\n",
      "Epoch 688/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0152 - val_loss: 0.0168\n",
      "Epoch 689/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0151 - val_loss: 0.0169\n",
      "Epoch 690/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0150 - val_loss: 0.0167\n",
      "Epoch 691/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0150 - val_loss: 0.0167\n",
      "Epoch 692/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0150 - val_loss: 0.0167\n",
      "Epoch 693/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0150 - val_loss: 0.0166\n",
      "Epoch 694/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0150 - val_loss: 0.0167\n",
      "Epoch 695/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0150 - val_loss: 0.0167\n",
      "Epoch 696/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0149 - val_loss: 0.0167\n",
      "Epoch 697/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0150 - val_loss: 0.0166\n",
      "Epoch 698/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0149 - val_loss: 0.0165\n",
      "Epoch 699/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0149 - val_loss: 0.0165\n",
      "Epoch 700/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0150 - val_loss: 0.0164\n",
      "Epoch 701/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0149 - val_loss: 0.0164\n",
      "Epoch 702/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0149 - val_loss: 0.0165\n",
      "Epoch 703/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0149 - val_loss: 0.0165\n",
      "Epoch 704/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0148 - val_loss: 0.0166\n",
      "Epoch 705/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0148 - val_loss: 0.0164\n",
      "Epoch 706/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0149 - val_loss: 0.0164\n",
      "Epoch 707/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0148 - val_loss: 0.0165\n",
      "Epoch 708/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0148 - val_loss: 0.0164\n",
      "Epoch 709/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0147 - val_loss: 0.0164\n",
      "Epoch 710/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0147 - val_loss: 0.0164\n",
      "Epoch 711/1200\n",
      "367/367 [==============================] - 0s 26us/step - loss: 0.0147 - val_loss: 0.0164\n",
      "Epoch 712/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0147 - val_loss: 0.0165\n",
      "Epoch 713/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0147 - val_loss: 0.0166\n",
      "Epoch 714/1200\n",
      "367/367 [==============================] - 0s 32us/step - loss: 0.0147 - val_loss: 0.0167\n",
      "Epoch 715/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0147 - val_loss: 0.0165\n",
      "Epoch 716/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0147 - val_loss: 0.0164\n",
      "Epoch 717/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0147 - val_loss: 0.0165\n",
      "Epoch 718/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0147 - val_loss: 0.0167\n",
      "Epoch 719/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0147 - val_loss: 0.0166\n",
      "Epoch 720/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0148 - val_loss: 0.0166\n",
      "Epoch 721/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0148 - val_loss: 0.0163\n",
      "Epoch 722/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0147 - val_loss: 0.0164\n",
      "Epoch 723/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0148 - val_loss: 0.0162\n",
      "Epoch 724/1200\n",
      "367/367 [==============================] - 0s 30us/step - loss: 0.0146 - val_loss: 0.0161\n",
      "Epoch 725/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0145 - val_loss: 0.0162\n",
      "Epoch 726/1200\n",
      "367/367 [==============================] - 0s 27us/step - loss: 0.0145 - val_loss: 0.0163\n",
      "Epoch 727/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0145 - val_loss: 0.0162\n",
      "Epoch 728/1200\n",
      "367/367 [==============================] - 0s 27us/step - loss: 0.0145 - val_loss: 0.0161\n",
      "Epoch 729/1200\n",
      "367/367 [==============================] - 0s 28us/step - loss: 0.0145 - val_loss: 0.0161\n",
      "Epoch 730/1200\n",
      "367/367 [==============================] - 0s 28us/step - loss: 0.0145 - val_loss: 0.0163\n",
      "Epoch 731/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0146 - val_loss: 0.0161\n",
      "Epoch 732/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0144 - val_loss: 0.0160\n",
      "Epoch 733/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0146 - val_loss: 0.0159\n",
      "Epoch 734/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0144 - val_loss: 0.0163\n",
      "Epoch 735/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0146 - val_loss: 0.0159\n",
      "Epoch 736/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0143 - val_loss: 0.0160\n",
      "Epoch 737/1200\n",
      "367/367 [==============================] - 0s 28us/step - loss: 0.0145 - val_loss: 0.0159\n",
      "Epoch 738/1200\n",
      "367/367 [==============================] - 0s 29us/step - loss: 0.0144 - val_loss: 0.0161\n",
      "Epoch 739/1200\n",
      "367/367 [==============================] - 0s 30us/step - loss: 0.0145 - val_loss: 0.0160\n",
      "Epoch 740/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0144 - val_loss: 0.0158\n",
      "Epoch 741/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0144 - val_loss: 0.0158\n",
      "Epoch 742/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0143 - val_loss: 0.0161\n",
      "Epoch 743/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0144 - val_loss: 0.0162\n",
      "Epoch 744/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0143 - val_loss: 0.0159\n",
      "Epoch 745/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0143 - val_loss: 0.0159\n",
      "Epoch 746/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0144 - val_loss: 0.0158\n",
      "Epoch 747/1200\n",
      "367/367 [==============================] - 0s 55us/step - loss: 0.0144 - val_loss: 0.0161\n",
      "Epoch 748/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0146 - val_loss: 0.0164\n",
      "Epoch 749/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0145 - val_loss: 0.0162\n",
      "Epoch 750/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0144 - val_loss: 0.0158\n",
      "Epoch 751/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0143 - val_loss: 0.0159\n",
      "Epoch 752/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0143 - val_loss: 0.0159\n",
      "Epoch 753/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0141 - val_loss: 0.0159\n",
      "Epoch 754/1200\n",
      "367/367 [==============================] - 0s 27us/step - loss: 0.0143 - val_loss: 0.0157\n",
      "Epoch 755/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0141 - val_loss: 0.0158\n",
      "Epoch 756/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0143 - val_loss: 0.0158\n",
      "Epoch 757/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0142 - val_loss: 0.0157\n",
      "Epoch 758/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0144 - val_loss: 0.0156\n",
      "Epoch 759/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0143 - val_loss: 0.0157\n",
      "Epoch 760/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0141 - val_loss: 0.0156\n",
      "Epoch 761/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0141 - val_loss: 0.0155\n",
      "Epoch 762/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0141 - val_loss: 0.0154\n",
      "Epoch 763/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0140 - val_loss: 0.0155\n",
      "Epoch 764/1200\n",
      "367/367 [==============================] - 0s 27us/step - loss: 0.0140 - val_loss: 0.0154\n",
      "Epoch 765/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0140 - val_loss: 0.0155\n",
      "Epoch 766/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0141 - val_loss: 0.0155\n",
      "Epoch 767/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0139 - val_loss: 0.0156\n",
      "Epoch 768/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0141 - val_loss: 0.0155\n",
      "Epoch 769/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0140 - val_loss: 0.0154\n",
      "Epoch 770/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0141 - val_loss: 0.0155\n",
      "Epoch 771/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0139 - val_loss: 0.0155\n",
      "Epoch 772/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0140 - val_loss: 0.0156\n",
      "Epoch 773/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0140 - val_loss: 0.0154\n",
      "Epoch 774/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0139 - val_loss: 0.0154\n",
      "Epoch 775/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0140 - val_loss: 0.0153\n",
      "Epoch 776/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0138 - val_loss: 0.0156\n",
      "Epoch 777/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0141 - val_loss: 0.0156\n",
      "Epoch 778/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0139 - val_loss: 0.0157\n",
      "Epoch 779/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0141 - val_loss: 0.0153\n",
      "Epoch 780/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0139 - val_loss: 0.0154\n",
      "Epoch 781/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 0s 19us/step - loss: 0.0142 - val_loss: 0.0154\n",
      "Epoch 782/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0138 - val_loss: 0.0155\n",
      "Epoch 783/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0139 - val_loss: 0.0158\n",
      "Epoch 784/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0140 - val_loss: 0.0153\n",
      "Epoch 785/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0138 - val_loss: 0.0154\n",
      "Epoch 786/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0141 - val_loss: 0.0151\n",
      "Epoch 787/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0137 - val_loss: 0.0155\n",
      "Epoch 788/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0139 - val_loss: 0.0153\n",
      "Epoch 789/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0138 - val_loss: 0.0151\n",
      "Epoch 790/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0138 - val_loss: 0.0150\n",
      "Epoch 791/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0138 - val_loss: 0.0149\n",
      "Epoch 792/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0137 - val_loss: 0.0150\n",
      "Epoch 793/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0137 - val_loss: 0.0149\n",
      "Epoch 794/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0137 - val_loss: 0.0149\n",
      "Epoch 795/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0136 - val_loss: 0.0150\n",
      "Epoch 796/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0136 - val_loss: 0.0152\n",
      "Epoch 797/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0137 - val_loss: 0.0152\n",
      "Epoch 798/1200\n",
      "367/367 [==============================] - 0s 26us/step - loss: 0.0136 - val_loss: 0.0153\n",
      "Epoch 799/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0137 - val_loss: 0.0150\n",
      "Epoch 800/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0136 - val_loss: 0.0150\n",
      "Epoch 801/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0136 - val_loss: 0.0150\n",
      "Epoch 802/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0136 - val_loss: 0.0150\n",
      "Epoch 803/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0136 - val_loss: 0.0149\n",
      "Epoch 804/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0136 - val_loss: 0.0150\n",
      "Epoch 805/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0136 - val_loss: 0.0148\n",
      "Epoch 806/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0136 - val_loss: 0.0149\n",
      "Epoch 807/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0135 - val_loss: 0.0151\n",
      "Epoch 808/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0137 - val_loss: 0.0152\n",
      "Epoch 809/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0136 - val_loss: 0.0147\n",
      "Epoch 810/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0136 - val_loss: 0.0149\n",
      "Epoch 811/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0138 - val_loss: 0.0148\n",
      "Epoch 812/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0136 - val_loss: 0.0153\n",
      "Epoch 813/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0136 - val_loss: 0.0150\n",
      "Epoch 814/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0134 - val_loss: 0.0148\n",
      "Epoch 815/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0136 - val_loss: 0.0148\n",
      "Epoch 816/1200\n",
      "367/367 [==============================] - 0s 15us/step - loss: 0.0135 - val_loss: 0.0150\n",
      "Epoch 817/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0134 - val_loss: 0.0152\n",
      "Epoch 818/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0135 - val_loss: 0.0149\n",
      "Epoch 819/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0133 - val_loss: 0.0147\n",
      "Epoch 820/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0135 - val_loss: 0.0147\n",
      "Epoch 821/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0134 - val_loss: 0.0148\n",
      "Epoch 822/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0134 - val_loss: 0.0151\n",
      "Epoch 823/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0135 - val_loss: 0.0148\n",
      "Epoch 824/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0134 - val_loss: 0.0145\n",
      "Epoch 825/1200\n",
      "367/367 [==============================] - 0s 15us/step - loss: 0.0134 - val_loss: 0.0145\n",
      "Epoch 826/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0134 - val_loss: 0.0146\n",
      "Epoch 827/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0133 - val_loss: 0.0146\n",
      "Epoch 828/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0133 - val_loss: 0.0146\n",
      "Epoch 829/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0133 - val_loss: 0.0145\n",
      "Epoch 830/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0133 - val_loss: 0.0144\n",
      "Epoch 831/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0132 - val_loss: 0.0146\n",
      "Epoch 832/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0133 - val_loss: 0.0145\n",
      "Epoch 833/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0133 - val_loss: 0.0146\n",
      "Epoch 834/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0132 - val_loss: 0.0146\n",
      "Epoch 835/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0133 - val_loss: 0.0146\n",
      "Epoch 836/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0133 - val_loss: 0.0145\n",
      "Epoch 837/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0132 - val_loss: 0.0144\n",
      "Epoch 838/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0132 - val_loss: 0.0144\n",
      "Epoch 839/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0131 - val_loss: 0.0147\n",
      "Epoch 840/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0132 - val_loss: 0.0146\n",
      "Epoch 841/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0131 - val_loss: 0.0144\n",
      "Epoch 842/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0134 - val_loss: 0.0144\n",
      "Epoch 843/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0132 - val_loss: 0.0148\n",
      "Epoch 844/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0135 - val_loss: 0.0150\n",
      "Epoch 845/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0133 - val_loss: 0.0149\n",
      "Epoch 846/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0135 - val_loss: 0.0145\n",
      "Epoch 847/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0132 - val_loss: 0.0143\n",
      "Epoch 848/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0134 - val_loss: 0.0144\n",
      "Epoch 849/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0132 - val_loss: 0.0143\n",
      "Epoch 850/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0132 - val_loss: 0.0146\n",
      "Epoch 851/1200\n",
      "367/367 [==============================] - 0s 31us/step - loss: 0.0133 - val_loss: 0.0144\n",
      "Epoch 852/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0130 - val_loss: 0.0144\n",
      "Epoch 853/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0133 - val_loss: 0.0141\n",
      "Epoch 854/1200\n",
      "367/367 [==============================] - 0s 15us/step - loss: 0.0130 - val_loss: 0.0144\n",
      "Epoch 855/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0133 - val_loss: 0.0146\n",
      "Epoch 856/1200\n",
      "367/367 [==============================] - 0s 35us/step - loss: 0.0131 - val_loss: 0.0142\n",
      "Epoch 857/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0131 - val_loss: 0.0142\n",
      "Epoch 858/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0131 - val_loss: 0.0141\n",
      "Epoch 859/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0130 - val_loss: 0.0146\n",
      "Epoch 860/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0132 - val_loss: 0.0146\n",
      "Epoch 861/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0131 - val_loss: 0.0143\n",
      "Epoch 862/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0130 - val_loss: 0.0141\n",
      "Epoch 863/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0131 - val_loss: 0.0142\n",
      "Epoch 864/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0129 - val_loss: 0.0145\n",
      "Epoch 865/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0131 - val_loss: 0.0147\n",
      "Epoch 866/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0130 - val_loss: 0.0141\n",
      "Epoch 867/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0129 - val_loss: 0.0141\n",
      "Epoch 868/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0131 - val_loss: 0.0141\n",
      "Epoch 869/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0130 - val_loss: 0.0141\n",
      "Epoch 870/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0129 - val_loss: 0.0140\n",
      "Epoch 871/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0129 - val_loss: 0.0139\n",
      "Epoch 872/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0129 - val_loss: 0.0139\n",
      "Epoch 873/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0128 - val_loss: 0.0142\n",
      "Epoch 874/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0129 - val_loss: 0.0140\n",
      "Epoch 875/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0128 - val_loss: 0.0138\n",
      "Epoch 876/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0128 - val_loss: 0.0138\n",
      "Epoch 877/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0128 - val_loss: 0.0139\n",
      "Epoch 878/1200\n",
      "367/367 [==============================] - 0s 15us/step - loss: 0.0128 - val_loss: 0.0139\n",
      "Epoch 879/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0128 - val_loss: 0.0138\n",
      "Epoch 880/1200\n",
      "367/367 [==============================] - 0s 15us/step - loss: 0.0128 - val_loss: 0.0138\n",
      "Epoch 881/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0128 - val_loss: 0.0140\n",
      "Epoch 882/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0128 - val_loss: 0.0141\n",
      "Epoch 883/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0129 - val_loss: 0.0143\n",
      "Epoch 884/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0130 - val_loss: 0.0139\n",
      "Epoch 885/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0129 - val_loss: 0.0143\n",
      "Epoch 886/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0130 - val_loss: 0.0138\n",
      "Epoch 887/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0128 - val_loss: 0.0142\n",
      "Epoch 888/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0129 - val_loss: 0.0141\n",
      "Epoch 889/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0128 - val_loss: 0.0142\n",
      "Epoch 890/1200\n",
      "367/367 [==============================] - 0s 27us/step - loss: 0.0129 - val_loss: 0.0137\n",
      "Epoch 891/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0127 - val_loss: 0.0137\n",
      "Epoch 892/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0129 - val_loss: 0.0137\n",
      "Epoch 893/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0127 - val_loss: 0.0139\n",
      "Epoch 894/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0127 - val_loss: 0.0140\n",
      "Epoch 895/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0128 - val_loss: 0.0138\n",
      "Epoch 896/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0126 - val_loss: 0.0137\n",
      "Epoch 897/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0126 - val_loss: 0.0137\n",
      "Epoch 898/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0126 - val_loss: 0.0137\n",
      "Epoch 899/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0126 - val_loss: 0.0139\n",
      "Epoch 900/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0127 - val_loss: 0.0138\n",
      "Epoch 901/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0125 - val_loss: 0.0139\n",
      "Epoch 902/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0128 - val_loss: 0.0137\n",
      "Epoch 903/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0125 - val_loss: 0.0139\n",
      "Epoch 904/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0127 - val_loss: 0.0139\n",
      "Epoch 905/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0127 - val_loss: 0.0137\n",
      "Epoch 906/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0126 - val_loss: 0.0137\n",
      "Epoch 907/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0127 - val_loss: 0.0136\n",
      "Epoch 908/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0125 - val_loss: 0.0136\n",
      "Epoch 909/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0126 - val_loss: 0.0135\n",
      "Epoch 910/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0125 - val_loss: 0.0135\n",
      "Epoch 911/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0125 - val_loss: 0.0134\n",
      "Epoch 912/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0126 - val_loss: 0.0134\n",
      "Epoch 913/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0124 - val_loss: 0.0137\n",
      "Epoch 914/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0126 - val_loss: 0.0138\n",
      "Epoch 915/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0125 - val_loss: 0.0135\n",
      "Epoch 916/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0127 - val_loss: 0.0134\n",
      "Epoch 917/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0125 - val_loss: 0.0138\n",
      "Epoch 918/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0126 - val_loss: 0.0139\n",
      "Epoch 919/1200\n",
      "367/367 [==============================] - 0s 15us/step - loss: 0.0126 - val_loss: 0.0137\n",
      "Epoch 920/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0125 - val_loss: 0.0134\n",
      "Epoch 921/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0125 - val_loss: 0.0135\n",
      "Epoch 922/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0126 - val_loss: 0.0136\n",
      "Epoch 923/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0125 - val_loss: 0.0136\n",
      "Epoch 924/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0124 - val_loss: 0.0135\n",
      "Epoch 925/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0124 - val_loss: 0.0136\n",
      "Epoch 926/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0124 - val_loss: 0.0141\n",
      "Epoch 927/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0128 - val_loss: 0.0135\n",
      "Epoch 928/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0125 - val_loss: 0.0135\n",
      "Epoch 929/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0125 - val_loss: 0.0133\n",
      "Epoch 930/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0125 - val_loss: 0.0135\n",
      "Epoch 931/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0125 - val_loss: 0.0134\n",
      "Epoch 932/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0124 - val_loss: 0.0136\n",
      "Epoch 933/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0125 - val_loss: 0.0134\n",
      "Epoch 934/1200\n",
      "367/367 [==============================] - 0s 15us/step - loss: 0.0123 - val_loss: 0.0134\n",
      "Epoch 935/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0123 - val_loss: 0.0134\n",
      "Epoch 936/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0123 - val_loss: 0.0135\n",
      "Epoch 937/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 0s 18us/step - loss: 0.0123 - val_loss: 0.0135\n",
      "Epoch 938/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0123 - val_loss: 0.0132\n",
      "Epoch 939/1200\n",
      "367/367 [==============================] - 0s 15us/step - loss: 0.0123 - val_loss: 0.0133\n",
      "Epoch 940/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0124 - val_loss: 0.0132\n",
      "Epoch 941/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0124 - val_loss: 0.0133\n",
      "Epoch 942/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0122 - val_loss: 0.0133\n",
      "Epoch 943/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0123 - val_loss: 0.0132\n",
      "Epoch 944/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0122 - val_loss: 0.0132\n",
      "Epoch 945/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0122 - val_loss: 0.0132\n",
      "Epoch 946/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0122 - val_loss: 0.0133\n",
      "Epoch 947/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0122 - val_loss: 0.0133\n",
      "Epoch 948/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0123 - val_loss: 0.0131\n",
      "Epoch 949/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0122 - val_loss: 0.0132\n",
      "Epoch 950/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0123 - val_loss: 0.0132\n",
      "Epoch 951/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0122 - val_loss: 0.0136\n",
      "Epoch 952/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0124 - val_loss: 0.0133\n",
      "Epoch 953/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0122 - val_loss: 0.0133\n",
      "Epoch 954/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0123 - val_loss: 0.0132\n",
      "Epoch 955/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0123 - val_loss: 0.0131\n",
      "Epoch 956/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0122 - val_loss: 0.0133\n",
      "Epoch 957/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0122 - val_loss: 0.0134\n",
      "Epoch 958/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0123 - val_loss: 0.0133\n",
      "Epoch 959/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0121 - val_loss: 0.0133\n",
      "Epoch 960/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0122 - val_loss: 0.0132\n",
      "Epoch 961/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0121 - val_loss: 0.0131\n",
      "Epoch 962/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0121 - val_loss: 0.0131\n",
      "Epoch 963/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0121 - val_loss: 0.0132\n",
      "Epoch 964/1200\n",
      "367/367 [==============================] - 0s 15us/step - loss: 0.0121 - val_loss: 0.0132\n",
      "Epoch 965/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0122 - val_loss: 0.0131\n",
      "Epoch 966/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0121 - val_loss: 0.0131\n",
      "Epoch 967/1200\n",
      "367/367 [==============================] - 0s 14us/step - loss: 0.0121 - val_loss: 0.0131\n",
      "Epoch 968/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0121 - val_loss: 0.0131\n",
      "Epoch 969/1200\n",
      "367/367 [==============================] - 0s 27us/step - loss: 0.0121 - val_loss: 0.0131\n",
      "Epoch 970/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0120 - val_loss: 0.0131\n",
      "Epoch 971/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0121 - val_loss: 0.0129\n",
      "Epoch 972/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0120 - val_loss: 0.0130\n",
      "Epoch 973/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0120 - val_loss: 0.0130\n",
      "Epoch 974/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0121 - val_loss: 0.0130\n",
      "Epoch 975/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0120 - val_loss: 0.0129\n",
      "Epoch 976/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0120 - val_loss: 0.0129\n",
      "Epoch 977/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0120 - val_loss: 0.0129\n",
      "Epoch 978/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0120 - val_loss: 0.0130\n",
      "Epoch 979/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0120 - val_loss: 0.0130\n",
      "Epoch 980/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0120 - val_loss: 0.0130\n",
      "Epoch 981/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0120 - val_loss: 0.0130\n",
      "Epoch 982/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0120 - val_loss: 0.0130\n",
      "Epoch 983/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0121 - val_loss: 0.0128\n",
      "Epoch 984/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0119 - val_loss: 0.0130\n",
      "Epoch 985/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0120 - val_loss: 0.0130\n",
      "Epoch 986/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0119 - val_loss: 0.0130\n",
      "Epoch 987/1200\n",
      "367/367 [==============================] - 0s 36us/step - loss: 0.0120 - val_loss: 0.0128\n",
      "Epoch 988/1200\n",
      "367/367 [==============================] - 0s 92us/step - loss: 0.0119 - val_loss: 0.0128\n",
      "Epoch 989/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0120 - val_loss: 0.0128\n",
      "Epoch 990/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0120 - val_loss: 0.0130\n",
      "Epoch 991/1200\n",
      "367/367 [==============================] - 0s 40us/step - loss: 0.0120 - val_loss: 0.0127\n",
      "Epoch 992/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0119 - val_loss: 0.0129\n",
      "Epoch 993/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0121 - val_loss: 0.0127\n",
      "Epoch 994/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0120 - val_loss: 0.0132\n",
      "Epoch 995/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0121 - val_loss: 0.0131\n",
      "Epoch 996/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0120 - val_loss: 0.0131\n",
      "Epoch 997/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0121 - val_loss: 0.0127\n",
      "Epoch 998/1200\n",
      "367/367 [==============================] - 0s 34us/step - loss: 0.0121 - val_loss: 0.0130\n",
      "Epoch 999/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0122 - val_loss: 0.0128\n",
      "Epoch 1000/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0119 - val_loss: 0.0134\n",
      "Epoch 1001/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0122 - val_loss: 0.0128\n",
      "Epoch 1002/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0119 - val_loss: 0.0126\n",
      "Epoch 1003/1200\n",
      "367/367 [==============================] - 0s 27us/step - loss: 0.0119 - val_loss: 0.0126\n",
      "Epoch 1004/1200\n",
      "367/367 [==============================] - 0s 37us/step - loss: 0.0119 - val_loss: 0.0126\n",
      "Epoch 1005/1200\n",
      "367/367 [==============================] - 0s 42us/step - loss: 0.0119 - val_loss: 0.0127\n",
      "Epoch 1006/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0118 - val_loss: 0.0128\n",
      "Epoch 1007/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0119 - val_loss: 0.0128\n",
      "Epoch 1008/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0118 - val_loss: 0.0126\n",
      "Epoch 1009/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0119 - val_loss: 0.0127\n",
      "Epoch 1010/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0117 - val_loss: 0.0131\n",
      "Epoch 1011/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0120 - val_loss: 0.0130\n",
      "Epoch 1012/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0118 - val_loss: 0.0126\n",
      "Epoch 1013/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0120 - val_loss: 0.0126\n",
      "Epoch 1014/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0119 - val_loss: 0.0128\n",
      "Epoch 1015/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 0s 26us/step - loss: 0.0117 - val_loss: 0.0131\n",
      "Epoch 1016/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0119 - val_loss: 0.0127\n",
      "Epoch 1017/1200\n",
      "367/367 [==============================] - 0s 44us/step - loss: 0.0117 - val_loss: 0.0125\n",
      "Epoch 1018/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0119 - val_loss: 0.0125\n",
      "Epoch 1019/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0118 - val_loss: 0.0126\n",
      "Epoch 1020/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0118 - val_loss: 0.0128\n",
      "Epoch 1021/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0117 - val_loss: 0.0125\n",
      "Epoch 1022/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0117 - val_loss: 0.0125\n",
      "Epoch 1023/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0117 - val_loss: 0.0125\n",
      "Epoch 1024/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0117 - val_loss: 0.0127\n",
      "Epoch 1025/1200\n",
      "367/367 [==============================] - 0s 27us/step - loss: 0.0117 - val_loss: 0.0127\n",
      "Epoch 1026/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0117 - val_loss: 0.0127\n",
      "Epoch 1027/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0117 - val_loss: 0.0124\n",
      "Epoch 1028/1200\n",
      "367/367 [==============================] - 0s 26us/step - loss: 0.0118 - val_loss: 0.0125\n",
      "Epoch 1029/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0118 - val_loss: 0.0125\n",
      "Epoch 1030/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0117 - val_loss: 0.0127\n",
      "Epoch 1031/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0117 - val_loss: 0.0125\n",
      "Epoch 1032/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0116 - val_loss: 0.0124\n",
      "Epoch 1033/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0117 - val_loss: 0.0125\n",
      "Epoch 1034/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0116 - val_loss: 0.0131\n",
      "Epoch 1035/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0118 - val_loss: 0.0129\n",
      "Epoch 1036/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0117 - val_loss: 0.0124\n",
      "Epoch 1037/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0117 - val_loss: 0.0125\n",
      "Epoch 1038/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0118 - val_loss: 0.0125\n",
      "Epoch 1039/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0116 - val_loss: 0.0130\n",
      "Epoch 1040/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0118 - val_loss: 0.0128\n",
      "Epoch 1041/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0118 - val_loss: 0.0126\n",
      "Epoch 1042/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0118 - val_loss: 0.0124\n",
      "Epoch 1043/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0116 - val_loss: 0.0126\n",
      "Epoch 1044/1200\n",
      "367/367 [==============================] - 0s 27us/step - loss: 0.0118 - val_loss: 0.0125\n",
      "Epoch 1045/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0117 - val_loss: 0.0123\n",
      "Epoch 1046/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0115 - val_loss: 0.0124\n",
      "Epoch 1047/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0116 - val_loss: 0.0124\n",
      "Epoch 1048/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0115 - val_loss: 0.0126\n",
      "Epoch 1049/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0118 - val_loss: 0.0124\n",
      "Epoch 1050/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0115 - val_loss: 0.0126\n",
      "Epoch 1051/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0118 - val_loss: 0.0124\n",
      "Epoch 1052/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0116 - val_loss: 0.0126\n",
      "Epoch 1053/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0118 - val_loss: 0.0123\n",
      "Epoch 1054/1200\n",
      "367/367 [==============================] - 0s 27us/step - loss: 0.0115 - val_loss: 0.0124\n",
      "Epoch 1055/1200\n",
      "367/367 [==============================] - 0s 29us/step - loss: 0.0117 - val_loss: 0.0125\n",
      "Epoch 1056/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0117 - val_loss: 0.0124\n",
      "Epoch 1057/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0116 - val_loss: 0.0125\n",
      "Epoch 1058/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0117 - val_loss: 0.0122\n",
      "Epoch 1059/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0115 - val_loss: 0.0124\n",
      "Epoch 1060/1200\n",
      "367/367 [==============================] - 0s 32us/step - loss: 0.0117 - val_loss: 0.0123\n",
      "Epoch 1061/1200\n",
      "367/367 [==============================] - 0s 28us/step - loss: 0.0116 - val_loss: 0.0126\n",
      "Epoch 1062/1200\n",
      "367/367 [==============================] - 0s 39us/step - loss: 0.0116 - val_loss: 0.0123\n",
      "Epoch 1063/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0115 - val_loss: 0.0123\n",
      "Epoch 1064/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0116 - val_loss: 0.0123\n",
      "Epoch 1065/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0115 - val_loss: 0.0127\n",
      "Epoch 1066/1200\n",
      "367/367 [==============================] - 0s 27us/step - loss: 0.0117 - val_loss: 0.0125\n",
      "Epoch 1067/1200\n",
      "367/367 [==============================] - 0s 26us/step - loss: 0.0116 - val_loss: 0.0123\n",
      "Epoch 1068/1200\n",
      "367/367 [==============================] - 0s 28us/step - loss: 0.0114 - val_loss: 0.0123\n",
      "Epoch 1069/1200\n",
      "367/367 [==============================] - 0s 26us/step - loss: 0.0114 - val_loss: 0.0123\n",
      "Epoch 1070/1200\n",
      "367/367 [==============================] - 0s 27us/step - loss: 0.0114 - val_loss: 0.0122\n",
      "Epoch 1071/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0114 - val_loss: 0.0121\n",
      "Epoch 1072/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0114 - val_loss: 0.0123\n",
      "Epoch 1073/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0115 - val_loss: 0.0125\n",
      "Epoch 1074/1200\n",
      "367/367 [==============================] - 0s 26us/step - loss: 0.0114 - val_loss: 0.0122\n",
      "Epoch 1075/1200\n",
      "367/367 [==============================] - 0s 29us/step - loss: 0.0114 - val_loss: 0.0122\n",
      "Epoch 1076/1200\n",
      "367/367 [==============================] - 0s 27us/step - loss: 0.0116 - val_loss: 0.0120\n",
      "Epoch 1077/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0114 - val_loss: 0.0125\n",
      "Epoch 1078/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0116 - val_loss: 0.0124\n",
      "Epoch 1079/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0114 - val_loss: 0.0123\n",
      "Epoch 1080/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0116 - val_loss: 0.0121\n",
      "Epoch 1081/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0115 - val_loss: 0.0121\n",
      "Epoch 1082/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0115 - val_loss: 0.0122\n",
      "Epoch 1083/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0114 - val_loss: 0.0126\n",
      "Epoch 1084/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0116 - val_loss: 0.0122\n",
      "Epoch 1085/1200\n",
      "367/367 [==============================] - 0s 27us/step - loss: 0.0113 - val_loss: 0.0122\n",
      "Epoch 1086/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0116 - val_loss: 0.0124\n",
      "Epoch 1087/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0116 - val_loss: 0.0122\n",
      "Epoch 1088/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0114 - val_loss: 0.0123\n",
      "Epoch 1089/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0114 - val_loss: 0.0121\n",
      "Epoch 1090/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0114 - val_loss: 0.0123\n",
      "Epoch 1091/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0115 - val_loss: 0.0121\n",
      "Epoch 1092/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0114 - val_loss: 0.0123\n",
      "Epoch 1093/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0114 - val_loss: 0.0120\n",
      "Epoch 1094/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0114 - val_loss: 0.0120\n",
      "Epoch 1095/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0113 - val_loss: 0.0121\n",
      "Epoch 1096/1200\n",
      "367/367 [==============================] - 0s 14us/step - loss: 0.0114 - val_loss: 0.0121\n",
      "Epoch 1097/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0113 - val_loss: 0.0120\n",
      "Epoch 1098/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0113 - val_loss: 0.0119\n",
      "Epoch 1099/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0113 - val_loss: 0.0119\n",
      "Epoch 1100/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0113 - val_loss: 0.0120\n",
      "Epoch 1101/1200\n",
      "367/367 [==============================] - 0s 15us/step - loss: 0.0113 - val_loss: 0.0120\n",
      "Epoch 1102/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0113 - val_loss: 0.0120\n",
      "Epoch 1103/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0112 - val_loss: 0.0120\n",
      "Epoch 1104/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0113 - val_loss: 0.0121\n",
      "Epoch 1105/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0113 - val_loss: 0.0121\n",
      "Epoch 1106/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0113 - val_loss: 0.0120\n",
      "Epoch 1107/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0113 - val_loss: 0.0121\n",
      "Epoch 1108/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0112 - val_loss: 0.0120\n",
      "Epoch 1109/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0114 - val_loss: 0.0121\n",
      "Epoch 1110/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0113 - val_loss: 0.0122\n",
      "Epoch 1111/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0113 - val_loss: 0.0120\n",
      "Epoch 1112/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0113 - val_loss: 0.0119\n",
      "Epoch 1113/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0112 - val_loss: 0.0120\n",
      "Epoch 1114/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0112 - val_loss: 0.0119\n",
      "Epoch 1115/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0112 - val_loss: 0.0119\n",
      "Epoch 1116/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0112 - val_loss: 0.0120\n",
      "Epoch 1117/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0112 - val_loss: 0.0120\n",
      "Epoch 1118/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0112 - val_loss: 0.0118\n",
      "Epoch 1119/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0112 - val_loss: 0.0117\n",
      "Epoch 1120/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0113 - val_loss: 0.0117\n",
      "Epoch 1121/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0112 - val_loss: 0.0119\n",
      "Epoch 1122/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0112 - val_loss: 0.0122\n",
      "Epoch 1123/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0112 - val_loss: 0.0120\n",
      "Epoch 1124/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0112 - val_loss: 0.0118\n",
      "Epoch 1125/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0112 - val_loss: 0.0118\n",
      "Epoch 1126/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0112 - val_loss: 0.0119\n",
      "Epoch 1127/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0111 - val_loss: 0.0120\n",
      "Epoch 1128/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0112 - val_loss: 0.0119\n",
      "Epoch 1129/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0111 - val_loss: 0.0119\n",
      "Epoch 1130/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0112 - val_loss: 0.0120\n",
      "Epoch 1131/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0112 - val_loss: 0.0118\n",
      "Epoch 1132/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0111 - val_loss: 0.0119\n",
      "Epoch 1133/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0111 - val_loss: 0.0118\n",
      "Epoch 1134/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0112 - val_loss: 0.0119\n",
      "Epoch 1135/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0111 - val_loss: 0.0119\n",
      "Epoch 1136/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0111 - val_loss: 0.0118\n",
      "Epoch 1137/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0113 - val_loss: 0.0118\n",
      "Epoch 1138/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0111 - val_loss: 0.0120\n",
      "Epoch 1139/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0111 - val_loss: 0.0120\n",
      "Epoch 1140/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0112 - val_loss: 0.0118\n",
      "Epoch 1141/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0111 - val_loss: 0.0119\n",
      "Epoch 1142/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0112 - val_loss: 0.0117\n",
      "Epoch 1143/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0111 - val_loss: 0.0119\n",
      "Epoch 1144/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0112 - val_loss: 0.0119\n",
      "Epoch 1145/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0112 - val_loss: 0.0120\n",
      "Epoch 1146/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0111 - val_loss: 0.0117\n",
      "Epoch 1147/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0111 - val_loss: 0.0117\n",
      "Epoch 1148/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0111 - val_loss: 0.0116\n",
      "Epoch 1149/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0111 - val_loss: 0.0117\n",
      "Epoch 1150/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0111 - val_loss: 0.0118\n",
      "Epoch 1151/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0111 - val_loss: 0.0118\n",
      "Epoch 1152/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0111 - val_loss: 0.0118\n",
      "Epoch 1153/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0111 - val_loss: 0.0116\n",
      "Epoch 1154/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0110 - val_loss: 0.0117\n",
      "Epoch 1155/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0111 - val_loss: 0.0117\n",
      "Epoch 1156/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0110 - val_loss: 0.0118\n",
      "Epoch 1157/1200\n",
      "367/367 [==============================] - 0s 26us/step - loss: 0.0112 - val_loss: 0.0116\n",
      "Epoch 1158/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0110 - val_loss: 0.0117\n",
      "Epoch 1159/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0111 - val_loss: 0.0120\n",
      "Epoch 1160/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0112 - val_loss: 0.0117\n",
      "Epoch 1161/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0110 - val_loss: 0.0115\n",
      "Epoch 1162/1200\n",
      "367/367 [==============================] - 0s 27us/step - loss: 0.0111 - val_loss: 0.0115\n",
      "Epoch 1163/1200\n",
      "367/367 [==============================] - 0s 31us/step - loss: 0.0112 - val_loss: 0.0117\n",
      "Epoch 1164/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0110 - val_loss: 0.0120\n",
      "Epoch 1165/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0112 - val_loss: 0.0116\n",
      "Epoch 1166/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0110 - val_loss: 0.0118\n",
      "Epoch 1167/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0112 - val_loss: 0.0117\n",
      "Epoch 1168/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0110 - val_loss: 0.0120\n",
      "Epoch 1169/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 0s 19us/step - loss: 0.0113 - val_loss: 0.0116\n",
      "Epoch 1170/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0109 - val_loss: 0.0119\n",
      "Epoch 1171/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0113 - val_loss: 0.0116\n",
      "Epoch 1172/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0112 - val_loss: 0.0116\n",
      "Epoch 1173/1200\n",
      "367/367 [==============================] - 0s 15us/step - loss: 0.0110 - val_loss: 0.0117\n",
      "Epoch 1174/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0109 - val_loss: 0.0117\n",
      "Epoch 1175/1200\n",
      "367/367 [==============================] - 0s 17us/step - loss: 0.0110 - val_loss: 0.0116\n",
      "Epoch 1176/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0109 - val_loss: 0.0116\n",
      "Epoch 1177/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0110 - val_loss: 0.0116\n",
      "Epoch 1178/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0109 - val_loss: 0.0115\n",
      "Epoch 1179/1200\n",
      "367/367 [==============================] - 0s 21us/step - loss: 0.0110 - val_loss: 0.0115\n",
      "Epoch 1180/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0109 - val_loss: 0.0117\n",
      "Epoch 1181/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0110 - val_loss: 0.0117\n",
      "Epoch 1182/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0109 - val_loss: 0.0114\n",
      "Epoch 1183/1200\n",
      "367/367 [==============================] - 0s 26us/step - loss: 0.0110 - val_loss: 0.0114\n",
      "Epoch 1184/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0110 - val_loss: 0.0115\n",
      "Epoch 1185/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0109 - val_loss: 0.0116\n",
      "Epoch 1186/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0109 - val_loss: 0.0115\n",
      "Epoch 1187/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0109 - val_loss: 0.0114\n",
      "Epoch 1188/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0110 - val_loss: 0.0115\n",
      "Epoch 1189/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0109 - val_loss: 0.0115\n",
      "Epoch 1190/1200\n",
      "367/367 [==============================] - 0s 16us/step - loss: 0.0109 - val_loss: 0.0117\n",
      "Epoch 1191/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0110 - val_loss: 0.0115\n",
      "Epoch 1192/1200\n",
      "367/367 [==============================] - 0s 24us/step - loss: 0.0110 - val_loss: 0.0115\n",
      "Epoch 1193/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0110 - val_loss: 0.0117\n",
      "Epoch 1194/1200\n",
      "367/367 [==============================] - 0s 18us/step - loss: 0.0109 - val_loss: 0.0117\n",
      "Epoch 1195/1200\n",
      "367/367 [==============================] - 0s 26us/step - loss: 0.0110 - val_loss: 0.0116\n",
      "Epoch 1196/1200\n",
      "367/367 [==============================] - 0s 25us/step - loss: 0.0109 - val_loss: 0.0116\n",
      "Epoch 1197/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0109 - val_loss: 0.0114\n",
      "Epoch 1198/1200\n",
      "367/367 [==============================] - 0s 23us/step - loss: 0.0109 - val_loss: 0.0114\n",
      "Epoch 1199/1200\n",
      "367/367 [==============================] - 0s 26us/step - loss: 0.0109 - val_loss: 0.0114\n",
      "Epoch 1200/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0109 - val_loss: 0.0114\n"
     ]
    }
   ],
   "source": [
    "# %load solutions/NN_1_layer_16_nodes.py\n",
    "\n",
    "H = 40 # number of nodes in the layer\n",
    "input_dim = 1 # input dimension: just x\n",
    "\n",
    "model2 = models.Sequential() # create sequential multi-layer perceptron\n",
    "\n",
    "# layer 0, our hidden layer\n",
    "model2.add(layers.Dense(H, input_dim=input_dim, \n",
    "                kernel_initializer='normal', \n",
    "                activation='relu')) \n",
    "# layer 1\n",
    "model2.add(layers.Dense(1, kernel_initializer='normal', \n",
    "                activation='linear')) \n",
    "\n",
    "# compile the model\n",
    "model2.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# fit the model\n",
    "model2_history = model2.fit(X_train, Y_train, batch_size=256, epochs=1200, verbose=1, \\\n",
    "                          shuffle = True, validation_split=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the loss smaller now? You may access the results in a model by its `.history`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018115125875286506"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model16_history.history['loss'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again let's use the new model to predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use our model to predict in the range we want\n",
    "X_range = np.linspace(-10, 10, 1000)\n",
    "y_pred = model2.predict(X_range)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=FIG_SIZE)\n",
    "ax.scatter(X_train, Y_train, label='Training data', alpha=0.3)\n",
    "ax.scatter(X_test, Y_test, label='Testing data' , alpha=0.3)\n",
    "ax.plot(X_range, y_pred, lw=4, color='r', label=f'NN with one hidden layer and {H} nodes')\n",
    "ax.set_xlabel(r'$X$', fontsize=FONT_SIZE)\n",
    "ax.set_ylabel(r'$Y$', fontsize=FONT_SIZE)\n",
    "ax.set_title(f'NN with {len(model2_history.model.layers)-1} layers, {H} nodes in each layer', fontsize=LABEL_SIZE)\n",
    "ax.tick_params(labelsize=LABEL_SIZE)\n",
    "\n",
    "ax.legend(loc=0, fontsize=FONT_SIZE)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 3:</b>\n",
    "</div>\n",
    "\n",
    "Plot the loss function as a function of the epochs. <b>Hint:</b> You can access the loss function values with the command:`model_history.history['loss']`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAn8AAAFFCAYAAACdR4utAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3XeYlNXZx/HvTUekC4KiNEUFUcqCqCggCFYQLIho1JgYNdEolrxGExFLxCgQExNLjF2JBizYEFRQQpFiBUFEBAFRel/qef+4Z7PDMLszCzM7s7u/z3XNNe4z53nmTN68yS+n3MdCCIiIiIhI2VAu0x0QERERkeKj8CciIiJShij8iYiIiJQhCn8iIiIiZYjCn4iIiEgZovAnIiIiUoYo/ImIiIiUIQp/IiIiImVIWsOfmbU0s/fMbLOZLTOzIWZWPsE9rczsnUj7rWa22Mz+aWYN47TtY2ZfmFmumc0xs/5x2tQ0syfNbI2ZrTOz582sbip/p4iIiEhJUSFdDzaz2sB4YA7QB2gOPIgHztsLubUmsBB4BlgGNAXuANqbWYcQwo7I8zsDo4C/A9cBZwAvmtmaEMK7Uc/7N3AE8AtgFzAUeBU4KdFvOOCAA0KTJk2S/MUiIiIimTNz5syVIYR6idpZuo53M7NbgVuAxiGE9ZFrtwCDgQZ515J81qnAu0D7EMKsyLWxQMUQwilR7d4CaoQQOkf+Ph6YDHQJIXwYudYRmAacGkIYX9j35uTkhBkzZiTbTREREZGMMbOZIYScRO3SOe17OjA2JuSNBKoCXYr4rFWR90oAZlYZ6Aa8FNNuJHC8mdWM6sOPecEPIITwMT6yeHoR+yAiIiJS4qUz/B0JzI2+EEJYDGyOfFYoMytnZpXM7AjgPmA68HHk4+ZAxdjnA1/hv6lFQX2IapewDyIiIiKlTTrDX21gbZzrayKfJfIWsBUPb3WAs0IIu6KeTZznr4n5vMh9MLMrzWyGmc1YsWJFEt0UERERKTnStuEjIt6CQivgeqxr8dB3OL5B5G0zOzGEkFvI8y3O9SL1IYTwGPAY+Jq/JPopIiIiWW779u0sWbKE3NzcxI2zXJUqVWjUqBEVK1bcq/vTGf7WALXiXK9J/NG43YQQ5kf+cZqZfYSv07sI+Bf5I3yxz8/7O+/5a4B4u15qJdMHERERKR2WLFlC9erVadKkCWaW+IYsFUJg1apVLFmyhKZNm+7VM9I57TuXmHV1ZnYIUI346/AKFEJYBKwGmkUuLQC2xz4/8vcu4OuC+hDVrkh9EBERkZIrNzeXunXrlujgB2Bm1K1bd59GMNMZ/t4GeplZ9ahr/YEtwMSiPCiy6aMuPvpHCGEr8AFwfkzT/sCUEMK6qD40iNQEzHtWDh4i3y5KH0RERKRkK+nBL8++/o50Tvs+ghdfHm1mQ/HANRgYFl3+xcy+ASaGEK6I/P0AsAOvxbcWOAqvF7gAL+WS5y5ggpmNwIs2nxF5nZbXIIQwJVIP8Bkzu4n8Is+TEtX4ExERESmN0jbyF0JYA3QHygNjgDuB4fhpHdEqRNrkmYGfvvEE8CYeIEcBnUIIm6KePwk4D+gBjAV6AxfFnO4BcCE+0vgv/NSQmUDfff+FIiIiIsnp2rUrY8eO3e3aiBEjuOaaawq8Z//9909LX9K62zeEMAc4JUGbJjF/j2T3Eb7C7n0VH/UrrM1a4PLIK6usXAmjRkHv3tBwj5OLRUREpLQYMGAAI0eOpFevXv+7NnLkSP785z8Xe1/SueZPEvjhB7jqKng3dqxSRERESpXzzjuPN954g61btwLw3XffsWzZMtq0aUP37t1p164drVu35rXXXkt7X9Jd508K0aoV1K0LEybApZdmujciIiJlw/XXw6efpvaZbdrAiBEFf163bl06duzIO++8Q58+fRg5ciT9+/enatWqvPLKK9SoUYOVK1fSqVMnevfundbNKRr5y6By5aBLF5hYpL3PIiIiUhLlTf2CT/kOGDCAEAK///3vOeaYY+jRowdLly7lxx9/TGs/NPKXYV26wOjRsGgRNG6c6d6IiIiUfoWN0KXTOeecw6BBg5g1axZbtmyhXbt2PPXUU6xYsYKZM2dSsWJFmjRpkvZTSDTyl2Fdu/q7Rv9ERERKt/3335+uXbvy85//nAEDBgCwbt066tevT8WKFfnggw9YtGhR2vuh8JdhRx8Nder4uj8REREp3QYMGMBnn33GhRdeCMDAgQOZMWMGOTk5PP/88xx5ZLyDyVJL074ZlrfuT+FPRESk9Ovbty8hhP/9fcABBzBlypS4bTdu3JiWPmjkLwt07QoLF8J332W6JyIiIlLaKfxlge7d/f299zLbDxERESn9FP6yQMuW0KCBwp+IiEg6RU+3lmT7+jsU/rKAmY/+vfcelJJ/X4qIiGSVKlWqsGrVqhIfAEMIrFq1iipVquz1M7ThI0t07w7PPw9ffgmtW2e6NyIiIqVLo0aNWLJkCStWrMh0V/ZZlSpVaNSo0V7fr/CXJaLX/Sn8iYiIpFbFihVp2rRppruRFTTtmyUOPRQOP1zr/kRERCS9FP6ySPfuXu9v+/ZM90RERERKK4W/LNK9O2zcCNOnZ7onIiIiUlop/GWRbt1856+mfkVERCRdFP6ySN260LYtjB+f6Z6IiIhIaaXwl2W6d4cpU2DTpkz3REREREqjtIY/M2tpZu+Z2WYzW2ZmQ8ysfIJ7OpjZk2b2TeS+eWZ2h5lViWn3nZmFAl4No9rF+3xqun7zvure3Td8fPRRpnsiIiIipVHa6vyZWW1gPDAH6AM0Bx7EA+fthdzaP9J2KDAfOAa4K/J+blS7vkDlmHsfB3aGEH6Iuf4g8J+ovzcU5bcUp86doVw5mDwZTjst070RERGR0iadRZ6vAqoC/UII64FxZlYDGGxm90euxTM0hBBdfnuCmeUCj5pZ4xDCIoAQwifRN5lZA+Ao4LY4z/wuhJC1o33RqlWDo4+GadMy3RMREREpjdI57Xs6MDYm5I3EA2GXgm6KCX558oJe/UK+7wL894wsYj+zznHHwccf65xfERERSb10hr8jgbnRF0IIi4HNkc+K4gRgFzCvkDYXAlPyRgZjDDazHWa20sz+ZWZ1ivj9xapjR1i7FubPz3RPREREpLRJZ/irDayNc31N5LOkRKZzbwOeLWiq2MwaA52IP+r3NPAr4BTgXnyt4LhEG08y6bjj/P3jjzPbDxERESl90l3qJd7EpRVwfc+GZpWAl4CNwA2FNL0QHxl8aY8OhHBZCGFUCOHDEMIw4CKgHXB2Ad95pZnNMLMZK1bEm4FOv5Ytfe2f1v2JiIhIqqUz/K0BasW5XpP4I4K7MTMDngFaAWeEENYU0vxC4IMQwo9J9OsdPEy2i/dhCOGxEEJOCCGnXr16STwu9cqXh5wcjfyJiIhI6qUz/M0lZm2fmR0CVCNmLWABhuMlYvqEEApsb2ZHAG2AF5PpVAj/20aR1dspjjsOPv0Utm7NdE9ERESkNEln+Hsb6GVm1aOu9Qe2ABMLu9HMbgWuBS4OIUxK8D0DgG3A6GQ6ZWanAfsDM5NpnykdO8K2bfDZZ5nuiYiIiJQm6Qx/jwBbgdFm1sPMrgQGA8OiN25ETvJ4Iurvi/CNGc8AS82sU9Qr3jxsf+DtEMIeU8mR9XuPmdkFZnaKmd2Ebwr5GHgzhb815fI2fWjdn4iIiKRS2oo8hxDWmFl34G/AGHyd33A8AMb2IXrnbc/I+2WRV7TLgafy/jCzNvjU8p0FdGMBcCl+MkgNYDkeKv8QQthZhJ9T7A4+GBo21Lo/ERERSS0LqiRcoJycnDBjxoyMfX/fvjB7Nnz9dca6ICIiIiWEmc0MIeQkapfuUi+yDzp08ELPawrb5ywiIiJSBAp/WaxDB3+fNSuz/RAREZHSQ+Evi7Vv7+/Tp2e2HyIiIlJ6KPxlsTp1oFkzyOCyQxERESllFP6yXIcOCn8iIiKSOgp/WS4nBxYtggwdMywiIiKljMJflsvb9KHRPxEREUkFhb8s17YtmGnTh4iIiKSGwl+Wq1EDjjhCI38iIiKSGgp/JYA2fYiIiEiqKPyVADk58MMPsGxZpnsiIiIiJZ3CXwnQrp2/f/JJZvshIiIiJZ/CXwlw7LG+6UPHvImIiMi+UvgrAapXh8MPV/gTERGRfafwV0K0a6dpXxEREdl3Cn8lRNu2ftLHqlWZ7omIiIiUZAp/JYQ2fYiIiEgqKPyVEG3b+rvCn4iIiOwLhb8Som5dOPRQbfoQERGRfaPwV4K0a6fwJyIiIvsmreHPzFqa2XtmttnMlpnZEDMrn+CeDmb2pJl9E7lvnpndYWZVYtoNNrMQ53VaTLvKZvagmf1kZpvM7E0za5L6X5t+7drB/PmwYUOmeyIiIiIlVYV0PdjMagPjgTlAH6A58CAeOG8v5Nb+kbZDgfnAMcBdkfdzY9quA06LufZVzN8PAecBNwArgMHAODNrHULILdKPyrC2bSEE+Owz6Nw5070RERGRkiht4Q+4CqgK9AshrMcDVw1gsJndH7kWz9AQwoqovyeYWS7wqJk1DiEsivpsRwhhakEdMLNGwBXAz0MIz0SufQ4sBC4G/rnXvy4D8nb8zpql8CciIiJ7J53TvqcDY2NC3kg8EHYp6KaY4Jcnb49r/SL2oWfkfXTU85cCkyL9K1EaNoQDD9SOXxEREdl76Qx/RwJzoy+EEBYDmyOfFcUJwC5gXsz1Wma20sy2m9knZtYvTh+WhBA2xlz/ai/6kHFmPvWrTR8iIiKyt9IZ/moDa+NcXxP5LClm1gC4DXg2ZhTxG+AW4AJ8LeAyYFRMACxyH8zsSjObYWYzVqyINwiZWe3awezZkFuiViuKiIhItkh3qZcQ55oVcH3PhmaVgJeAjfiGjfwHh/BcCGFYCOH9EMLrwFnAVOCP+9KHEMJjIYScEEJOvXr1kulmsWrbFnbuhC+/zHRPREREpCRKZ/hbA9SKc70m8UfjdmNmBjwDtALOCCGsKax9CCHga/uOiSonU1AfaiXTh7SbMwdOPhmmFrhnZQ866UNERET2RTrD31xi1tWZ2SFANWLWAhZgOF4ipk8IIZn2eaJH9OYCh5hZtZg2e6xHzIjq1eGjj4qU5Jo1g5o1Ff5ERERk76Qz/L0N9DKz6lHX+gNbgImF3WhmtwLXAheHECYl82WRkcK+wGchhJ2Ry+9G3vtGtTsIOCnSv8xq1Ahq1CjSHK4ZtGmjTR8iIiKyd9JZ5+8R4DpgtJkNBZrhBZaHRW/cMLNvgIkhhCsif18E3As8BSw1s05Rz1yQVwrGzCYCo/ARvGrAL4FOwDl5jUMIS8zsCWBEJBzmFXleBDyX+p9cRGZwzDEwbVqRbmvbFh591Nf+lS/0vBQRERGR3aVt5C+yRq87UB4YA9yJT+XeEdO0QqRNnrzafJcBU2JeZ0a1+wa4HngND3LVgTMjmz+iXYevHRyGh8XVQM+sOd3jzDNh5kxYvDjpW9q2hS1bYF5s4RsRERGRBMz3SUg8OTk5YcaMGen9kq+/hiOOgBEj4Le/TeqWL77wAcPnnoOBA9PbPRERESkZzGxmCCEnUbt0l3qRRFq0gKOPhtGjE7eNOOooqFJF6/5ERESk6BT+ssG55/qu3x9/TKp5hQrQurXCn4iIiBSdwl826NcPQoDXXkv6lpwcD3+7dqWxXyIiIlLqKPxlg9at4bDDYNSopG9p3x7Wr4cFC9LYLxERESl1FP6ygZmP/r3/Pqwp9CCT/2nf3t/TvR9FRERESheFv2xx7rmwYwe88UZSzVu1gsqVvUqMiIiISLIU/rJFTo6f+JHk1G/FinDssQp/IiIiUjQKf9miXDmf+h07FjZuTOqWnBwPfzt3Jm4rIiIiAgp/2aVvX8jNhXffTdwW6NQJNmyAr75Kc79ERESk1FD4yyadO0Pt2vB67Al18Z1wgr9PnpzGPomIiEipovCXTSpU8LN+33jDN38k0KwZ1K+v8CciIiLJU/jLNn36wKpVSSU6Mzj+eIU/ERERSZ7CX7bp1ctHAN96K6nmJ5wA8+fDihVp7peIiIiUCgp/2aZ6dTjxRN/1m4S8dX9TpqSxTyIiIlJqKPxlo1694NNPYfnyhE3bt/eaf//9bzH0S0REREo8hb9sdNpp/p5EyZeqVaFtW5g2Lc19EhERkVJB4S8bHXusb+NNcuq3QwcVexYREZHkKPxlo3LloGdPH/nbtSth8w4d/FCQuXOLoW8iIiJSoin8ZatevWDlSl/7l0CHDv4+fXqa+yQiIiIlnsJfture3d/Hj0/Y9IgjfJOwwp+IiIgkktbwZ2Ytzew9M9tsZsvMbIiZlU9wTwcze9LMvoncN8/M7jCzKjHtfmVm48zsRzNbZ2b/NbOecZ73nZmFmFfibbSZ1rAhtGqVVPgrX953/Sr8iYiISCJpC39mVhsYDwSgDzAEuBG4M8Gt/YHmwFDgDOBhYBDwfEy724CFwK+A84BvgHfMrHecZ74AHB/1OqPovygDevSASZMgNzdh006d4JNPYNOmYuiXiIiIlFgV0vjsq4CqQL8QwnpgnJnVAAab2f2Ra/EMDSFEn1cxwcxygUfNrHEIYVHkersQwsqoduPM7HDgBuD1mGf+EEKYuu8/qZj16AF/+YtXcO7WrdCm3brBffd5VuzVq5j6JyIiIiVOOqd9TwfGxoS8kXgg7FLQTTHBL88nkff6Ue1WFtCufpzrJVOXLj6nm8TUb+fOXuz5vfeKoV8iIiJSYqUz/B0J7FZ8JISwGNgc+awoTgB2AfMStDsemBPn+s/NbFtkbeB/zKxxEb8/M6pXh+OOg3HjEjbdbz84/nh4//1i6JeIiIiUWOkMf7WBtXGur4l8lhQza4Cv73u2kKlizOznQFvg7zEfvQb8GugO3IwHxI/MrGYBz7nSzGaY2YwVK+INQhazHj28gvPaeP9S7q57d5g1C1avLoZ+iYiISImU7lIvIc41K+D6ng3NKgEvARvxtXwFtWsP/BX4Swjhg906EMJvQwgvhhA+CiE8BvQCDgIuj9vhEB4LIeSEEHLq1auXTDfTq0cPL/Q8YULCpqecAiEk1VRERETKqHSGvzVArTjXaxJ/RHA3ZmbAM0Ar4IwQwpoC2jUD3gTew3cTFyqE8CU+fdwuUduscNxxUK1aUuv+Onb0ppr6FRERkYKkc7fvXGLW9pnZIUA1YtYCFmA4XiLm1BBC3PZmVh8YCywCLgwhFOV026RGHzOuUiU4+eSkwl+lSnDSSdr0ISIiIgVL58jf20AvM6seda0/sAWYWNiNZnYrcC1wcQhhUgFt9gfeivx5VghhczKdMrOjgSOAmcm0zwo9esC8ebBkScKmp57qZ/x++20x9EtERERKnHSGv0eArcBoM+thZlcCg4Fh0Rs3Iid5PBH190XAvfiU71Iz6xT1il6ENxo4BrgDaB7dLupZZ5rZi2Y20My6mdnV+EjhYuCpdP3wlOvRw9+TGNI791x/f/nlNPZHRERESqy0hb/IGr3uQHlgDH6yx3A8rEWrEGmTJ++ItsuAKTGvM6PanQpUxE/+iG2X53u87t8I4N3Id48DOhe2czjrHH001KuX1NRv48bQti289VbCpiIiIlIGpXPNHyGEOcApCdo0ifn7Mjz4JXq2JdHmczyAlmzlynkdl/HjfTuvFf7TTz8dhg716jC14m25ERERkTIr3aVeJFV69IDly+GrrxI2PfNM2LkT3nijGPolIiIiJYrCX0mRt+4vianfTp2gWTN44omETUVERKSMUfgrKRo3hubNkwp/5crBz3/uxZ4XLkx/10RERKTkUPgrSXr08ES3Y0fCphde6O+vv57eLomIiEjJovBXkvToARs2wPTpCZs2bw5HHQVjxhRDv0RERKTEUPgrSbp1852+SUz9Apx9NkycCOvWpblfIiIiUmIo/JUkdet6Eb8kw1/v3j5DrJp/IiIikkfhr6Tp0QOmTIFNmxI27dTJp3/vvddr/omIiIgo/JU0PXrA9u3w0UcJm5YvDw895KUBzznH60OLiIhI2abwV9KceCJUqpT01O8ZZ8CwYb72b9q0NPdNREREsp7CX0mz334eAN97L+lbLrsMqlSB559PX7dERESkZFD4K4l69IBPP4UVK5JqXqOG7/x9/nn4/vs0901ERESymsJfSdS9u7+//37St/zhD7BtG7RpA998k6Z+iYiISNZT+CuJ2reHmjWTXvcH0Lo1zJgBW7bAkCFp7JuIiIhkNYW/kqhCBS/4XIR1fwBHHglXX+3Tv/PmpalvIiIiktUU/kqqHj1g4UKv41IEN9/se0aOPx4mTUpT30RERCRrKfyVVOee64X8iriFt0EDmDoV6tSB/v399I/c3DT1UURERLKOwl9J1aABnHACvP12kW9t1Qr+8hdYtgzOPBMGDlQBaBERkbIiqfBnZs3NrHLkn7ua2XVmViu9XZOETjsNZs2CH38s8q1nngn/+IcvHRw92gtBv/kmLF2ahn6KiIhI1kh25G8UsNPMDgOeAJoCLyS6ycxamtl7ZrbZzJaZ2RAzK5/gng5m9qSZfRO5b56Z3WFmVeK0PdHMppnZFjNbaGbXxWlT2cweNLOfzGyTmb1pZk2S/N3ZrVcvf3/nnb26/aqrYNw4rxl9001w1lmQk6NpYBERkdIs2fC3K4SwA+gLjAgh3AA0LOwGM6sNjAcC0AcYAtwI3Jngu/oDzYGhwBnAw8AgYLfFbZEgOhZYCJwJPAoMM7NfxDzvIeAy4CbgPOAAYFy8MFnitG0LjRrBqFF7/Yjy5b1c4Pnn+27g5cth5MgU9lFERESySoUk2203swHApcDZkWsVE9xzFVAV6BdCWI8HrhrAYDO7P3ItnqEhhOijKyaYWS7wqJk1DiEsily/GVgGXBwJpu+b2aHAHWb2RAghmFkj4Arg5yGEZwDM7HM8MF4M/DPJ35+dypXz1Pbww7Bundf+2wuVKsFLL/m6v6OOggcf9DOB69dPcX9FREQk45Id+bscOB64J4Sw0MyaAs8luOd0YGxMyBuJB8IuBd0UE/zyfBJ5j44jpwOjI8Ev+vmNgKMjf/eMvI+Oev5SYFLk/pLvggv86I5XX93nR5nBvffCl19C8+bwzDMp6J+IiIhklaTCXwhhTgjhuhDCi5Hp3OohhPsS3HYkMDfmOYuBzZHPiuIEYBcwD8DMqgGHxD4fyCt6d2TU+5IQwsY47Yrah+x03HHQtCm8kHAJZlL69YPp030E8NJLYfjwlDxWREREskSyu30nmFkNM6sDfAY8aWbDEtxWG1gb5/qayGdJMbMGwG3As1GjiHk7jWOfvybqu1PWh6xmBhdd5Ee9LV+ekkfm5MB//wvnnQeDBsGUKSl5rIiIiGSBZKd9a0aCVz/gyRBCe6BHEvfFqx5nBVzfs6FZJeAlYCNwQ5LPj71epD6Y2ZVmNsPMZqxYEW8GOgsNHAi7dsG//52yR1asCE8+6eUEr7jCN4Fs2JCyx4uIiEiGJBv+KphZQ+AC4I0k71lD/ghdtJrEH43bjZkZ8AzQCjgjhLAm6uO8+2OfXzvm84L6UKugPoQQHgsh5IQQcurVq5eom9nhqKN8528RT/tIZP/9vRbgd9/BgAE+w7xlS0q/QkRERIpZsuFvCF5WZUEIYbqZNQPmJ7hnLjHr6szsEKAae67Vi2c4XiKmTwghdu3gJuD72OdH/T036v2QyBrB2HbJ9KHkuOgiX6w3P9H/WYrmnHNgzRp45BE/RrhzZ1ibMLqLiIhItkp2w8fLIYRjQghXR/7+NoRwboLb3gZ6mVn1qGv9gS3AxMJuNLNbgWvxMi6TCnl+35ii0f3xUPhl5O93I+99o559EHBS5P7SY8AAX/+Xoo0f0SpXhl/9Ch5/HL74Alq2hL59YdOmlH+ViIiIpFmyGz4amdkrkVMyfjSzUZEaeoV5BNgKjDazHmZ2JTAYGBZd/iVykscTUX9fBNyLT/kuNbNOUa/oedg/42VdnjWzbmZ2C/ArYEgIflJtCGEJfiLJCDO7xMxOw8u+LCJxqZqS5eCDoWtXn/pN00G9v/iFr/3LzfXKMr/9bVq+RkRERNIo2WnfJ4HXgYOAg4ExkWsFiqzR6w6Uj7S/E5/KvSOmaYVImzx5tfkuA6bEvM6Mev43wGnAYfgo3jXAjSGE2MLN1+FBchh+TN1qoGcIofQdYjZwoE/7pvGIjn79YPVquO46eOIJ+M9/0vZVIiIikgYWkhglMrNPQwhtEl0rbXJycsKMGTMy3Y3kbdsGHTr4yN9nn/k0cJrMnw8tWvg/3323l4SpWjVtXyciIiIJmNnMEEJOonbJjvytNLOLzax85HUxsGrfuigpV6kSXHONL8x75520ftXhh8PChX7C3O23w7mJVoCKiIhIVkg2/P0cL/OyHPgBOA8/8k2yzeWXw2GHwY03wo4didvvgyZNYMECOPFEePttmDo1rV8nIiIiKZDsbt/FIYTeIYR6IYT6IYRz8ILPkm0qVYI//9nrsjz+eNq/rkkTeOMNOOQQ3wHco4f/LSIiItkp2ZG/eAalrBeSWn36QJcu8Mc/wrp1af+6WrXg5Zd9oPG99+Dss70LI0dCw4awdGnauyAiIiJJ2pfwl77dBLJvzGDYMFi1Cu69t1i+8rjjYNkymDTJv/7117304PLlad18LCIiIkW0L+EvPcXkJDXatYOf/QyGD4eJhdbUTpmKFX3939Kl8PTTPiUMcNddvjZQREREMq/Q8GdmG8xsfZzXBrzmn2Sz4cOheXPfivv998X2tQ0beu5cuNBf27d7OZiffkr7HhQRERFJoNDwF0KoHkKoEedVPYRQobg6KXupdm147TXYuhV69oQffyz2LjRp4huQn3oKDjwQunVL2wEkIiIikoR9mfaVkqBFCxgzBhYt8p0Yq4q/POOwYXBm5GyWSZN8U8jy5bBzZ7F3RUREpMxT+CsLunaFl16Czz+HE06A2bOL9esrVfLyL1u2+JRwnz7QuDGcd54HwNWri7U7IiIiZZrCX1lx1lk+5LZqFbRp41WZi1mVKnDDDbB5s59E9+qrUKEC1K3rNalFREQk/RT+ypITT/Sj31q2hP794ZFHYMOGYu3Cb34DQ4eYZsJeAAAgAElEQVTCl1/CVVflXx82zDeFbNtWrN0REREpcyxo9X2BcnJywowZMzLdjdRbvBjOPx8+/tiPgnvuOS/UV8xCgO++8yLRJ5/sgbBBA58OPu88v7ZyJdSrV+xdExERKXHMbGYIISdRO438lUWHHuo7LwYN8o0gnTrBwQfDRx8VazfMoGlT35T8+edeG7BVKx+Q7NoVTjoJ6tcv9m6JiIiUagp/ZVXFivDgg1587+ST/XiOfv3goYcyMvdq5rUBx4/30b5ateC///XP/vEPf6lQtIiIyL5T+CvratWCCRNgzhw45BD47W+he/f85JUBNWvCW2/BH/7ggfDFF+Gaa6Bjx2KtVS0iIlIqqVCz+LDbUUfBrFnwwgtw9dXQubMfznvXXX5KSDE7/nh/rV4N++0HzZrBH//oYbBrV+9i/frF3i0REZESTxs+ClFqN3wksmED3HEHPPaYTw9fd51v083wzou77/bRwDzt28PMmT4qePPNUL68D16KiIiURclu+FD4K0SZDX95vv3W67GMGwf77w8XXQSDB3ul5gwIAdas8XrVV1+95+eNGvm6wEqVir9vIiIimabdvrLvmjWDd9/1rbjnnQf/+pfvFB4+HHbtKvbumEGdOp5Hly71Lkyc6GcGAyxZ4ieJLF/uLxEREdlTWsOfmbU0s/fMbLOZLTOzIWZWPsE9lczsz2b2kZltMbO4Q5NmFgp4bY1q06SANiNT/VtLtdat4cknPWk1a+YlYm64AbZvz1iXDjrIw+DJJ/to37ZtflLIuef6wGTbtl7P+sEHYf16Lyz98ssZ666IiEjWSNuGDzOrDYwH5gB9gObAg3jgvL2QW/cDfgF8DEwGTimg3fFxro0B4m1TvSnm+srC+i4FOOEEmDvXF9k99BB8+qmPDFaunNFuVavm7//+t2fU5cv9JLtjjvHrH3/sU8XgZwmX03i3iIiUYenc7XsVUBXoF0JYD4wzsxrAYDO7P3JtDyGEtWZWJ4QQzOw3FBD+QghTo/82sw7AAcCLcZrPi20ve8nMi+516gSXXeYH9j77LFx8caZ7Rvfu/gJ44AEYNQqmTs0PfuCjgT/84OsCTynof1aIiIiUYukcAzkdGBsT8kbigbBLYTeGvduFMgDYhI/+SbpdeqlvsQW4/np4553M9ifGTTfBlCnwwQe+A3jQIKhaFdq0gdNP95D47LO+iURERKQsSWf4OxKYG30hhLAY2Bz5LGXMzIDzgddCCJvjNHnSzHaa2Q9mNszMqqby+8us+++H99+HVavgjDPg9tshNzfTvdpN165+lPGDD8Krr3o5w4MO8s9+9jM4+2y44gro1g22bMloV0VERIpFOqd9awNr41xfE/kslU4CGuEji9G2Ag8D7wLrga7A7/D1h33iPcjMrgSuBDj00ENT3M1SqFs331HRvz/cc48vtnv8cT8ruGbNrFpg17OnH2QCsHAh/P73MDLq3zG33+6niFSuDCee6Nfq1fN1guUL3aYkIiJScqT7hI94k2pWwPV9MQAPlWN3+/IQfgB+E3Vpgpn9CPzdzNqEED6NfVAI4THgMfA6fynuZ+lUvbqfxzZqlE8Ht27t18uV83nXY47xY+SySNOmfmxcv35eznD6dBg2bPc21at7feu//tU3Ordpk5m+ioiIpFI6h2XWAPH+G78m8UcE94qZVQDOBUaFELYlcct/Iu/tUtUHiTj3XB9S69HD/961C7p08SG3jRszUhswkfPPh9/9zjeFTJ4Mf/+7L2Vs2dIPOrnnnvyBzddfz3RvRURE9l06w99cYtb2mdkhQDVi1gLuo+5APeLv8o0nxLxLKtWr5+VffvoJ/vQnP5h3+nQfRuvePX/eNcuUK+dnCV99tS9lnD0bXnvNj5O76CL4+mvo0we++irTPRUREdk36Qx/bwO9zKx61LX+wBZgYgq/ZwCwHJiQZPvzIu8zU9gHiWbmIfD//g82bcqvtTJhgk8Jn3gijB4Na1M2AJwWvXvDkCFeO/DVV30t4NVXw4wZfm34cPjxR8+5IiIiJUXazvaNFHmeA3wJDAWaAcOAESGE26PafQNMDCFcEXXtdHyE8DTgCnwnL8D0EMKiqHaVgR+Bp0II18fpw2CgOl7geT1wMnAz8FYI4dxEv6HMn+2bagsXwr33wiuv+A7hvGJ77dvDnXdm/a6Kxx/3o+ViZ68PPNCnidetg6efhlatPP+CHznXoAFUSPfqWhERKfOSPds3beEv0omWwN/w0zjWAv8EBocQdka1+Q6YEEK4LOZa4ziPvDyE8FRUu3OAV4Dj4xVxNrML8dM9DsfrCy4GXgDuCSFsjW0fS+EvTZYu9WGzsWPhyy/zr993n58i0r69Txdnofnz4Ykn4LTTPNg9//yeJQ6rVvVyMg88AH37wpVXwqOPZqa/IiJSdmRF+CvpFP6KwapVvqti+PD8a0ce6Wnp6KOhTp3M9S1J06bBrFm+1PHVV+O3efpp3/SsHcMiIpIuCn8poPBXjLZt8+22I0fCc8/5WsFKlXw77okn+lFyVbO/Nve6db5R5MAD/cS71at3nyb+8EM46aTM9U9EREovhb8UUPjLkHXr4I03PASOHetnsB12mNdb6dwZevXKX1SX5Xbt8l3EH3+cf+2dd/wniIiIpJLCXwoo/GWBHTt8KO2ee+CTT/zawQf7Doubb/a51oYN4Ze/9HIyWSg310vJ3H+/l44BX9bYoQP8+te+z+WoozLbRxERKfkU/lJA4S/L/PQTPPusD52NH7/7ZwcfDA895MX4snTX8K5d8NFHfhzya6/BvHn5RyH37etBsHv3zPZRRERKLoW/FFD4y2LffefHcfz5z7tfb9nSr51yClSpkpGuJWvWLPjXv3wG+5FHfJCzVy8fFbzsMqhfHypWzNqNzyIikmUU/lJA4a8E2LkTtmzx0cCXX/azhFes8M8OOwzOOQdq1vSg+O23WRsIN2yAG26AF17wn3PkkT6A+c038LOf+Yl5vXt7oekSstxRRESKmcJfCij8lUDbtnnxvXvv9eQUa8QIuPxyP7C3UaPi718Cubm+x+Wcc+J/fsIJ/tO6dCnefomISPZT+EsBhb8S7uuv4d//hi++8FHBWP/5D5yb8KCXjHj2Wc+u7drBggW+PvCxx/I/HzoUmjaF3/0OXnzRp4fbttWooIhIWabwlwIKf6XMpEm+UeSpp2DRovzrd9zhh/YeeGDGupaM7dt94PKWW+J//sorBY8YiohI6afwlwIKf6XYwoVwzTX5Z7NVqACXXurHcLRt64Wly5XLbB/jWLUK/vQnmDkTJkzY/bNLL4Vjj4WBA2HNGmjRYveRwBA0MigiUpop/KWAwl8ZsGuXTw8/8AA884wPr4GPAl52GZx3nofBLCsfs3AhXHihHxcXPR0c7b77/Azi/ff3ncW//CV8/rmfO1yhQvH2V0RE0k/hLwUU/sqYbdt87nT6dD+kd8ECv16jhq8NvPpqr8ycZdatg88+gyuv9LIwebWw81SuDFu3+j//7GeecceP9+WQ27fDk08Wf59FRCT1FP5SQOGvjPvkE/jb3zxdjRnjSalLF59P7drVKzNnYemYpUth7Vro2BGqVcuvfBOtaVMfPQSvL5hlA5siIrIXFP5SQOFP/mfpUp8anjYNZs/2UjGHHQYXXACnn+5HzDVunFXzqdu3e3fGjPHpXjO4/fY92z33HCxbBtdem5VZVkREkqTwlwIKfxLX1q1eS/DZZ/28tp07/XqdOj4tfOut0LmzD7/VqpU1w2q7dvlGkQoV4OyzvZj06tX5n99+O9x1V3LP0uYREZHso/CXAgp/ktDq1V6VecECP13k/ff3bNOypdcUPOwwL8iXBfLC24gR8N57Xvnmiy98g0ilStCtm5dGHD16zwo448ZBz57w1Vd+EomIiGQHhb8UUPiTIlu+3BPTr38d//MLLoDjj/c51iwZEQT48ksYMADmzvU1gHmuvNIPQunXzzdFH3CAz36//jo8/LCvHaxc2Y9SFhGRzFL4SwGFP9lrO3fChx9C1aowfDi89NLunw8ZAoMG+Y6MLBKC7wK+6SbYtMlnrgEOOQS+/97/uUEDz7gDB/rsd959IiKSWQp/KaDwJyn1+efw97/DE0/48Fq1atCjh9cS7NwZmjTJdA//JwSfCr7xRt/rMm1a4vYiIpJZWRH+zKwl8FfgeGAt8E/gzhDCzkLuqQTcA3QCcoAqIYQ9lpab2VPApXEecVQIYW5Uu5rACOAcoBzwBnBdCGFVov4r/ElabN7sR8299JLXE1y1yqeAGzf2MjJ9+vg8aosWme7p/7z7rndx1Sp44w1fxnjrrfmf33GHl5R5+OHM9VFEpKzLePgzs9rAbGAOMBRoDjwIDA8hxCk48b/7agELgY+BCsAphYS/44DLYz76NISQG9XuHeAI4CZgV6QvP4YQTkr0GxT+JO22bYPJk31DyLx5Xn05z6mnQq9evvCuevXM9bEA994Ljz4KixfnXxszBlq39k0kRxzh9bFbt/aRwZ07s6oSjohIqZMN4e9W4BagcQhhfeTaLcBgoEHetQLutRBCMLPfAH8tJPwdXdiPNLPjgclAlxDCh5FrHYFpwKkhhPEF3QsKf5IBEyf6ruHJk/21aZNfb9UK6tXz0jG//a2fQVynTmb7is9eN20KS5YU3Obxx33n8IoVnm379fMlj+3a+YkkWXiEsohIiZQN4e9DYFkI4cKoa4cCi4DeIYQxSTxjX8PfEODKEEKDmOvfAq+EEG4s7PsV/iSjduzwTSNPPOElZJYv3/3zwYP9feVKn4M96KBi7yL4ASg//eR1AkeNyi97mIy77opfeFpERIou2fCXzkmYI4Hdip6FEBab2ebIZwnDXxJamtl6oDIwHbgthDAxpg9z49z3VeQzkexVoYKv/curozJ5sh/HMWmSF+XLC38AU6fCCy/A4YcXezdr1vTXv//tf69f713fts272b27nzYSzxtv+Cl6Bx8MDz1UfH0WESnL0hn+auObPGKtiXy2rz7Bp2/nAPWAG4FxZtY5hPBxEn1oloI+iBSfE07wV55ly3yR3TffeHLKO3N44EA/aaRZs4ysFaxRw9/32w9OOgl+/NFrW/ft6/l1//19pLBFi913ER99tNfKvvPO/GPmcnN15JyISKqle/l1vDllK+B60R4cwl92e6jZm3gQ/D2+s3ev+mBmVwJXAhx66KH72k2R9DnoIPjVr/yff/Urnz+dPBl++Uu/Vrmyjw527gwnnpix89hqR/6n3rhxPiW8YoVPFTdq5CN+69bl/wTwQ1M2b4arr/Zjk//4R+jSxd/vv9+XO4qIyN5LZ/hbA9SKc70m8Ufj9kkIYYuZvQWcHdOHenGa1yqoDyGEx4DHwNf8pbqfImlx2GEwcqQf4Pv5536I75NP5tdjqV/fS8n8+KMXl/71rz0MFvMpI+XLe5HoBpFVuF98ARs2wM9/nj8K+M9/+vsLL/j7Lbd4UFyyxIPiww/7ZhEREdk76dxnN5eYdXVmdghQjfjr8FIlOrDt0YeIgtYCipRs5cpBmzZwxRXw0UceAh96yIfLpk/3uizXX+/zsBUqwOWXQwY3NR1yiNcM/PBDmD/fR/fOOQeGDvXPW7Xy6eEQvLtTp0L79l6AWkRE9k66S73cjJd62RC5dhMwhASlXqKeUeBu3zhtq+J1BT8NIfSLXMsr9XJSCGFS5FoOvjlEpV6kbNm82RPWrFk+1Bbt8sv9pJEuXXz0MMN1BUPwwtLHHps/SrhkiU8Fv/GG/926NYwdCw0bZq6fIiLZJBtKvdTG1+B9iRdWbgYMA0ZEF3k2s2+AiSGEK6KunY6PEJ4GXAGcH/loeghhUeTUjjeA54BvgAOAG4C2wIkhhBlRz3oHaMHuRZ5/UpFnKfMmTvQFdn//u5eS2bXLr1euDOefDzk5vsGkWTOoWzezfY1y4YX5O4vBZ7YXL/YZ7ZkzfXb717+GSy+FP/zBM21Owv8oFBEp+TIe/iKdaAn8jd2PdxscfbybmX0HTAghXBZzrXGcR14eQnjKzKoALwAdgPpALjAl8uypMX2oBQwH+rL78W4rE/Vf4U/KjLVrYcIEeOcdL9a3Mur/Pdq1g/vug7ZtYcsWn6vNC4oZqNC8Y4fXvh4xYvdqNwce6OsHN2/evf355/tJeiIipV1WhL+STuFPyqRt27x8zJNPwtNP+/bceNq399NGBg70bbwVKxZrN0PwDSBbtsABB+R//fz5ux+LXLu2ryt8+mkvkXj++V6GRkSktFH4SwGFPxFg6VI/d/iee3x6uCCffZY1dVjWrIFhw3wQ86uvdv/snnvgkku88HTjxrBxoxep3rbNA2SGKuKIiOwzhb8UUPgTiRECvPgijB7t08SrVuV/Vq6cbxw580zfspsFKWrhQu/K7Nn5x86VK+ddq1EDTj0V3nvPQ2LXrl5WZvFiePDBjJ2WJyKy1xT+UkDhTySBTZugalWfa737bj9+Lk/79nDjjdC7t8+z5oXBsWN9NDF2x3EabdwIjz/up4iMGAGHHgqPPFJw+7POgubNvdRMXs1sEZFsp/CXAgp/IkW0daufNPLmmx4Id+zY/fPKlb0NeAjs2bP4+xjxzDPwyiu+QeTddwtu16WLTxNfEalHsH69b5Q+++w9286f73tljj8+PX0WESmMwl8KKPyJ7INNm3yN4N/+5lPE27bt2aZaNS8187OfFXv38uzYAd9/D5Uq+ax1+fK+6TnW3Xd7pv3pJz+DeMIED4bR8gY39R+rIpIJCn8poPAnkiIh+JBZuXLwww9w3HE+F5s3Mli/PnTsCMuX+4K7k0/OWFd37fJ1gB07wpgxvnP4oos88EU74ADv9o035i9xrFPHP9uwAfbfv/j7LiJlm8JfCij8iaTZJ5/A/ff7ucR5ypf3ozxatIDTToPDD89c/yJ+/NFnqQ84wM8WbtHC1w4WZOZMnT8sIsVP4S8FFP5Eiklurp9FvGyZn9/2yiv523OPPtp3EG/YAL16+WK7DO8k3rnTByjLlYObb97z80su8ZrYN9yw+3WVkxGRdFL4SwGFP5EMyc2FKVO8rMz77+8553rEEb4l95proGnTjKapv/wFJk+Of4pIx47w/PPwxRdeFef662HQIBgypPj7KSKln8JfCij8iWSJ7dt9reBTT/nBvnPm5H924IEeBG+7DWrV8iM9AMaNg4YNfeSwGPzf/8HBB/vpd/ff77UF16+P33bxYvj00/g7hkVE9pbCXwoo/Ilksc8+8+23Y8fChx/mX+/Y0VPYK6/43/Pm+brBYh4dDMEDYO/ePuoXLwj+4he+xPHrr/3YuQ8+8L0wZ57pm0fq1y/WLotICafwlwIKfyIlxJdf+ojg5Mnw7bfw3Xe7f24GF1/suzTytuRmwI4dvg7wxRehQgXfSAJeA3vz5j3bH3cc/PWvvlbwxBM9UJp55h02zN+rVCne3yAi2UvhLwUU/kRKqOnTYcsWr7g8YgQsWeJnvYEPq/3xj36w78iRXr05Q3VZ3nwT6taFY4/1tYA7d/pJJPFccQW88ALk5PjeGPAQ2aoVtG5dfH0Wkeyl8JcCCn8ipcTy5XDvvT73+txz+TuJwUcC//xnH1Y74gg/nqN8+Yx19dNP4auvvLZgsr74AmbNgj59/JziM86ABg3S10cRyU4Kfymg8CdSCq1Y4ZtB3n3XRwO//dZHBqN17QqnnOJTxU2bZqSbX3/trxo1fADzkkt8wHLTJl/iOHFiftuKFX1PTJ7+/aFbNx8lbN/elz02buylaSpVKv7fIiLFQ+EvBRT+RMqAEPysttmzPQgOH77758ce6wnq22/h97/3RXadO++5gWTnTrjpJq/ufPHFKd9gkrfeL8/33/t075Yt8U/Oy1O+vHetbVuvqf3FF74BessWOPVUX4N47rkp7aqIZIjCXwoo/ImUUbt2eYG+6dN9lHDu3D3bdO/uuzZ69fLdxDVq5B/2+9RTcOmlxdLV2bPhH//wGoKjRnnYi1d4Os+gQR4cDz3UC1WDziIWKS0U/lJA4U9ECMFrtbz1FowfD88+m9x9q1fn1xwsZgsWeL1B8EA4d27hhaXPO8/LJLZpUzz9E5H0UPhLAYU/EYkrBN+V8Y9/+NrB5s1h6VL4/PPd2118MXTo4CeWHH449O2bse5OnepLHAcPhgsugDFjfFlj9BnFc+b4npdy5RI/c9cuf0+mrYgUD4W/FFD4E5GkheCF+374Ad55x9cHxipf3ofZfvlLL+KXoRIzeXbu9OWLU6fufr15cz+lpF8/32xSpUp+V3//e18iuWOHb0j5/HOfQhaRzMuK8GdmLYG/AscDa4F/AneGEHYWck8l4B6gE5ADVAkhWEyb8sBNwFlAy8jlmcBtIYTpMW3j/cBpIYROifqv8Ccie23hQq+/smqV1295/XUfHczTqpUX76teHY45xkcIM3BGcV5mXb0aHnrIlzpWreqhr3VrX1OYt2Hk6KP3nPXu0MFra1eokH9tyxYPjLE/Z/p03w+TwUo6IqVaxsOfmdUGZgNzgKFAc+BBYHgI4fZC7qsFLAQ+BioAp8QJf/sD3wNPAuOBAPwG6AGcEEKYGdU2RL73P1GP2BBCmJ3oNyj8iUhKLVkCjzzi225nzsw/4gM8WdWoASef7EX6Zs3yas61a8O//uW7jovJ5s1eLuatt3xkMO/0PDMPhPPn+6kkq1b59ZNO8mOV+/b1Npdf7ptJBg3ycPnJJ96ufXv43e/gvvuK7aeIlCnZEP5uBW4BGocQ1keu3QIMBhrkXSvgXgshBDP7DfDXAkb+aoQQ1kRdqwR8DXwQQrg86noArg0h/K2ov0HhT0TSZts2rzn43XdetO/112HatILbDxkCN97oi+y++soLUw8fDgcemJbuheCjgXXrwtq1XkuwalX/+nXrfBnjtGleWLog11zj9/3lLx4QP/rI6w3Gnr4nIqmRDeHvQ2BZCOHCqGuHAouA3iGEMUk8I274K6T9mwAhhDOjrin8iUjJsHAh/PQTjB3r6Wvw4OTu+/RTnzrOwLTxnDk+MFmjBvznP15HMJEjj/QTTPr189nvRELwpZQHHbTv/RUpzbIh/P0E/D2EMDjm+iZgcAjhz0k8I+nwZ2aV8WD5bAjh5qjrAVgF1MLXHb4O3BRCWJ3omQp/IpJxW7f6Irmnn/ap4AULPBzGatkSrr3WQ2AI0KIF1KtX7N39/nt44glf9zdunE/5Xn21b4xu2jT/iOU8gwbBn/7kJ4/kFbLescNPLLngAj/R5KyzfNBz7lzfjSwi8WVD+NsO3BxCGBFzfQnwTAghzla4PZ5RlPA3BPgdcEwIYV7U9aeAMcAKfAPJH4BvgY7xNp6Y2ZXAlQCHHnpo+0WLFiX6ahGR4vX66z7dO3s2TJrk87H//OeeR3107Og7L845x4v4zZzpOzTyilGD7+b46itfc5hiW7f6scqNG8OXX/r7xo2wbJnPWD//fH7bQYPgmWfg9NN9s/SKFXs+76CDfPp45MiUd1WkVMiW8HdTCOEvMdeXAk+FEG5L4hlJhT8zOxMf0bsxNmzGaXs68BbQN4TwamFtNfInIiXG2rU+Ijh3rietiRPjJyjw5PXCC76J5OmnfZjt2We9LmExmjbNc+y99xbtvpkzfdfwli0+2HnxxX4cc55t2+Dss71w9XHH+bpD1SOUsiDZ8FchUYN9sAafao1VE59+TQkz6wD8G3g0UfCLeAfYCLQDCg1/IiIlRq1avkU3T94c6sqVvhhv4kR47TXfqXHDDd5melRlrEsugWrV/Ni6rVuLZcr4uOP8dcklXitwv/08w1apAg884IObc+bAYYf58XU7dvh9r73m4e+ss+D99/3Y5ZYtoWZNOP98L0D97rvwwQeea2+80X/S4YfDddcV3J8QvH2lSmn/6SIZle4NH0tDCAOirh0CLCZFGz7MrAUwCZgC9CusfmDMfRuAYSGEOwprp5E/ESl1Nm70EjNVq/oawtGjvcrzV1/t3q5BA183OGiQb/k97DC/liG5uR72Jkzwmeq9Vdh/5d19t5ehmTYtuY0oItkmG0b+3gZuNrPqIYQNkWv9gS3AxH19uJk1BMYCC4ABRQh+pwH740WhRUTKlv33zz+u46CDPFGBF/d76y0/9+3VyKTIhx/mF/mrVMm35x5xhAdIgClTvMLzlVfCo4/mf8eOHZ7QKldOWberVPGjlZcv95HC8eOhd2/Ppv/+t28oScb330P9+vldW7vWRwp/+MGD36ZN/ryCzkLesMH/pUpThR2RYpHuIs9zgC/xIs/NgGHAiOgiz2b2DTAxhHBF1LXTgWrAacAVwPmRj6aHEBaZWVV8tK8JMBDfzZtnawjhk8hzrsQ3eYwHVuJTvbcD8/Bi0IUGRo38iUiZtmaNz7t+/73Pob7xhu/WiOe227ww4Ntv5xfy++c/YeBAT24//ACdOsHf/uYL8vbRli0+eBnt9dd9PeCQIXDHHT5w2aCBd+3bb72KDnhw27rVQ9y2bT7DHb088rTTfDlk795exqZVK3jySTjhBHj5ZQ+M+zL6KJIuGd/wEelES+Bv7H682+Do0GVm3wETQgiXxVxrHOeRl4cQnjKzJvgpIPEsCiE0iTynOzAEOBKoASwHXgH+EEJYl6j/Cn8iIjHWrPEwt3atrzP84QevyTKzkMmURo38dJM848b5ENrYsb5OsVu3lHUvBM+eTZvufn3HDg90y5Z51wtyzDF+XnEi27b5RpLY737iCf+uK67Y83ORdMuK8FfSKfyJiCQhBB86W73a67XMnu3DcLFq1fLUtHnz7tfffNOH2zZv9mfUru1nHq9d60N8r70GP/uZ7wjZB9u2+R6YpUu9GPXZZ/vG6CeegDp1fP/LnXfC8cf7yGBhHnzQj7P705/gnnt89HD27N0r5vzxj16ne29qb+/a5fdloG63lGAKfymg8Cciso927PBRvtmz/e7gM6gAABaRSURBVKDgqVM9XYFvv/3pJz8vLta558KoUXte79PHdy9XSOeSdXfssbuPAsZOD+e59FJf8tivny+bjDZ2rOfhxx/3AdMVKzzPHnronsFu27b8nca1a/u/TLHPEymMwl8KKPyJiKTJxo2+8WTzZnjxRfjVr5JfSHfEETB0KPTs6QX8NmyAAw7I/3zGDA+If/rTPg2d5eb6oOaWLbBqlW963m8/3yT94IO+UTpZgwfvflrfnXf6yODOnTBsmH/Hfff5IOjJJ+dnW/1XtBSFwl8KKPyJiBSjlSs9Ya1dCzff7NO9N93kG0e++abwewcO9EODJ0/2TSfgQ3IPP+z1C1Nsxw4PbQcf7BtMcnN9P8sDD/gmkcqV4dZbC3/Geef5QOYll+Rfa9HCD2N56SX/e/t2Hyw98cT4OTYEn67u0EFTxKLwlxIKfyIiWWTJEg+GzZv7fOivf+01CxOpWxdycmD9enjoIf/nPNEHCg8bBr/7nW8Hfu01r0C9DyZP9lntY47x3cJHHeUjfSF4Li2Ko47y+156CVq3zr/+0ku+Z+bZZ6FXL/8ZDRvuU7fZts1n4jNwNLTsI4W/FFD4ExHJcnnhbcECn0p+/nlPQ+vXwymnxL9nv/18K+6xx/qI4oEH+mK86B3J0R57DH75y5R2e/16+Pvf/Wi7gw/2U/mOPto3oDz3nJeo6dEj/r2HH+4/7Z13IO/4+egN1R99BPPmwZlnFq0u97x5nqsvushL2uzcqWPxShqFvxRQ+BMRKcF++smHr15+2YNhkyZewXnqVN/JUa2aV3VOlhlcdRU0buxVpkeO9FHFaFu2wOLF/r116iT96KlTfUSvXLn8+oXz53uZxVNP9e5fe23+dHAy6tTxe2vVgt/8xv8+6CDPy8uX54/slSvnm6xjR/qWLvX2P/0Ed90Ft9ziO5sHD44fKkPwI6PPOcdHDg88EMqXT76/su8U/lJA4U9EpJTKq6WyerWf6zZ1qi+4u+02D4n/+IcfKJzI/ff7xpPDDvPRxLPO8jqGAE8/7YmqZ8+UpKAQfDQuN9d3EDdr5iVrbrzRN6B8/70vkTzrLP/aBQvyRwbB1yH27euZNU+TJr7D+Ouv9/y+SZN8x/GwYb4EM8811/hSyliffOJnLp9xhs/KDxjgYVCKj8JfCij8iYiUYbNmebXoypV9pLBcOd/FkZvrO4q3bUv+WZMn+zDawIH+nAcegPbt80Ph11/7d+VVhv7iC09djz6aX/+liHbt8i7efbdn3A8/9JNOevb0JY2JDB/uaxVji15fcIG/DxrkA6etWvnR0JMmwR/+sHvbRFPHIcCIEV5z8bDDivb7ZE8Kfymg8CciInHt3On1Xz791BfLLV/ur6pVvUbhkCEwYULi5/TuvXtB7MMP9yKAubnw3/96wrr77j3PstsLubkeBmvU8OnkrVvhs8+87EzeiXyp1q2bL5m87jpfVtmwoR8FvWOH/6QFC3zfziGH+Gx5nrwTVJYv95HK66/XbuZkKPylgMKfiIjstaVLfTfyJ594weq8EjR74/e/97nXDz/0atE9e+Z/9txznqTatPEdG3spBN94UqUKvPeeb4z+0598tLBaNZ/FbtLEp5zT4ZNPYMwY78Pbb8Ppp3v1n3ff9fWOd90FNWum57tLC4W/FFD4ExGRlNqyJb+Oyvz5sHChJ63evX34a+lS30wydKiXmmnRwo8HiZWT40Np0Yv6wBcCPvyw37t+vW9OKarvvvPRzK5dfco7yvbt8MgjvjP5gw98FnvwYM+ijz3m6/3mzYPzz4fbb/fdy6lW0JpD8Hrf+++/+yjh6tUeXmN+Sqmk8JcCCn8iIpIRO3b4ekAzH/76//buPcyq6rzj+PfHRQQFQfGS1rvig1qtF9IGHiPxLqZKY6JA5LGSmFSs1cfWJNQ2iUnUPtbYaMRobWOstl5iq6mV4AW8R/BajCJIQEEzQUEzBBkVkFn9490ns9meYc6cOcOZ4fw+z7OfmbPOOmv2fjmc/Z6111r70Ufh+efjMnNzc9wZ5aWXOm5n4MBIOE86KRLBSZPikvVPfhKrQ595ZowpXL8epk+HsWNjuRyIu67ccEPVh7B2bVy+XbIk8toBA+L3XXdtuyHLhRdGD98rr1Q2v6Zkt91g2rRY//DeeyMsEGG66KLInefPj3GE++4bh3/ddRHSPn3aksNFi+Iq+4ABsVTObru1/zfnz4+r8m+/vel69eTkrwac/JmZWY+Vn7G8bl0kjL/4RdtYxLlzY42Yrgzo+/a3I8ks3cvusMPi9nqXXx7XgIuammI/SvfCK8722LAB+vZlyZKY/5Ifyvjuu9EZOnNmXFo+91x45plI5Pr3jx7GGTMqW9e7ZMyYmGsDccn4vfdizOOFF8aklxde2Lj+jBkxTnHBAjj00Ph58skxhHPy5LZ6550H115b+X5sLk7+asDJn5mZ9XobNkSiuHp1TMmdNy8StNmz4+exx8Z10V12gYkTY5mb/Nou7TnllFhEsKkpeiNHjy5/Pfaaa6L3cdq0eDx5cmRUu+8el6+l6CYcNKjDP5lSJIeHHx67uWZN9P5NmBDrda9bFz1/KcWhQtwn+aOPKgvV6afHpepXXum47pVXwqmnRm/iVVdFnlxa9vGddyLcc+dGZ+vmmqzi5K8GnPyZmVnDeu+9yKjuvDMuE0+YENdVX3opEsZnn43Map99ondxxYrq/9bAgdHNJsUMj9IdVcaMiX1YsSLKrr++4jUTFy2Ku5WceGLc7aS1Ne6RvHx55KstLdH0woUx0/i99yKx7Ns38uXOOvLI6C1cvTrCVbI5ewmd/NWAkz8zM7MKtLbG7Uduuqmt1/CAA2L67tSpG9cdPjy6xoraKy/aYYdYL+b442OMYqlbbeXKyOIOO6yqrraWlugMHTEiXv7yy9FjuGIFXHBBTG6ZMiU6SWfNirGLDz8c91Vuz+DBkVSedhqMHx9tdCcnfzXg5M/MzKyLUoqewdbWtqVoWlsjs1q2DIYNi17E22+PLrmmppgyDHEp+q234vcDD4xZF3nDh8NOO8X13sWL28onT45uuLvuihnQgwfH/eZ22gmOOSYGHN56a9yK5OKLYwmdoUMjOxsyJPYZYl8k1rf2pX/T0nh82WWxLs2Pf0ya8iXmzo3ewtI9mZuaYqL04sUxbvFzn4uxheeeG0Mlu5OTvxpw8mdmZlYHLS2x4GCfPjHDY/36tim2q1bFuokS3HdfJGqlGxYvXhzL3Mya1bk7sOQddFD0IpaSzk1pbY2fb78dPZL9+sV+pRRL+my33WZdndrJXw04+TMzM+uFPvwwZoMsXBi9fS0t0ctXWmNx2bK4Hvvmm7FgIcRsj/vvj4TtzTer+7sjRkT7pSnGEJe9Dzoo1pw57riuH9smVJr89evWvTAzMzPb3LbeOrYjjmgrO/TQjl+X0sZjCF98Me65/PLL0bP3ox9Fz+MJJ0RC+cQTsbW0xKXlDz9sSxyPOCKmHF9/fTw+++xuT/4q1a3Jn6QDgGuB0cAq4N+A76SU2p1HI2kr4DLgU8AoYOuUUtk+U0njgUuBEcBrWdt3FupsB1wN/DnQB7gPOD+l9G7Xjs7MzMy2KPlLtDvuGLOaoW2sYj6ZzMsnjRBTfktjB5cujUGBPWhl6D4dV6mOpGHALCAB44HvAn8LfKeDlw4CzgbeB55qr5KkI4D/Bh4BxgEzgNslHV+oeifwmazNs4BPAj/r1MGYmZmZtac4rm/IkLbyvfaKNQ0349i/jnRnz985wEDg1JTSauAhSUOASyT9U1b2MSmlVZK2TyklSecBR7fT/jeBx1NK52ePH5F0IPAt4EEASaOBE4CxKaXHs7Im4GlJx6aUZtXoWM3MzMx6hW7r+SN64x4oJHl3EAnh2E29MHUwC0XSAOAo4KeFp+4ARmeXekv78HYp8cvafgZ4PXvOzMzMrKF0Z/I3EliYL0gpvUFczh3Zxbb3AfoX2wcWEMe0X3v7kKvX1X0wMzMz63W6M/kbRkzyKGrOnutq25Rpv7nwfKf3QdJXJT0n6bmVK1d2cTfNzMzMepbuTP4gJnsUqZ3yWrSvMuWd2oeU0o0ppVEppVE77rhjDXbRzMzMrOfozuSvGRhapnw7yvfGdbZtyrRferwqV6/cPgytwT6YmZmZ9TrdmfwtpDCuTtJuwDaUH4fXGUuA9cX2s8etwKL29iFXr6v7YGZmZtbrdGfyNxM4QdLgXNkE4APgsa40nFJaS6zvd1rhqQnAnJTS73L7sEu2JiAAkkYBe2fPmZmZmTWU7lzn7wbgfOBuSVcQCdclwD/nl3+RtBh4LKX05VzZOKKH8JDs8Reyp55NKS3Lfv8e8Kikq4lFm0/KthNL7aSU5kh6ALhF0kVEr+AVwJNe48/MzMwaUbclfymlZknHANOB/yXG2P2ASACL+9C3UHY9sEfu8V3ZzynAzVn7T2ZJ4aXAVGLtvi+mlB4stDUx+7s3kbu9W7XHZWZmZtabqYP1lBuapJXAsg4rdt1w4J3N8HcaheNZe45pbTmeteeY1p5jWlubI557pJQ6XKrEyV8PIOm5lNKoeu/HlsLxrD3HtLYcz9pzTGvPMa2tnhTP7l7nz8zMzMx6ECd/ZmZmZg3EyV/PcGO9d2AL43jWnmNaW45n7TmmteeY1laPiafH/JmZmZk1EPf8mZmZmTUQJ391IukASbMlvS/pN5K+K6m43mHDk3SapHslNUlaI+l5SZPK1PuKpF9J+jCrc0yZOn8o6Z6snXckTZc0aPMcSc+UxWSNpCRp21y5JF0s6U1JH0h6XNIhZV7v9zEgqZ+kadl7cK2kX0v6QaGOY9oJkiZKeiF7fzZJukXSHxTqOKZlSNpX0r9IelHSBkmPlqlTs9hV2lZv1lFMJX1C0pXZ82uyWPx78T2b1a3oXFTJea1qKSVvm3kDhgG/AWYBxwHnAC3ApfXet562AXOA24DTgaOB7wMJ+OtcnYnABuCbwFHALcRtBP8oV6cf8DLwAvBZ4AzgbeA/6n2MdY7vbcBbWUy3zZX/XRbD84BjgZ8T61Ptkqvj93FbLG7NYvGXwFhgMnB5oY5jWnk8T8nek9OBY7J4Ls3+//ZxTDuM33jgTeIGCQuAR8vUqVnsKmmrt28dxRT4M2AxMC07D00EFmbv2/xna0XnIio4r3XpeOod0Ebcsv8ozcCQXNnXgffzZd4SwPAyZbcBr+cevwrclHvcB3gp/58JmJT9R9orV3Y6ccu/EfU+zjrF9tPAb4GLyCV/wNbA74Bv5epuA6zMf+j7ffz7Yz4RWA8csIk6jmnnYnoH8HyhrJQQ7u+Ydhi/fIL8X2USlZrFrtK2evtWQUyHAv0KZftl79m/yJVVdC6igvNaVzZf9q2PccADKXePY+LDbiDRa2CZlFK51dD/D9gJQNLexH+wn+Ze00p8OxuXe8044t7Qr+fKfgasI3c/6EaRXba5FvguH19xfgwwhI1j2kLcprEYU7+P4UvAwymlVzZRxzHtnP5EQpG3Kvup7Kdj2o7sM3BTahm7Stvq1TqKaUppVUrpo0LZIiJR3ilX3OG5qBPntao5+auPkUR38O+llN4g3iQj67JHvcsYoHSiLcVrYaHOAmB7STvm6hVjvg5YQmPG/BziG/t1ZZ4bSXwz/VWhfAEbx8rv4/CnwKJs3M7qbGzU3YWxPo5p59wEfFrSmZKGSNqPuI/7I7kk2zGtXi1jV2lbDUfSwcAg2s5XUNm5qNLzWtWc/NXHMNq+xeY1Z89ZO7IBr+NpS1pK8SrGs7nwvGOekbQD8D3gb1JK68tUGQasSSltKJQ3A4MkbZWr55jCLsBZwCHEOJ0pwOHAPZJKvVSOaSeklGYQMb2R6AF8FegLnJqr5phWr5axq7SthiKpD3ANkRQ/mHuq0phSpl7xvFa1fl1twKpWboFFtVNugKQ9ifF+/5NSurnwdDFuKlPumIfLgKdTSj/fRJ32YlV8zjGN4xUwPqX0LoCk5cBjxCSl2Vk9x7RCko4CbiBOnjOBnYFLiIT62Fyi4ZhWr5axq7StRvKPwGhgbJkv2ZW+Hys5r1XFyV99NBODQ4u2o/w3goYnaXviJPAGMfOvpPRNaCgbjxEqxXdVrl65mA+lgWIu6UBijNqRkkrxKC0xsJ2kDUSsBkvqW/g2PxR4P/dB5vdxaAZeKyV+mSeJMTwHEMmfY9o5VwH3ppS+USqQNI+4DDYeuBvHtCtqGbtK22oYks4FvgZMSik9XXi6knNRpee1qvmyb30spDAWQtJuxAyp4jX+hpetf3QfsBXw2WwwcUkpXsWxJSOB36aUVubqFWO+FbA3jRXzEcRg+jnEB0wzbZfQf01MAllIXGLbt/Da4lgVv4/DgnbKRczgA8e0s0YC8/IFKaVXiaUu9smKHNPq1TJ2lbbVECR9nvgc/XpK6c4yVSo5F1V6Xquak7/6mAmcIGlwrmwC8cH2WH12qWeS1I+Y4TQCGJdSWpF/PqX0GrAIOC33mj7Z45m5qjOBT0raI1d2CjAAuL979r5HepJYMyq/XZE9dxJwJfAUsJqNYzoIOJmPx9Tv4/hicrCk4bmyI4kk+8XssWPaOcuAw/IFkvYnZpkuzYoc0+rVMnaVtrXFk/QZ4D+B6Sml77dTrcNzUSfOa9Wrx3o5jb4RgzWXAw8RC2J+FVjDFrQmUg1jdSMxvuF84FOFbUBWp7Ru0j8QyczNfHyR5/7EwprPE0nOJGJx44Ze5DmLzVmUX+T5feCviEV2ZxBLwuycq+P3ccRhCDEcYQ5xwvsisRjsQ4V6jmnlMb2A6DW9KovDGcSkj9eBbRzTDuM3CPhCts0B5uceD6p17Cppq7dvHcUU2J+4HDuPWJEif67aJ9dOReciKjivdel46h3QRt2IsUAPZ/+Yy4nZl33rvV89bSO+5ad2tj1z9b5CrK6+llg5/Zgybe1KrKe0BniXuNw5qN7HWO+N8smfgL8nLgV/ADwBHFrmtX4fRxz2Je5q0EJcSr8ZGFao45hWHk8BU4FfZjFtAu4E9nZMK4rfnh19btYydpW21Zu3jmKa+xwtt91caKuicxEVnNeq3ZT9ATMzMzNrAB7zZ2ZmZtZAnPyZmZmZNRAnf2ZmZmYNxMmfmZmZWQNx8mdmZmbWQJz8mZmZmTUQJ39mZlWStEHSvNw2rYZt7ynp5Vq1Z2ZW0q/eO2Bm1ot9kFI6pN47YWbWGe75MzOrMUlLJV0h6Zls2zcr30PSbEm/zH7unpXvLOkeSS9m25isqb6S/lXSfEkPShpYt4Mysy2Gkz8zs+oNLFz2nZB7bnVK6U+A6cDVWdl04JaU0sHEDeB/mJX/EHgspfTHwGHEfUMBRgDXpZQOJO4b+vluPh4zawC+vZuZWZUkrUkpbVumfClwdErpNUn9gbdSSjtIegf4REppfVa+PKU0XNJKYNeU0tpcG3sCD6WURmSPvwH0Tyld2v1HZmZbMvf8mZl1j9TO7+3VKWdt7vcNeJy2mdWAkz8zs+4xIfdzTvb7U8DE7PczgCez32cDUwEk9ZU0ZHPtpJk1Hn+LNDOr3kBJ83KP708plZZ7GSDpaeJL9qSs7HzgJklfA1YCU7LyC4AbJX2Z6OGbCizv9r03s4bkMX9mZjWWjfkblVJ6p977YmZW5Mu+ZmZmZg3EPX9mZmZmDcQ9f2ZmZmYNxMmfmZmZWQNx8mdmZmbWQJz8mZmZmTUQJ39mZmZmDcTJn5mZmVkD+X8miOBkfY9YAgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load solutions/print_history.py\n",
    "fig, ax = plt.subplots(1, 1, figsize=FIG_SIZE)\n",
    "ax.plot(np.sqrt(model2_history.history['loss']), 'r')\n",
    "ax.plot(np.sqrt(model2_history.history['val_loss']), 'b' ,label='Val')\n",
    "ax.set_xlabel(r'Epoch', fontsize=FONT_SIZE)\n",
    "ax.set_ylabel(r'Loss', fontsize=FONT_SIZE)\n",
    "ax.legend()\n",
    "ax.tick_params(labelsize=LABEL_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How good is the model?  We can compute the $R^{2}$ score to get a sense of the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "735/735 [==============================] - 0s 149us/step\n",
      "Train loss: 0.023916935971399555\n",
      "Train R2: 0.6303734832840676\n",
      "315/315 [==============================] - 0s 31us/step\n",
      "Test loss: 0.026080995555671435\n",
      "Test R2: 0.6061098128714042\n"
     ]
    }
   ],
   "source": [
    "# evaluate the training and testing performance of your model \n",
    "# note: you should extract and check both the loss function and your evaluation metric\n",
    "from sklearn.metrics import r2_score as r2\n",
    "\n",
    "train_score = model.evaluate(X_train, Y_train, verbose=1)\n",
    "print('Train loss:', train_score)\n",
    "print('Train R2:', r2(Y_train, model.predict(X_train)))\n",
    "\n",
    "test_score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print('Test loss:', test_score)\n",
    "print('Test R2:', r2(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 4</b> </div>\n",
    "\n",
    "Let's add more layers. Fix the width $H$ and fit a MLP network with <b>multiple</b> hidden layers, each with the same width. Start with logistic or hyperbolic-tan activation functions for the hidden nodes and linear activation for the output. Experiment with the number of layers and observe the effect of this on the quality of the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/NN_10_layers_100_nodes.py\n",
    "\n",
    "# number of hidden nodes\n",
    "H =  100\n",
    "# input dimension\n",
    "input_dim = 1\n",
    "\n",
    "# create sequential multi-layer perceptron\n",
    "model3 = models.Sequential()\n",
    "# layer 0\n",
    "model3.add(layers.Dense(H, input_dim=input_dim,  \n",
    "                activation='tanh')) \n",
    "# layer 1\n",
    "model3.add(layers.Dense(H,\n",
    "                activation='tanh')) \n",
    "# layer 2\n",
    "model3.add(layers.Dense(H,\n",
    "                activation='tanh')) \n",
    "# layer 3\n",
    "model3.add(layers.Dense(H,  \n",
    "                activation='tanh')) \n",
    "# layer 4\n",
    "model3.add(layers.Dense(H,  \n",
    "                activation='tanh')) \n",
    "# layer 5\n",
    "model3.add(layers.Dense(H,  \n",
    "                activation='tanh')) \n",
    "# layer 6\n",
    "model3.add(layers.Dense(H,  \n",
    "                activation='tanh'))\n",
    "# layer 7\n",
    "model3.add(layers.Dense(H,  \n",
    "                activation='tanh'))\n",
    "# layer 8\n",
    "model3.add(layers.Dense(H,  \n",
    "                activation='tanh'))\n",
    "# layer 9\n",
    "model3.add(layers.Dense(H,  \n",
    "                activation='tanh'))\n",
    "# layer 10 - output\n",
    "model3.add(layers.Dense(1, \n",
    "                activation='linear')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/NN_10_layers_100_nodes.py\n",
    "\n",
    "# number of hidden nodes\n",
    "H =  100\n",
    "# input dimension\n",
    "input_dim = 1\n",
    "\n",
    "# create sequential multi-layer perceptron\n",
    "model3 = models.Sequential()\n",
    "\n",
    "#add 10 hidden layers\n",
    "for i in range(9):\n",
    "    model3.add(layers.Dense(H, input_dim=input_dim, activation='tanh')) \n",
    "\n",
    "# layer 10 - output\n",
    "model3.add(layers.Dense(1, \n",
    "                activation='linear')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the model\n",
    "model3.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 514 samples, validate on 221 samples\n",
      "Epoch 1/1500\n",
      "514/514 [==============================] - 1s 2ms/step - loss: 0.8693 - val_loss: 0.2847\n",
      "Epoch 2/1500\n",
      "514/514 [==============================] - 0s 41us/step - loss: 0.4050 - val_loss: 0.0686\n",
      "Epoch 3/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.1593 - val_loss: 0.2233\n",
      "Epoch 4/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.1484 - val_loss: 0.1235\n",
      "Epoch 5/1500\n",
      "514/514 [==============================] - 0s 45us/step - loss: 0.1252 - val_loss: 0.0815\n",
      "Epoch 6/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0615 - val_loss: 0.0942\n",
      "Epoch 7/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0948 - val_loss: 0.0656\n",
      "Epoch 8/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0529 - val_loss: 0.0931\n",
      "Epoch 9/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0926 - val_loss: 0.0699\n",
      "Epoch 10/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0528 - val_loss: 0.0634\n",
      "Epoch 11/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0590 - val_loss: 0.0646\n",
      "Epoch 12/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0507 - val_loss: 0.0525\n",
      "Epoch 13/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0462 - val_loss: 0.0604\n",
      "Epoch 14/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0526 - val_loss: 0.0380\n",
      "Epoch 15/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0373 - val_loss: 0.0582\n",
      "Epoch 16/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0515 - val_loss: 0.0358\n",
      "Epoch 17/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0294 - val_loss: 0.0356\n",
      "Epoch 18/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0293 - val_loss: 0.0306\n",
      "Epoch 19/1500\n",
      "514/514 [==============================] - 0s 61us/step - loss: 0.0252 - val_loss: 0.0267\n",
      "Epoch 20/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0225 - val_loss: 0.0235\n",
      "Epoch 21/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0209 - val_loss: 0.0222\n",
      "Epoch 22/1500\n",
      "514/514 [==============================] - 0s 60us/step - loss: 0.0226 - val_loss: 0.0215\n",
      "Epoch 23/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0176 - val_loss: 0.0189\n",
      "Epoch 24/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0167 - val_loss: 0.0158\n",
      "Epoch 25/1500\n",
      "514/514 [==============================] - 0s 66us/step - loss: 0.0150 - val_loss: 0.0169\n",
      "Epoch 26/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0179 - val_loss: 0.0166\n",
      "Epoch 27/1500\n",
      "514/514 [==============================] - 0s 66us/step - loss: 0.0164 - val_loss: 0.0230\n",
      "Epoch 28/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0207 - val_loss: 0.0173\n",
      "Epoch 29/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0149 - val_loss: 0.0129\n",
      "Epoch 30/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0129 - val_loss: 0.0150\n",
      "Epoch 31/1500\n",
      "514/514 [==============================] - 0s 44us/step - loss: 0.0153 - val_loss: 0.0137\n",
      "Epoch 32/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0120 - val_loss: 0.0248\n",
      "Epoch 33/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0341 - val_loss: 0.0246\n",
      "Epoch 34/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0316 - val_loss: 0.0283\n",
      "Epoch 35/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0205 - val_loss: 0.0405\n",
      "Epoch 36/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0401 - val_loss: 0.0326\n",
      "Epoch 37/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0467 - val_loss: 0.0200\n",
      "Epoch 38/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0205 - val_loss: 0.0402\n",
      "Epoch 39/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0309 - val_loss: 0.0330\n",
      "Epoch 40/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0323 - val_loss: 0.0240\n",
      "Epoch 41/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0174 - val_loss: 0.0327\n",
      "Epoch 42/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0302 - val_loss: 0.0186\n",
      "Epoch 43/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0217 - val_loss: 0.0190\n",
      "Epoch 44/1500\n",
      "514/514 [==============================] - 0s 60us/step - loss: 0.0157 - val_loss: 0.0251\n",
      "Epoch 45/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0200 - val_loss: 0.0167\n",
      "Epoch 46/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0167 - val_loss: 0.0123\n",
      "Epoch 47/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0123 - val_loss: 0.0119\n",
      "Epoch 48/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0133 - val_loss: 0.0216\n",
      "Epoch 49/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0187 - val_loss: 0.0125\n",
      "Epoch 50/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0144 - val_loss: 0.0144\n",
      "Epoch 51/1500\n",
      "514/514 [==============================] - 0s 60us/step - loss: 0.0132 - val_loss: 0.0167\n",
      "Epoch 52/1500\n",
      "514/514 [==============================] - 0s 62us/step - loss: 0.0152 - val_loss: 0.0186\n",
      "Epoch 53/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0153 - val_loss: 0.0128\n",
      "Epoch 54/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0123 - val_loss: 0.0133\n",
      "Epoch 55/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0120 - val_loss: 0.0173\n",
      "Epoch 56/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0181 - val_loss: 0.0123\n",
      "Epoch 57/1500\n",
      "514/514 [==============================] - 0s 45us/step - loss: 0.0131 - val_loss: 0.0296\n",
      "Epoch 58/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0289 - val_loss: 0.0109\n",
      "Epoch 59/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0118 - val_loss: 0.0120\n",
      "Epoch 60/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0112 - val_loss: 0.0140\n",
      "Epoch 61/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0143 - val_loss: 0.0231\n",
      "Epoch 62/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0259 - val_loss: 0.0129\n",
      "Epoch 63/1500\n",
      "514/514 [==============================] - 0s 63us/step - loss: 0.0131 - val_loss: 0.0124\n",
      "Epoch 64/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0127 - val_loss: 0.0183\n",
      "Epoch 65/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0148 - val_loss: 0.0116\n",
      "Epoch 66/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0131 - val_loss: 0.0107\n",
      "Epoch 67/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0118 - val_loss: 0.0144\n",
      "Epoch 68/1500\n",
      "514/514 [==============================] - 0s 60us/step - loss: 0.0125 - val_loss: 0.0194\n",
      "Epoch 69/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0203 - val_loss: 0.0106\n",
      "Epoch 70/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0108 - val_loss: 0.0177\n",
      "Epoch 71/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0151 - val_loss: 0.0176\n",
      "Epoch 72/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0158 - val_loss: 0.0147\n",
      "Epoch 73/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0133 - val_loss: 0.0116\n",
      "Epoch 74/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0119 - val_loss: 0.0246\n",
      "Epoch 75/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0229 - val_loss: 0.0185\n",
      "Epoch 76/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0200 - val_loss: 0.0135\n",
      "Epoch 77/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0148 - val_loss: 0.0179\n",
      "Epoch 78/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0148 - val_loss: 0.0167\n",
      "Epoch 79/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0169 - val_loss: 0.0197\n",
      "Epoch 80/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0191 - val_loss: 0.0138\n",
      "Epoch 81/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0132 - val_loss: 0.0109\n",
      "Epoch 82/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0111 - val_loss: 0.0129\n",
      "Epoch 83/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0123 - val_loss: 0.0131\n",
      "Epoch 84/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0128 - val_loss: 0.0113\n",
      "Epoch 85/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0116 - val_loss: 0.0113\n",
      "Epoch 86/1500\n",
      "514/514 [==============================] - 0s 62us/step - loss: 0.0110 - val_loss: 0.0110\n",
      "Epoch 87/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0103 - val_loss: 0.0120\n",
      "Epoch 88/1500\n",
      "514/514 [==============================] - 0s 67us/step - loss: 0.0118 - val_loss: 0.0144\n",
      "Epoch 89/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0135 - val_loss: 0.0152\n",
      "Epoch 90/1500\n",
      "514/514 [==============================] - 0s 43us/step - loss: 0.0136 - val_loss: 0.0154\n",
      "Epoch 91/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0231 - val_loss: 0.0164\n",
      "Epoch 92/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0241 - val_loss: 0.0256\n",
      "Epoch 93/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0195 - val_loss: 0.0525\n",
      "Epoch 94/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0532 - val_loss: 0.0123\n",
      "Epoch 95/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0212 - val_loss: 0.0278\n",
      "Epoch 96/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0193 - val_loss: 0.0296\n",
      "Epoch 97/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0288 - val_loss: 0.0137\n",
      "Epoch 98/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0160 - val_loss: 0.0200\n",
      "Epoch 99/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0154 - val_loss: 0.0154\n",
      "Epoch 100/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0175 - val_loss: 0.0118\n",
      "Epoch 101/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0114 - val_loss: 0.0147\n",
      "Epoch 102/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0128 - val_loss: 0.0108\n",
      "Epoch 103/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0112 - val_loss: 0.0111\n",
      "Epoch 104/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0109 - val_loss: 0.0152\n",
      "Epoch 105/1500\n",
      "514/514 [==============================] - 0s 65us/step - loss: 0.0139 - val_loss: 0.0134\n",
      "Epoch 106/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0118 - val_loss: 0.0131\n",
      "Epoch 107/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0166 - val_loss: 0.0115\n",
      "Epoch 108/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0117 - val_loss: 0.0154\n",
      "Epoch 109/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0132 - val_loss: 0.0104\n",
      "Epoch 110/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 111/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0103 - val_loss: 0.0115\n",
      "Epoch 112/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0113 - val_loss: 0.0120\n",
      "Epoch 113/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0127 - val_loss: 0.0144\n",
      "Epoch 114/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0137 - val_loss: 0.0163\n",
      "Epoch 115/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0127 - val_loss: 0.0181\n",
      "Epoch 116/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0204 - val_loss: 0.0225\n",
      "Epoch 117/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0209 - val_loss: 0.0124\n",
      "Epoch 118/1500\n",
      "514/514 [==============================] - 0s 61us/step - loss: 0.0126 - val_loss: 0.0168\n",
      "Epoch 119/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0144 - val_loss: 0.0201\n",
      "Epoch 120/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0238 - val_loss: 0.0126\n",
      "Epoch 121/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0118 - val_loss: 0.0294\n",
      "Epoch 122/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0289 - val_loss: 0.0205\n",
      "Epoch 123/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0190 - val_loss: 0.0220\n",
      "Epoch 124/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0226 - val_loss: 0.0135\n",
      "Epoch 125/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0149 - val_loss: 0.0127\n",
      "Epoch 126/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0143 - val_loss: 0.0144\n",
      "Epoch 127/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0142 - val_loss: 0.0236\n",
      "Epoch 128/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0255 - val_loss: 0.0135\n",
      "Epoch 129/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0115 - val_loss: 0.0216\n",
      "Epoch 130/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0221 - val_loss: 0.0165\n",
      "Epoch 131/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0173 - val_loss: 0.0201\n",
      "Epoch 132/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0152 - val_loss: 0.0132\n",
      "Epoch 133/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0131 - val_loss: 0.0124\n",
      "Epoch 134/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0130 - val_loss: 0.0121\n",
      "Epoch 135/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0139 - val_loss: 0.0199\n",
      "Epoch 136/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0207 - val_loss: 0.0121\n",
      "Epoch 137/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0122 - val_loss: 0.0111\n",
      "Epoch 138/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0109 - val_loss: 0.0117\n",
      "Epoch 139/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0121 - val_loss: 0.0121\n",
      "Epoch 140/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0127 - val_loss: 0.0120\n",
      "Epoch 141/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0115 - val_loss: 0.0131\n",
      "Epoch 142/1500\n",
      "514/514 [==============================] - 0s 44us/step - loss: 0.0112 - val_loss: 0.0114\n",
      "Epoch 143/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0105 - val_loss: 0.0141\n",
      "Epoch 144/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0136 - val_loss: 0.0112\n",
      "Epoch 145/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0107 - val_loss: 0.0103\n",
      "Epoch 146/1500\n",
      "514/514 [==============================] - 0s 45us/step - loss: 0.0103 - val_loss: 0.0152\n",
      "Epoch 147/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0129 - val_loss: 0.0136\n",
      "Epoch 148/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0182 - val_loss: 0.0105\n",
      "Epoch 149/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0160 - val_loss: 0.0218\n",
      "Epoch 150/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0153 - val_loss: 0.0122\n",
      "Epoch 151/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0119 - val_loss: 0.0134\n",
      "Epoch 152/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 153/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0148 - val_loss: 0.0137\n",
      "Epoch 154/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0136 - val_loss: 0.0127\n",
      "Epoch 155/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0118 - val_loss: 0.0109\n",
      "Epoch 156/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0115 - val_loss: 0.0142\n",
      "Epoch 157/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s 55us/step - loss: 0.0142 - val_loss: 0.0118\n",
      "Epoch 158/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0117 - val_loss: 0.0231\n",
      "Epoch 159/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0245 - val_loss: 0.0224\n",
      "Epoch 160/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0170 - val_loss: 0.0146\n",
      "Epoch 161/1500\n",
      "514/514 [==============================] - 0s 77us/step - loss: 0.0156 - val_loss: 0.0113\n",
      "Epoch 162/1500\n",
      "514/514 [==============================] - 0s 70us/step - loss: 0.0107 - val_loss: 0.0156\n",
      "Epoch 163/1500\n",
      "514/514 [==============================] - 0s 62us/step - loss: 0.0140 - val_loss: 0.0155\n",
      "Epoch 164/1500\n",
      "514/514 [==============================] - 0s 63us/step - loss: 0.0150 - val_loss: 0.0147\n",
      "Epoch 165/1500\n",
      "514/514 [==============================] - 0s 61us/step - loss: 0.0140 - val_loss: 0.0116\n",
      "Epoch 166/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0107 - val_loss: 0.0200\n",
      "Epoch 167/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0229 - val_loss: 0.0180\n",
      "Epoch 168/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0152 - val_loss: 0.0160\n",
      "Epoch 169/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0149 - val_loss: 0.0156\n",
      "Epoch 170/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0139 - val_loss: 0.0134\n",
      "Epoch 171/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0189 - val_loss: 0.0130\n",
      "Epoch 172/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0119 - val_loss: 0.0280\n",
      "Epoch 173/1500\n",
      "514/514 [==============================] - 0s 45us/step - loss: 0.0268 - val_loss: 0.0126\n",
      "Epoch 174/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0114 - val_loss: 0.0175\n",
      "Epoch 175/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0191 - val_loss: 0.0105\n",
      "Epoch 176/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0129 - val_loss: 0.0208\n",
      "Epoch 177/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0162 - val_loss: 0.0115\n",
      "Epoch 178/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0115 - val_loss: 0.0117\n",
      "Epoch 179/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0117 - val_loss: 0.0151\n",
      "Epoch 180/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0119 - val_loss: 0.0133\n",
      "Epoch 181/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0147 - val_loss: 0.0112\n",
      "Epoch 182/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0105 - val_loss: 0.0209\n",
      "Epoch 183/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0212 - val_loss: 0.0143\n",
      "Epoch 184/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0115 - val_loss: 0.0175\n",
      "Epoch 185/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0169 - val_loss: 0.0163\n",
      "Epoch 186/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0169 - val_loss: 0.0170\n",
      "Epoch 187/1500\n",
      "514/514 [==============================] - 0s 43us/step - loss: 0.0133 - val_loss: 0.0285\n",
      "Epoch 188/1500\n",
      "514/514 [==============================] - 0s 42us/step - loss: 0.0275 - val_loss: 0.0128\n",
      "Epoch 189/1500\n",
      "514/514 [==============================] - 0s 41us/step - loss: 0.0115 - val_loss: 0.0140\n",
      "Epoch 190/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0119 - val_loss: 0.0135\n",
      "Epoch 191/1500\n",
      "514/514 [==============================] - 0s 44us/step - loss: 0.0134 - val_loss: 0.0133\n",
      "Epoch 192/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0132 - val_loss: 0.0109\n",
      "Epoch 193/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0111 - val_loss: 0.0175\n",
      "Epoch 194/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0165 - val_loss: 0.0182\n",
      "Epoch 195/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0170 - val_loss: 0.0165\n",
      "Epoch 196/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0146 - val_loss: 0.0138\n",
      "Epoch 197/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0147 - val_loss: 0.0205\n",
      "Epoch 198/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0175 - val_loss: 0.0142\n",
      "Epoch 199/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0182 - val_loss: 0.0123\n",
      "Epoch 200/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0117 - val_loss: 0.0309\n",
      "Epoch 201/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0307 - val_loss: 0.0126\n",
      "Epoch 202/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0129 - val_loss: 0.0236\n",
      "Epoch 203/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0238 - val_loss: 0.0108\n",
      "Epoch 204/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0132 - val_loss: 0.0144\n",
      "Epoch 205/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0129 - val_loss: 0.0151\n",
      "Epoch 206/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0144 - val_loss: 0.0120\n",
      "Epoch 207/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0115 - val_loss: 0.0125\n",
      "Epoch 208/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0133 - val_loss: 0.0106\n",
      "Epoch 209/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0104 - val_loss: 0.0123\n",
      "Epoch 210/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0117 - val_loss: 0.0122\n",
      "Epoch 211/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0114 - val_loss: 0.0101\n",
      "Epoch 212/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 213/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0110 - val_loss: 0.0106\n",
      "Epoch 214/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 215/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0109 - val_loss: 0.0121\n",
      "Epoch 216/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0127 - val_loss: 0.0099\n",
      "Epoch 217/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0100 - val_loss: 0.0118\n",
      "Epoch 218/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 219/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0126 - val_loss: 0.0116\n",
      "Epoch 220/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0112 - val_loss: 0.0246\n",
      "Epoch 221/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0212 - val_loss: 0.0200\n",
      "Epoch 222/1500\n",
      "514/514 [==============================] - 0s 43us/step - loss: 0.0244 - val_loss: 0.0148\n",
      "Epoch 223/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0147 - val_loss: 0.0263\n",
      "Epoch 224/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0205 - val_loss: 0.0137\n",
      "Epoch 225/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0151 - val_loss: 0.0195\n",
      "Epoch 226/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0160 - val_loss: 0.0171\n",
      "Epoch 227/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0165 - val_loss: 0.0150\n",
      "Epoch 228/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0120 - val_loss: 0.0161\n",
      "Epoch 229/1500\n",
      "514/514 [==============================] - 0s 45us/step - loss: 0.0141 - val_loss: 0.0131\n",
      "Epoch 230/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0115 - val_loss: 0.0120\n",
      "Epoch 231/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0115 - val_loss: 0.0105\n",
      "Epoch 232/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0102 - val_loss: 0.0132\n",
      "Epoch 233/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0120 - val_loss: 0.0118\n",
      "Epoch 234/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0112 - val_loss: 0.0117\n",
      "Epoch 235/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0123 - val_loss: 0.0110\n",
      "Epoch 236/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0138 - val_loss: 0.0258\n",
      "Epoch 237/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0260 - val_loss: 0.0417\n",
      "Epoch 238/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0416 - val_loss: 0.0306\n",
      "Epoch 239/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0300 - val_loss: 0.0360\n",
      "Epoch 240/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0301 - val_loss: 0.0195\n",
      "Epoch 241/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0303 - val_loss: 0.0308\n",
      "Epoch 242/1500\n",
      "514/514 [==============================] - 0s 60us/step - loss: 0.0230 - val_loss: 0.0384\n",
      "Epoch 243/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0350 - val_loss: 0.0245\n",
      "Epoch 244/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0357 - val_loss: 0.0144\n",
      "Epoch 245/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0267 - val_loss: 0.0157\n",
      "Epoch 246/1500\n",
      "514/514 [==============================] - 0s 60us/step - loss: 0.0201 - val_loss: 0.0394\n",
      "Epoch 247/1500\n",
      "514/514 [==============================] - 0s 63us/step - loss: 0.0302 - val_loss: 0.0389\n",
      "Epoch 248/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0341 - val_loss: 0.0187\n",
      "Epoch 249/1500\n",
      "514/514 [==============================] - 0s 63us/step - loss: 0.0315 - val_loss: 0.0169\n",
      "Epoch 250/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0166 - val_loss: 0.0322\n",
      "Epoch 251/1500\n",
      "514/514 [==============================] - 0s 65us/step - loss: 0.0240 - val_loss: 0.0131\n",
      "Epoch 252/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0167 - val_loss: 0.0171\n",
      "Epoch 253/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0166 - val_loss: 0.0192\n",
      "Epoch 254/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0178 - val_loss: 0.0131\n",
      "Epoch 255/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0124 - val_loss: 0.0142\n",
      "Epoch 256/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0161 - val_loss: 0.0126\n",
      "Epoch 257/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0143 - val_loss: 0.0124\n",
      "Epoch 258/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0118 - val_loss: 0.0159\n",
      "Epoch 259/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0166 - val_loss: 0.0115\n",
      "Epoch 260/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0134 - val_loss: 0.0280\n",
      "Epoch 261/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0227 - val_loss: 0.0124\n",
      "Epoch 262/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0134 - val_loss: 0.0201\n",
      "Epoch 263/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0174 - val_loss: 0.0172\n",
      "Epoch 264/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0172 - val_loss: 0.0199\n",
      "Epoch 265/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0157 - val_loss: 0.0175\n",
      "Epoch 266/1500\n",
      "514/514 [==============================] - 0s 61us/step - loss: 0.0169 - val_loss: 0.0105\n",
      "Epoch 267/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0106 - val_loss: 0.0153\n",
      "Epoch 268/1500\n",
      "514/514 [==============================] - 0s 61us/step - loss: 0.0146 - val_loss: 0.0125\n",
      "Epoch 269/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0116 - val_loss: 0.0151\n",
      "Epoch 270/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0133 - val_loss: 0.0224\n",
      "Epoch 271/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0185 - val_loss: 0.0229\n",
      "Epoch 272/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0181 - val_loss: 0.0234\n",
      "Epoch 273/1500\n",
      "514/514 [==============================] - 0s 45us/step - loss: 0.0172 - val_loss: 0.0193\n",
      "Epoch 274/1500\n",
      "514/514 [==============================] - 0s 63us/step - loss: 0.0159 - val_loss: 0.0171\n",
      "Epoch 275/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0145 - val_loss: 0.0135\n",
      "Epoch 276/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0137 - val_loss: 0.0172\n",
      "Epoch 277/1500\n",
      "514/514 [==============================] - 0s 60us/step - loss: 0.0142 - val_loss: 0.0126\n",
      "Epoch 278/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0134 - val_loss: 0.0127\n",
      "Epoch 279/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0121 - val_loss: 0.0110\n",
      "Epoch 280/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0105 - val_loss: 0.0113\n",
      "Epoch 281/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0104 - val_loss: 0.0109\n",
      "Epoch 282/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0103 - val_loss: 0.0109\n",
      "Epoch 283/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0112 - val_loss: 0.0114\n",
      "Epoch 284/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0111 - val_loss: 0.0159\n",
      "Epoch 285/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0136 - val_loss: 0.0110\n",
      "Epoch 286/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0116 - val_loss: 0.0125\n",
      "Epoch 287/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0118 - val_loss: 0.0158\n",
      "Epoch 288/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0183 - val_loss: 0.0167\n",
      "Epoch 289/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0130 - val_loss: 0.0229\n",
      "Epoch 290/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0300 - val_loss: 0.0138\n",
      "Epoch 291/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0123 - val_loss: 0.0226\n",
      "Epoch 292/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0224 - val_loss: 0.0207\n",
      "Epoch 293/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0269 - val_loss: 0.0126\n",
      "Epoch 294/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0127 - val_loss: 0.0307\n",
      "Epoch 295/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0288 - val_loss: 0.0392\n",
      "Epoch 296/1500\n",
      "514/514 [==============================] - 0s 45us/step - loss: 0.0383 - val_loss: 0.0426\n",
      "Epoch 297/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0390 - val_loss: 0.0315\n",
      "Epoch 298/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0302 - val_loss: 0.0325\n",
      "Epoch 299/1500\n",
      "514/514 [==============================] - 0s 43us/step - loss: 0.0298 - val_loss: 0.0282\n",
      "Epoch 300/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0278 - val_loss: 0.0924\n",
      "Epoch 301/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0771 - val_loss: 0.0510\n",
      "Epoch 302/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0695 - val_loss: 0.0359\n",
      "Epoch 303/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0241 - val_loss: 0.0455\n",
      "Epoch 304/1500\n",
      "514/514 [==============================] - 0s 61us/step - loss: 0.0373 - val_loss: 0.0520\n",
      "Epoch 305/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0556 - val_loss: 0.0176\n",
      "Epoch 306/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0271 - val_loss: 0.0158\n",
      "Epoch 307/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0182 - val_loss: 0.0302\n",
      "Epoch 308/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0249 - val_loss: 0.0230\n",
      "Epoch 309/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0182 - val_loss: 0.0127\n",
      "Epoch 310/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0163 - val_loss: 0.0131\n",
      "Epoch 311/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0166 - val_loss: 0.0220\n",
      "Epoch 312/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0171 - val_loss: 0.0109\n",
      "Epoch 313/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s 49us/step - loss: 0.0103 - val_loss: 0.0133\n",
      "Epoch 314/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0119 - val_loss: 0.0138\n",
      "Epoch 315/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0114 - val_loss: 0.0194\n",
      "Epoch 316/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0194 - val_loss: 0.0203\n",
      "Epoch 317/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0150 - val_loss: 0.0163\n",
      "Epoch 318/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0167 - val_loss: 0.0110\n",
      "Epoch 319/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0133 - val_loss: 0.0228\n",
      "Epoch 320/1500\n",
      "514/514 [==============================] - 0s 62us/step - loss: 0.0178 - val_loss: 0.0105\n",
      "Epoch 321/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0129 - val_loss: 0.0106\n",
      "Epoch 322/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0107 - val_loss: 0.0136\n",
      "Epoch 323/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0121 - val_loss: 0.0112\n",
      "Epoch 324/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0105 - val_loss: 0.0120\n",
      "Epoch 325/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0129 - val_loss: 0.0122\n",
      "Epoch 326/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0111 - val_loss: 0.0131\n",
      "Epoch 327/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0122 - val_loss: 0.0124\n",
      "Epoch 328/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0103 - val_loss: 0.0128\n",
      "Epoch 329/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0152 - val_loss: 0.0158\n",
      "Epoch 330/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0148 - val_loss: 0.0102\n",
      "Epoch 331/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0099 - val_loss: 0.0166\n",
      "Epoch 332/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0153 - val_loss: 0.0136\n",
      "Epoch 333/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0114 - val_loss: 0.0128\n",
      "Epoch 334/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0133 - val_loss: 0.0167\n",
      "Epoch 335/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0140 - val_loss: 0.0159\n",
      "Epoch 336/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0131 - val_loss: 0.0131\n",
      "Epoch 337/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0108 - val_loss: 0.0124\n",
      "Epoch 338/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0112 - val_loss: 0.0111\n",
      "Epoch 339/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0120 - val_loss: 0.0137\n",
      "Epoch 340/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0146 - val_loss: 0.0108\n",
      "Epoch 341/1500\n",
      "514/514 [==============================] - 0s 61us/step - loss: 0.0115 - val_loss: 0.0145\n",
      "Epoch 342/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0133 - val_loss: 0.0104\n",
      "Epoch 343/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0105 - val_loss: 0.0098\n",
      "Epoch 344/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0098 - val_loss: 0.0127\n",
      "Epoch 345/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0122 - val_loss: 0.0118\n",
      "Epoch 346/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0100 - val_loss: 0.0109\n",
      "Epoch 347/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 348/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0100 - val_loss: 0.0124\n",
      "Epoch 349/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0109 - val_loss: 0.0108\n",
      "Epoch 350/1500\n",
      "514/514 [==============================] - 0s 61us/step - loss: 0.0100 - val_loss: 0.0109\n",
      "Epoch 351/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0102 - val_loss: 0.0125\n",
      "Epoch 352/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0133 - val_loss: 0.0136\n",
      "Epoch 353/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0110 - val_loss: 0.0135\n",
      "Epoch 354/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0135 - val_loss: 0.0102\n",
      "Epoch 355/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0099 - val_loss: 0.0135\n",
      "Epoch 356/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0117 - val_loss: 0.0104\n",
      "Epoch 357/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 358/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0100 - val_loss: 0.0125\n",
      "Epoch 359/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0118 - val_loss: 0.0134\n",
      "Epoch 360/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0157 - val_loss: 0.0115\n",
      "Epoch 361/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0118 - val_loss: 0.0130\n",
      "Epoch 362/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0119 - val_loss: 0.0128\n",
      "Epoch 363/1500\n",
      "514/514 [==============================] - 0s 40us/step - loss: 0.0129 - val_loss: 0.0136\n",
      "Epoch 364/1500\n",
      "514/514 [==============================] - 0s 42us/step - loss: 0.0133 - val_loss: 0.0120\n",
      "Epoch 365/1500\n",
      "514/514 [==============================] - 0s 42us/step - loss: 0.0116 - val_loss: 0.0117\n",
      "Epoch 366/1500\n",
      "514/514 [==============================] - 0s 67us/step - loss: 0.0106 - val_loss: 0.0157\n",
      "Epoch 367/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0129 - val_loss: 0.0176\n",
      "Epoch 368/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0137 - val_loss: 0.0180\n",
      "Epoch 369/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0171 - val_loss: 0.0172\n",
      "Epoch 370/1500\n",
      "514/514 [==============================] - 0s 44us/step - loss: 0.0124 - val_loss: 0.0174\n",
      "Epoch 371/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0194 - val_loss: 0.0139\n",
      "Epoch 372/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0131 - val_loss: 0.0150\n",
      "Epoch 373/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0155 - val_loss: 0.0122\n",
      "Epoch 374/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0105 - val_loss: 0.0153\n",
      "Epoch 375/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0171 - val_loss: 0.0105\n",
      "Epoch 376/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0102 - val_loss: 0.0145\n",
      "Epoch 377/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0132 - val_loss: 0.0099\n",
      "Epoch 378/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0106 - val_loss: 0.0157\n",
      "Epoch 379/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0163 - val_loss: 0.0102\n",
      "Epoch 380/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0113 - val_loss: 0.0144\n",
      "Epoch 381/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0114 - val_loss: 0.0103\n",
      "Epoch 382/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0100 - val_loss: 0.0103\n",
      "Epoch 383/1500\n",
      "514/514 [==============================] - 0s 60us/step - loss: 0.0097 - val_loss: 0.0118\n",
      "Epoch 384/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0104 - val_loss: 0.0113\n",
      "Epoch 385/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0105 - val_loss: 0.0110\n",
      "Epoch 386/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 387/1500\n",
      "514/514 [==============================] - 0s 62us/step - loss: 0.0107 - val_loss: 0.0125\n",
      "Epoch 388/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0137 - val_loss: 0.0109\n",
      "Epoch 389/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 390/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0106 - val_loss: 0.0105\n",
      "Epoch 391/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0097 - val_loss: 0.0107\n",
      "Epoch 392/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0112 - val_loss: 0.0103\n",
      "Epoch 393/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 394/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0095 - val_loss: 0.0102\n",
      "Epoch 395/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0098 - val_loss: 0.0112\n",
      "Epoch 396/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0101 - val_loss: 0.0097\n",
      "Epoch 397/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0096 - val_loss: 0.0105\n",
      "Epoch 398/1500\n",
      "514/514 [==============================] - 0s 67us/step - loss: 0.0106 - val_loss: 0.0126\n",
      "Epoch 399/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0107 - val_loss: 0.0137\n",
      "Epoch 400/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0111 - val_loss: 0.0136\n",
      "Epoch 401/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0110 - val_loss: 0.0133\n",
      "Epoch 402/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0127 - val_loss: 0.0146\n",
      "Epoch 403/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0134 - val_loss: 0.0104\n",
      "Epoch 404/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0098 - val_loss: 0.0161\n",
      "Epoch 405/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0160 - val_loss: 0.0121\n",
      "Epoch 406/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0105 - val_loss: 0.0164\n",
      "Epoch 407/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0189 - val_loss: 0.0121\n",
      "Epoch 408/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0113 - val_loss: 0.0126\n",
      "Epoch 409/1500\n",
      "514/514 [==============================] - 0s 61us/step - loss: 0.0112 - val_loss: 0.0107\n",
      "Epoch 410/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 411/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0110 - val_loss: 0.0097\n",
      "Epoch 412/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0098 - val_loss: 0.0100\n",
      "Epoch 413/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 414/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0112 - val_loss: 0.0111\n",
      "Epoch 415/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0112 - val_loss: 0.0101\n",
      "Epoch 416/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0097 - val_loss: 0.0103\n",
      "Epoch 417/1500\n",
      "514/514 [==============================] - 0s 62us/step - loss: 0.0095 - val_loss: 0.0099\n",
      "Epoch 418/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0097 - val_loss: 0.0131\n",
      "Epoch 419/1500\n",
      "514/514 [==============================] - 0s 65us/step - loss: 0.0127 - val_loss: 0.0148\n",
      "Epoch 420/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0130 - val_loss: 0.0112\n",
      "Epoch 421/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0108 - val_loss: 0.0099\n",
      "Epoch 422/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0100 - val_loss: 0.0111\n",
      "Epoch 423/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0105 - val_loss: 0.0120\n",
      "Epoch 424/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 425/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0097 - val_loss: 0.0107\n",
      "Epoch 426/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0108 - val_loss: 0.0105\n",
      "Epoch 427/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0099 - val_loss: 0.0108\n",
      "Epoch 428/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0100 - val_loss: 0.0121\n",
      "Epoch 429/1500\n",
      "514/514 [==============================] - 0s 70us/step - loss: 0.0119 - val_loss: 0.0123\n",
      "Epoch 430/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 431/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 432/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 433/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0097 - val_loss: 0.0104\n",
      "Epoch 434/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0097 - val_loss: 0.0102\n",
      "Epoch 435/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0095 - val_loss: 0.0122\n",
      "Epoch 436/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0112 - val_loss: 0.0143\n",
      "Epoch 437/1500\n",
      "514/514 [==============================] - 0s 62us/step - loss: 0.0124 - val_loss: 0.0130\n",
      "Epoch 438/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0161 - val_loss: 0.0220\n",
      "Epoch 439/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0214 - val_loss: 0.0099\n",
      "Epoch 440/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0108 - val_loss: 0.0168\n",
      "Epoch 441/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0141 - val_loss: 0.0100\n",
      "Epoch 442/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0115 - val_loss: 0.0162\n",
      "Epoch 443/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0146 - val_loss: 0.0143\n",
      "Epoch 444/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0144 - val_loss: 0.0202\n",
      "Epoch 445/1500\n",
      "514/514 [==============================] - 0s 71us/step - loss: 0.0146 - val_loss: 0.0181\n",
      "Epoch 446/1500\n",
      "514/514 [==============================] - 0s 65us/step - loss: 0.0215 - val_loss: 0.0148\n",
      "Epoch 447/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0128 - val_loss: 0.0222\n",
      "Epoch 448/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0205 - val_loss: 0.0111\n",
      "Epoch 449/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0108 - val_loss: 0.0243\n",
      "Epoch 450/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0216 - val_loss: 0.0156\n",
      "Epoch 451/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0139 - val_loss: 0.0172\n",
      "Epoch 452/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0131 - val_loss: 0.0172\n",
      "Epoch 453/1500\n",
      "514/514 [==============================] - 0s 44us/step - loss: 0.0156 - val_loss: 0.0103\n",
      "Epoch 454/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0103 - val_loss: 0.0175\n",
      "Epoch 455/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0163 - val_loss: 0.0137\n",
      "Epoch 456/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0116 - val_loss: 0.0104\n",
      "Epoch 457/1500\n",
      "514/514 [==============================] - 0s 44us/step - loss: 0.0111 - val_loss: 0.0158\n",
      "Epoch 458/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0163 - val_loss: 0.0242\n",
      "Epoch 459/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0203 - val_loss: 0.0259\n",
      "Epoch 460/1500\n",
      "514/514 [==============================] - 0s 45us/step - loss: 0.0203 - val_loss: 0.0219\n",
      "Epoch 461/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0183 - val_loss: 0.0178\n",
      "Epoch 462/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0149 - val_loss: 0.0170\n",
      "Epoch 463/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0151 - val_loss: 0.0150\n",
      "Epoch 464/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0130 - val_loss: 0.0121\n",
      "Epoch 465/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0118 - val_loss: 0.0128\n",
      "Epoch 466/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0131 - val_loss: 0.0185\n",
      "Epoch 467/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0205 - val_loss: 0.0130\n",
      "Epoch 468/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0141 - val_loss: 0.0211\n",
      "Epoch 469/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s 47us/step - loss: 0.0217 - val_loss: 0.0101\n",
      "Epoch 470/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0108 - val_loss: 0.0106\n",
      "Epoch 471/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0107 - val_loss: 0.0180\n",
      "Epoch 472/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0197 - val_loss: 0.0124\n",
      "Epoch 473/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0123 - val_loss: 0.0289\n",
      "Epoch 474/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0243 - val_loss: 0.0116\n",
      "Epoch 475/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0116 - val_loss: 0.0132\n",
      "Epoch 476/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0117 - val_loss: 0.0161\n",
      "Epoch 477/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0173 - val_loss: 0.0216\n",
      "Epoch 478/1500\n",
      "514/514 [==============================] - 0s 60us/step - loss: 0.0165 - val_loss: 0.0125\n",
      "Epoch 479/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0170 - val_loss: 0.0245\n",
      "Epoch 480/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0234 - val_loss: 0.0120\n",
      "Epoch 481/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0144 - val_loss: 0.0310\n",
      "Epoch 482/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0238 - val_loss: 0.0100\n",
      "Epoch 483/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0111 - val_loss: 0.0137\n",
      "Epoch 484/1500\n",
      "514/514 [==============================] - 0s 45us/step - loss: 0.0131 - val_loss: 0.0143\n",
      "Epoch 485/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0155 - val_loss: 0.0143\n",
      "Epoch 486/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0121 - val_loss: 0.0149\n",
      "Epoch 487/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0160 - val_loss: 0.0112\n",
      "Epoch 488/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 489/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0104 - val_loss: 0.0103\n",
      "Epoch 490/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 491/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 492/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0096 - val_loss: 0.0106\n",
      "Epoch 493/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0118 - val_loss: 0.0167\n",
      "Epoch 494/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0189 - val_loss: 0.0152\n",
      "Epoch 495/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0140 - val_loss: 0.0195\n",
      "Epoch 496/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0174 - val_loss: 0.0141\n",
      "Epoch 497/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0112 - val_loss: 0.0139\n",
      "Epoch 498/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0123 - val_loss: 0.0122\n",
      "Epoch 499/1500\n",
      "514/514 [==============================] - 0s 62us/step - loss: 0.0102 - val_loss: 0.0113\n",
      "Epoch 500/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0097 - val_loss: 0.0102\n",
      "Epoch 501/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0097 - val_loss: 0.0111\n",
      "Epoch 502/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0111 - val_loss: 0.0125\n",
      "Epoch 503/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0111 - val_loss: 0.0108\n",
      "Epoch 504/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0122 - val_loss: 0.0146\n",
      "Epoch 505/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0155 - val_loss: 0.0151\n",
      "Epoch 506/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0127 - val_loss: 0.0212\n",
      "Epoch 507/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0164 - val_loss: 0.0175\n",
      "Epoch 508/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0128 - val_loss: 0.0144\n",
      "Epoch 509/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0113 - val_loss: 0.0140\n",
      "Epoch 510/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0123 - val_loss: 0.0186\n",
      "Epoch 511/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0162 - val_loss: 0.0135\n",
      "Epoch 512/1500\n",
      "514/514 [==============================] - 0s 61us/step - loss: 0.0118 - val_loss: 0.0110\n",
      "Epoch 513/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0102 - val_loss: 0.0135\n",
      "Epoch 514/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0133 - val_loss: 0.0171\n",
      "Epoch 515/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0160 - val_loss: 0.0164\n",
      "Epoch 516/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0158 - val_loss: 0.0148\n",
      "Epoch 517/1500\n",
      "514/514 [==============================] - 0s 42us/step - loss: 0.0149 - val_loss: 0.0113\n",
      "Epoch 518/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0112 - val_loss: 0.0117\n",
      "Epoch 519/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0123 - val_loss: 0.0180\n",
      "Epoch 520/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0187 - val_loss: 0.0149\n",
      "Epoch 521/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0137 - val_loss: 0.0165\n",
      "Epoch 522/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0134 - val_loss: 0.0253\n",
      "Epoch 523/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0205 - val_loss: 0.0317\n",
      "Epoch 524/1500\n",
      "514/514 [==============================] - 0s 61us/step - loss: 0.0239 - val_loss: 0.0246\n",
      "Epoch 525/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0189 - val_loss: 0.0213\n",
      "Epoch 526/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0161 - val_loss: 0.0150\n",
      "Epoch 527/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0133 - val_loss: 0.0138\n",
      "Epoch 528/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0127 - val_loss: 0.0193\n",
      "Epoch 529/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0204 - val_loss: 0.0128\n",
      "Epoch 530/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0147 - val_loss: 0.0242\n",
      "Epoch 531/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0197 - val_loss: 0.0218\n",
      "Epoch 532/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0223 - val_loss: 0.0197\n",
      "Epoch 533/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0218 - val_loss: 0.0307\n",
      "Epoch 534/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0247 - val_loss: 0.0128\n",
      "Epoch 535/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0174 - val_loss: 0.0167\n",
      "Epoch 536/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0144 - val_loss: 0.0158\n",
      "Epoch 537/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0157 - val_loss: 0.0129\n",
      "Epoch 538/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0109 - val_loss: 0.0201\n",
      "Epoch 539/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0236 - val_loss: 0.0112\n",
      "Epoch 540/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0113 - val_loss: 0.0171\n",
      "Epoch 541/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0139 - val_loss: 0.0118\n",
      "Epoch 542/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0114 - val_loss: 0.0149\n",
      "Epoch 543/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0140 - val_loss: 0.0189\n",
      "Epoch 544/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0195 - val_loss: 0.0283\n",
      "Epoch 545/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0205 - val_loss: 0.0126\n",
      "Epoch 546/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0127 - val_loss: 0.0204\n",
      "Epoch 547/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0210 - val_loss: 0.0336\n",
      "Epoch 548/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0259 - val_loss: 0.0134\n",
      "Epoch 549/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0112 - val_loss: 0.0149\n",
      "Epoch 550/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0165 - val_loss: 0.0175\n",
      "Epoch 551/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0150 - val_loss: 0.0294\n",
      "Epoch 552/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0239 - val_loss: 0.0162\n",
      "Epoch 553/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0117 - val_loss: 0.0127\n",
      "Epoch 554/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0135 - val_loss: 0.0113\n",
      "Epoch 555/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0114 - val_loss: 0.0123\n",
      "Epoch 556/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0107 - val_loss: 0.0119\n",
      "Epoch 557/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0133 - val_loss: 0.0106\n",
      "Epoch 558/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0098 - val_loss: 0.0150\n",
      "Epoch 559/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0136 - val_loss: 0.0153\n",
      "Epoch 560/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0126 - val_loss: 0.0111\n",
      "Epoch 561/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0099 - val_loss: 0.0138\n",
      "Epoch 562/1500\n",
      "514/514 [==============================] - 0s 44us/step - loss: 0.0140 - val_loss: 0.0119\n",
      "Epoch 563/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0110 - val_loss: 0.0145\n",
      "Epoch 564/1500\n",
      "514/514 [==============================] - 0s 65us/step - loss: 0.0126 - val_loss: 0.0105\n",
      "Epoch 565/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0098 - val_loss: 0.0130\n",
      "Epoch 566/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0134 - val_loss: 0.0114\n",
      "Epoch 567/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0117 - val_loss: 0.0207\n",
      "Epoch 568/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0190 - val_loss: 0.0110\n",
      "Epoch 569/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0119 - val_loss: 0.0257\n",
      "Epoch 570/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0261 - val_loss: 0.0111\n",
      "Epoch 571/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0121 - val_loss: 0.0162\n",
      "Epoch 572/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0125 - val_loss: 0.0273\n",
      "Epoch 573/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0313 - val_loss: 0.0099\n",
      "Epoch 574/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0111 - val_loss: 0.0243\n",
      "Epoch 575/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0209 - val_loss: 0.0150\n",
      "Epoch 576/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0186 - val_loss: 0.0154\n",
      "Epoch 577/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0145 - val_loss: 0.0126\n",
      "Epoch 578/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0114 - val_loss: 0.0108\n",
      "Epoch 579/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0110 - val_loss: 0.0161\n",
      "Epoch 580/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0168 - val_loss: 0.0138\n",
      "Epoch 581/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0158 - val_loss: 0.0252\n",
      "Epoch 582/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0188 - val_loss: 0.0194\n",
      "Epoch 583/1500\n",
      "514/514 [==============================] - 0s 64us/step - loss: 0.0217 - val_loss: 0.0125\n",
      "Epoch 584/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0120 - val_loss: 0.0190\n",
      "Epoch 585/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0152 - val_loss: 0.0113\n",
      "Epoch 586/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0133 - val_loss: 0.0109\n",
      "Epoch 587/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0105 - val_loss: 0.0123\n",
      "Epoch 588/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 589/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 590/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0099 - val_loss: 0.0097\n",
      "Epoch 591/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 592/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0098 - val_loss: 0.0120\n",
      "Epoch 593/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0125 - val_loss: 0.0148\n",
      "Epoch 594/1500\n",
      "514/514 [==============================] - 0s 45us/step - loss: 0.0117 - val_loss: 0.0102\n",
      "Epoch 595/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0112 - val_loss: 0.0151\n",
      "Epoch 596/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0178 - val_loss: 0.0102\n",
      "Epoch 597/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0114 - val_loss: 0.0169\n",
      "Epoch 598/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0135 - val_loss: 0.0103\n",
      "Epoch 599/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 600/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0099 - val_loss: 0.0136\n",
      "Epoch 601/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0120 - val_loss: 0.0114\n",
      "Epoch 602/1500\n",
      "514/514 [==============================] - 0s 60us/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 603/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0122 - val_loss: 0.0130\n",
      "Epoch 604/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0133 - val_loss: 0.0104\n",
      "Epoch 605/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0110 - val_loss: 0.0131\n",
      "Epoch 606/1500\n",
      "514/514 [==============================] - 0s 61us/step - loss: 0.0110 - val_loss: 0.0124\n",
      "Epoch 607/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0110 - val_loss: 0.0137\n",
      "Epoch 608/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0118 - val_loss: 0.0136\n",
      "Epoch 609/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0115 - val_loss: 0.0122\n",
      "Epoch 610/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0102 - val_loss: 0.0109\n",
      "Epoch 611/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0098 - val_loss: 0.0106\n",
      "Epoch 612/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0098 - val_loss: 0.0100\n",
      "Epoch 613/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0101 - val_loss: 0.0112\n",
      "Epoch 614/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0111 - val_loss: 0.0126\n",
      "Epoch 615/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0124 - val_loss: 0.0119\n",
      "Epoch 616/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0112 - val_loss: 0.0113\n",
      "Epoch 617/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0107 - val_loss: 0.0106\n",
      "Epoch 618/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 619/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0096 - val_loss: 0.0117\n",
      "Epoch 620/1500\n",
      "514/514 [==============================] - 0s 44us/step - loss: 0.0100 - val_loss: 0.0117\n",
      "Epoch 621/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0098 - val_loss: 0.0127\n",
      "Epoch 622/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0111 - val_loss: 0.0134\n",
      "Epoch 623/1500\n",
      "514/514 [==============================] - 0s 44us/step - loss: 0.0105 - val_loss: 0.0115\n",
      "Epoch 624/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0099 - val_loss: 0.0109\n",
      "Epoch 625/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s 56us/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 626/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0099 - val_loss: 0.0151\n",
      "Epoch 627/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0137 - val_loss: 0.0136\n",
      "Epoch 628/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0109 - val_loss: 0.0102\n",
      "Epoch 629/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0103 - val_loss: 0.0103\n",
      "Epoch 630/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0102 - val_loss: 0.0116\n",
      "Epoch 631/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0116 - val_loss: 0.0173\n",
      "Epoch 632/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0142 - val_loss: 0.0117\n",
      "Epoch 633/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0102 - val_loss: 0.0133\n",
      "Epoch 634/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0138 - val_loss: 0.0120\n",
      "Epoch 635/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0108 - val_loss: 0.0130\n",
      "Epoch 636/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0123 - val_loss: 0.0125\n",
      "Epoch 637/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0100 - val_loss: 0.0122\n",
      "Epoch 638/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0142 - val_loss: 0.0176\n",
      "Epoch 639/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0174 - val_loss: 0.0113\n",
      "Epoch 640/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0107 - val_loss: 0.0105\n",
      "Epoch 641/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0097 - val_loss: 0.0111\n",
      "Epoch 642/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0099 - val_loss: 0.0113\n",
      "Epoch 643/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0108 - val_loss: 0.0135\n",
      "Epoch 644/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0116 - val_loss: 0.0103\n",
      "Epoch 645/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0103 - val_loss: 0.0155\n",
      "Epoch 646/1500\n",
      "514/514 [==============================] - 0s 62us/step - loss: 0.0176 - val_loss: 0.0137\n",
      "Epoch 647/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0127 - val_loss: 0.0130\n",
      "Epoch 648/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0131 - val_loss: 0.0138\n",
      "Epoch 649/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0116 - val_loss: 0.0117\n",
      "Epoch 650/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0131 - val_loss: 0.0120\n",
      "Epoch 651/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0115 - val_loss: 0.0125\n",
      "Epoch 652/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0124 - val_loss: 0.0138\n",
      "Epoch 653/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0112 - val_loss: 0.0101\n",
      "Epoch 654/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0103 - val_loss: 0.0105\n",
      "Epoch 655/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0105 - val_loss: 0.0120\n",
      "Epoch 656/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0106 - val_loss: 0.0182\n",
      "Epoch 657/1500\n",
      "514/514 [==============================] - 0s 67us/step - loss: 0.0185 - val_loss: 0.0227\n",
      "Epoch 658/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0177 - val_loss: 0.0148\n",
      "Epoch 659/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0140 - val_loss: 0.0189\n",
      "Epoch 660/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0177 - val_loss: 0.0277\n",
      "Epoch 661/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0277 - val_loss: 0.0236\n",
      "Epoch 662/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0205 - val_loss: 0.0217\n",
      "Epoch 663/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0191 - val_loss: 0.0143\n",
      "Epoch 664/1500\n",
      "514/514 [==============================] - 0s 60us/step - loss: 0.0122 - val_loss: 0.0259\n",
      "Epoch 665/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0297 - val_loss: 0.0141\n",
      "Epoch 666/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0132 - val_loss: 0.0155\n",
      "Epoch 667/1500\n",
      "514/514 [==============================] - 0s 60us/step - loss: 0.0143 - val_loss: 0.0193\n",
      "Epoch 668/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0181 - val_loss: 0.0210\n",
      "Epoch 669/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0205 - val_loss: 0.0198\n",
      "Epoch 670/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0197 - val_loss: 0.0138\n",
      "Epoch 671/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0150 - val_loss: 0.0225\n",
      "Epoch 672/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0221 - val_loss: 0.0120\n",
      "Epoch 673/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0162 - val_loss: 0.0167\n",
      "Epoch 674/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0158 - val_loss: 0.0256\n",
      "Epoch 675/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0269 - val_loss: 0.0156\n",
      "Epoch 676/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0164 - val_loss: 0.0249\n",
      "Epoch 677/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0224 - val_loss: 0.0128\n",
      "Epoch 678/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0153 - val_loss: 0.0196\n",
      "Epoch 679/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0196 - val_loss: 0.0206\n",
      "Epoch 680/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0188 - val_loss: 0.0116\n",
      "Epoch 681/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0120 - val_loss: 0.0238\n",
      "Epoch 682/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0220 - val_loss: 0.0155\n",
      "Epoch 683/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0163 - val_loss: 0.0211\n",
      "Epoch 684/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0189 - val_loss: 0.0155\n",
      "Epoch 685/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0164 - val_loss: 0.0232\n",
      "Epoch 686/1500\n",
      "514/514 [==============================] - 0s 44us/step - loss: 0.0182 - val_loss: 0.0188\n",
      "Epoch 687/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0192 - val_loss: 0.0250\n",
      "Epoch 688/1500\n",
      "514/514 [==============================] - 0s 44us/step - loss: 0.0175 - val_loss: 0.0275\n",
      "Epoch 689/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0194 - val_loss: 0.0240\n",
      "Epoch 690/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0171 - val_loss: 0.0177\n",
      "Epoch 691/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0132 - val_loss: 0.0129\n",
      "Epoch 692/1500\n",
      "514/514 [==============================] - 0s 43us/step - loss: 0.0105 - val_loss: 0.0099\n",
      "Epoch 693/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 694/1500\n",
      "514/514 [==============================] - 0s 45us/step - loss: 0.0109 - val_loss: 0.0128\n",
      "Epoch 695/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0121 - val_loss: 0.0119\n",
      "Epoch 696/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 697/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0122 - val_loss: 0.0118\n",
      "Epoch 698/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0113 - val_loss: 0.0133\n",
      "Epoch 699/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 700/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0114 - val_loss: 0.0141\n",
      "Epoch 701/1500\n",
      "514/514 [==============================] - 0s 45us/step - loss: 0.0133 - val_loss: 0.0104\n",
      "Epoch 702/1500\n",
      "514/514 [==============================] - 0s 45us/step - loss: 0.0099 - val_loss: 0.0144\n",
      "Epoch 703/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0132 - val_loss: 0.0107\n",
      "Epoch 704/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0096 - val_loss: 0.0117\n",
      "Epoch 705/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0113 - val_loss: 0.0104\n",
      "Epoch 706/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0098 - val_loss: 0.0117\n",
      "Epoch 707/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 708/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0103 - val_loss: 0.0100\n",
      "Epoch 709/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0095 - val_loss: 0.0121\n",
      "Epoch 710/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0113 - val_loss: 0.0115\n",
      "Epoch 711/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0099 - val_loss: 0.0110\n",
      "Epoch 712/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0122 - val_loss: 0.0127\n",
      "Epoch 713/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0124 - val_loss: 0.0101\n",
      "Epoch 714/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0101 - val_loss: 0.0127\n",
      "Epoch 715/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0109 - val_loss: 0.0102\n",
      "Epoch 716/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0109 - val_loss: 0.0147\n",
      "Epoch 717/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0153 - val_loss: 0.0108\n",
      "Epoch 718/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0104 - val_loss: 0.0131\n",
      "Epoch 719/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0125 - val_loss: 0.0117\n",
      "Epoch 720/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0104 - val_loss: 0.0106\n",
      "Epoch 721/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0107 - val_loss: 0.0104\n",
      "Epoch 722/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 723/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0097 - val_loss: 0.0108\n",
      "Epoch 724/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0095 - val_loss: 0.0111\n",
      "Epoch 725/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0102 - val_loss: 0.0129\n",
      "Epoch 726/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0121 - val_loss: 0.0121\n",
      "Epoch 727/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0110 - val_loss: 0.0185\n",
      "Epoch 728/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0162 - val_loss: 0.0134\n",
      "Epoch 729/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0109 - val_loss: 0.0129\n",
      "Epoch 730/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0139 - val_loss: 0.0151\n",
      "Epoch 731/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0147 - val_loss: 0.0110\n",
      "Epoch 732/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0122 - val_loss: 0.0152\n",
      "Epoch 733/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0120 - val_loss: 0.0113\n",
      "Epoch 734/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0126 - val_loss: 0.0120\n",
      "Epoch 735/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0114 - val_loss: 0.0107\n",
      "Epoch 736/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0100 - val_loss: 0.0149\n",
      "Epoch 737/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0139 - val_loss: 0.0131\n",
      "Epoch 738/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0113 - val_loss: 0.0148\n",
      "Epoch 739/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0133 - val_loss: 0.0133\n",
      "Epoch 740/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0116 - val_loss: 0.0152\n",
      "Epoch 741/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0127 - val_loss: 0.0138\n",
      "Epoch 742/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0116 - val_loss: 0.0128\n",
      "Epoch 743/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0110 - val_loss: 0.0116\n",
      "Epoch 744/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0103 - val_loss: 0.0133\n",
      "Epoch 745/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0153 - val_loss: 0.0126\n",
      "Epoch 746/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0117 - val_loss: 0.0123\n",
      "Epoch 747/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0127 - val_loss: 0.0185\n",
      "Epoch 748/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0161 - val_loss: 0.0201\n",
      "Epoch 749/1500\n",
      "514/514 [==============================] - 0s 61us/step - loss: 0.0180 - val_loss: 0.0210\n",
      "Epoch 750/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0210 - val_loss: 0.0145\n",
      "Epoch 751/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0128 - val_loss: 0.0191\n",
      "Epoch 752/1500\n",
      "514/514 [==============================] - 0s 62us/step - loss: 0.0208 - val_loss: 0.0173\n",
      "Epoch 753/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0132 - val_loss: 0.0233\n",
      "Epoch 754/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0207 - val_loss: 0.0143\n",
      "Epoch 755/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0130 - val_loss: 0.0238\n",
      "Epoch 756/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0209 - val_loss: 0.0162\n",
      "Epoch 757/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0152 - val_loss: 0.0186\n",
      "Epoch 758/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0164 - val_loss: 0.0181\n",
      "Epoch 759/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0181 - val_loss: 0.0186\n",
      "Epoch 760/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0148 - val_loss: 0.0101\n",
      "Epoch 761/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0096 - val_loss: 0.0107\n",
      "Epoch 762/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0105 - val_loss: 0.0114\n",
      "Epoch 763/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0113 - val_loss: 0.0175\n",
      "Epoch 764/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0154 - val_loss: 0.0110\n",
      "Epoch 765/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0106 - val_loss: 0.0105\n",
      "Epoch 766/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0103 - val_loss: 0.0173\n",
      "Epoch 767/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0158 - val_loss: 0.0160\n",
      "Epoch 768/1500\n",
      "514/514 [==============================] - 0s 60us/step - loss: 0.0123 - val_loss: 0.0126\n",
      "Epoch 769/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0137 - val_loss: 0.0132\n",
      "Epoch 770/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0129 - val_loss: 0.0109\n",
      "Epoch 771/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0108 - val_loss: 0.0198\n",
      "Epoch 772/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0174 - val_loss: 0.0151\n",
      "Epoch 773/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0117 - val_loss: 0.0113\n",
      "Epoch 774/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0110 - val_loss: 0.0116\n",
      "Epoch 775/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0111 - val_loss: 0.0105\n",
      "Epoch 776/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0099 - val_loss: 0.0119\n",
      "Epoch 777/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0101 - val_loss: 0.0101\n",
      "Epoch 778/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0097 - val_loss: 0.0103\n",
      "Epoch 779/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0097 - val_loss: 0.0106\n",
      "Epoch 780/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0094 - val_loss: 0.0126\n",
      "Epoch 781/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s 59us/step - loss: 0.0104 - val_loss: 0.0140\n",
      "Epoch 782/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0111 - val_loss: 0.0141\n",
      "Epoch 783/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0110 - val_loss: 0.0132\n",
      "Epoch 784/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0112 - val_loss: 0.0119\n",
      "Epoch 785/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0112 - val_loss: 0.0115\n",
      "Epoch 786/1500\n",
      "514/514 [==============================] - 0s 63us/step - loss: 0.0115 - val_loss: 0.0110\n",
      "Epoch 787/1500\n",
      "514/514 [==============================] - 0s 75us/step - loss: 0.0106 - val_loss: 0.0102\n",
      "Epoch 788/1500\n",
      "514/514 [==============================] - 0s 65us/step - loss: 0.0098 - val_loss: 0.0121\n",
      "Epoch 789/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0104 - val_loss: 0.0159\n",
      "Epoch 790/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0126 - val_loss: 0.0151\n",
      "Epoch 791/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0115 - val_loss: 0.0126\n",
      "Epoch 792/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0102 - val_loss: 0.0119\n",
      "Epoch 793/1500\n",
      "514/514 [==============================] - 0s 61us/step - loss: 0.0112 - val_loss: 0.0146\n",
      "Epoch 794/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0142 - val_loss: 0.0124\n",
      "Epoch 795/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0114 - val_loss: 0.0112\n",
      "Epoch 796/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0100 - val_loss: 0.0133\n",
      "Epoch 797/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0111 - val_loss: 0.0135\n",
      "Epoch 798/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0112 - val_loss: 0.0123\n",
      "Epoch 799/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0104 - val_loss: 0.0111\n",
      "Epoch 800/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 801/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0103 - val_loss: 0.0107\n",
      "Epoch 802/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0100 - val_loss: 0.0129\n",
      "Epoch 803/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0116 - val_loss: 0.0135\n",
      "Epoch 804/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0116 - val_loss: 0.0125\n",
      "Epoch 805/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0105 - val_loss: 0.0119\n",
      "Epoch 806/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0103 - val_loss: 0.0123\n",
      "Epoch 807/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0112 - val_loss: 0.0114\n",
      "Epoch 808/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0106 - val_loss: 0.0125\n",
      "Epoch 809/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0113 - val_loss: 0.0112\n",
      "Epoch 810/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0102 - val_loss: 0.0110\n",
      "Epoch 811/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0114 - val_loss: 0.0104\n",
      "Epoch 812/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0098 - val_loss: 0.0161\n",
      "Epoch 813/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0153 - val_loss: 0.0160\n",
      "Epoch 814/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0130 - val_loss: 0.0108\n",
      "Epoch 815/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0098 - val_loss: 0.0106\n",
      "Epoch 816/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0097 - val_loss: 0.0114\n",
      "Epoch 817/1500\n",
      "514/514 [==============================] - 0s 45us/step - loss: 0.0102 - val_loss: 0.0110\n",
      "Epoch 818/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0098 - val_loss: 0.0119\n",
      "Epoch 819/1500\n",
      "514/514 [==============================] - 0s 45us/step - loss: 0.0108 - val_loss: 0.0184\n",
      "Epoch 820/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0135 - val_loss: 0.0220\n",
      "Epoch 821/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0174 - val_loss: 0.0221\n",
      "Epoch 822/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0154 - val_loss: 0.0198\n",
      "Epoch 823/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0151 - val_loss: 0.0184\n",
      "Epoch 824/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0141 - val_loss: 0.0120\n",
      "Epoch 825/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0103 - val_loss: 0.0132\n",
      "Epoch 826/1500\n",
      "514/514 [==============================] - 0s 63us/step - loss: 0.0109 - val_loss: 0.0098\n",
      "Epoch 827/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 828/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0105 - val_loss: 0.0120\n",
      "Epoch 829/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0117 - val_loss: 0.0128\n",
      "Epoch 830/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0120 - val_loss: 0.0110\n",
      "Epoch 831/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0104 - val_loss: 0.0109\n",
      "Epoch 832/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0109 - val_loss: 0.0107\n",
      "Epoch 833/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0102 - val_loss: 0.0099\n",
      "Epoch 834/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0094 - val_loss: 0.0100\n",
      "Epoch 835/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 836/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 837/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0104 - val_loss: 0.0120\n",
      "Epoch 838/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0103 - val_loss: 0.0109\n",
      "Epoch 839/1500\n",
      "514/514 [==============================] - 0s 61us/step - loss: 0.0103 - val_loss: 0.0131\n",
      "Epoch 840/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0117 - val_loss: 0.0121\n",
      "Epoch 841/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0105 - val_loss: 0.0133\n",
      "Epoch 842/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0123 - val_loss: 0.0118\n",
      "Epoch 843/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0102 - val_loss: 0.0116\n",
      "Epoch 844/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0117 - val_loss: 0.0130\n",
      "Epoch 845/1500\n",
      "514/514 [==============================] - 0s 45us/step - loss: 0.0111 - val_loss: 0.0148\n",
      "Epoch 846/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0130 - val_loss: 0.0146\n",
      "Epoch 847/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0130 - val_loss: 0.0125\n",
      "Epoch 848/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0115 - val_loss: 0.0153\n",
      "Epoch 849/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0151 - val_loss: 0.0147\n",
      "Epoch 850/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0128 - val_loss: 0.0113\n",
      "Epoch 851/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0104 - val_loss: 0.0111\n",
      "Epoch 852/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 853/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0098 - val_loss: 0.0112\n",
      "Epoch 854/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0100 - val_loss: 0.0120\n",
      "Epoch 855/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0106 - val_loss: 0.0138\n",
      "Epoch 856/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0119 - val_loss: 0.0131\n",
      "Epoch 857/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0105 - val_loss: 0.0113\n",
      "Epoch 858/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0104 - val_loss: 0.0121\n",
      "Epoch 859/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0108 - val_loss: 0.0112\n",
      "Epoch 860/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0102 - val_loss: 0.0151\n",
      "Epoch 861/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0133 - val_loss: 0.0126\n",
      "Epoch 862/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 863/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 864/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 865/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0098 - val_loss: 0.0115\n",
      "Epoch 866/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0110 - val_loss: 0.0135\n",
      "Epoch 867/1500\n",
      "514/514 [==============================] - 0s 67us/step - loss: 0.0127 - val_loss: 0.0117\n",
      "Epoch 868/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 869/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 870/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0094 - val_loss: 0.0119\n",
      "Epoch 871/1500\n",
      "514/514 [==============================] - 0s 45us/step - loss: 0.0123 - val_loss: 0.0120\n",
      "Epoch 872/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0115 - val_loss: 0.0118\n",
      "Epoch 873/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0105 - val_loss: 0.0172\n",
      "Epoch 874/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0129 - val_loss: 0.0193\n",
      "Epoch 875/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0136 - val_loss: 0.0180\n",
      "Epoch 876/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0126 - val_loss: 0.0147\n",
      "Epoch 877/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0108 - val_loss: 0.0118\n",
      "Epoch 878/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 879/1500\n",
      "514/514 [==============================] - 0s 45us/step - loss: 0.0101 - val_loss: 0.0110\n",
      "Epoch 880/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0113 - val_loss: 0.0173\n",
      "Epoch 881/1500\n",
      "514/514 [==============================] - 0s 43us/step - loss: 0.0143 - val_loss: 0.0103\n",
      "Epoch 882/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0112 - val_loss: 0.0157\n",
      "Epoch 883/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0127 - val_loss: 0.0197\n",
      "Epoch 884/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0170 - val_loss: 0.0211\n",
      "Epoch 885/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0149 - val_loss: 0.0155\n",
      "Epoch 886/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0161 - val_loss: 0.0180\n",
      "Epoch 887/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0157 - val_loss: 0.0123\n",
      "Epoch 888/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0126 - val_loss: 0.0170\n",
      "Epoch 889/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0133 - val_loss: 0.0114\n",
      "Epoch 890/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0142 - val_loss: 0.0110\n",
      "Epoch 891/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0111 - val_loss: 0.0134\n",
      "Epoch 892/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0124 - val_loss: 0.0125\n",
      "Epoch 893/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0113 - val_loss: 0.0120\n",
      "Epoch 894/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0112 - val_loss: 0.0157\n",
      "Epoch 895/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0138 - val_loss: 0.0124\n",
      "Epoch 896/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0099 - val_loss: 0.0120\n",
      "Epoch 897/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0108 - val_loss: 0.0122\n",
      "Epoch 898/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0111 - val_loss: 0.0114\n",
      "Epoch 899/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0105 - val_loss: 0.0115\n",
      "Epoch 900/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0105 - val_loss: 0.0125\n",
      "Epoch 901/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0127 - val_loss: 0.0117\n",
      "Epoch 902/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0118 - val_loss: 0.0124\n",
      "Epoch 903/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0123 - val_loss: 0.0151\n",
      "Epoch 904/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0143 - val_loss: 0.0136\n",
      "Epoch 905/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0120 - val_loss: 0.0138\n",
      "Epoch 906/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0130 - val_loss: 0.0119\n",
      "Epoch 907/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0105 - val_loss: 0.0136\n",
      "Epoch 908/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0131 - val_loss: 0.0163\n",
      "Epoch 909/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0130 - val_loss: 0.0111\n",
      "Epoch 910/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0099 - val_loss: 0.0117\n",
      "Epoch 911/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0107 - val_loss: 0.0110\n",
      "Epoch 912/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0100 - val_loss: 0.0165\n",
      "Epoch 913/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0153 - val_loss: 0.0158\n",
      "Epoch 914/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0132 - val_loss: 0.0102\n",
      "Epoch 915/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0103 - val_loss: 0.0129\n",
      "Epoch 916/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0131 - val_loss: 0.0099\n",
      "Epoch 917/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0096 - val_loss: 0.0150\n",
      "Epoch 918/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0126 - val_loss: 0.0100\n",
      "Epoch 919/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0097 - val_loss: 0.0115\n",
      "Epoch 920/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0113 - val_loss: 0.0102\n",
      "Epoch 921/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0097 - val_loss: 0.0109\n",
      "Epoch 922/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0099 - val_loss: 0.0119\n",
      "Epoch 923/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0106 - val_loss: 0.0105\n",
      "Epoch 924/1500\n",
      "514/514 [==============================] - 0s 44us/step - loss: 0.0098 - val_loss: 0.0127\n",
      "Epoch 925/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0121 - val_loss: 0.0116\n",
      "Epoch 926/1500\n",
      "514/514 [==============================] - 0s 45us/step - loss: 0.0103 - val_loss: 0.0124\n",
      "Epoch 927/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0113 - val_loss: 0.0150\n",
      "Epoch 928/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0126 - val_loss: 0.0108\n",
      "Epoch 929/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0097 - val_loss: 0.0135\n",
      "Epoch 930/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0132 - val_loss: 0.0110\n",
      "Epoch 931/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0105 - val_loss: 0.0115\n",
      "Epoch 932/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0102 - val_loss: 0.0106\n",
      "Epoch 933/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0104 - val_loss: 0.0111\n",
      "Epoch 934/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0111 - val_loss: 0.0105\n",
      "Epoch 935/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0105 - val_loss: 0.0099\n",
      "Epoch 936/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0099 - val_loss: 0.0111\n",
      "Epoch 937/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s 49us/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 938/1500\n",
      "514/514 [==============================] - 0s 60us/step - loss: 0.0096 - val_loss: 0.0113\n",
      "Epoch 939/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0106 - val_loss: 0.0119\n",
      "Epoch 940/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0107 - val_loss: 0.0130\n",
      "Epoch 941/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0105 - val_loss: 0.0120\n",
      "Epoch 942/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0114 - val_loss: 0.0133\n",
      "Epoch 943/1500\n",
      "514/514 [==============================] - 0s 61us/step - loss: 0.0126 - val_loss: 0.0109\n",
      "Epoch 944/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0104 - val_loss: 0.0148\n",
      "Epoch 945/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0142 - val_loss: 0.0129\n",
      "Epoch 946/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0128 - val_loss: 0.0146\n",
      "Epoch 947/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0153 - val_loss: 0.0138\n",
      "Epoch 948/1500\n",
      "514/514 [==============================] - 0s 45us/step - loss: 0.0131 - val_loss: 0.0160\n",
      "Epoch 949/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0129 - val_loss: 0.0163\n",
      "Epoch 950/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0178 - val_loss: 0.0365\n",
      "Epoch 951/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0267 - val_loss: 0.0498\n",
      "Epoch 952/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0400 - val_loss: 0.0445\n",
      "Epoch 953/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0326 - val_loss: 0.0558\n",
      "Epoch 954/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0398 - val_loss: 0.0414\n",
      "Epoch 955/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0289 - val_loss: 0.0405\n",
      "Epoch 956/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0306 - val_loss: 0.0331\n",
      "Epoch 957/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0239 - val_loss: 0.0328\n",
      "Epoch 958/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0242 - val_loss: 0.0232\n",
      "Epoch 959/1500\n",
      "514/514 [==============================] - 0s 44us/step - loss: 0.0184 - val_loss: 0.0167\n",
      "Epoch 960/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0149 - val_loss: 0.0151\n",
      "Epoch 961/1500\n",
      "514/514 [==============================] - 0s 44us/step - loss: 0.0113 - val_loss: 0.0188\n",
      "Epoch 962/1500\n",
      "514/514 [==============================] - 0s 43us/step - loss: 0.0165 - val_loss: 0.0146\n",
      "Epoch 963/1500\n",
      "514/514 [==============================] - 0s 43us/step - loss: 0.0125 - val_loss: 0.0146\n",
      "Epoch 964/1500\n",
      "514/514 [==============================] - 0s 45us/step - loss: 0.0149 - val_loss: 0.0194\n",
      "Epoch 965/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0149 - val_loss: 0.0178\n",
      "Epoch 966/1500\n",
      "514/514 [==============================] - 0s 43us/step - loss: 0.0198 - val_loss: 0.0179\n",
      "Epoch 967/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0154 - val_loss: 0.0224\n",
      "Epoch 968/1500\n",
      "514/514 [==============================] - 0s 43us/step - loss: 0.0200 - val_loss: 0.0241\n",
      "Epoch 969/1500\n",
      "514/514 [==============================] - 0s 42us/step - loss: 0.0166 - val_loss: 0.0190\n",
      "Epoch 970/1500\n",
      "514/514 [==============================] - 0s 45us/step - loss: 0.0187 - val_loss: 0.0202\n",
      "Epoch 971/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0146 - val_loss: 0.0174\n",
      "Epoch 972/1500\n",
      "514/514 [==============================] - 0s 42us/step - loss: 0.0139 - val_loss: 0.0128\n",
      "Epoch 973/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0111 - val_loss: 0.0140\n",
      "Epoch 974/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0116 - val_loss: 0.0134\n",
      "Epoch 975/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0125 - val_loss: 0.0167\n",
      "Epoch 976/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0132 - val_loss: 0.0110\n",
      "Epoch 977/1500\n",
      "514/514 [==============================] - 0s 61us/step - loss: 0.0100 - val_loss: 0.0128\n",
      "Epoch 978/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0119 - val_loss: 0.0126\n",
      "Epoch 979/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0114 - val_loss: 0.0121\n",
      "Epoch 980/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0110 - val_loss: 0.0127\n",
      "Epoch 981/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0140 - val_loss: 0.0169\n",
      "Epoch 982/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0161 - val_loss: 0.0124\n",
      "Epoch 983/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0123 - val_loss: 0.0163\n",
      "Epoch 984/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0148 - val_loss: 0.0119\n",
      "Epoch 985/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0109 - val_loss: 0.0114\n",
      "Epoch 986/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0106 - val_loss: 0.0120\n",
      "Epoch 987/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0108 - val_loss: 0.0136\n",
      "Epoch 988/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0117 - val_loss: 0.0120\n",
      "Epoch 989/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0097 - val_loss: 0.0136\n",
      "Epoch 990/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0127 - val_loss: 0.0139\n",
      "Epoch 991/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0118 - val_loss: 0.0120\n",
      "Epoch 992/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0109 - val_loss: 0.0138\n",
      "Epoch 993/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0110 - val_loss: 0.0113\n",
      "Epoch 994/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0100 - val_loss: 0.0120\n",
      "Epoch 995/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0105 - val_loss: 0.0119\n",
      "Epoch 996/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0105 - val_loss: 0.0125\n",
      "Epoch 997/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0119 - val_loss: 0.0129\n",
      "Epoch 998/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0116 - val_loss: 0.0123\n",
      "Epoch 999/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0135 - val_loss: 0.0134\n",
      "Epoch 1000/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0134 - val_loss: 0.0111\n",
      "Epoch 1001/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0109 - val_loss: 0.0145\n",
      "Epoch 1002/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0131 - val_loss: 0.0121\n",
      "Epoch 1003/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 1004/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0100 - val_loss: 0.0110\n",
      "Epoch 1005/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0101 - val_loss: 0.0116\n",
      "Epoch 1006/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0102 - val_loss: 0.0119\n",
      "Epoch 1007/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0105 - val_loss: 0.0129\n",
      "Epoch 1008/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0113 - val_loss: 0.0116\n",
      "Epoch 1009/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0100 - val_loss: 0.0124\n",
      "Epoch 1010/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0106 - val_loss: 0.0119\n",
      "Epoch 1011/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0102 - val_loss: 0.0143\n",
      "Epoch 1012/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0123 - val_loss: 0.0131\n",
      "Epoch 1013/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 1014/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0097 - val_loss: 0.0111\n",
      "Epoch 1015/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s 53us/step - loss: 0.0104 - val_loss: 0.0112\n",
      "Epoch 1016/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0101 - val_loss: 0.0120\n",
      "Epoch 1017/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0106 - val_loss: 0.0130\n",
      "Epoch 1018/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0114 - val_loss: 0.0112\n",
      "Epoch 1019/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 1020/1500\n",
      "514/514 [==============================] - 0s 62us/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 1021/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0097 - val_loss: 0.0106\n",
      "Epoch 1022/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0099 - val_loss: 0.0126\n",
      "Epoch 1023/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0112 - val_loss: 0.0111\n",
      "Epoch 1024/1500\n",
      "514/514 [==============================] - 0s 61us/step - loss: 0.0101 - val_loss: 0.0109\n",
      "Epoch 1025/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0104 - val_loss: 0.0100\n",
      "Epoch 1026/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0100 - val_loss: 0.0119\n",
      "Epoch 1027/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0122 - val_loss: 0.0155\n",
      "Epoch 1028/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0157 - val_loss: 0.0208\n",
      "Epoch 1029/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0172 - val_loss: 0.0184\n",
      "Epoch 1030/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0149 - val_loss: 0.0157\n",
      "Epoch 1031/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0154 - val_loss: 0.0147\n",
      "Epoch 1032/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0145 - val_loss: 0.0108\n",
      "Epoch 1033/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0101 - val_loss: 0.0141\n",
      "Epoch 1034/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0130 - val_loss: 0.0138\n",
      "Epoch 1035/1500\n",
      "514/514 [==============================] - 0s 45us/step - loss: 0.0106 - val_loss: 0.0142\n",
      "Epoch 1036/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0138 - val_loss: 0.0150\n",
      "Epoch 1037/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0130 - val_loss: 0.0116\n",
      "Epoch 1038/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0102 - val_loss: 0.0136\n",
      "Epoch 1039/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0131 - val_loss: 0.0141\n",
      "Epoch 1040/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0128 - val_loss: 0.0112\n",
      "Epoch 1041/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0138 - val_loss: 0.0135\n",
      "Epoch 1042/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0119 - val_loss: 0.0124\n",
      "Epoch 1043/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0114 - val_loss: 0.0108\n",
      "Epoch 1044/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0123 - val_loss: 0.0163\n",
      "Epoch 1045/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0177 - val_loss: 0.0107\n",
      "Epoch 1046/1500\n",
      "514/514 [==============================] - 0s 86us/step - loss: 0.0113 - val_loss: 0.0117\n",
      "Epoch 1047/1500\n",
      "514/514 [==============================] - 0s 64us/step - loss: 0.0111 - val_loss: 0.0116\n",
      "Epoch 1048/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0115 - val_loss: 0.0133\n",
      "Epoch 1049/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0126 - val_loss: 0.0114\n",
      "Epoch 1050/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0104 - val_loss: 0.0120\n",
      "Epoch 1051/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0109 - val_loss: 0.0139\n",
      "Epoch 1052/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0119 - val_loss: 0.0135\n",
      "Epoch 1053/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0113 - val_loss: 0.0140\n",
      "Epoch 1054/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0147 - val_loss: 0.0236\n",
      "Epoch 1055/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0239 - val_loss: 0.0261\n",
      "Epoch 1056/1500\n",
      "514/514 [==============================] - 0s 45us/step - loss: 0.0260 - val_loss: 0.0267\n",
      "Epoch 1057/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0264 - val_loss: 0.0220\n",
      "Epoch 1058/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0278 - val_loss: 0.0391\n",
      "Epoch 1059/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0367 - val_loss: 0.0180\n",
      "Epoch 1060/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0178 - val_loss: 0.0167\n",
      "Epoch 1061/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0159 - val_loss: 0.0158\n",
      "Epoch 1062/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0233 - val_loss: 0.0150\n",
      "Epoch 1063/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0133 - val_loss: 0.0248\n",
      "Epoch 1064/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0182 - val_loss: 0.0207\n",
      "Epoch 1065/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0226 - val_loss: 0.0118\n",
      "Epoch 1066/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0144 - val_loss: 0.0160\n",
      "Epoch 1067/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0124 - val_loss: 0.0133\n",
      "Epoch 1068/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0127 - val_loss: 0.0139\n",
      "Epoch 1069/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0135 - val_loss: 0.0110\n",
      "Epoch 1070/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0100 - val_loss: 0.0112\n",
      "Epoch 1071/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0128 - val_loss: 0.0183\n",
      "Epoch 1072/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0191 - val_loss: 0.0194\n",
      "Epoch 1073/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0202 - val_loss: 0.0173\n",
      "Epoch 1074/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0180 - val_loss: 0.0204\n",
      "Epoch 1075/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0190 - val_loss: 0.0122\n",
      "Epoch 1076/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0133 - val_loss: 0.0125\n",
      "Epoch 1077/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0129 - val_loss: 0.0223\n",
      "Epoch 1078/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0180 - val_loss: 0.0204\n",
      "Epoch 1079/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0237 - val_loss: 0.0273\n",
      "Epoch 1080/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0208 - val_loss: 0.0139\n",
      "Epoch 1081/1500\n",
      "514/514 [==============================] - 0s 73us/step - loss: 0.0112 - val_loss: 0.0148\n",
      "Epoch 1082/1500\n",
      "514/514 [==============================] - 0s 73us/step - loss: 0.0122 - val_loss: 0.0178\n",
      "Epoch 1083/1500\n",
      "514/514 [==============================] - 0s 61us/step - loss: 0.0177 - val_loss: 0.0108\n",
      "Epoch 1084/1500\n",
      "514/514 [==============================] - 0s 64us/step - loss: 0.0111 - val_loss: 0.0216\n",
      "Epoch 1085/1500\n",
      "514/514 [==============================] - 0s 67us/step - loss: 0.0206 - val_loss: 0.0124\n",
      "Epoch 1086/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0135 - val_loss: 0.0207\n",
      "Epoch 1087/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0164 - val_loss: 0.0111\n",
      "Epoch 1088/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0099 - val_loss: 0.0142\n",
      "Epoch 1089/1500\n",
      "514/514 [==============================] - 0s 63us/step - loss: 0.0129 - val_loss: 0.0128\n",
      "Epoch 1090/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0121 - val_loss: 0.0181\n",
      "Epoch 1091/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0154 - val_loss: 0.0181\n",
      "Epoch 1092/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0176 - val_loss: 0.0125\n",
      "Epoch 1093/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0118 - val_loss: 0.0117\n",
      "Epoch 1094/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0123 - val_loss: 0.0142\n",
      "Epoch 1095/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0121 - val_loss: 0.0127\n",
      "Epoch 1096/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0120 - val_loss: 0.0117\n",
      "Epoch 1097/1500\n",
      "514/514 [==============================] - 0s 63us/step - loss: 0.0106 - val_loss: 0.0110\n",
      "Epoch 1098/1500\n",
      "514/514 [==============================] - 0s 71us/step - loss: 0.0103 - val_loss: 0.0178\n",
      "Epoch 1099/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0164 - val_loss: 0.0169\n",
      "Epoch 1100/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0134 - val_loss: 0.0117\n",
      "Epoch 1101/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0099 - val_loss: 0.0118\n",
      "Epoch 1102/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0101 - val_loss: 0.0129\n",
      "Epoch 1103/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0108 - val_loss: 0.0126\n",
      "Epoch 1104/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0104 - val_loss: 0.0115\n",
      "Epoch 1105/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0099 - val_loss: 0.0112\n",
      "Epoch 1106/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0098 - val_loss: 0.0111\n",
      "Epoch 1107/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0104 - val_loss: 0.0108\n",
      "Epoch 1108/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0102 - val_loss: 0.0123\n",
      "Epoch 1109/1500\n",
      "514/514 [==============================] - 0s 77us/step - loss: 0.0105 - val_loss: 0.0111\n",
      "Epoch 1110/1500\n",
      "514/514 [==============================] - 0s 78us/step - loss: 0.0099 - val_loss: 0.0109\n",
      "Epoch 1111/1500\n",
      "514/514 [==============================] - 0s 67us/step - loss: 0.0103 - val_loss: 0.0115\n",
      "Epoch 1112/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0107 - val_loss: 0.0116\n",
      "Epoch 1113/1500\n",
      "514/514 [==============================] - 0s 64us/step - loss: 0.0112 - val_loss: 0.0113\n",
      "Epoch 1114/1500\n",
      "514/514 [==============================] - 0s 61us/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 1115/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0097 - val_loss: 0.0106\n",
      "Epoch 1116/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0097 - val_loss: 0.0128\n",
      "Epoch 1117/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0135 - val_loss: 0.0175\n",
      "Epoch 1118/1500\n",
      "514/514 [==============================] - 0s 62us/step - loss: 0.0173 - val_loss: 0.0145\n",
      "Epoch 1119/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0129 - val_loss: 0.0117\n",
      "Epoch 1120/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0104 - val_loss: 0.0118\n",
      "Epoch 1121/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 1122/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0099 - val_loss: 0.0130\n",
      "Epoch 1123/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0136 - val_loss: 0.0228\n",
      "Epoch 1124/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0220 - val_loss: 0.0193\n",
      "Epoch 1125/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0163 - val_loss: 0.0141\n",
      "Epoch 1126/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0113 - val_loss: 0.0121\n",
      "Epoch 1127/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0103 - val_loss: 0.0130\n",
      "Epoch 1128/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0114 - val_loss: 0.0128\n",
      "Epoch 1129/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0122 - val_loss: 0.0104\n",
      "Epoch 1130/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0101 - val_loss: 0.0180\n",
      "Epoch 1131/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0157 - val_loss: 0.0160\n",
      "Epoch 1132/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0120 - val_loss: 0.0119\n",
      "Epoch 1133/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0107 - val_loss: 0.0115\n",
      "Epoch 1134/1500\n",
      "514/514 [==============================] - 0s 60us/step - loss: 0.0100 - val_loss: 0.0134\n",
      "Epoch 1135/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0108 - val_loss: 0.0133\n",
      "Epoch 1136/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0105 - val_loss: 0.0124\n",
      "Epoch 1137/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0102 - val_loss: 0.0120\n",
      "Epoch 1138/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0102 - val_loss: 0.0120\n",
      "Epoch 1139/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0104 - val_loss: 0.0131\n",
      "Epoch 1140/1500\n",
      "514/514 [==============================] - 0s 60us/step - loss: 0.0112 - val_loss: 0.0128\n",
      "Epoch 1141/1500\n",
      "514/514 [==============================] - 0s 63us/step - loss: 0.0110 - val_loss: 0.0136\n",
      "Epoch 1142/1500\n",
      "514/514 [==============================] - 0s 66us/step - loss: 0.0132 - val_loss: 0.0114\n",
      "Epoch 1143/1500\n",
      "514/514 [==============================] - 0s 68us/step - loss: 0.0101 - val_loss: 0.0120\n",
      "Epoch 1144/1500\n",
      "514/514 [==============================] - 0s 64us/step - loss: 0.0108 - val_loss: 0.0131\n",
      "Epoch 1145/1500\n",
      "514/514 [==============================] - 0s 66us/step - loss: 0.0116 - val_loss: 0.0135\n",
      "Epoch 1146/1500\n",
      "514/514 [==============================] - 0s 69us/step - loss: 0.0125 - val_loss: 0.0160\n",
      "Epoch 1147/1500\n",
      "514/514 [==============================] - 0s 66us/step - loss: 0.0128 - val_loss: 0.0147\n",
      "Epoch 1148/1500\n",
      "514/514 [==============================] - 0s 77us/step - loss: 0.0117 - val_loss: 0.0137\n",
      "Epoch 1149/1500\n",
      "514/514 [==============================] - 0s 72us/step - loss: 0.0108 - val_loss: 0.0126\n",
      "Epoch 1150/1500\n",
      "514/514 [==============================] - 0s 67us/step - loss: 0.0115 - val_loss: 0.0139\n",
      "Epoch 1151/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0121 - val_loss: 0.0127\n",
      "Epoch 1152/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0117 - val_loss: 0.0173\n",
      "Epoch 1153/1500\n",
      "514/514 [==============================] - 0s 63us/step - loss: 0.0148 - val_loss: 0.0116\n",
      "Epoch 1154/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0129 - val_loss: 0.0146\n",
      "Epoch 1155/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0129 - val_loss: 0.0154\n",
      "Epoch 1156/1500\n",
      "514/514 [==============================] - 0s 65us/step - loss: 0.0160 - val_loss: 0.0126\n",
      "Epoch 1157/1500\n",
      "514/514 [==============================] - 0s 66us/step - loss: 0.0111 - val_loss: 0.0124\n",
      "Epoch 1158/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0129 - val_loss: 0.0122\n",
      "Epoch 1159/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0121 - val_loss: 0.0149\n",
      "Epoch 1160/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0125 - val_loss: 0.0108\n",
      "Epoch 1161/1500\n",
      "514/514 [==============================] - 0s 60us/step - loss: 0.0109 - val_loss: 0.0147\n",
      "Epoch 1162/1500\n",
      "514/514 [==============================] - 0s 70us/step - loss: 0.0131 - val_loss: 0.0117\n",
      "Epoch 1163/1500\n",
      "514/514 [==============================] - 0s 66us/step - loss: 0.0107 - val_loss: 0.0166\n",
      "Epoch 1164/1500\n",
      "514/514 [==============================] - 0s 62us/step - loss: 0.0135 - val_loss: 0.0114\n",
      "Epoch 1165/1500\n",
      "514/514 [==============================] - 0s 63us/step - loss: 0.0126 - val_loss: 0.0107\n",
      "Epoch 1166/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0103 - val_loss: 0.0156\n",
      "Epoch 1167/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0139 - val_loss: 0.0110\n",
      "Epoch 1168/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0103 - val_loss: 0.0120\n",
      "Epoch 1169/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s 64us/step - loss: 0.0119 - val_loss: 0.0129\n",
      "Epoch 1170/1500\n",
      "514/514 [==============================] - 0s 66us/step - loss: 0.0136 - val_loss: 0.0212\n",
      "Epoch 1171/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0196 - val_loss: 0.0131\n",
      "Epoch 1172/1500\n",
      "514/514 [==============================] - 0s 61us/step - loss: 0.0135 - val_loss: 0.0291\n",
      "Epoch 1173/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0320 - val_loss: 0.0150\n",
      "Epoch 1174/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0183 - val_loss: 0.0115\n",
      "Epoch 1175/1500\n",
      "514/514 [==============================] - 0s 65us/step - loss: 0.0161 - val_loss: 0.0333\n",
      "Epoch 1176/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0257 - val_loss: 0.0230\n",
      "Epoch 1177/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0268 - val_loss: 0.0177\n",
      "Epoch 1178/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0133 - val_loss: 0.0129\n",
      "Epoch 1179/1500\n",
      "514/514 [==============================] - 0s 61us/step - loss: 0.0116 - val_loss: 0.0159\n",
      "Epoch 1180/1500\n",
      "514/514 [==============================] - 0s 66us/step - loss: 0.0115 - val_loss: 0.0167\n",
      "Epoch 1181/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0174 - val_loss: 0.0154\n",
      "Epoch 1182/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0149 - val_loss: 0.0113\n",
      "Epoch 1183/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0111 - val_loss: 0.0117\n",
      "Epoch 1184/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0110 - val_loss: 0.0125\n",
      "Epoch 1185/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0116 - val_loss: 0.0136\n",
      "Epoch 1186/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0116 - val_loss: 0.0103\n",
      "Epoch 1187/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0094 - val_loss: 0.0125\n",
      "Epoch 1188/1500\n",
      "514/514 [==============================] - 0s 60us/step - loss: 0.0129 - val_loss: 0.0129\n",
      "Epoch 1189/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0110 - val_loss: 0.0129\n",
      "Epoch 1190/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0110 - val_loss: 0.0127\n",
      "Epoch 1191/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0108 - val_loss: 0.0118\n",
      "Epoch 1192/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 1193/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0100 - val_loss: 0.0116\n",
      "Epoch 1194/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0126 - val_loss: 0.0159\n",
      "Epoch 1195/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0147 - val_loss: 0.0132\n",
      "Epoch 1196/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0126 - val_loss: 0.0144\n",
      "Epoch 1197/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0119 - val_loss: 0.0160\n",
      "Epoch 1198/1500\n",
      "514/514 [==============================] - 0s 61us/step - loss: 0.0128 - val_loss: 0.0185\n",
      "Epoch 1199/1500\n",
      "514/514 [==============================] - 0s 64us/step - loss: 0.0135 - val_loss: 0.0157\n",
      "Epoch 1200/1500\n",
      "514/514 [==============================] - 0s 68us/step - loss: 0.0120 - val_loss: 0.0185\n",
      "Epoch 1201/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0152 - val_loss: 0.0173\n",
      "Epoch 1202/1500\n",
      "514/514 [==============================] - 0s 67us/step - loss: 0.0144 - val_loss: 0.0171\n",
      "Epoch 1203/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0167 - val_loss: 0.0146\n",
      "Epoch 1204/1500\n",
      "514/514 [==============================] - 0s 61us/step - loss: 0.0131 - val_loss: 0.0102\n",
      "Epoch 1205/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0097 - val_loss: 0.0115\n",
      "Epoch 1206/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 1207/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0114 - val_loss: 0.0120\n",
      "Epoch 1208/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0124 - val_loss: 0.0130\n",
      "Epoch 1209/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0131 - val_loss: 0.0131\n",
      "Epoch 1210/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0132 - val_loss: 0.0204\n",
      "Epoch 1211/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0207 - val_loss: 0.0196\n",
      "Epoch 1212/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0176 - val_loss: 0.0191\n",
      "Epoch 1213/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0150 - val_loss: 0.0209\n",
      "Epoch 1214/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0153 - val_loss: 0.0211\n",
      "Epoch 1215/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0149 - val_loss: 0.0202\n",
      "Epoch 1216/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0152 - val_loss: 0.0167\n",
      "Epoch 1217/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0142 - val_loss: 0.0179\n",
      "Epoch 1218/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0175 - val_loss: 0.0142\n",
      "Epoch 1219/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0123 - val_loss: 0.0116\n",
      "Epoch 1220/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0130 - val_loss: 0.0156\n",
      "Epoch 1221/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0176 - val_loss: 0.0130\n",
      "Epoch 1222/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0125 - val_loss: 0.0178\n",
      "Epoch 1223/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0176 - val_loss: 0.0113\n",
      "Epoch 1224/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0109 - val_loss: 0.0169\n",
      "Epoch 1225/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0157 - val_loss: 0.0116\n",
      "Epoch 1226/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0102 - val_loss: 0.0119\n",
      "Epoch 1227/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0101 - val_loss: 0.0109\n",
      "Epoch 1228/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0100 - val_loss: 0.0124\n",
      "Epoch 1229/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0109 - val_loss: 0.0155\n",
      "Epoch 1230/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0123 - val_loss: 0.0155\n",
      "Epoch 1231/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0119 - val_loss: 0.0200\n",
      "Epoch 1232/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0169 - val_loss: 0.0211\n",
      "Epoch 1233/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0160 - val_loss: 0.0139\n",
      "Epoch 1234/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 1235/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0144 - val_loss: 0.0140\n",
      "Epoch 1236/1500\n",
      "514/514 [==============================] - 0s 88us/step - loss: 0.0153 - val_loss: 0.0236\n",
      "Epoch 1237/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0223 - val_loss: 0.0176\n",
      "Epoch 1238/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0176 - val_loss: 0.0161\n",
      "Epoch 1239/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0170 - val_loss: 0.0164\n",
      "Epoch 1240/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0170 - val_loss: 0.0155\n",
      "Epoch 1241/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0142 - val_loss: 0.0120\n",
      "Epoch 1242/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0152 - val_loss: 0.0259\n",
      "Epoch 1243/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0272 - val_loss: 0.0243\n",
      "Epoch 1244/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0218 - val_loss: 0.0174\n",
      "Epoch 1245/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0146 - val_loss: 0.0200\n",
      "Epoch 1246/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0155 - val_loss: 0.0289\n",
      "Epoch 1247/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0228 - val_loss: 0.0340\n",
      "Epoch 1248/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0265 - val_loss: 0.0280\n",
      "Epoch 1249/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0291 - val_loss: 0.0113\n",
      "Epoch 1250/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0133 - val_loss: 0.0145\n",
      "Epoch 1251/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0195 - val_loss: 0.0161\n",
      "Epoch 1252/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0138 - val_loss: 0.0240\n",
      "Epoch 1253/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0202 - val_loss: 0.0140\n",
      "Epoch 1254/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0156 - val_loss: 0.0128\n",
      "Epoch 1255/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0129 - val_loss: 0.0274\n",
      "Epoch 1256/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0233 - val_loss: 0.0153\n",
      "Epoch 1257/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0169 - val_loss: 0.0570\n",
      "Epoch 1258/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0404 - val_loss: 0.0599\n",
      "Epoch 1259/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0444 - val_loss: 0.0649\n",
      "Epoch 1260/1500\n",
      "514/514 [==============================] - 0s 60us/step - loss: 0.0491 - val_loss: 0.0729\n",
      "Epoch 1261/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0482 - val_loss: 0.0544\n",
      "Epoch 1262/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0377 - val_loss: 0.0483\n",
      "Epoch 1263/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0323 - val_loss: 0.0433\n",
      "Epoch 1264/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0287 - val_loss: 0.0316\n",
      "Epoch 1265/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0223 - val_loss: 0.0242\n",
      "Epoch 1266/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0192 - val_loss: 0.0193\n",
      "Epoch 1267/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0176 - val_loss: 0.0271\n",
      "Epoch 1268/1500\n",
      "514/514 [==============================] - 0s 61us/step - loss: 0.0243 - val_loss: 0.0305\n",
      "Epoch 1269/1500\n",
      "514/514 [==============================] - 0s 61us/step - loss: 0.0274 - val_loss: 0.0137\n",
      "Epoch 1270/1500\n",
      "514/514 [==============================] - 0s 68us/step - loss: 0.0142 - val_loss: 0.0187\n",
      "Epoch 1271/1500\n",
      "514/514 [==============================] - 0s 61us/step - loss: 0.0225 - val_loss: 0.0177\n",
      "Epoch 1272/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0129 - val_loss: 0.0192\n",
      "Epoch 1273/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0182 - val_loss: 0.0126\n",
      "Epoch 1274/1500\n",
      "514/514 [==============================] - 0s 63us/step - loss: 0.0114 - val_loss: 0.0148\n",
      "Epoch 1275/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0119 - val_loss: 0.0130\n",
      "Epoch 1276/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0123 - val_loss: 0.0159\n",
      "Epoch 1277/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0156 - val_loss: 0.0199\n",
      "Epoch 1278/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0208 - val_loss: 0.0193\n",
      "Epoch 1279/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0193 - val_loss: 0.0227\n",
      "Epoch 1280/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0221 - val_loss: 0.0156\n",
      "Epoch 1281/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0131 - val_loss: 0.0124\n",
      "Epoch 1282/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0144 - val_loss: 0.0132\n",
      "Epoch 1283/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0134 - val_loss: 0.0148\n",
      "Epoch 1284/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0127 - val_loss: 0.0242\n",
      "Epoch 1285/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0187 - val_loss: 0.0205\n",
      "Epoch 1286/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0147 - val_loss: 0.0171\n",
      "Epoch 1287/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0136 - val_loss: 0.0148\n",
      "Epoch 1288/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0113 - val_loss: 0.0155\n",
      "Epoch 1289/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0145 - val_loss: 0.0142\n",
      "Epoch 1290/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0113 - val_loss: 0.0126\n",
      "Epoch 1291/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0115 - val_loss: 0.0126\n",
      "Epoch 1292/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0111 - val_loss: 0.0141\n",
      "Epoch 1293/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0124 - val_loss: 0.0162\n",
      "Epoch 1294/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0124 - val_loss: 0.0148\n",
      "Epoch 1295/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0112 - val_loss: 0.0135\n",
      "Epoch 1296/1500\n",
      "514/514 [==============================] - 0s 45us/step - loss: 0.0104 - val_loss: 0.0122\n",
      "Epoch 1297/1500\n",
      "514/514 [==============================] - 0s 44us/step - loss: 0.0100 - val_loss: 0.0118\n",
      "Epoch 1298/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0103 - val_loss: 0.0125\n",
      "Epoch 1299/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0108 - val_loss: 0.0111\n",
      "Epoch 1300/1500\n",
      "514/514 [==============================] - 0s 60us/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 1301/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0094 - val_loss: 0.0108\n",
      "Epoch 1302/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0102 - val_loss: 0.0128\n",
      "Epoch 1303/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0126 - val_loss: 0.0116\n",
      "Epoch 1304/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0109 - val_loss: 0.0107\n",
      "Epoch 1305/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0109 - val_loss: 0.0178\n",
      "Epoch 1306/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0175 - val_loss: 0.0193\n",
      "Epoch 1307/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0173 - val_loss: 0.0144\n",
      "Epoch 1308/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0132 - val_loss: 0.0116\n",
      "Epoch 1309/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0115 - val_loss: 0.0129\n",
      "Epoch 1310/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0130 - val_loss: 0.0102\n",
      "Epoch 1311/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0102 - val_loss: 0.0138\n",
      "Epoch 1312/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0129 - val_loss: 0.0122\n",
      "Epoch 1313/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0112 - val_loss: 0.0142\n",
      "Epoch 1314/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0157 - val_loss: 0.0135\n",
      "Epoch 1315/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0122 - val_loss: 0.0146\n",
      "Epoch 1316/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 1317/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0113 - val_loss: 0.0118\n",
      "Epoch 1318/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0106 - val_loss: 0.0118\n",
      "Epoch 1319/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0111 - val_loss: 0.0117\n",
      "Epoch 1320/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0115 - val_loss: 0.0106\n",
      "Epoch 1321/1500\n",
      "514/514 [==============================] - 0s 61us/step - loss: 0.0100 - val_loss: 0.0117\n",
      "Epoch 1322/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0108 - val_loss: 0.0133\n",
      "Epoch 1323/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s 55us/step - loss: 0.0112 - val_loss: 0.0113\n",
      "Epoch 1324/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0098 - val_loss: 0.0104\n",
      "Epoch 1325/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0096 - val_loss: 0.0136\n",
      "Epoch 1326/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0138 - val_loss: 0.0145\n",
      "Epoch 1327/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0135 - val_loss: 0.0106\n",
      "Epoch 1328/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0098 - val_loss: 0.0115\n",
      "Epoch 1329/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0102 - val_loss: 0.0107\n",
      "Epoch 1330/1500\n",
      "514/514 [==============================] - 0s 66us/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 1331/1500\n",
      "514/514 [==============================] - 0s 60us/step - loss: 0.0097 - val_loss: 0.0102\n",
      "Epoch 1332/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0101 - val_loss: 0.0100\n",
      "Epoch 1333/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0095 - val_loss: 0.0113\n",
      "Epoch 1334/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0105 - val_loss: 0.0126\n",
      "Epoch 1335/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0110 - val_loss: 0.0111\n",
      "Epoch 1336/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0100 - val_loss: 0.0111\n",
      "Epoch 1337/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0102 - val_loss: 0.0109\n",
      "Epoch 1338/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0097 - val_loss: 0.0124\n",
      "Epoch 1339/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0113 - val_loss: 0.0148\n",
      "Epoch 1340/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0129 - val_loss: 0.0126\n",
      "Epoch 1341/1500\n",
      "514/514 [==============================] - 0s 63us/step - loss: 0.0107 - val_loss: 0.0108\n",
      "Epoch 1342/1500\n",
      "514/514 [==============================] - 0s 45us/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 1343/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0097 - val_loss: 0.0106\n",
      "Epoch 1344/1500\n",
      "514/514 [==============================] - 0s 64us/step - loss: 0.0100 - val_loss: 0.0114\n",
      "Epoch 1345/1500\n",
      "514/514 [==============================] - 0s 60us/step - loss: 0.0105 - val_loss: 0.0108\n",
      "Epoch 1346/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0102 - val_loss: 0.0117\n",
      "Epoch 1347/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0115 - val_loss: 0.0134\n",
      "Epoch 1348/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0130 - val_loss: 0.0130\n",
      "Epoch 1349/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0125 - val_loss: 0.0125\n",
      "Epoch 1350/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0120 - val_loss: 0.0115\n",
      "Epoch 1351/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0109 - val_loss: 0.0103\n",
      "Epoch 1352/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0099 - val_loss: 0.0101\n",
      "Epoch 1353/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 1354/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0099 - val_loss: 0.0108\n",
      "Epoch 1355/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0096 - val_loss: 0.0116\n",
      "Epoch 1356/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0102 - val_loss: 0.0129\n",
      "Epoch 1357/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0107 - val_loss: 0.0120\n",
      "Epoch 1358/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0107 - val_loss: 0.0142\n",
      "Epoch 1359/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0129 - val_loss: 0.0166\n",
      "Epoch 1360/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0149 - val_loss: 0.0166\n",
      "Epoch 1361/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0150 - val_loss: 0.0150\n",
      "Epoch 1362/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0138 - val_loss: 0.0128\n",
      "Epoch 1363/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0118 - val_loss: 0.0116\n",
      "Epoch 1364/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 1365/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0098 - val_loss: 0.0109\n",
      "Epoch 1366/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0112 - val_loss: 0.0146\n",
      "Epoch 1367/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0146 - val_loss: 0.0121\n",
      "Epoch 1368/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0108 - val_loss: 0.0112\n",
      "Epoch 1369/1500\n",
      "514/514 [==============================] - 0s 44us/step - loss: 0.0104 - val_loss: 0.0159\n",
      "Epoch 1370/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0146 - val_loss: 0.0134\n",
      "Epoch 1371/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0116 - val_loss: 0.0186\n",
      "Epoch 1372/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0152 - val_loss: 0.0191\n",
      "Epoch 1373/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0138 - val_loss: 0.0162\n",
      "Epoch 1374/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0118 - val_loss: 0.0153\n",
      "Epoch 1375/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0118 - val_loss: 0.0118\n",
      "Epoch 1376/1500\n",
      "514/514 [==============================] - 0s 46us/step - loss: 0.0105 - val_loss: 0.0122\n",
      "Epoch 1377/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0113 - val_loss: 0.0118\n",
      "Epoch 1378/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 1379/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 1380/1500\n",
      "514/514 [==============================] - 0s 64us/step - loss: 0.0099 - val_loss: 0.0107\n",
      "Epoch 1381/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0102 - val_loss: 0.0122\n",
      "Epoch 1382/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0106 - val_loss: 0.0113\n",
      "Epoch 1383/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0102 - val_loss: 0.0110\n",
      "Epoch 1384/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0099 - val_loss: 0.0112\n",
      "Epoch 1385/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0099 - val_loss: 0.0110\n",
      "Epoch 1386/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0098 - val_loss: 0.0111\n",
      "Epoch 1387/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0107 - val_loss: 0.0106\n",
      "Epoch 1388/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 1389/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0097 - val_loss: 0.0103\n",
      "Epoch 1390/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 1391/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0103 - val_loss: 0.0114\n",
      "Epoch 1392/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0106 - val_loss: 0.0119\n",
      "Epoch 1393/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0103 - val_loss: 0.0114\n",
      "Epoch 1394/1500\n",
      "514/514 [==============================] - 0s 60us/step - loss: 0.0104 - val_loss: 0.0123\n",
      "Epoch 1395/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0109 - val_loss: 0.0117\n",
      "Epoch 1396/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0101 - val_loss: 0.0118\n",
      "Epoch 1397/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0098 - val_loss: 0.0113\n",
      "Epoch 1398/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0096 - val_loss: 0.0112\n",
      "Epoch 1399/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0099 - val_loss: 0.0110\n",
      "Epoch 1400/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0096 - val_loss: 0.0133\n",
      "Epoch 1401/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0122 - val_loss: 0.0180\n",
      "Epoch 1402/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0142 - val_loss: 0.0176\n",
      "Epoch 1403/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0163 - val_loss: 0.0161\n",
      "Epoch 1404/1500\n",
      "514/514 [==============================] - 0s 60us/step - loss: 0.0154 - val_loss: 0.0110\n",
      "Epoch 1405/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0105 - val_loss: 0.0184\n",
      "Epoch 1406/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0159 - val_loss: 0.0168\n",
      "Epoch 1407/1500\n",
      "514/514 [==============================] - 0s 64us/step - loss: 0.0162 - val_loss: 0.0180\n",
      "Epoch 1408/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0174 - val_loss: 0.0149\n",
      "Epoch 1409/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0157 - val_loss: 0.0207\n",
      "Epoch 1410/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0163 - val_loss: 0.0151\n",
      "Epoch 1411/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0133 - val_loss: 0.0109\n",
      "Epoch 1412/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 1413/1500\n",
      "514/514 [==============================] - 0s 62us/step - loss: 0.0095 - val_loss: 0.0139\n",
      "Epoch 1414/1500\n",
      "514/514 [==============================] - 0s 60us/step - loss: 0.0138 - val_loss: 0.0174\n",
      "Epoch 1415/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0146 - val_loss: 0.0131\n",
      "Epoch 1416/1500\n",
      "514/514 [==============================] - 0s 45us/step - loss: 0.0112 - val_loss: 0.0201\n",
      "Epoch 1417/1500\n",
      "514/514 [==============================] - 0s 78us/step - loss: 0.0179 - val_loss: 0.0157\n",
      "Epoch 1418/1500\n",
      "514/514 [==============================] - 0s 62us/step - loss: 0.0126 - val_loss: 0.0112\n",
      "Epoch 1419/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0118 - val_loss: 0.0115\n",
      "Epoch 1420/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0109 - val_loss: 0.0129\n",
      "Epoch 1421/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0124 - val_loss: 0.0151\n",
      "Epoch 1422/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0123 - val_loss: 0.0114\n",
      "Epoch 1423/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0096 - val_loss: 0.0112\n",
      "Epoch 1424/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0103 - val_loss: 0.0155\n",
      "Epoch 1425/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0147 - val_loss: 0.0183\n",
      "Epoch 1426/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0166 - val_loss: 0.0158\n",
      "Epoch 1427/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0149 - val_loss: 0.0143\n",
      "Epoch 1428/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0138 - val_loss: 0.0121\n",
      "Epoch 1429/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0118 - val_loss: 0.0108\n",
      "Epoch 1430/1500\n",
      "514/514 [==============================] - 0s 61us/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 1431/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0100 - val_loss: 0.0114\n",
      "Epoch 1432/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0106 - val_loss: 0.0114\n",
      "Epoch 1433/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0102 - val_loss: 0.0115\n",
      "Epoch 1434/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0101 - val_loss: 0.0116\n",
      "Epoch 1435/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0097 - val_loss: 0.0121\n",
      "Epoch 1436/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0100 - val_loss: 0.0113\n",
      "Epoch 1437/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0098 - val_loss: 0.0106\n",
      "Epoch 1438/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0099 - val_loss: 0.0123\n",
      "Epoch 1439/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0120 - val_loss: 0.0137\n",
      "Epoch 1440/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0113 - val_loss: 0.0122\n",
      "Epoch 1441/1500\n",
      "514/514 [==============================] - 0s 61us/step - loss: 0.0126 - val_loss: 0.0143\n",
      "Epoch 1442/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0127 - val_loss: 0.0114\n",
      "Epoch 1443/1500\n",
      "514/514 [==============================] - 0s 58us/step - loss: 0.0097 - val_loss: 0.0118\n",
      "Epoch 1444/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0100 - val_loss: 0.0111\n",
      "Epoch 1445/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0097 - val_loss: 0.0107\n",
      "Epoch 1446/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0096 - val_loss: 0.0114\n",
      "Epoch 1447/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0104 - val_loss: 0.0124\n",
      "Epoch 1448/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0108 - val_loss: 0.0127\n",
      "Epoch 1449/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0106 - val_loss: 0.0123\n",
      "Epoch 1450/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0104 - val_loss: 0.0129\n",
      "Epoch 1451/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0105 - val_loss: 0.0127\n",
      "Epoch 1452/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0112 - val_loss: 0.0163\n",
      "Epoch 1453/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0147 - val_loss: 0.0169\n",
      "Epoch 1454/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0155 - val_loss: 0.0145\n",
      "Epoch 1455/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0139 - val_loss: 0.0139\n",
      "Epoch 1456/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0138 - val_loss: 0.0148\n",
      "Epoch 1457/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0140 - val_loss: 0.0130\n",
      "Epoch 1458/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0119 - val_loss: 0.0119\n",
      "Epoch 1459/1500\n",
      "514/514 [==============================] - 0s 61us/step - loss: 0.0115 - val_loss: 0.0152\n",
      "Epoch 1460/1500\n",
      "514/514 [==============================] - 0s 59us/step - loss: 0.0132 - val_loss: 0.0121\n",
      "Epoch 1461/1500\n",
      "514/514 [==============================] - 0s 69us/step - loss: 0.0101 - val_loss: 0.0130\n",
      "Epoch 1462/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0106 - val_loss: 0.0132\n",
      "Epoch 1463/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0108 - val_loss: 0.0119\n",
      "Epoch 1464/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0104 - val_loss: 0.0149\n",
      "Epoch 1465/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0133 - val_loss: 0.0119\n",
      "Epoch 1466/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0102 - val_loss: 0.0126\n",
      "Epoch 1467/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0121 - val_loss: 0.0126\n",
      "Epoch 1468/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0110 - val_loss: 0.0116\n",
      "Epoch 1469/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0105 - val_loss: 0.0119\n",
      "Epoch 1470/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 1471/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0104 - val_loss: 0.0109\n",
      "Epoch 1472/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0110 - val_loss: 0.0105\n",
      "Epoch 1473/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0101 - val_loss: 0.0111\n",
      "Epoch 1474/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0103 - val_loss: 0.0150\n",
      "Epoch 1475/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0134 - val_loss: 0.0132\n",
      "Epoch 1476/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0109 - val_loss: 0.0169\n",
      "Epoch 1477/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s 56us/step - loss: 0.0132 - val_loss: 0.0220\n",
      "Epoch 1478/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0158 - val_loss: 0.0200\n",
      "Epoch 1479/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0145 - val_loss: 0.0187\n",
      "Epoch 1480/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0139 - val_loss: 0.0153\n",
      "Epoch 1481/1500\n",
      "514/514 [==============================] - 0s 51us/step - loss: 0.0120 - val_loss: 0.0118\n",
      "Epoch 1482/1500\n",
      "514/514 [==============================] - 0s 55us/step - loss: 0.0106 - val_loss: 0.0102\n",
      "Epoch 1483/1500\n",
      "514/514 [==============================] - 0s 61us/step - loss: 0.0102 - val_loss: 0.0101\n",
      "Epoch 1484/1500\n",
      "514/514 [==============================] - 0s 57us/step - loss: 0.0101 - val_loss: 0.0114\n",
      "Epoch 1485/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0111 - val_loss: 0.0149\n",
      "Epoch 1486/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0140 - val_loss: 0.0136\n",
      "Epoch 1487/1500\n",
      "514/514 [==============================] - 0s 45us/step - loss: 0.0115 - val_loss: 0.0113\n",
      "Epoch 1488/1500\n",
      "514/514 [==============================] - 0s 56us/step - loss: 0.0101 - val_loss: 0.0135\n",
      "Epoch 1489/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0108 - val_loss: 0.0134\n",
      "Epoch 1490/1500\n",
      "514/514 [==============================] - 0s 43us/step - loss: 0.0105 - val_loss: 0.0139\n",
      "Epoch 1491/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0111 - val_loss: 0.0120\n",
      "Epoch 1492/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0098 - val_loss: 0.0106\n",
      "Epoch 1493/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0093 - val_loss: 0.0105\n",
      "Epoch 1494/1500\n",
      "514/514 [==============================] - 0s 48us/step - loss: 0.0096 - val_loss: 0.0118\n",
      "Epoch 1495/1500\n",
      "514/514 [==============================] - 0s 52us/step - loss: 0.0105 - val_loss: 0.0122\n",
      "Epoch 1496/1500\n",
      "514/514 [==============================] - 0s 44us/step - loss: 0.0106 - val_loss: 0.0121\n",
      "Epoch 1497/1500\n",
      "514/514 [==============================] - 0s 44us/step - loss: 0.0104 - val_loss: 0.0113\n",
      "Epoch 1498/1500\n",
      "514/514 [==============================] - 0s 50us/step - loss: 0.0096 - val_loss: 0.0123\n",
      "Epoch 1499/1500\n",
      "514/514 [==============================] - 0s 53us/step - loss: 0.0119 - val_loss: 0.0137\n",
      "Epoch 1500/1500\n",
      "514/514 [==============================] - 0s 49us/step - loss: 0.0123 - val_loss: 0.0108\n"
     ]
    }
   ],
   "source": [
    "# fit the model - INTENSIVE\n",
    "model3_history = model3.fit(X_train, Y_train, batch_size=256, epochs=1500, verbose=1, \\\n",
    "                            shuffle = True, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model3_history.model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use our model to predict in the range we want\n",
    "num_epochs = f'{len(model3_history.epoch)}'\n",
    "\n",
    "X_range = np.linspace(-10, 10, 500)\n",
    "y_pred = model3.predict(X_range)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,6))\n",
    "ax.scatter(X_train, Y_train, label='Training data')\n",
    "ax.plot(X_range, y_pred, lw=4, color='r', label=f'NN ({num_epochs} epochs)')\n",
    "\n",
    "ax.set_xlabel(r'$X$', fontsize=20)\n",
    "ax.set_ylabel(r'$Y$', fontsize=20)\n",
    "ax.set_title(f'NN with {len(model3_history.model.layers)} layers, {H} nodes in each layer', fontsize=LABEL_SIZE)\n",
    "ax.tick_params(labelsize=20)\n",
    "\n",
    "ax.legend(loc=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
    "ax.plot(np.sqrt(model2_history.history['loss']), 'r')\n",
    "ax.plot(np.sqrt(model2_history.history['val_loss']), 'b' ,label='Val')\n",
    "ax.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax.set_ylabel(r'Loss', fontsize=20)\n",
    "ax.legend()\n",
    "ax.tick_params(labelsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the training and testing performance of your model \n",
    "# note: you should extract and check both the loss function and your evaluation metric\n",
    "score = model2.evaluate(X_train, Y_train, verbose=1)\n",
    "print('Train loss:', score)\n",
    "print('Train R2:', r2(Y_train, model2.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model2.evaluate(X_test, Y_test, verbose=1)\n",
    "print('Test loss:', score)\n",
    "print('Test R2:', r2(Y_test, model2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got a better score this time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 5</b> </div>\n",
    "\n",
    "Usually we want to avoid overfitting of the data to our model. But here we want to achive overfitting! So we can regularize! There are a few reasons why a model overfits. One is the lack of data. So we will try to overfit by reducing the data. Try that with model3 and see if it overfits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Having very few points in our data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 50 # set the number of samples to take for each dataset\n",
    "test_size = 0.3 # set the proportion of data to hold out for testing\n",
    "\n",
    "# define the function and add noise\n",
    "\n",
    "def f_gauss(x):\n",
    "    return np.exp(-x * x) + np.random.normal(loc=0, scale=.1, size = x.shape[0])\n",
    "\n",
    "X = np.random.permutation(np.linspace(-10, 10, n_samples)) # choose some points from the function\n",
    "Y = f_gauss(X)\n",
    "\n",
    "# create training and testing data from this set of points\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a2ea2c198>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD/CAYAAADxL6FlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFy1JREFUeJzt3W+snNdd4PHvD9ulFzuuleYSya5cm25iJLd1gu4Ltl4v1dLK4o8Ut943m2zSCpBpoqyqBQwOKNpuhIgbw77pRgmRSlsCSmCRY1J5WfPCGxG3gHKD5boWtatNNrQ3onFq2fI1t0kwv30xz03Gd2fm3hmfmXlm5vuRRvJ95szMb47nmd+cP885kZlIkvRDww5AklQPJgRJEmBCkCRVTAiSJMCEIEmqmBAkSYAJQZJUMSFIkgATgiSpsnrYAXTjpptuyi1btgw7DEkaKS+++OLrmTm9XLmRSghbtmxhdnZ22GFI0kiJiFdWUs4uI0kSYEKQJFVMCJIkwIQgSaqYECRJgAlBklQxIUiSABOCJKkyUhemScNy5OQch46d5dWLC2zcMMX+3dvYc/umYYclFWVCkJZx5OQcDxw+zcJbVwGYu7jAA4dPA5gUNFbsMpKWcejY2beTwaKFt65y6NjZIUUk9YcJQVrGqxcXujoujSoTgrSMjRumujoujaqiCSEiboyIZyLiSkS8EhF3tin3wxHxeER8LyIuRMRXI8LOWNXS/t3bmFqz6ppjU2tWsX/3tiFFJPVH6RbCo8CbwM3AXcBjEbG9RbnPAv8a+DCwEbgIfKFwLFIRe27fxMOf/BCbNkwRwKYNUzz8yQ85oKyxU2yWUUSsBfYCH8zMeeBERDwL3A0cWFJ8K3AsM79XPfZp4L+VikUqbc/tm0wAGnslWwi3Alcz81zTsVNAqxbCF4GdEbExIn6ERmviLwrGIknqUsnrENYBl5YcuwTc0KLsOeAfgDngKnAauL/Vk0bEPmAfwObNm0vFKklaomQLYR5Yv+TYeuByi7KPAe8G3gusBQ7TpoWQmU9k5kxmzkxPL7slqCSpRyVbCOeA1RFxS2Z+uzq2AzjTouwO4Lcy8wJARHwBeCgibsrM1wvGJPWVS1ponBRrIWTmFRq/9B+KiLURsRO4A3iyRfEXgHsi4j0RsQa4D3jVZKBRsrikxdzFBZJ3lrQ4cnJu2KFJPSk97fQ+YAp4DXgKuDczz0TEroiYbyr3a8APgG8D54GfBT5ROBapr1zSQuOm6OJ2VRfQnhbHn6cx6Lz49/dpzCySRpZLWmjcuHSF1COXtNC4MSFIPVpuSYsjJ+fYefA4Ww8cZefB444tqPbcD0Hq0eJsolazjNxDQaPIhCBdh3ZLWnQacDYhqK7sMpL6wAFnjSITgtQHDjhrFJkQpD5wDwWNIscQpD7oNOAs1ZUJQeoT91DQqLHLSJIEmBAkSRUTgiQJMCFIkiomBEkSYEKQJFVMCJIkwIQgSaqYECRJgFcqS9c4cnLO5SY0sUwIUsVNbTTp7DKSKp02tZEmgQlBqripjSadCUGquKmNJp0JQaq4qY0mnYPKUsVNbTTpTAhSEze10SSzy0iSBJgQJEkVE4IkCSicECLixoh4JiKuRMQrEXFnh7I/ERF/FRHzEfG9iPhsyVgkSd0pPaj8KPAmcDNwG3A0Ik5l5pnmQhFxE/C/gP8M/BnwLuB9hWORJHWhWAshItYCe4EHM3M+M08AzwJ3tyj+K8CxzPzjzHwjMy9n5t+XikWS1L2SXUa3Alcz81zTsVPA9hZlfxK4EBFfj4jXIuKrEbG51ZNGxL6ImI2I2fPnzxcMV5LUrGRCWAdcWnLsEnBDi7LvAz4FfBbYDLwMPNXqSTPzicycycyZ6enpguFKkpqVHEOYB9YvObYeuNyi7ALwTGa+ABAR/xV4PSLek5lLk4okaQBKthDOAasj4pamYzuAMy3KfgPIpr8X/x0F45EkdaFYQsjMK8Bh4KGIWBsRO4E7gCdbFP8S8ImIuC0i1gAPAicy82KpeCRJ3Sl9Ydp9wBTwGo0xgXsz80xE7IqI+cVCmXkc+E3gaFX2XwFtr1mQJPVf0esQMvMCsKfF8edpDDo3H3sMeKzk60uSeufSFZIkwIQgSaqYECRJgAlBklQxIUiSABOCJKliQpAkASYESVLFhCBJAkwIkqSKCUGSBJgQJEkVE4IkCTAhSJIqJgRJEmBCkCRVTAiSJMCEIEmqmBAkSYAJQZJUMSFIkgATgiSpYkKQJAEmBElSxYQgSQJMCJKkiglBkgSYECRJlaIJISJujIhnIuJKRLwSEXcuU/5dEfGtiPhuyTikTo6cnGPnweNsPXCUnQePc+Tk3LBDkmphdeHnexR4E7gZuA04GhGnMvNMm/L7gdeAdYXjkFo6cnKOBw6fZuGtqwDMXVzggcOnAdhz+6ZhhiYNXbEWQkSsBfYCD2bmfGaeAJ4F7m5TfivwH4GHS8UgLefQsbNvJ4NFC29d5dCxs0OKSKqPkl1GtwJXM/Nc07FTwPY25b8A/CawUDAGqaNXL7b+uLU7Lk2SkglhHXBpybFLwA1LC0bEJ4DVmfnMck8aEfsiYjYiZs+fP18mUk2sjRumujouTZKSCWEeWL/k2HrgcvOBqmvpEeA/reRJM/OJzJzJzJnp6ekigWpy7d+9jak1q645NrVmFft3bxtSRFJ9lBxUPgesjohbMvPb1bEdwNIB5VuALcDzEQHwLuA9EfGPwE9m5v8tGJN0jcWB40PHzvLqxQU2bphi/+5tDihLQGRmuSeLeBpI4JdozDL6n8BHmmcZRcRq4Kamh30E+O/ATwDnM/PaEb8mMzMzOTs7WyxeSZoEEfFiZs4sV670hWn3AVM0ppI+BdybmWciYldEzANk5j9n5j8u3oALwL9Uf7dNBpKk/ip6HUJmXgD2tDj+PG2uNcjM54D3lYxDktQ9l66QJAEmBElSxYQgSQJMCJKkiglBkgSYECRJFROCJAkwIUiSKiYESRJgQpAkVUwIkiSg/J7KkpZx5OScy2+rlkwI0gAdOTnHA4dPv72v89zFBR44fBrApKChs8tIGqBDx86+nQwWLbx1lUPHzg4pIukdJgRpgF69uNDVcWmQTAjSAG3cMNXVcWmQTAjSAO3fvY2pNauuOTa1ZhX7d28bUkTSOxxUlgZoceDYWUaqIxOCNGB7bt9kAlAt2WUkSQJMCJKkiglBkgSYECRJFROCJAkwIUiSKiYESRJgQpAkVUwIkiTAhCBJqhRNCBFxY0Q8ExFXIuKViLizTbn9EfHNiLgcES9HxP6ScUiSuld6LaNHgTeBm4HbgKMRcSozzywpF8A9wDeADwB/GRHfycynC8cjSVqhYgkhItYCe4EPZuY8cCIingXuBg40l83MR5r+PBsRfw7sBEwIUp+5p7PaKdlldCtwNTPPNR07BWzv9KCICGAXsLQVsXj/voiYjYjZ8+fPFwtWmkSLezrPXVwgeWdP5yMn54YdmmqgZEJYB1xacuwScMMyj/tcFceXWt2ZmU9k5kxmzkxPT193kNIkc09ndVJyDGEeWL/k2HrgcrsHRMT9NMYSdmXmGwVjkdSCezrXU1268Uq2EM4BqyPilqZjO2jfFfQLNMYWfjozv1swDkltuKdz/dSpG69YQsjMK8Bh4KGIWBsRO4E7gCeXlo2Iu4DfAT6emS+VikFSZ+7pXD916sYrPe30PuAPgNeA7wP3ZuaZiNgF/EVmrqvK/TbwXuCFxpgyAH+UmZ8pHE9tmmJSHbinc/3UqRuvaELIzAvAnhbHn6cx6Lz499aSr9vOYlNsMfsuNsUATwBNLPd0rpeNG6aYa/HlP4xuvLFeuqJOTTEN3pGTc+w8eJytB46y8+Bxp1aqlurUjVe6y6hW6tQU02DZOtSoqFM33lgnhDo1xTRYnVqHJgTVTV268ca6y6hOTTENlq1DqXtjnRD23L6Jhz/5ITZtmCKATRumePiTH6pFJlZ/Od9e6t5YdxlBfZpiGqz9u7ddM4YAtg6l5Yx9QtB46PZ6kjoN1EmjwoRQQ+NyMV2n99HNe+x1xpCtQ6k7JoSaGZfpkp3eB9DVe3TGkDQYYz2oPIrG5WK6Tu+j2/fojCFpMEwINTMuX36d3ke379EZQ9JgmBBqZly+/Dq9j27fo9eTjB6XDRlNJoSaGZcvv07vo9v36PUko6VO6/u3is1E1Z6DyjUzLtMlV/I+up1GOmp1MKnqOglgXCZs9FNk5rBjWLGZmZmcnZ0t9nzjMr1TqpOtB47S6lslgJcP/txAYmh1bh86drbl2mabNkzxtQP/biBxDUtEvJiZM8uVm9gWgr8WpP4Y9qKS7c7tpa2WRaM2YaOfJnYMYVymd0p1M+xxsHbn9qp3dme8xqhN2OiniW0hjMv0Tqluhj0O1u4cvprJ1JpVXa9vNUldyxObEIbdrB2USfowqz6GOQmg3bm9qWksYaXnQ69dyyXPu0GewxObECZhNUzHSTSJOp3b3SaqXmZMlTzvBn0OT+wYwiTMbXecRJOo5LndS9dyyfNu0OfwxLYQYPzntjtOoklV6tzupWu55Hk36HN4YlsIk2BclsGQhqWXGVMlz7tBn8MmhDE27Ol/0qjrpfup5Hk36HN4oruMxkW7WQjDnv4njYNuu59KnneDPocneumKcbB0FgI0fkGM2wC5pN6tdOkKu4xGnDOJJJViQhhxziSSVErRhBARN0bEMxFxJSJeiYg725SLiPh8RHy/uj0S0WahEXXkTCJJpZRuITwKvAncDNwFPBYR21uU2wfsAXYAHwZ+HvjlwrFMBGcSSSqlWEKIiLXAXuDBzJzPzBPAs8DdLYp/Cvi9zPxuZs4Bvwd8ulQsk2QSrriWNBglp53eClzNzHNNx04BP9Wi7PbqvuZyrVoSWoFxv+Jak8GFGIevZEJYB1xacuwScMMKyl4C1kVE5JJ5sBGxj0YXE5s3by4X7YTz5FOduBBjPZQcQ5gH1i85th64vIKy64H5pckAIDOfyMyZzJyZnp4uFuwkq/Mm6JpMTp+uh5IJ4RywOiJuaTq2AzjTouyZ6r7lyo28Iyfn2HnwOFsPHGXnweO1+NL15FPdOH26HoolhMy8AhwGHoqItRGxE7gDeLJF8T8EfiUiNkXERuBXgS+XiqUu6vpL3JNPdeP06XooPe30PmAKeA14Crg3M89ExK6ImG8q9/vAV4HTwDeBo9WxsVL6l3ip1oYnn+rG6dP1UHRxu8y8QOP6gqXHn6cxkLz4dwK/Xt3GVslf4iUH3eq8W5yD3ZPJhRjrwdVO+6jkvs29bOXXTl1PPmeaTDanTw+fCaGPSv4SL93vX8eTr2TSk9Q9F7fro5JXEU9Cv7+D3dJw2ULos1K/xOvc719KyS62SedYjHphC2FETMKaRc40aa+bGWZ1ne6s+rOFMELq2O9fUl0Hu4et28F2x2LUKxOCVmwQ3RDjnvR60e0XvGMx6pVdRloRuyGGp9sv+EmYgKD+sIWgFVnuqmu7efqn28H2SZiAoP6whVBIHRexK6ndr9HFloIth/7pdrB9EiYgqD9sIRQwCVfYtvuVuirCAcw+62Ww3bEY9cKEUMAkzOpo1w2x9H0vcgCzLL/gNQh2GRUwCbM62nVDbHIAUxobthAKmJQrbNv9SnUAUxoPthAKmOQrbB3AlMaHLYQCJv0KW/u3NSyu2VSWCaEQvxSlwZqE2X2DZpeRpJFUeotamRAkjahJmN03aCYESSPJNZvKMyFIGkmTPLuvXxxUljSSJn12Xz+YECSNLGf3lWVC0MhzLrpUhglBI8256FI5DiprpDkXXSrHhKCR5lx0qRwTgkaac9GlckwIGmnORZfKKZIQIuLGiHgmIq5ExCsRcWeHsvsj4psRcTkiXo6I/SVi0GRy+W2pnFKzjB4F3gRuBm4DjkbEqcw806JsAPcA3wA+APxlRHwnM58uFIsmjHPRpTKuu4UQEWuBvcCDmTmfmSeAZ4G7W5XPzEcy8+8y858z8yzw58DO641DknR9SnQZ3QpczcxzTcdOAduXe2BEBLALaNWSWCyzLyJmI2L2/Pnz1x2sJKm1EglhHXBpybFLwA0reOznqhi+1K5AZj6RmTOZOTM9Pd1zkJKkzpZNCBHxXERkm9sJYB5Yv+Rh64HLyzzv/TTGEn4uM9/o9Q1IkspYdlA5Mz/a6f5qDGF1RNySmd+uDu+gczfQLwAHgH+bmd9debiSpH657i6jzLwCHAYeioi1EbETuAN4slX5iLgL+B3g45n50vW+viSpjFIXpt0HTAGvAU8B9y5OOY2IXREx31T2t4H3Ai9ExHx1e7xQHJKkHhW5DiEzLwB72tz3PI2B58W/t5Z4TUlSWZGZw45hxSLiPPDKMsVuAl4fQDi9MLbe1DW2usYFxtarcY3t/Zm57DTNkUoIKxERs5k5M+w4WjG23tQ1trrGBcbWq0mPzcXtJEmACUGSVBnHhPDEsAPowNh6U9fY6hoXGFuvJjq2sRtDkCT1ZhxbCJKkHpgQJEnACCaEiLi/Wg77jYj4cov7fzoivhUR/xQR/zsi3t/hubZUZf6peszHCsc6v+R2NSK+0Kbsp6v7m8t/tGQ8S17vuYj4QdNrne1QNiLi8xHx/er2SLV0eemYfjgivljtunc5Ik5GxM90KN/3OlvpboCDqqOm11txXdX1szWEOqvV+djpu2xY32MjlxCAV2ksf/EHS++IiJtorKv0IHAjMAv8SYfnego4SWMpjd8C/iwiiq2xnZnrFm80dpNbAP5Hh4f8dfNjMvO5UrG0cX/Ta3XahHgfjSvRdwAfBn4e+OU+xLMa+A7wU8B7aPw//mlEbOnwmH7XWfNugHcBj0VEq70+BlVHi7qtqzp+tgZaZzU8H1t+lw31eywzR/JWVeSXlxzbB3y96e+1NP7Tf7zF428F3gBuaDr2PPCZPsX7KeAlqoH8Fvd/GjgxwPp7DvilFZb9OrCv6e9fBP5mQHF+A9g7jDqrPj9vArc2HXsSOFinOlqurur62Rry56o25+PS77Jhfo+NYguhk+00dmsD3l6J9f/Qeve27cBLmdm8b8OKdnrr0aeAP8zqf6yN2yPi9Yg4FxEPRkSpPa/bebh6va8t0xy+pl7pbz29LSJupvGBb7uUOv2ts252AxxKHS1aQV3V8bM1zDqr4/m4aGjfY+OWELrZve16dnrrSkRsptG0/0qHYn8FfBD4URp7VP8HYH/pWJr8BvBjwCYa85u/GhEfaFN2aV1dAtb1ub93DfDHwFcy81ttivW7zq7n89T3Olq0grqq62drKHVW0/Ox2dC+x2qVEGL53dmW083ubT3t9NZjrPfQaH6+3O75MvOlzHw5M/8lM08DDwH/fiWx9BJbZv5tZl7OzDcy8yvA14CfbfOUS+tqPTC/zK+rnuKqyv0Qja6ZN4H72z1fyTpr43o+Tz3VUbdWUlcDqKelr7fSz9ZQ6owBn489GNj32FK1SgiZ+dHMjDa3f7OCpzhDY4AKeHs3tw/Quhl9BvixiGjOpB13eruOWO+h86+Rli8B9PRLqcd67PR619QrXdRTt3FVvw6/SGPQb29mvtXNS3R4D704R7UbYNOxdu+9SB114zrqqnQ99fp6A6+zykDPxx4M7Hvs/9PvAZPSNxqzK94NPEzjl9G7gdXVfdM0mkt7q+Ofp8MgFfA3wO9WZT8BXASmC8f7EeAKTYM+bcr9DHBz9e8fB74J/Jc+1eEGYPdi3dGYPXMF2Nam/GeAv6fRBbCx+rD1a/D98er/Zd0Kyva9zoCnacziWAvsrD5f24dZR93WVV0/W0Oqs9qcj+2+y4b5Pda3iu/jf+jnaGTr5tvnmu7/GPAtGqPyzwFbmu57HHi86e8tVZkF4CzwsT7E+/vAky2Ob6bR3Ntc/f27wPeqD+tLNJqoa/pUh9PACzSalRerD9THm+7fRaPpvvh3AI8AF6rbI7SZnXGdcb2/+v/8QVU3i7e7hlVnNKb9Hale4x+AO4dZRyupq7p+toZdZ9Vr1uZ8pMN3GUP6HnMtI0kSULMxBEnS8JgQJEmACUGSVDEhSJIAE4IkqWJCkCQBJgRJUsWEIEkCTAiSpMr/A6jm9v0nF0OuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of hidden nodes\n",
    "H =  100\n",
    "# input dimension\n",
    "input_dim = 1\n",
    "\n",
    "# create sequential multi-layer perceptron\n",
    "model4 = models.Sequential()\n",
    "\n",
    "#add 10 hidden layers\n",
    "for i in range(9):\n",
    "    model4.add(layers.Dense(H, input_dim=input_dim, activation='tanh')) \n",
    "\n",
    "# layer 10 - output\n",
    "model4.add(layers.Dense(1, \n",
    "                activation='linear')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the model\n",
    "model4.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28 samples, validate on 7 samples\n",
      "Epoch 1/1500\n",
      "28/28 [==============================] - 1s 47ms/step - loss: 0.1120 - val_loss: 0.6273\n",
      "Epoch 2/1500\n",
      "28/28 [==============================] - 0s 199us/step - loss: 0.8437 - val_loss: 0.0556\n",
      "Epoch 3/1500\n",
      "28/28 [==============================] - 0s 209us/step - loss: 0.1162 - val_loss: 0.2584\n",
      "Epoch 4/1500\n",
      "28/28 [==============================] - 0s 209us/step - loss: 0.2696 - val_loss: 0.3140\n",
      "Epoch 5/1500\n",
      "28/28 [==============================] - 0s 207us/step - loss: 0.3151 - val_loss: 0.1331\n",
      "Epoch 6/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.1231 - val_loss: 0.0451\n",
      "Epoch 7/1500\n",
      "28/28 [==============================] - 0s 260us/step - loss: 0.0690 - val_loss: 0.1097\n",
      "Epoch 8/1500\n",
      "28/28 [==============================] - 0s 242us/step - loss: 0.1759 - val_loss: 0.1012\n",
      "Epoch 9/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.1537 - val_loss: 0.0489\n",
      "Epoch 10/1500\n",
      "28/28 [==============================] - 0s 182us/step - loss: 0.0685 - val_loss: 0.0594\n",
      "Epoch 11/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.0664 - val_loss: 0.1082\n",
      "Epoch 12/1500\n",
      "28/28 [==============================] - 0s 170us/step - loss: 0.1157 - val_loss: 0.1103\n",
      "Epoch 13/1500\n",
      "28/28 [==============================] - 0s 176us/step - loss: 0.1118 - val_loss: 0.0765\n",
      "Epoch 14/1500\n",
      "28/28 [==============================] - 0s 191us/step - loss: 0.0691 - val_loss: 0.0572\n",
      "Epoch 15/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0475 - val_loss: 0.0667\n",
      "Epoch 16/1500\n",
      "28/28 [==============================] - 0s 230us/step - loss: 0.0626 - val_loss: 0.0812\n",
      "Epoch 17/1500\n",
      "28/28 [==============================] - 0s 183us/step - loss: 0.0812 - val_loss: 0.0800\n",
      "Epoch 18/1500\n",
      "28/28 [==============================] - 0s 188us/step - loss: 0.0751 - val_loss: 0.0707\n",
      "Epoch 19/1500\n",
      "28/28 [==============================] - 0s 180us/step - loss: 0.0530 - val_loss: 0.0716\n",
      "Epoch 20/1500\n",
      "28/28 [==============================] - 0s 172us/step - loss: 0.0399 - val_loss: 0.0872\n",
      "Epoch 21/1500\n",
      "28/28 [==============================] - 0s 173us/step - loss: 0.0453 - val_loss: 0.1021\n",
      "Epoch 22/1500\n",
      "28/28 [==============================] - 0s 166us/step - loss: 0.0553 - val_loss: 0.1000\n",
      "Epoch 23/1500\n",
      "28/28 [==============================] - 0s 169us/step - loss: 0.0531 - val_loss: 0.0823\n",
      "Epoch 24/1500\n",
      "28/28 [==============================] - 0s 172us/step - loss: 0.0398 - val_loss: 0.0634\n",
      "Epoch 25/1500\n",
      "28/28 [==============================] - 0s 187us/step - loss: 0.0295 - val_loss: 0.0539\n",
      "Epoch 26/1500\n",
      "28/28 [==============================] - 0s 263us/step - loss: 0.0303 - val_loss: 0.0520\n",
      "Epoch 27/1500\n",
      "28/28 [==============================] - 0s 171us/step - loss: 0.0360 - val_loss: 0.0504\n",
      "Epoch 28/1500\n",
      "28/28 [==============================] - 0s 196us/step - loss: 0.0360 - val_loss: 0.0471\n",
      "Epoch 29/1500\n",
      "28/28 [==============================] - 0s 231us/step - loss: 0.0287 - val_loss: 0.0467\n",
      "Epoch 30/1500\n",
      "28/28 [==============================] - 0s 187us/step - loss: 0.0212 - val_loss: 0.0527\n",
      "Epoch 31/1500\n",
      "28/28 [==============================] - 0s 240us/step - loss: 0.0202 - val_loss: 0.0613\n",
      "Epoch 32/1500\n",
      "28/28 [==============================] - 0s 282us/step - loss: 0.0233 - val_loss: 0.0649\n",
      "Epoch 33/1500\n",
      "28/28 [==============================] - 0s 268us/step - loss: 0.0233 - val_loss: 0.0617\n",
      "Epoch 34/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.0182 - val_loss: 0.0568\n",
      "Epoch 35/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.0135 - val_loss: 0.0554\n",
      "Epoch 36/1500\n",
      "28/28 [==============================] - 0s 177us/step - loss: 0.0135 - val_loss: 0.0565\n",
      "Epoch 37/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.0161 - val_loss: 0.0560\n",
      "Epoch 38/1500\n",
      "28/28 [==============================] - 0s 190us/step - loss: 0.0158 - val_loss: 0.0530\n",
      "Epoch 39/1500\n",
      "28/28 [==============================] - 0s 200us/step - loss: 0.0123 - val_loss: 0.0505\n",
      "Epoch 40/1500\n",
      "28/28 [==============================] - 0s 196us/step - loss: 0.0100 - val_loss: 0.0497\n",
      "Epoch 41/1500\n",
      "28/28 [==============================] - 0s 247us/step - loss: 0.0110 - val_loss: 0.0480\n",
      "Epoch 42/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0123 - val_loss: 0.0429\n",
      "Epoch 43/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.0110 - val_loss: 0.0368\n",
      "Epoch 44/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.0086 - val_loss: 0.0333\n",
      "Epoch 45/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.0085 - val_loss: 0.0321\n",
      "Epoch 46/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.0098 - val_loss: 0.0305\n",
      "Epoch 47/1500\n",
      "28/28 [==============================] - 0s 196us/step - loss: 0.0099 - val_loss: 0.0282\n",
      "Epoch 48/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.0084 - val_loss: 0.0271\n",
      "Epoch 49/1500\n",
      "28/28 [==============================] - 0s 226us/step - loss: 0.0078 - val_loss: 0.0276\n",
      "Epoch 50/1500\n",
      "28/28 [==============================] - 0s 245us/step - loss: 0.0087 - val_loss: 0.0280\n",
      "Epoch 51/1500\n",
      "28/28 [==============================] - 0s 251us/step - loss: 0.0090 - val_loss: 0.0274\n",
      "Epoch 52/1500\n",
      "28/28 [==============================] - 0s 191us/step - loss: 0.0080 - val_loss: 0.0274\n",
      "Epoch 53/1500\n",
      "28/28 [==============================] - 0s 233us/step - loss: 0.0075 - val_loss: 0.0283\n",
      "Epoch 54/1500\n",
      "28/28 [==============================] - 0s 169us/step - loss: 0.0081 - val_loss: 0.0288\n",
      "Epoch 55/1500\n",
      "28/28 [==============================] - 0s 183us/step - loss: 0.0085 - val_loss: 0.0282\n",
      "Epoch 56/1500\n",
      "28/28 [==============================] - 0s 185us/step - loss: 0.0078 - val_loss: 0.0277\n",
      "Epoch 57/1500\n",
      "28/28 [==============================] - 0s 150us/step - loss: 0.0074 - val_loss: 0.0278\n",
      "Epoch 58/1500\n",
      "28/28 [==============================] - 0s 287us/step - loss: 0.0078 - val_loss: 0.0275\n",
      "Epoch 59/1500\n",
      "28/28 [==============================] - 0s 253us/step - loss: 0.0079 - val_loss: 0.0264\n",
      "Epoch 60/1500\n",
      "28/28 [==============================] - 0s 184us/step - loss: 0.0074 - val_loss: 0.0253\n",
      "Epoch 61/1500\n",
      "28/28 [==============================] - 0s 179us/step - loss: 0.0071 - val_loss: 0.0248\n",
      "Epoch 62/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.0074 - val_loss: 0.0244\n",
      "Epoch 63/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0075 - val_loss: 0.0242\n",
      "Epoch 64/1500\n",
      "28/28 [==============================] - 0s 196us/step - loss: 0.0072 - val_loss: 0.0246\n",
      "Epoch 65/1500\n",
      "28/28 [==============================] - 0s 179us/step - loss: 0.0070 - val_loss: 0.0254\n",
      "Epoch 66/1500\n",
      "28/28 [==============================] - 0s 279us/step - loss: 0.0072 - val_loss: 0.0257\n",
      "Epoch 67/1500\n",
      "28/28 [==============================] - 0s 167us/step - loss: 0.0073 - val_loss: 0.0255\n",
      "Epoch 68/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.0070 - val_loss: 0.0253\n",
      "Epoch 69/1500\n",
      "28/28 [==============================] - 0s 233us/step - loss: 0.0070 - val_loss: 0.0254\n",
      "Epoch 70/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0072 - val_loss: 0.0257\n",
      "Epoch 71/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0071 - val_loss: 0.0263\n",
      "Epoch 72/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0070 - val_loss: 0.0271\n",
      "Epoch 73/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.0070 - val_loss: 0.0276\n",
      "Epoch 74/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0071 - val_loss: 0.0274\n",
      "Epoch 75/1500\n",
      "28/28 [==============================] - 0s 193us/step - loss: 0.0071 - val_loss: 0.0268\n",
      "Epoch 76/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.0070 - val_loss: 0.0263\n",
      "Epoch 77/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0070 - val_loss: 0.0260\n",
      "Epoch 78/1500\n",
      "28/28 [==============================] - 0s 230us/step - loss: 0.0070 - val_loss: 0.0261\n",
      "Epoch 79/1500\n",
      "28/28 [==============================] - 0s 241us/step - loss: 0.0069 - val_loss: 0.0264\n",
      "Epoch 80/1500\n",
      "28/28 [==============================] - 0s 244us/step - loss: 0.0069 - val_loss: 0.0267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/1500\n",
      "28/28 [==============================] - 0s 190us/step - loss: 0.0069 - val_loss: 0.0268\n",
      "Epoch 82/1500\n",
      "28/28 [==============================] - 0s 216us/step - loss: 0.0069 - val_loss: 0.0267\n",
      "Epoch 83/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.0069 - val_loss: 0.0265\n",
      "Epoch 84/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.0068 - val_loss: 0.0265\n",
      "Epoch 85/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0069 - val_loss: 0.0268\n",
      "Epoch 86/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0068 - val_loss: 0.0272\n",
      "Epoch 87/1500\n",
      "28/28 [==============================] - 0s 280us/step - loss: 0.0068 - val_loss: 0.0275\n",
      "Epoch 88/1500\n",
      "28/28 [==============================] - 0s 244us/step - loss: 0.0068 - val_loss: 0.0277\n",
      "Epoch 89/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.0068 - val_loss: 0.0276\n",
      "Epoch 90/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0068 - val_loss: 0.0274\n",
      "Epoch 91/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0068 - val_loss: 0.0272\n",
      "Epoch 92/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.0068 - val_loss: 0.0272\n",
      "Epoch 93/1500\n",
      "28/28 [==============================] - 0s 233us/step - loss: 0.0068 - val_loss: 0.0273\n",
      "Epoch 94/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.0068 - val_loss: 0.0275\n",
      "Epoch 95/1500\n",
      "28/28 [==============================] - 0s 253us/step - loss: 0.0068 - val_loss: 0.0276\n",
      "Epoch 96/1500\n",
      "28/28 [==============================] - 0s 232us/step - loss: 0.0068 - val_loss: 0.0275\n",
      "Epoch 97/1500\n",
      "28/28 [==============================] - 0s 374us/step - loss: 0.0068 - val_loss: 0.0275\n",
      "Epoch 98/1500\n",
      "28/28 [==============================] - 0s 232us/step - loss: 0.0067 - val_loss: 0.0275\n",
      "Epoch 99/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0068 - val_loss: 0.0276\n",
      "Epoch 100/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.0067 - val_loss: 0.0278\n",
      "Epoch 101/1500\n",
      "28/28 [==============================] - 0s 193us/step - loss: 0.0067 - val_loss: 0.0281\n",
      "Epoch 102/1500\n",
      "28/28 [==============================] - 0s 283us/step - loss: 0.0067 - val_loss: 0.0282\n",
      "Epoch 103/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.0067 - val_loss: 0.0282\n",
      "Epoch 104/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.0067 - val_loss: 0.0281\n",
      "Epoch 105/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.0067 - val_loss: 0.0280\n",
      "Epoch 106/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.0067 - val_loss: 0.0279\n",
      "Epoch 107/1500\n",
      "28/28 [==============================] - 0s 238us/step - loss: 0.0067 - val_loss: 0.0280\n",
      "Epoch 108/1500\n",
      "28/28 [==============================] - 0s 232us/step - loss: 0.0067 - val_loss: 0.0281\n",
      "Epoch 109/1500\n",
      "28/28 [==============================] - 0s 159us/step - loss: 0.0067 - val_loss: 0.0281\n",
      "Epoch 110/1500\n",
      "28/28 [==============================] - 0s 232us/step - loss: 0.0067 - val_loss: 0.0280\n",
      "Epoch 111/1500\n",
      "28/28 [==============================] - 0s 191us/step - loss: 0.0067 - val_loss: 0.0279\n",
      "Epoch 112/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.0067 - val_loss: 0.0279\n",
      "Epoch 113/1500\n",
      "28/28 [==============================] - 0s 167us/step - loss: 0.0067 - val_loss: 0.0279\n",
      "Epoch 114/1500\n",
      "28/28 [==============================] - 0s 239us/step - loss: 0.0067 - val_loss: 0.0280\n",
      "Epoch 115/1500\n",
      "28/28 [==============================] - 0s 268us/step - loss: 0.0067 - val_loss: 0.0281\n",
      "Epoch 116/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0067 - val_loss: 0.0281\n",
      "Epoch 117/1500\n",
      "28/28 [==============================] - 0s 253us/step - loss: 0.0067 - val_loss: 0.0280\n",
      "Epoch 118/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.0067 - val_loss: 0.0279\n",
      "Epoch 119/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.0067 - val_loss: 0.0278\n",
      "Epoch 120/1500\n",
      "28/28 [==============================] - 0s 177us/step - loss: 0.0067 - val_loss: 0.0278\n",
      "Epoch 121/1500\n",
      "28/28 [==============================] - 0s 154us/step - loss: 0.0067 - val_loss: 0.0278\n",
      "Epoch 122/1500\n",
      "28/28 [==============================] - 0s 238us/step - loss: 0.0067 - val_loss: 0.0278\n",
      "Epoch 123/1500\n",
      "28/28 [==============================] - 0s 216us/step - loss: 0.0067 - val_loss: 0.0277\n",
      "Epoch 124/1500\n",
      "28/28 [==============================] - 0s 258us/step - loss: 0.0067 - val_loss: 0.0276\n",
      "Epoch 125/1500\n",
      "28/28 [==============================] - 0s 261us/step - loss: 0.0066 - val_loss: 0.0275\n",
      "Epoch 126/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.0066 - val_loss: 0.0275\n",
      "Epoch 127/1500\n",
      "28/28 [==============================] - 0s 207us/step - loss: 0.0066 - val_loss: 0.0275\n",
      "Epoch 128/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 0.0066 - val_loss: 0.0275\n",
      "Epoch 129/1500\n",
      "28/28 [==============================] - 0s 195us/step - loss: 0.0066 - val_loss: 0.0275\n",
      "Epoch 130/1500\n",
      "28/28 [==============================] - 0s 200us/step - loss: 0.0066 - val_loss: 0.0274\n",
      "Epoch 131/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0066 - val_loss: 0.0274\n",
      "Epoch 132/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.0066 - val_loss: 0.0273\n",
      "Epoch 133/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.0066 - val_loss: 0.0273\n",
      "Epoch 134/1500\n",
      "28/28 [==============================] - 0s 175us/step - loss: 0.0066 - val_loss: 0.0272\n",
      "Epoch 135/1500\n",
      "28/28 [==============================] - 0s 247us/step - loss: 0.0066 - val_loss: 0.0272\n",
      "Epoch 136/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.0066 - val_loss: 0.0271\n",
      "Epoch 137/1500\n",
      "28/28 [==============================] - 0s 166us/step - loss: 0.0066 - val_loss: 0.0271\n",
      "Epoch 138/1500\n",
      "28/28 [==============================] - 0s 247us/step - loss: 0.0066 - val_loss: 0.0270\n",
      "Epoch 139/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0066 - val_loss: 0.0270\n",
      "Epoch 140/1500\n",
      "28/28 [==============================] - 0s 168us/step - loss: 0.0066 - val_loss: 0.0270\n",
      "Epoch 141/1500\n",
      "28/28 [==============================] - 0s 238us/step - loss: 0.0066 - val_loss: 0.0270\n",
      "Epoch 142/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0066 - val_loss: 0.0270\n",
      "Epoch 143/1500\n",
      "28/28 [==============================] - 0s 193us/step - loss: 0.0066 - val_loss: 0.0269\n",
      "Epoch 144/1500\n",
      "28/28 [==============================] - 0s 265us/step - loss: 0.0066 - val_loss: 0.0269\n",
      "Epoch 145/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0066 - val_loss: 0.0268\n",
      "Epoch 146/1500\n",
      "28/28 [==============================] - 0s 257us/step - loss: 0.0066 - val_loss: 0.0268\n",
      "Epoch 147/1500\n",
      "28/28 [==============================] - 0s 163us/step - loss: 0.0066 - val_loss: 0.0268\n",
      "Epoch 148/1500\n",
      "28/28 [==============================] - 0s 174us/step - loss: 0.0066 - val_loss: 0.0267\n",
      "Epoch 149/1500\n",
      "28/28 [==============================] - 0s 179us/step - loss: 0.0066 - val_loss: 0.0267\n",
      "Epoch 150/1500\n",
      "28/28 [==============================] - 0s 168us/step - loss: 0.0066 - val_loss: 0.0266\n",
      "Epoch 151/1500\n",
      "28/28 [==============================] - 0s 263us/step - loss: 0.0066 - val_loss: 0.0266\n",
      "Epoch 152/1500\n",
      "28/28 [==============================] - 0s 255us/step - loss: 0.0066 - val_loss: 0.0266\n",
      "Epoch 153/1500\n",
      "28/28 [==============================] - 0s 259us/step - loss: 0.0066 - val_loss: 0.0265\n",
      "Epoch 154/1500\n",
      "28/28 [==============================] - 0s 150us/step - loss: 0.0066 - val_loss: 0.0265\n",
      "Epoch 155/1500\n",
      "28/28 [==============================] - 0s 185us/step - loss: 0.0066 - val_loss: 0.0265\n",
      "Epoch 156/1500\n",
      "28/28 [==============================] - 0s 196us/step - loss: 0.0066 - val_loss: 0.0264\n",
      "Epoch 157/1500\n",
      "28/28 [==============================] - 0s 260us/step - loss: 0.0066 - val_loss: 0.0264\n",
      "Epoch 158/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.0065 - val_loss: 0.0264\n",
      "Epoch 159/1500\n",
      "28/28 [==============================] - 0s 216us/step - loss: 0.0065 - val_loss: 0.0263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.0065 - val_loss: 0.0263\n",
      "Epoch 161/1500\n",
      "28/28 [==============================] - 0s 155us/step - loss: 0.0065 - val_loss: 0.0262\n",
      "Epoch 162/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.0065 - val_loss: 0.0262\n",
      "Epoch 163/1500\n",
      "28/28 [==============================] - 0s 183us/step - loss: 0.0065 - val_loss: 0.0262\n",
      "Epoch 164/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.0065 - val_loss: 0.0261\n",
      "Epoch 165/1500\n",
      "28/28 [==============================] - 0s 246us/step - loss: 0.0065 - val_loss: 0.0261\n",
      "Epoch 166/1500\n",
      "28/28 [==============================] - 0s 262us/step - loss: 0.0065 - val_loss: 0.0261\n",
      "Epoch 167/1500\n",
      "28/28 [==============================] - 0s 181us/step - loss: 0.0065 - val_loss: 0.0260\n",
      "Epoch 168/1500\n",
      "28/28 [==============================] - 0s 194us/step - loss: 0.0065 - val_loss: 0.0260\n",
      "Epoch 169/1500\n",
      "28/28 [==============================] - 0s 257us/step - loss: 0.0065 - val_loss: 0.0260\n",
      "Epoch 170/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.0065 - val_loss: 0.0259\n",
      "Epoch 171/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.0065 - val_loss: 0.0259\n",
      "Epoch 172/1500\n",
      "28/28 [==============================] - 0s 241us/step - loss: 0.0065 - val_loss: 0.0258\n",
      "Epoch 173/1500\n",
      "28/28 [==============================] - 0s 238us/step - loss: 0.0065 - val_loss: 0.0258\n",
      "Epoch 174/1500\n",
      "28/28 [==============================] - 0s 183us/step - loss: 0.0065 - val_loss: 0.0258\n",
      "Epoch 175/1500\n",
      "28/28 [==============================] - 0s 202us/step - loss: 0.0065 - val_loss: 0.0257\n",
      "Epoch 176/1500\n",
      "28/28 [==============================] - 0s 248us/step - loss: 0.0065 - val_loss: 0.0257\n",
      "Epoch 177/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.0065 - val_loss: 0.0257\n",
      "Epoch 178/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.0065 - val_loss: 0.0256\n",
      "Epoch 179/1500\n",
      "28/28 [==============================] - 0s 194us/step - loss: 0.0065 - val_loss: 0.0256\n",
      "Epoch 180/1500\n",
      "28/28 [==============================] - 0s 233us/step - loss: 0.0065 - val_loss: 0.0256\n",
      "Epoch 181/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.0065 - val_loss: 0.0255\n",
      "Epoch 182/1500\n",
      "28/28 [==============================] - 0s 248us/step - loss: 0.0065 - val_loss: 0.0255\n",
      "Epoch 183/1500\n",
      "28/28 [==============================] - 0s 261us/step - loss: 0.0065 - val_loss: 0.0255\n",
      "Epoch 184/1500\n",
      "28/28 [==============================] - 0s 184us/step - loss: 0.0065 - val_loss: 0.0254\n",
      "Epoch 185/1500\n",
      "28/28 [==============================] - 0s 252us/step - loss: 0.0065 - val_loss: 0.0254\n",
      "Epoch 186/1500\n",
      "28/28 [==============================] - 0s 240us/step - loss: 0.0065 - val_loss: 0.0254\n",
      "Epoch 187/1500\n",
      "28/28 [==============================] - 0s 216us/step - loss: 0.0065 - val_loss: 0.0253\n",
      "Epoch 188/1500\n",
      "28/28 [==============================] - 0s 257us/step - loss: 0.0065 - val_loss: 0.0253\n",
      "Epoch 189/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.0065 - val_loss: 0.0253\n",
      "Epoch 190/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.0065 - val_loss: 0.0252\n",
      "Epoch 191/1500\n",
      "28/28 [==============================] - 0s 193us/step - loss: 0.0065 - val_loss: 0.0252\n",
      "Epoch 192/1500\n",
      "28/28 [==============================] - 0s 273us/step - loss: 0.0065 - val_loss: 0.0252\n",
      "Epoch 193/1500\n",
      "28/28 [==============================] - 0s 200us/step - loss: 0.0065 - val_loss: 0.0252\n",
      "Epoch 194/1500\n",
      "28/28 [==============================] - 0s 189us/step - loss: 0.0065 - val_loss: 0.0251\n",
      "Epoch 195/1500\n",
      "28/28 [==============================] - 0s 240us/step - loss: 0.0065 - val_loss: 0.0251\n",
      "Epoch 196/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.0065 - val_loss: 0.0251\n",
      "Epoch 197/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.0065 - val_loss: 0.0250\n",
      "Epoch 198/1500\n",
      "28/28 [==============================] - 0s 175us/step - loss: 0.0064 - val_loss: 0.0250\n",
      "Epoch 199/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.0064 - val_loss: 0.0250\n",
      "Epoch 200/1500\n",
      "28/28 [==============================] - 0s 235us/step - loss: 0.0064 - val_loss: 0.0250\n",
      "Epoch 201/1500\n",
      "28/28 [==============================] - 0s 244us/step - loss: 0.0064 - val_loss: 0.0249\n",
      "Epoch 202/1500\n",
      "28/28 [==============================] - 0s 243us/step - loss: 0.0064 - val_loss: 0.0249\n",
      "Epoch 203/1500\n",
      "28/28 [==============================] - 0s 257us/step - loss: 0.0064 - val_loss: 0.0249\n",
      "Epoch 204/1500\n",
      "28/28 [==============================] - 0s 202us/step - loss: 0.0064 - val_loss: 0.0248\n",
      "Epoch 205/1500\n",
      "28/28 [==============================] - 0s 207us/step - loss: 0.0064 - val_loss: 0.0248\n",
      "Epoch 206/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0064 - val_loss: 0.0248\n",
      "Epoch 207/1500\n",
      "28/28 [==============================] - 0s 246us/step - loss: 0.0064 - val_loss: 0.0248\n",
      "Epoch 208/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.0064 - val_loss: 0.0247\n",
      "Epoch 209/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.0064 - val_loss: 0.0247\n",
      "Epoch 210/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.0064 - val_loss: 0.0247\n",
      "Epoch 211/1500\n",
      "28/28 [==============================] - 0s 192us/step - loss: 0.0064 - val_loss: 0.0247\n",
      "Epoch 212/1500\n",
      "28/28 [==============================] - 0s 238us/step - loss: 0.0064 - val_loss: 0.0247\n",
      "Epoch 213/1500\n",
      "28/28 [==============================] - 0s 241us/step - loss: 0.0064 - val_loss: 0.0246\n",
      "Epoch 214/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.0064 - val_loss: 0.0246\n",
      "Epoch 215/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.0064 - val_loss: 0.0246\n",
      "Epoch 216/1500\n",
      "28/28 [==============================] - 0s 185us/step - loss: 0.0064 - val_loss: 0.0246\n",
      "Epoch 217/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.0064 - val_loss: 0.0245\n",
      "Epoch 218/1500\n",
      "28/28 [==============================] - 0s 232us/step - loss: 0.0064 - val_loss: 0.0245\n",
      "Epoch 219/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.0064 - val_loss: 0.0245\n",
      "Epoch 220/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0064 - val_loss: 0.0245\n",
      "Epoch 221/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0064 - val_loss: 0.0245\n",
      "Epoch 222/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0064 - val_loss: 0.0244\n",
      "Epoch 223/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.0064 - val_loss: 0.0244\n",
      "Epoch 224/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.0064 - val_loss: 0.0244\n",
      "Epoch 225/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.0064 - val_loss: 0.0244\n",
      "Epoch 226/1500\n",
      "28/28 [==============================] - 0s 337us/step - loss: 0.0064 - val_loss: 0.0244\n",
      "Epoch 227/1500\n",
      "28/28 [==============================] - 0s 180us/step - loss: 0.0064 - val_loss: 0.0243\n",
      "Epoch 228/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.0064 - val_loss: 0.0243\n",
      "Epoch 229/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.0064 - val_loss: 0.0243\n",
      "Epoch 230/1500\n",
      "28/28 [==============================] - 0s 168us/step - loss: 0.0064 - val_loss: 0.0243\n",
      "Epoch 231/1500\n",
      "28/28 [==============================] - 0s 179us/step - loss: 0.0064 - val_loss: 0.0243\n",
      "Epoch 232/1500\n",
      "28/28 [==============================] - 0s 162us/step - loss: 0.0064 - val_loss: 0.0243\n",
      "Epoch 233/1500\n",
      "28/28 [==============================] - 0s 185us/step - loss: 0.0064 - val_loss: 0.0242\n",
      "Epoch 234/1500\n",
      "28/28 [==============================] - 0s 261us/step - loss: 0.0064 - val_loss: 0.0242\n",
      "Epoch 235/1500\n",
      "28/28 [==============================] - 0s 237us/step - loss: 0.0064 - val_loss: 0.0242\n",
      "Epoch 236/1500\n",
      "28/28 [==============================] - 0s 231us/step - loss: 0.0064 - val_loss: 0.0242\n",
      "Epoch 237/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0064 - val_loss: 0.0242\n",
      "Epoch 238/1500\n",
      "28/28 [==============================] - 0s 195us/step - loss: 0.0064 - val_loss: 0.0242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239/1500\n",
      "28/28 [==============================] - 0s 187us/step - loss: 0.0064 - val_loss: 0.0242\n",
      "Epoch 240/1500\n",
      "28/28 [==============================] - 0s 166us/step - loss: 0.0064 - val_loss: 0.0242\n",
      "Epoch 241/1500\n",
      "28/28 [==============================] - 0s 187us/step - loss: 0.0064 - val_loss: 0.0241\n",
      "Epoch 242/1500\n",
      "28/28 [==============================] - 0s 251us/step - loss: 0.0064 - val_loss: 0.0241\n",
      "Epoch 243/1500\n",
      "28/28 [==============================] - 0s 231us/step - loss: 0.0064 - val_loss: 0.0241\n",
      "Epoch 244/1500\n",
      "28/28 [==============================] - 0s 231us/step - loss: 0.0064 - val_loss: 0.0241\n",
      "Epoch 245/1500\n",
      "28/28 [==============================] - 0s 202us/step - loss: 0.0063 - val_loss: 0.0241\n",
      "Epoch 246/1500\n",
      "28/28 [==============================] - 0s 190us/step - loss: 0.0063 - val_loss: 0.0241\n",
      "Epoch 247/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.0063 - val_loss: 0.0241\n",
      "Epoch 248/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0063 - val_loss: 0.0241\n",
      "Epoch 249/1500\n",
      "28/28 [==============================] - 0s 250us/step - loss: 0.0063 - val_loss: 0.0241\n",
      "Epoch 250/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.0063 - val_loss: 0.0241\n",
      "Epoch 251/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.0063 - val_loss: 0.0241\n",
      "Epoch 252/1500\n",
      "28/28 [==============================] - 0s 280us/step - loss: 0.0063 - val_loss: 0.0240\n",
      "Epoch 253/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.0063 - val_loss: 0.0240\n",
      "Epoch 254/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.0063 - val_loss: 0.0240\n",
      "Epoch 255/1500\n",
      "28/28 [==============================] - 0s 239us/step - loss: 0.0063 - val_loss: 0.0240\n",
      "Epoch 256/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.0063 - val_loss: 0.0240\n",
      "Epoch 257/1500\n",
      "28/28 [==============================] - 0s 237us/step - loss: 0.0063 - val_loss: 0.0240\n",
      "Epoch 258/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.0063 - val_loss: 0.0240\n",
      "Epoch 259/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0063 - val_loss: 0.0240\n",
      "Epoch 260/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0063 - val_loss: 0.0240\n",
      "Epoch 261/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.0063 - val_loss: 0.0240\n",
      "Epoch 262/1500\n",
      "28/28 [==============================] - 0s 239us/step - loss: 0.0063 - val_loss: 0.0240\n",
      "Epoch 263/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0063 - val_loss: 0.0240\n",
      "Epoch 264/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0063 - val_loss: 0.0240\n",
      "Epoch 265/1500\n",
      "28/28 [==============================] - 0s 236us/step - loss: 0.0063 - val_loss: 0.0240\n",
      "Epoch 266/1500\n",
      "28/28 [==============================] - 0s 188us/step - loss: 0.0063 - val_loss: 0.0240\n",
      "Epoch 267/1500\n",
      "28/28 [==============================] - 0s 246us/step - loss: 0.0063 - val_loss: 0.0240\n",
      "Epoch 268/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0063 - val_loss: 0.0240\n",
      "Epoch 269/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.0063 - val_loss: 0.0240\n",
      "Epoch 270/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0063 - val_loss: 0.0240\n",
      "Epoch 271/1500\n",
      "28/28 [==============================] - 0s 254us/step - loss: 0.0063 - val_loss: 0.0240\n",
      "Epoch 272/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.0063 - val_loss: 0.0240\n",
      "Epoch 273/1500\n",
      "28/28 [==============================] - 0s 174us/step - loss: 0.0063 - val_loss: 0.0240\n",
      "Epoch 274/1500\n",
      "28/28 [==============================] - 0s 182us/step - loss: 0.0063 - val_loss: 0.0240\n",
      "Epoch 275/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 0.0063 - val_loss: 0.0240\n",
      "Epoch 276/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.0063 - val_loss: 0.0240\n",
      "Epoch 277/1500\n",
      "28/28 [==============================] - 0s 241us/step - loss: 0.0063 - val_loss: 0.0240\n",
      "Epoch 278/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 0.0063 - val_loss: 0.0240\n",
      "Epoch 279/1500\n",
      "28/28 [==============================] - 0s 240us/step - loss: 0.0063 - val_loss: 0.0240\n",
      "Epoch 280/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.0063 - val_loss: 0.0240\n",
      "Epoch 281/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.0063 - val_loss: 0.0240\n",
      "Epoch 282/1500\n",
      "28/28 [==============================] - 0s 272us/step - loss: 0.0063 - val_loss: 0.0241\n",
      "Epoch 283/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0063 - val_loss: 0.0241\n",
      "Epoch 284/1500\n",
      "28/28 [==============================] - 0s 202us/step - loss: 0.0063 - val_loss: 0.0241\n",
      "Epoch 285/1500\n",
      "28/28 [==============================] - 0s 231us/step - loss: 0.0063 - val_loss: 0.0241\n",
      "Epoch 286/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.0063 - val_loss: 0.0241\n",
      "Epoch 287/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.0063 - val_loss: 0.0241\n",
      "Epoch 288/1500\n",
      "28/28 [==============================] - 0s 247us/step - loss: 0.0062 - val_loss: 0.0241\n",
      "Epoch 289/1500\n",
      "28/28 [==============================] - 0s 216us/step - loss: 0.0062 - val_loss: 0.0241\n",
      "Epoch 290/1500\n",
      "28/28 [==============================] - 0s 186us/step - loss: 0.0062 - val_loss: 0.0241\n",
      "Epoch 291/1500\n",
      "28/28 [==============================] - 0s 186us/step - loss: 0.0062 - val_loss: 0.0241\n",
      "Epoch 292/1500\n",
      "28/28 [==============================] - 0s 239us/step - loss: 0.0062 - val_loss: 0.0241\n",
      "Epoch 293/1500\n",
      "28/28 [==============================] - 0s 238us/step - loss: 0.0062 - val_loss: 0.0241\n",
      "Epoch 294/1500\n",
      "28/28 [==============================] - 0s 156us/step - loss: 0.0062 - val_loss: 0.0242\n",
      "Epoch 295/1500\n",
      "28/28 [==============================] - 0s 243us/step - loss: 0.0062 - val_loss: 0.0242\n",
      "Epoch 296/1500\n",
      "28/28 [==============================] - 0s 193us/step - loss: 0.0062 - val_loss: 0.0242\n",
      "Epoch 297/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.0062 - val_loss: 0.0242\n",
      "Epoch 298/1500\n",
      "28/28 [==============================] - 0s 184us/step - loss: 0.0062 - val_loss: 0.0242\n",
      "Epoch 299/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0062 - val_loss: 0.0242\n",
      "Epoch 300/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.0062 - val_loss: 0.0242\n",
      "Epoch 301/1500\n",
      "28/28 [==============================] - 0s 171us/step - loss: 0.0062 - val_loss: 0.0242\n",
      "Epoch 302/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.0062 - val_loss: 0.0243\n",
      "Epoch 303/1500\n",
      "28/28 [==============================] - 0s 165us/step - loss: 0.0062 - val_loss: 0.0243\n",
      "Epoch 304/1500\n",
      "28/28 [==============================] - 0s 181us/step - loss: 0.0062 - val_loss: 0.0243\n",
      "Epoch 305/1500\n",
      "28/28 [==============================] - 0s 256us/step - loss: 0.0062 - val_loss: 0.0243\n",
      "Epoch 306/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.0062 - val_loss: 0.0243\n",
      "Epoch 307/1500\n",
      "28/28 [==============================] - 0s 172us/step - loss: 0.0062 - val_loss: 0.0243\n",
      "Epoch 308/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0062 - val_loss: 0.0243\n",
      "Epoch 309/1500\n",
      "28/28 [==============================] - 0s 181us/step - loss: 0.0062 - val_loss: 0.0244\n",
      "Epoch 310/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.0062 - val_loss: 0.0244\n",
      "Epoch 311/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0062 - val_loss: 0.0244\n",
      "Epoch 312/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.0062 - val_loss: 0.0244\n",
      "Epoch 313/1500\n",
      "28/28 [==============================] - 0s 205us/step - loss: 0.0062 - val_loss: 0.0244\n",
      "Epoch 314/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.0062 - val_loss: 0.0244\n",
      "Epoch 315/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.0062 - val_loss: 0.0245\n",
      "Epoch 316/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.0062 - val_loss: 0.0245\n",
      "Epoch 317/1500\n",
      "28/28 [==============================] - 0s 176us/step - loss: 0.0062 - val_loss: 0.0245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 318/1500\n",
      "28/28 [==============================] - 0s 265us/step - loss: 0.0062 - val_loss: 0.0245\n",
      "Epoch 319/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 0.0062 - val_loss: 0.0245\n",
      "Epoch 320/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.0061 - val_loss: 0.0245\n",
      "Epoch 321/1500\n",
      "28/28 [==============================] - 0s 151us/step - loss: 0.0061 - val_loss: 0.0246\n",
      "Epoch 322/1500\n",
      "28/28 [==============================] - 0s 199us/step - loss: 0.0061 - val_loss: 0.0246\n",
      "Epoch 323/1500\n",
      "28/28 [==============================] - 0s 187us/step - loss: 0.0061 - val_loss: 0.0246\n",
      "Epoch 324/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.0061 - val_loss: 0.0246\n",
      "Epoch 325/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.0061 - val_loss: 0.0247\n",
      "Epoch 326/1500\n",
      "28/28 [==============================] - 0s 237us/step - loss: 0.0061 - val_loss: 0.0247\n",
      "Epoch 327/1500\n",
      "28/28 [==============================] - 0s 239us/step - loss: 0.0061 - val_loss: 0.0247\n",
      "Epoch 328/1500\n",
      "28/28 [==============================] - 0s 179us/step - loss: 0.0061 - val_loss: 0.0247\n",
      "Epoch 329/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0061 - val_loss: 0.0247\n",
      "Epoch 330/1500\n",
      "28/28 [==============================] - 0s 170us/step - loss: 0.0061 - val_loss: 0.0248\n",
      "Epoch 331/1500\n",
      "28/28 [==============================] - 0s 256us/step - loss: 0.0061 - val_loss: 0.0248\n",
      "Epoch 332/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.0061 - val_loss: 0.0248\n",
      "Epoch 333/1500\n",
      "28/28 [==============================] - 0s 250us/step - loss: 0.0061 - val_loss: 0.0248\n",
      "Epoch 334/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.0061 - val_loss: 0.0249\n",
      "Epoch 335/1500\n",
      "28/28 [==============================] - 0s 277us/step - loss: 0.0061 - val_loss: 0.0249\n",
      "Epoch 336/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0061 - val_loss: 0.0249\n",
      "Epoch 337/1500\n",
      "28/28 [==============================] - 0s 157us/step - loss: 0.0061 - val_loss: 0.0249\n",
      "Epoch 338/1500\n",
      "28/28 [==============================] - 0s 244us/step - loss: 0.0061 - val_loss: 0.0250\n",
      "Epoch 339/1500\n",
      "28/28 [==============================] - 0s 242us/step - loss: 0.0061 - val_loss: 0.0250\n",
      "Epoch 340/1500\n",
      "28/28 [==============================] - 0s 255us/step - loss: 0.0061 - val_loss: 0.0250\n",
      "Epoch 341/1500\n",
      "28/28 [==============================] - 0s 162us/step - loss: 0.0061 - val_loss: 0.0250\n",
      "Epoch 342/1500\n",
      "28/28 [==============================] - 0s 245us/step - loss: 0.0061 - val_loss: 0.0251\n",
      "Epoch 343/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0061 - val_loss: 0.0251\n",
      "Epoch 344/1500\n",
      "28/28 [==============================] - 0s 244us/step - loss: 0.0061 - val_loss: 0.0251\n",
      "Epoch 345/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.0060 - val_loss: 0.0251\n",
      "Epoch 346/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.0060 - val_loss: 0.0252\n",
      "Epoch 347/1500\n",
      "28/28 [==============================] - 0s 264us/step - loss: 0.0060 - val_loss: 0.0252\n",
      "Epoch 348/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0060 - val_loss: 0.0252\n",
      "Epoch 349/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.0060 - val_loss: 0.0253\n",
      "Epoch 350/1500\n",
      "28/28 [==============================] - 0s 246us/step - loss: 0.0060 - val_loss: 0.0253\n",
      "Epoch 351/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.0060 - val_loss: 0.0253\n",
      "Epoch 352/1500\n",
      "28/28 [==============================] - 0s 293us/step - loss: 0.0060 - val_loss: 0.0253\n",
      "Epoch 353/1500\n",
      "28/28 [==============================] - 0s 232us/step - loss: 0.0060 - val_loss: 0.0254\n",
      "Epoch 354/1500\n",
      "28/28 [==============================] - 0s 267us/step - loss: 0.0060 - val_loss: 0.0254\n",
      "Epoch 355/1500\n",
      "28/28 [==============================] - 0s 266us/step - loss: 0.0060 - val_loss: 0.0254\n",
      "Epoch 356/1500\n",
      "28/28 [==============================] - 0s 230us/step - loss: 0.0060 - val_loss: 0.0255\n",
      "Epoch 357/1500\n",
      "28/28 [==============================] - 0s 252us/step - loss: 0.0060 - val_loss: 0.0255\n",
      "Epoch 358/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.0060 - val_loss: 0.0255\n",
      "Epoch 359/1500\n",
      "28/28 [==============================] - 0s 244us/step - loss: 0.0060 - val_loss: 0.0256\n",
      "Epoch 360/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.0060 - val_loss: 0.0256\n",
      "Epoch 361/1500\n",
      "28/28 [==============================] - 0s 207us/step - loss: 0.0060 - val_loss: 0.0256\n",
      "Epoch 362/1500\n",
      "28/28 [==============================] - 0s 240us/step - loss: 0.0060 - val_loss: 0.0257\n",
      "Epoch 363/1500\n",
      "28/28 [==============================] - 0s 245us/step - loss: 0.0060 - val_loss: 0.0257\n",
      "Epoch 364/1500\n",
      "28/28 [==============================] - 0s 207us/step - loss: 0.0060 - val_loss: 0.0257\n",
      "Epoch 365/1500\n",
      "28/28 [==============================] - 0s 166us/step - loss: 0.0060 - val_loss: 0.0258\n",
      "Epoch 366/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0060 - val_loss: 0.0258\n",
      "Epoch 367/1500\n",
      "28/28 [==============================] - 0s 190us/step - loss: 0.0059 - val_loss: 0.0258\n",
      "Epoch 368/1500\n",
      "28/28 [==============================] - 0s 266us/step - loss: 0.0059 - val_loss: 0.0259\n",
      "Epoch 369/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.0059 - val_loss: 0.0259\n",
      "Epoch 370/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0059 - val_loss: 0.0260\n",
      "Epoch 371/1500\n",
      "28/28 [==============================] - 0s 190us/step - loss: 0.0059 - val_loss: 0.0260\n",
      "Epoch 372/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0059 - val_loss: 0.0260\n",
      "Epoch 373/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.0059 - val_loss: 0.0261\n",
      "Epoch 374/1500\n",
      "28/28 [==============================] - 0s 251us/step - loss: 0.0059 - val_loss: 0.0261\n",
      "Epoch 375/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.0059 - val_loss: 0.0261\n",
      "Epoch 376/1500\n",
      "28/28 [==============================] - 0s 189us/step - loss: 0.0059 - val_loss: 0.0262\n",
      "Epoch 377/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.0059 - val_loss: 0.0262\n",
      "Epoch 378/1500\n",
      "28/28 [==============================] - 0s 176us/step - loss: 0.0059 - val_loss: 0.0263\n",
      "Epoch 379/1500\n",
      "28/28 [==============================] - 0s 262us/step - loss: 0.0059 - val_loss: 0.0263\n",
      "Epoch 380/1500\n",
      "28/28 [==============================] - 0s 237us/step - loss: 0.0059 - val_loss: 0.0263\n",
      "Epoch 381/1500\n",
      "28/28 [==============================] - 0s 261us/step - loss: 0.0059 - val_loss: 0.0264\n",
      "Epoch 382/1500\n",
      "28/28 [==============================] - 0s 319us/step - loss: 0.0059 - val_loss: 0.0264\n",
      "Epoch 383/1500\n",
      "28/28 [==============================] - 0s 278us/step - loss: 0.0059 - val_loss: 0.0265\n",
      "Epoch 384/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.0059 - val_loss: 0.0265\n",
      "Epoch 385/1500\n",
      "28/28 [==============================] - 0s 181us/step - loss: 0.0059 - val_loss: 0.0266\n",
      "Epoch 386/1500\n",
      "28/28 [==============================] - 0s 173us/step - loss: 0.0058 - val_loss: 0.0266\n",
      "Epoch 387/1500\n",
      "28/28 [==============================] - 0s 179us/step - loss: 0.0058 - val_loss: 0.0266\n",
      "Epoch 388/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.0058 - val_loss: 0.0267\n",
      "Epoch 389/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.0058 - val_loss: 0.0267\n",
      "Epoch 390/1500\n",
      "28/28 [==============================] - 0s 240us/step - loss: 0.0058 - val_loss: 0.0268\n",
      "Epoch 391/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.0058 - val_loss: 0.0268\n",
      "Epoch 392/1500\n",
      "28/28 [==============================] - 0s 184us/step - loss: 0.0058 - val_loss: 0.0269\n",
      "Epoch 393/1500\n",
      "28/28 [==============================] - 0s 244us/step - loss: 0.0058 - val_loss: 0.0269\n",
      "Epoch 394/1500\n",
      "28/28 [==============================] - 0s 187us/step - loss: 0.0058 - val_loss: 0.0270\n",
      "Epoch 395/1500\n",
      "28/28 [==============================] - 0s 194us/step - loss: 0.0058 - val_loss: 0.0270\n",
      "Epoch 396/1500\n",
      "28/28 [==============================] - 0s 297us/step - loss: 0.0058 - val_loss: 0.0271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 397/1500\n",
      "28/28 [==============================] - 0s 196us/step - loss: 0.0058 - val_loss: 0.0271\n",
      "Epoch 398/1500\n",
      "28/28 [==============================] - 0s 256us/step - loss: 0.0058 - val_loss: 0.0272\n",
      "Epoch 399/1500\n",
      "28/28 [==============================] - 0s 151us/step - loss: 0.0058 - val_loss: 0.0272\n",
      "Epoch 400/1500\n",
      "28/28 [==============================] - 0s 190us/step - loss: 0.0058 - val_loss: 0.0272\n",
      "Epoch 401/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.0058 - val_loss: 0.0273\n",
      "Epoch 402/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.0058 - val_loss: 0.0273\n",
      "Epoch 403/1500\n",
      "28/28 [==============================] - 0s 290us/step - loss: 0.0058 - val_loss: 0.0274\n",
      "Epoch 404/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0058 - val_loss: 0.0274\n",
      "Epoch 405/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.0057 - val_loss: 0.0275\n",
      "Epoch 406/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0057 - val_loss: 0.0275\n",
      "Epoch 407/1500\n",
      "28/28 [==============================] - 0s 193us/step - loss: 0.0057 - val_loss: 0.0276\n",
      "Epoch 408/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.0057 - val_loss: 0.0276\n",
      "Epoch 409/1500\n",
      "28/28 [==============================] - 0s 345us/step - loss: 0.0057 - val_loss: 0.0277\n",
      "Epoch 410/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.0057 - val_loss: 0.0277\n",
      "Epoch 411/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0057 - val_loss: 0.0278\n",
      "Epoch 412/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.0057 - val_loss: 0.0278\n",
      "Epoch 413/1500\n",
      "28/28 [==============================] - 0s 278us/step - loss: 0.0057 - val_loss: 0.0279\n",
      "Epoch 414/1500\n",
      "28/28 [==============================] - 0s 235us/step - loss: 0.0057 - val_loss: 0.0279\n",
      "Epoch 415/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.0057 - val_loss: 0.0280\n",
      "Epoch 416/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0057 - val_loss: 0.0280\n",
      "Epoch 417/1500\n",
      "28/28 [==============================] - 0s 178us/step - loss: 0.0057 - val_loss: 0.0281\n",
      "Epoch 418/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.0057 - val_loss: 0.0281\n",
      "Epoch 419/1500\n",
      "28/28 [==============================] - 0s 188us/step - loss: 0.0057 - val_loss: 0.0282\n",
      "Epoch 420/1500\n",
      "28/28 [==============================] - 0s 232us/step - loss: 0.0057 - val_loss: 0.0282\n",
      "Epoch 421/1500\n",
      "28/28 [==============================] - 0s 242us/step - loss: 0.0057 - val_loss: 0.0283\n",
      "Epoch 422/1500\n",
      "28/28 [==============================] - 0s 231us/step - loss: 0.0056 - val_loss: 0.0284\n",
      "Epoch 423/1500\n",
      "28/28 [==============================] - 0s 192us/step - loss: 0.0056 - val_loss: 0.0284\n",
      "Epoch 424/1500\n",
      "28/28 [==============================] - 0s 226us/step - loss: 0.0056 - val_loss: 0.0285\n",
      "Epoch 425/1500\n",
      "28/28 [==============================] - 0s 182us/step - loss: 0.0056 - val_loss: 0.0285\n",
      "Epoch 426/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.0056 - val_loss: 0.0286\n",
      "Epoch 427/1500\n",
      "28/28 [==============================] - 0s 252us/step - loss: 0.0056 - val_loss: 0.0286\n",
      "Epoch 428/1500\n",
      "28/28 [==============================] - 0s 160us/step - loss: 0.0056 - val_loss: 0.0287\n",
      "Epoch 429/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.0056 - val_loss: 0.0287\n",
      "Epoch 430/1500\n",
      "28/28 [==============================] - 0s 242us/step - loss: 0.0056 - val_loss: 0.0288\n",
      "Epoch 431/1500\n",
      "28/28 [==============================] - 0s 250us/step - loss: 0.0056 - val_loss: 0.0288\n",
      "Epoch 432/1500\n",
      "28/28 [==============================] - 0s 183us/step - loss: 0.0056 - val_loss: 0.0289\n",
      "Epoch 433/1500\n",
      "28/28 [==============================] - 0s 251us/step - loss: 0.0056 - val_loss: 0.0289\n",
      "Epoch 434/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.0056 - val_loss: 0.0290\n",
      "Epoch 435/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.0056 - val_loss: 0.0290\n",
      "Epoch 436/1500\n",
      "28/28 [==============================] - 0s 249us/step - loss: 0.0056 - val_loss: 0.0291\n",
      "Epoch 437/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.0056 - val_loss: 0.0291\n",
      "Epoch 438/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.0056 - val_loss: 0.0292\n",
      "Epoch 439/1500\n",
      "28/28 [==============================] - 0s 251us/step - loss: 0.0056 - val_loss: 0.0292\n",
      "Epoch 440/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0055 - val_loss: 0.0293\n",
      "Epoch 441/1500\n",
      "28/28 [==============================] - 0s 252us/step - loss: 0.0055 - val_loss: 0.0293\n",
      "Epoch 442/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.0055 - val_loss: 0.0294\n",
      "Epoch 443/1500\n",
      "28/28 [==============================] - 0s 188us/step - loss: 0.0055 - val_loss: 0.0294\n",
      "Epoch 444/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.0055 - val_loss: 0.0295\n",
      "Epoch 445/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.0055 - val_loss: 0.0296\n",
      "Epoch 446/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0055 - val_loss: 0.0296\n",
      "Epoch 447/1500\n",
      "28/28 [==============================] - 0s 244us/step - loss: 0.0055 - val_loss: 0.0297\n",
      "Epoch 448/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0055 - val_loss: 0.0297\n",
      "Epoch 449/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0055 - val_loss: 0.0298\n",
      "Epoch 450/1500\n",
      "28/28 [==============================] - 0s 186us/step - loss: 0.0055 - val_loss: 0.0298\n",
      "Epoch 451/1500\n",
      "28/28 [==============================] - 0s 180us/step - loss: 0.0055 - val_loss: 0.0299\n",
      "Epoch 452/1500\n",
      "28/28 [==============================] - 0s 195us/step - loss: 0.0055 - val_loss: 0.0299\n",
      "Epoch 453/1500\n",
      "28/28 [==============================] - 0s 232us/step - loss: 0.0055 - val_loss: 0.0300\n",
      "Epoch 454/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 0.0055 - val_loss: 0.0300\n",
      "Epoch 455/1500\n",
      "28/28 [==============================] - 0s 230us/step - loss: 0.0055 - val_loss: 0.0301\n",
      "Epoch 456/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0055 - val_loss: 0.0301\n",
      "Epoch 457/1500\n",
      "28/28 [==============================] - 0s 189us/step - loss: 0.0054 - val_loss: 0.0302\n",
      "Epoch 458/1500\n",
      "28/28 [==============================] - 0s 175us/step - loss: 0.0054 - val_loss: 0.0303\n",
      "Epoch 459/1500\n",
      "28/28 [==============================] - 0s 253us/step - loss: 0.0054 - val_loss: 0.0303\n",
      "Epoch 460/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 0.0054 - val_loss: 0.0304\n",
      "Epoch 461/1500\n",
      "28/28 [==============================] - 0s 196us/step - loss: 0.0054 - val_loss: 0.0304\n",
      "Epoch 462/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0054 - val_loss: 0.0305\n",
      "Epoch 463/1500\n",
      "28/28 [==============================] - 0s 199us/step - loss: 0.0054 - val_loss: 0.0305\n",
      "Epoch 464/1500\n",
      "28/28 [==============================] - 0s 209us/step - loss: 0.0054 - val_loss: 0.0306\n",
      "Epoch 465/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0054 - val_loss: 0.0306\n",
      "Epoch 466/1500\n",
      "28/28 [==============================] - 0s 243us/step - loss: 0.0054 - val_loss: 0.0307\n",
      "Epoch 467/1500\n",
      "28/28 [==============================] - 0s 202us/step - loss: 0.0054 - val_loss: 0.0307\n",
      "Epoch 468/1500\n",
      "28/28 [==============================] - 0s 190us/step - loss: 0.0054 - val_loss: 0.0308\n",
      "Epoch 469/1500\n",
      "28/28 [==============================] - 0s 167us/step - loss: 0.0054 - val_loss: 0.0308\n",
      "Epoch 470/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.0054 - val_loss: 0.0309\n",
      "Epoch 471/1500\n",
      "28/28 [==============================] - 0s 192us/step - loss: 0.0054 - val_loss: 0.0310\n",
      "Epoch 472/1500\n",
      "28/28 [==============================] - 0s 245us/step - loss: 0.0054 - val_loss: 0.0310\n",
      "Epoch 473/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.0054 - val_loss: 0.0311\n",
      "Epoch 474/1500\n",
      "28/28 [==============================] - 0s 188us/step - loss: 0.0054 - val_loss: 0.0311\n",
      "Epoch 475/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.0053 - val_loss: 0.0312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 476/1500\n",
      "28/28 [==============================] - 0s 202us/step - loss: 0.0053 - val_loss: 0.0312\n",
      "Epoch 477/1500\n",
      "28/28 [==============================] - 0s 186us/step - loss: 0.0053 - val_loss: 0.0313\n",
      "Epoch 478/1500\n",
      "28/28 [==============================] - 0s 195us/step - loss: 0.0053 - val_loss: 0.0313\n",
      "Epoch 479/1500\n",
      "28/28 [==============================] - 0s 193us/step - loss: 0.0053 - val_loss: 0.0314\n",
      "Epoch 480/1500\n",
      "28/28 [==============================] - 0s 299us/step - loss: 0.0053 - val_loss: 0.0314\n",
      "Epoch 481/1500\n",
      "28/28 [==============================] - 0s 231us/step - loss: 0.0053 - val_loss: 0.0315\n",
      "Epoch 482/1500\n",
      "28/28 [==============================] - 0s 236us/step - loss: 0.0053 - val_loss: 0.0315\n",
      "Epoch 483/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.0053 - val_loss: 0.0316\n",
      "Epoch 484/1500\n",
      "28/28 [==============================] - 0s 326us/step - loss: 0.0053 - val_loss: 0.0316\n",
      "Epoch 485/1500\n",
      "28/28 [==============================] - 0s 312us/step - loss: 0.0053 - val_loss: 0.0317\n",
      "Epoch 486/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.0053 - val_loss: 0.0317\n",
      "Epoch 487/1500\n",
      "28/28 [==============================] - 0s 153us/step - loss: 0.0053 - val_loss: 0.0318\n",
      "Epoch 488/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.0053 - val_loss: 0.0318\n",
      "Epoch 489/1500\n",
      "28/28 [==============================] - 0s 242us/step - loss: 0.0053 - val_loss: 0.0318\n",
      "Epoch 490/1500\n",
      "28/28 [==============================] - 0s 247us/step - loss: 0.0053 - val_loss: 0.0319\n",
      "Epoch 491/1500\n",
      "28/28 [==============================] - 0s 300us/step - loss: 0.0053 - val_loss: 0.0319\n",
      "Epoch 492/1500\n",
      "28/28 [==============================] - 0s 230us/step - loss: 0.0053 - val_loss: 0.0320\n",
      "Epoch 493/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0053 - val_loss: 0.0320\n",
      "Epoch 494/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0052 - val_loss: 0.0321\n",
      "Epoch 495/1500\n",
      "28/28 [==============================] - 0s 184us/step - loss: 0.0052 - val_loss: 0.0321\n",
      "Epoch 496/1500\n",
      "28/28 [==============================] - 0s 298us/step - loss: 0.0052 - val_loss: 0.0321\n",
      "Epoch 497/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.0052 - val_loss: 0.0322\n",
      "Epoch 498/1500\n",
      "28/28 [==============================] - 0s 202us/step - loss: 0.0052 - val_loss: 0.0322\n",
      "Epoch 499/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.0052 - val_loss: 0.0322\n",
      "Epoch 500/1500\n",
      "28/28 [==============================] - 0s 237us/step - loss: 0.0052 - val_loss: 0.0323\n",
      "Epoch 501/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0052 - val_loss: 0.0323\n",
      "Epoch 502/1500\n",
      "28/28 [==============================] - 0s 237us/step - loss: 0.0052 - val_loss: 0.0324\n",
      "Epoch 503/1500\n",
      "28/28 [==============================] - 0s 231us/step - loss: 0.0052 - val_loss: 0.0324\n",
      "Epoch 504/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.0052 - val_loss: 0.0324\n",
      "Epoch 505/1500\n",
      "28/28 [==============================] - 0s 265us/step - loss: 0.0052 - val_loss: 0.0324\n",
      "Epoch 506/1500\n",
      "28/28 [==============================] - 0s 271us/step - loss: 0.0052 - val_loss: 0.0325\n",
      "Epoch 507/1500\n",
      "28/28 [==============================] - 0s 189us/step - loss: 0.0052 - val_loss: 0.0325\n",
      "Epoch 508/1500\n",
      "28/28 [==============================] - 0s 265us/step - loss: 0.0052 - val_loss: 0.0325\n",
      "Epoch 509/1500\n",
      "28/28 [==============================] - 0s 232us/step - loss: 0.0052 - val_loss: 0.0326\n",
      "Epoch 510/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 0.0052 - val_loss: 0.0326\n",
      "Epoch 511/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0052 - val_loss: 0.0326\n",
      "Epoch 512/1500\n",
      "28/28 [==============================] - 0s 157us/step - loss: 0.0052 - val_loss: 0.0326\n",
      "Epoch 513/1500\n",
      "28/28 [==============================] - 0s 187us/step - loss: 0.0051 - val_loss: 0.0327\n",
      "Epoch 514/1500\n",
      "28/28 [==============================] - 0s 175us/step - loss: 0.0051 - val_loss: 0.0327\n",
      "Epoch 515/1500\n",
      "28/28 [==============================] - 0s 257us/step - loss: 0.0051 - val_loss: 0.0327\n",
      "Epoch 516/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.0051 - val_loss: 0.0327\n",
      "Epoch 517/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0051 - val_loss: 0.0328\n",
      "Epoch 518/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.0051 - val_loss: 0.0328\n",
      "Epoch 519/1500\n",
      "28/28 [==============================] - 0s 161us/step - loss: 0.0051 - val_loss: 0.0328\n",
      "Epoch 520/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.0051 - val_loss: 0.0328\n",
      "Epoch 521/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0051 - val_loss: 0.0328\n",
      "Epoch 522/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0051 - val_loss: 0.0328\n",
      "Epoch 523/1500\n",
      "28/28 [==============================] - 0s 230us/step - loss: 0.0051 - val_loss: 0.0329\n",
      "Epoch 524/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0051 - val_loss: 0.0329\n",
      "Epoch 525/1500\n",
      "28/28 [==============================] - 0s 250us/step - loss: 0.0051 - val_loss: 0.0329\n",
      "Epoch 526/1500\n",
      "28/28 [==============================] - 0s 195us/step - loss: 0.0051 - val_loss: 0.0329\n",
      "Epoch 527/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0051 - val_loss: 0.0329\n",
      "Epoch 528/1500\n",
      "28/28 [==============================] - 0s 205us/step - loss: 0.0051 - val_loss: 0.0329\n",
      "Epoch 529/1500\n",
      "28/28 [==============================] - 0s 171us/step - loss: 0.0051 - val_loss: 0.0329\n",
      "Epoch 530/1500\n",
      "28/28 [==============================] - 0s 297us/step - loss: 0.0051 - val_loss: 0.0330\n",
      "Epoch 531/1500\n",
      "28/28 [==============================] - 0s 200us/step - loss: 0.0050 - val_loss: 0.0330\n",
      "Epoch 532/1500\n",
      "28/28 [==============================] - 0s 180us/step - loss: 0.0050 - val_loss: 0.0330\n",
      "Epoch 533/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0050 - val_loss: 0.0330\n",
      "Epoch 534/1500\n",
      "28/28 [==============================] - 0s 252us/step - loss: 0.0050 - val_loss: 0.0330\n",
      "Epoch 535/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.0050 - val_loss: 0.0330\n",
      "Epoch 536/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.0050 - val_loss: 0.0330\n",
      "Epoch 537/1500\n",
      "28/28 [==============================] - 0s 168us/step - loss: 0.0050 - val_loss: 0.0330\n",
      "Epoch 538/1500\n",
      "28/28 [==============================] - 0s 183us/step - loss: 0.0050 - val_loss: 0.0330\n",
      "Epoch 539/1500\n",
      "28/28 [==============================] - 0s 202us/step - loss: 0.0050 - val_loss: 0.0330\n",
      "Epoch 540/1500\n",
      "28/28 [==============================] - 0s 248us/step - loss: 0.0050 - val_loss: 0.0330\n",
      "Epoch 541/1500\n",
      "28/28 [==============================] - 0s 177us/step - loss: 0.0050 - val_loss: 0.0330\n",
      "Epoch 542/1500\n",
      "28/28 [==============================] - 0s 194us/step - loss: 0.0050 - val_loss: 0.0330\n",
      "Epoch 543/1500\n",
      "28/28 [==============================] - 0s 236us/step - loss: 0.0050 - val_loss: 0.0330\n",
      "Epoch 544/1500\n",
      "28/28 [==============================] - 0s 191us/step - loss: 0.0050 - val_loss: 0.0330\n",
      "Epoch 545/1500\n",
      "28/28 [==============================] - 0s 202us/step - loss: 0.0050 - val_loss: 0.0330\n",
      "Epoch 546/1500\n",
      "28/28 [==============================] - 0s 316us/step - loss: 0.0050 - val_loss: 0.0330\n",
      "Epoch 547/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.0050 - val_loss: 0.0330\n",
      "Epoch 548/1500\n",
      "28/28 [==============================] - 0s 237us/step - loss: 0.0049 - val_loss: 0.0331\n",
      "Epoch 549/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0049 - val_loss: 0.0331\n",
      "Epoch 550/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.0049 - val_loss: 0.0330\n",
      "Epoch 551/1500\n",
      "28/28 [==============================] - 0s 235us/step - loss: 0.0049 - val_loss: 0.0330\n",
      "Epoch 552/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0049 - val_loss: 0.0330\n",
      "Epoch 553/1500\n",
      "28/28 [==============================] - 0s 192us/step - loss: 0.0049 - val_loss: 0.0330\n",
      "Epoch 554/1500\n",
      "28/28 [==============================] - 0s 200us/step - loss: 0.0049 - val_loss: 0.0330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 555/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.0049 - val_loss: 0.0330\n",
      "Epoch 556/1500\n",
      "28/28 [==============================] - 0s 207us/step - loss: 0.0049 - val_loss: 0.0330\n",
      "Epoch 557/1500\n",
      "28/28 [==============================] - 0s 300us/step - loss: 0.0049 - val_loss: 0.0330\n",
      "Epoch 558/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.0049 - val_loss: 0.0330\n",
      "Epoch 559/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0049 - val_loss: 0.0330\n",
      "Epoch 560/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0049 - val_loss: 0.0330\n",
      "Epoch 561/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.0049 - val_loss: 0.0330\n",
      "Epoch 562/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.0049 - val_loss: 0.0330\n",
      "Epoch 563/1500\n",
      "28/28 [==============================] - 0s 226us/step - loss: 0.0049 - val_loss: 0.0330\n",
      "Epoch 564/1500\n",
      "28/28 [==============================] - 0s 171us/step - loss: 0.0048 - val_loss: 0.0330\n",
      "Epoch 565/1500\n",
      "28/28 [==============================] - 0s 252us/step - loss: 0.0048 - val_loss: 0.0330\n",
      "Epoch 566/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.0048 - val_loss: 0.0330\n",
      "Epoch 567/1500\n",
      "28/28 [==============================] - 0s 183us/step - loss: 0.0048 - val_loss: 0.0330\n",
      "Epoch 568/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.0048 - val_loss: 0.0330\n",
      "Epoch 569/1500\n",
      "28/28 [==============================] - 0s 305us/step - loss: 0.0048 - val_loss: 0.0329\n",
      "Epoch 570/1500\n",
      "28/28 [==============================] - 0s 199us/step - loss: 0.0048 - val_loss: 0.0329\n",
      "Epoch 571/1500\n",
      "28/28 [==============================] - 0s 157us/step - loss: 0.0048 - val_loss: 0.0329\n",
      "Epoch 572/1500\n",
      "28/28 [==============================] - 0s 303us/step - loss: 0.0048 - val_loss: 0.0329\n",
      "Epoch 573/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.0048 - val_loss: 0.0329\n",
      "Epoch 574/1500\n",
      "28/28 [==============================] - 0s 174us/step - loss: 0.0048 - val_loss: 0.0329\n",
      "Epoch 575/1500\n",
      "28/28 [==============================] - 0s 257us/step - loss: 0.0048 - val_loss: 0.0329\n",
      "Epoch 576/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 0.0048 - val_loss: 0.0329\n",
      "Epoch 577/1500\n",
      "28/28 [==============================] - 0s 161us/step - loss: 0.0048 - val_loss: 0.0328\n",
      "Epoch 578/1500\n",
      "28/28 [==============================] - 0s 269us/step - loss: 0.0047 - val_loss: 0.0328\n",
      "Epoch 579/1500\n",
      "28/28 [==============================] - 0s 230us/step - loss: 0.0047 - val_loss: 0.0328\n",
      "Epoch 580/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.0047 - val_loss: 0.0328\n",
      "Epoch 581/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.0047 - val_loss: 0.0328\n",
      "Epoch 582/1500\n",
      "28/28 [==============================] - 0s 259us/step - loss: 0.0047 - val_loss: 0.0328\n",
      "Epoch 583/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0047 - val_loss: 0.0327\n",
      "Epoch 584/1500\n",
      "28/28 [==============================] - 0s 393us/step - loss: 0.0047 - val_loss: 0.0327\n",
      "Epoch 585/1500\n",
      "28/28 [==============================] - 0s 238us/step - loss: 0.0047 - val_loss: 0.0327\n",
      "Epoch 586/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.0047 - val_loss: 0.0327\n",
      "Epoch 587/1500\n",
      "28/28 [==============================] - 0s 275us/step - loss: 0.0047 - val_loss: 0.0327\n",
      "Epoch 588/1500\n",
      "28/28 [==============================] - 0s 244us/step - loss: 0.0047 - val_loss: 0.0326\n",
      "Epoch 589/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0047 - val_loss: 0.0326\n",
      "Epoch 590/1500\n",
      "28/28 [==============================] - 0s 200us/step - loss: 0.0047 - val_loss: 0.0326\n",
      "Epoch 591/1500\n",
      "28/28 [==============================] - 0s 266us/step - loss: 0.0047 - val_loss: 0.0326\n",
      "Epoch 592/1500\n",
      "28/28 [==============================] - 0s 243us/step - loss: 0.0047 - val_loss: 0.0325\n",
      "Epoch 593/1500\n",
      "28/28 [==============================] - 0s 254us/step - loss: 0.0046 - val_loss: 0.0325\n",
      "Epoch 594/1500\n",
      "28/28 [==============================] - 0s 249us/step - loss: 0.0046 - val_loss: 0.0325\n",
      "Epoch 595/1500\n",
      "28/28 [==============================] - 0s 253us/step - loss: 0.0046 - val_loss: 0.0325\n",
      "Epoch 596/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 0.0046 - val_loss: 0.0324\n",
      "Epoch 597/1500\n",
      "28/28 [==============================] - 0s 245us/step - loss: 0.0046 - val_loss: 0.0324\n",
      "Epoch 598/1500\n",
      "28/28 [==============================] - 0s 316us/step - loss: 0.0046 - val_loss: 0.0324\n",
      "Epoch 599/1500\n",
      "28/28 [==============================] - 0s 338us/step - loss: 0.0046 - val_loss: 0.0324\n",
      "Epoch 600/1500\n",
      "28/28 [==============================] - 0s 193us/step - loss: 0.0046 - val_loss: 0.0323\n",
      "Epoch 601/1500\n",
      "28/28 [==============================] - 0s 281us/step - loss: 0.0046 - val_loss: 0.0323\n",
      "Epoch 602/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.0046 - val_loss: 0.0323\n",
      "Epoch 603/1500\n",
      "28/28 [==============================] - 0s 191us/step - loss: 0.0046 - val_loss: 0.0322\n",
      "Epoch 604/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.0046 - val_loss: 0.0322\n",
      "Epoch 605/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0046 - val_loss: 0.0322\n",
      "Epoch 606/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.0046 - val_loss: 0.0321\n",
      "Epoch 607/1500\n",
      "28/28 [==============================] - 0s 401us/step - loss: 0.0045 - val_loss: 0.0321\n",
      "Epoch 608/1500\n",
      "28/28 [==============================] - 0s 238us/step - loss: 0.0045 - val_loss: 0.0321\n",
      "Epoch 609/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.0045 - val_loss: 0.0320\n",
      "Epoch 610/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 0.0045 - val_loss: 0.0320\n",
      "Epoch 611/1500\n",
      "28/28 [==============================] - 0s 216us/step - loss: 0.0045 - val_loss: 0.0319\n",
      "Epoch 612/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.0045 - val_loss: 0.0319\n",
      "Epoch 613/1500\n",
      "28/28 [==============================] - 0s 200us/step - loss: 0.0045 - val_loss: 0.0319\n",
      "Epoch 614/1500\n",
      "28/28 [==============================] - 0s 232us/step - loss: 0.0045 - val_loss: 0.0318\n",
      "Epoch 615/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0045 - val_loss: 0.0318\n",
      "Epoch 616/1500\n",
      "28/28 [==============================] - 0s 237us/step - loss: 0.0045 - val_loss: 0.0317\n",
      "Epoch 617/1500\n",
      "28/28 [==============================] - 0s 172us/step - loss: 0.0045 - val_loss: 0.0317\n",
      "Epoch 618/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0045 - val_loss: 0.0317\n",
      "Epoch 619/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.0045 - val_loss: 0.0316\n",
      "Epoch 620/1500\n",
      "28/28 [==============================] - 0s 308us/step - loss: 0.0045 - val_loss: 0.0316\n",
      "Epoch 621/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.0044 - val_loss: 0.0315\n",
      "Epoch 622/1500\n",
      "28/28 [==============================] - 0s 189us/step - loss: 0.0044 - val_loss: 0.0315\n",
      "Epoch 623/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0044 - val_loss: 0.0314\n",
      "Epoch 624/1500\n",
      "28/28 [==============================] - 0s 233us/step - loss: 0.0044 - val_loss: 0.0314\n",
      "Epoch 625/1500\n",
      "28/28 [==============================] - 0s 191us/step - loss: 0.0044 - val_loss: 0.0313\n",
      "Epoch 626/1500\n",
      "28/28 [==============================] - 0s 254us/step - loss: 0.0044 - val_loss: 0.0313\n",
      "Epoch 627/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.0044 - val_loss: 0.0312\n",
      "Epoch 628/1500\n",
      "28/28 [==============================] - 0s 151us/step - loss: 0.0044 - val_loss: 0.0312\n",
      "Epoch 629/1500\n",
      "28/28 [==============================] - 0s 244us/step - loss: 0.0044 - val_loss: 0.0311\n",
      "Epoch 630/1500\n",
      "28/28 [==============================] - 0s 187us/step - loss: 0.0044 - val_loss: 0.0311\n",
      "Epoch 631/1500\n",
      "28/28 [==============================] - 0s 185us/step - loss: 0.0044 - val_loss: 0.0310\n",
      "Epoch 632/1500\n",
      "28/28 [==============================] - 0s 260us/step - loss: 0.0044 - val_loss: 0.0310\n",
      "Epoch 633/1500\n",
      "28/28 [==============================] - 0s 241us/step - loss: 0.0044 - val_loss: 0.0309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 634/1500\n",
      "28/28 [==============================] - 0s 173us/step - loss: 0.0043 - val_loss: 0.0309\n",
      "Epoch 635/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.0043 - val_loss: 0.0308\n",
      "Epoch 636/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.0043 - val_loss: 0.0308\n",
      "Epoch 637/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.0043 - val_loss: 0.0307\n",
      "Epoch 638/1500\n",
      "28/28 [==============================] - 0s 202us/step - loss: 0.0043 - val_loss: 0.0307\n",
      "Epoch 639/1500\n",
      "28/28 [==============================] - 0s 216us/step - loss: 0.0043 - val_loss: 0.0306\n",
      "Epoch 640/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.0043 - val_loss: 0.0306\n",
      "Epoch 641/1500\n",
      "28/28 [==============================] - 0s 161us/step - loss: 0.0043 - val_loss: 0.0305\n",
      "Epoch 642/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0043 - val_loss: 0.0305\n",
      "Epoch 643/1500\n",
      "28/28 [==============================] - 0s 199us/step - loss: 0.0043 - val_loss: 0.0304\n",
      "Epoch 644/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0043 - val_loss: 0.0304\n",
      "Epoch 645/1500\n",
      "28/28 [==============================] - 0s 192us/step - loss: 0.0043 - val_loss: 0.0303\n",
      "Epoch 646/1500\n",
      "28/28 [==============================] - 0s 168us/step - loss: 0.0043 - val_loss: 0.0303\n",
      "Epoch 647/1500\n",
      "28/28 [==============================] - 0s 242us/step - loss: 0.0043 - val_loss: 0.0302\n",
      "Epoch 648/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.0042 - val_loss: 0.0302\n",
      "Epoch 649/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.0042 - val_loss: 0.0301\n",
      "Epoch 650/1500\n",
      "28/28 [==============================] - 0s 191us/step - loss: 0.0042 - val_loss: 0.0301\n",
      "Epoch 651/1500\n",
      "28/28 [==============================] - 0s 233us/step - loss: 0.0042 - val_loss: 0.0300\n",
      "Epoch 652/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.0042 - val_loss: 0.0299\n",
      "Epoch 653/1500\n",
      "28/28 [==============================] - 0s 325us/step - loss: 0.0042 - val_loss: 0.0299\n",
      "Epoch 654/1500\n",
      "28/28 [==============================] - 0s 253us/step - loss: 0.0042 - val_loss: 0.0298\n",
      "Epoch 655/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0042 - val_loss: 0.0298\n",
      "Epoch 656/1500\n",
      "28/28 [==============================] - 0s 207us/step - loss: 0.0042 - val_loss: 0.0297\n",
      "Epoch 657/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.0042 - val_loss: 0.0297\n",
      "Epoch 658/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.0042 - val_loss: 0.0296\n",
      "Epoch 659/1500\n",
      "28/28 [==============================] - 0s 205us/step - loss: 0.0042 - val_loss: 0.0296\n",
      "Epoch 660/1500\n",
      "28/28 [==============================] - 0s 240us/step - loss: 0.0042 - val_loss: 0.0295\n",
      "Epoch 661/1500\n",
      "28/28 [==============================] - 0s 226us/step - loss: 0.0041 - val_loss: 0.0295\n",
      "Epoch 662/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.0041 - val_loss: 0.0294\n",
      "Epoch 663/1500\n",
      "28/28 [==============================] - 0s 236us/step - loss: 0.0041 - val_loss: 0.0294\n",
      "Epoch 664/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0041 - val_loss: 0.0293\n",
      "Epoch 665/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.0041 - val_loss: 0.0293\n",
      "Epoch 666/1500\n",
      "28/28 [==============================] - 0s 245us/step - loss: 0.0041 - val_loss: 0.0292\n",
      "Epoch 667/1500\n",
      "28/28 [==============================] - 0s 182us/step - loss: 0.0041 - val_loss: 0.0292\n",
      "Epoch 668/1500\n",
      "28/28 [==============================] - 0s 190us/step - loss: 0.0041 - val_loss: 0.0291\n",
      "Epoch 669/1500\n",
      "28/28 [==============================] - 0s 191us/step - loss: 0.0041 - val_loss: 0.0291\n",
      "Epoch 670/1500\n",
      "28/28 [==============================] - 0s 154us/step - loss: 0.0041 - val_loss: 0.0290\n",
      "Epoch 671/1500\n",
      "28/28 [==============================] - 0s 278us/step - loss: 0.0041 - val_loss: 0.0291\n",
      "Epoch 672/1500\n",
      "28/28 [==============================] - 0s 156us/step - loss: 0.0041 - val_loss: 0.0288\n",
      "Epoch 673/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.0041 - val_loss: 0.0293\n",
      "Epoch 674/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.0042 - val_loss: 0.0288\n",
      "Epoch 675/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.0044 - val_loss: 0.0299\n",
      "Epoch 676/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.0049 - val_loss: 0.0293\n",
      "Epoch 677/1500\n",
      "28/28 [==============================] - 0s 245us/step - loss: 0.0059 - val_loss: 0.0318\n",
      "Epoch 678/1500\n",
      "28/28 [==============================] - 0s 279us/step - loss: 0.0071 - val_loss: 0.0306\n",
      "Epoch 679/1500\n",
      "28/28 [==============================] - 0s 260us/step - loss: 0.0087 - val_loss: 0.0313\n",
      "Epoch 680/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0075 - val_loss: 0.0279\n",
      "Epoch 681/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.0052 - val_loss: 0.0281\n",
      "Epoch 682/1500\n",
      "28/28 [==============================] - 0s 269us/step - loss: 0.0040 - val_loss: 0.0302\n",
      "Epoch 683/1500\n",
      "28/28 [==============================] - 0s 315us/step - loss: 0.0054 - val_loss: 0.0306\n",
      "Epoch 684/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.0069 - val_loss: 0.0286\n",
      "Epoch 685/1500\n",
      "28/28 [==============================] - 0s 555us/step - loss: 0.0055 - val_loss: 0.0264\n",
      "Epoch 686/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.0040 - val_loss: 0.0267\n",
      "Epoch 687/1500\n",
      "28/28 [==============================] - 0s 257us/step - loss: 0.0046 - val_loss: 0.0290\n",
      "Epoch 688/1500\n",
      "28/28 [==============================] - 0s 233us/step - loss: 0.0052 - val_loss: 0.0283\n",
      "Epoch 689/1500\n",
      "28/28 [==============================] - 0s 209us/step - loss: 0.0043 - val_loss: 0.0287\n",
      "Epoch 690/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 0.0040 - val_loss: 0.0293\n",
      "Epoch 691/1500\n",
      "28/28 [==============================] - 0s 254us/step - loss: 0.0047 - val_loss: 0.0283\n",
      "Epoch 692/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.0045 - val_loss: 0.0275\n",
      "Epoch 693/1500\n",
      "28/28 [==============================] - 0s 252us/step - loss: 0.0039 - val_loss: 0.0283\n",
      "Epoch 694/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 0.0044 - val_loss: 0.0284\n",
      "Epoch 695/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.0044 - val_loss: 0.0288\n",
      "Epoch 696/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.0038 - val_loss: 0.0295\n",
      "Epoch 697/1500\n",
      "28/28 [==============================] - 0s 194us/step - loss: 0.0042 - val_loss: 0.0293\n",
      "Epoch 698/1500\n",
      "28/28 [==============================] - 0s 248us/step - loss: 0.0042 - val_loss: 0.0284\n",
      "Epoch 699/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.0038 - val_loss: 0.0283\n",
      "Epoch 700/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.0041 - val_loss: 0.0279\n",
      "Epoch 701/1500\n",
      "28/28 [==============================] - 0s 232us/step - loss: 0.0041 - val_loss: 0.0280\n",
      "Epoch 702/1500\n",
      "28/28 [==============================] - 0s 240us/step - loss: 0.0038 - val_loss: 0.0286\n",
      "Epoch 703/1500\n",
      "28/28 [==============================] - 0s 188us/step - loss: 0.0040 - val_loss: 0.0289\n",
      "Epoch 704/1500\n",
      "28/28 [==============================] - 0s 284us/step - loss: 0.0040 - val_loss: 0.0286\n",
      "Epoch 705/1500\n",
      "28/28 [==============================] - 0s 243us/step - loss: 0.0037 - val_loss: 0.0286\n",
      "Epoch 706/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.0039 - val_loss: 0.0283\n",
      "Epoch 707/1500\n",
      "28/28 [==============================] - 0s 199us/step - loss: 0.0038 - val_loss: 0.0282\n",
      "Epoch 708/1500\n",
      "28/28 [==============================] - 0s 171us/step - loss: 0.0037 - val_loss: 0.0283\n",
      "Epoch 709/1500\n",
      "28/28 [==============================] - 0s 185us/step - loss: 0.0038 - val_loss: 0.0284\n",
      "Epoch 710/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0037 - val_loss: 0.0284\n",
      "Epoch 711/1500\n",
      "28/28 [==============================] - 0s 230us/step - loss: 0.0037 - val_loss: 0.0285\n",
      "Epoch 712/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.0038 - val_loss: 0.0285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 713/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0036 - val_loss: 0.0286\n",
      "Epoch 714/1500\n",
      "28/28 [==============================] - 0s 199us/step - loss: 0.0036 - val_loss: 0.0286\n",
      "Epoch 715/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.0037 - val_loss: 0.0286\n",
      "Epoch 716/1500\n",
      "28/28 [==============================] - 0s 258us/step - loss: 0.0036 - val_loss: 0.0286\n",
      "Epoch 717/1500\n",
      "28/28 [==============================] - 0s 264us/step - loss: 0.0036 - val_loss: 0.0285\n",
      "Epoch 718/1500\n",
      "28/28 [==============================] - 0s 236us/step - loss: 0.0036 - val_loss: 0.0286\n",
      "Epoch 719/1500\n",
      "28/28 [==============================] - 0s 235us/step - loss: 0.0035 - val_loss: 0.0287\n",
      "Epoch 720/1500\n",
      "28/28 [==============================] - 0s 180us/step - loss: 0.0035 - val_loss: 0.0287\n",
      "Epoch 721/1500\n",
      "28/28 [==============================] - 0s 186us/step - loss: 0.0035 - val_loss: 0.0287\n",
      "Epoch 722/1500\n",
      "28/28 [==============================] - 0s 202us/step - loss: 0.0035 - val_loss: 0.0287\n",
      "Epoch 723/1500\n",
      "28/28 [==============================] - 0s 171us/step - loss: 0.0035 - val_loss: 0.0285\n",
      "Epoch 724/1500\n",
      "28/28 [==============================] - 0s 270us/step - loss: 0.0034 - val_loss: 0.0285\n",
      "Epoch 725/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.0034 - val_loss: 0.0286\n",
      "Epoch 726/1500\n",
      "28/28 [==============================] - 0s 196us/step - loss: 0.0034 - val_loss: 0.0287\n",
      "Epoch 727/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.0034 - val_loss: 0.0288\n",
      "Epoch 728/1500\n",
      "28/28 [==============================] - 0s 295us/step - loss: 0.0034 - val_loss: 0.0289\n",
      "Epoch 729/1500\n",
      "28/28 [==============================] - 0s 252us/step - loss: 0.0034 - val_loss: 0.0288\n",
      "Epoch 730/1500\n",
      "28/28 [==============================] - 0s 259us/step - loss: 0.0033 - val_loss: 0.0287\n",
      "Epoch 731/1500\n",
      "28/28 [==============================] - 0s 243us/step - loss: 0.0033 - val_loss: 0.0288\n",
      "Epoch 732/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.0033 - val_loss: 0.0288\n",
      "Epoch 733/1500\n",
      "28/28 [==============================] - 0s 250us/step - loss: 0.0033 - val_loss: 0.0289\n",
      "Epoch 734/1500\n",
      "28/28 [==============================] - 0s 243us/step - loss: 0.0033 - val_loss: 0.0290\n",
      "Epoch 735/1500\n",
      "28/28 [==============================] - 0s 199us/step - loss: 0.0032 - val_loss: 0.0291\n",
      "Epoch 736/1500\n",
      "28/28 [==============================] - 0s 269us/step - loss: 0.0032 - val_loss: 0.0289\n",
      "Epoch 737/1500\n",
      "28/28 [==============================] - 0s 275us/step - loss: 0.0032 - val_loss: 0.0290\n",
      "Epoch 738/1500\n",
      "28/28 [==============================] - 0s 280us/step - loss: 0.0032 - val_loss: 0.0291\n",
      "Epoch 739/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0032 - val_loss: 0.0290\n",
      "Epoch 740/1500\n",
      "28/28 [==============================] - 0s 248us/step - loss: 0.0032 - val_loss: 0.0290\n",
      "Epoch 741/1500\n",
      "28/28 [==============================] - 0s 264us/step - loss: 0.0031 - val_loss: 0.0291\n",
      "Epoch 742/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.0031 - val_loss: 0.0290\n",
      "Epoch 743/1500\n",
      "28/28 [==============================] - 0s 187us/step - loss: 0.0031 - val_loss: 0.0290\n",
      "Epoch 744/1500\n",
      "28/28 [==============================] - 0s 231us/step - loss: 0.0031 - val_loss: 0.0291\n",
      "Epoch 745/1500\n",
      "28/28 [==============================] - 0s 269us/step - loss: 0.0031 - val_loss: 0.0290\n",
      "Epoch 746/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0031 - val_loss: 0.0289\n",
      "Epoch 747/1500\n",
      "28/28 [==============================] - 0s 196us/step - loss: 0.0030 - val_loss: 0.0289\n",
      "Epoch 748/1500\n",
      "28/28 [==============================] - 0s 185us/step - loss: 0.0030 - val_loss: 0.0289\n",
      "Epoch 749/1500\n",
      "28/28 [==============================] - 0s 199us/step - loss: 0.0030 - val_loss: 0.0289\n",
      "Epoch 750/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.0030 - val_loss: 0.0289\n",
      "Epoch 751/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.0030 - val_loss: 0.0288\n",
      "Epoch 752/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.0030 - val_loss: 0.0287\n",
      "Epoch 753/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.0029 - val_loss: 0.0287\n",
      "Epoch 754/1500\n",
      "28/28 [==============================] - 0s 185us/step - loss: 0.0029 - val_loss: 0.0287\n",
      "Epoch 755/1500\n",
      "28/28 [==============================] - 0s 176us/step - loss: 0.0029 - val_loss: 0.0286\n",
      "Epoch 756/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.0029 - val_loss: 0.0286\n",
      "Epoch 757/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.0029 - val_loss: 0.0286\n",
      "Epoch 758/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.0029 - val_loss: 0.0285\n",
      "Epoch 759/1500\n",
      "28/28 [==============================] - 0s 162us/step - loss: 0.0029 - val_loss: 0.0284\n",
      "Epoch 760/1500\n",
      "28/28 [==============================] - 0s 216us/step - loss: 0.0028 - val_loss: 0.0284\n",
      "Epoch 761/1500\n",
      "28/28 [==============================] - 0s 176us/step - loss: 0.0028 - val_loss: 0.0283\n",
      "Epoch 762/1500\n",
      "28/28 [==============================] - 0s 400us/step - loss: 0.0028 - val_loss: 0.0283\n",
      "Epoch 763/1500\n",
      "28/28 [==============================] - 0s 297us/step - loss: 0.0028 - val_loss: 0.0283\n",
      "Epoch 764/1500\n",
      "28/28 [==============================] - 0s 273us/step - loss: 0.0028 - val_loss: 0.0282\n",
      "Epoch 765/1500\n",
      "28/28 [==============================] - 0s 275us/step - loss: 0.0028 - val_loss: 0.0282\n",
      "Epoch 766/1500\n",
      "28/28 [==============================] - 0s 499us/step - loss: 0.0027 - val_loss: 0.0282\n",
      "Epoch 767/1500\n",
      "28/28 [==============================] - 0s 181us/step - loss: 0.0027 - val_loss: 0.0281\n",
      "Epoch 768/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.0027 - val_loss: 0.0281\n",
      "Epoch 769/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.0027 - val_loss: 0.0281\n",
      "Epoch 770/1500\n",
      "28/28 [==============================] - 0s 270us/step - loss: 0.0027 - val_loss: 0.0281\n",
      "Epoch 771/1500\n",
      "28/28 [==============================] - 0s 194us/step - loss: 0.0027 - val_loss: 0.0280\n",
      "Epoch 772/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.0027 - val_loss: 0.0280\n",
      "Epoch 773/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0026 - val_loss: 0.0280\n",
      "Epoch 774/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.0026 - val_loss: 0.0280\n",
      "Epoch 775/1500\n",
      "28/28 [==============================] - 0s 182us/step - loss: 0.0026 - val_loss: 0.0280\n",
      "Epoch 776/1500\n",
      "28/28 [==============================] - 0s 150us/step - loss: 0.0026 - val_loss: 0.0280\n",
      "Epoch 777/1500\n",
      "28/28 [==============================] - 0s 350us/step - loss: 0.0026 - val_loss: 0.0280\n",
      "Epoch 778/1500\n",
      "28/28 [==============================] - 0s 200us/step - loss: 0.0026 - val_loss: 0.0280\n",
      "Epoch 779/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0026 - val_loss: 0.0280\n",
      "Epoch 780/1500\n",
      "28/28 [==============================] - 0s 183us/step - loss: 0.0026 - val_loss: 0.0280\n",
      "Epoch 781/1500\n",
      "28/28 [==============================] - 0s 190us/step - loss: 0.0025 - val_loss: 0.0280\n",
      "Epoch 782/1500\n",
      "28/28 [==============================] - 0s 244us/step - loss: 0.0025 - val_loss: 0.0280\n",
      "Epoch 783/1500\n",
      "28/28 [==============================] - 0s 238us/step - loss: 0.0025 - val_loss: 0.0280\n",
      "Epoch 784/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.0025 - val_loss: 0.0280\n",
      "Epoch 785/1500\n",
      "28/28 [==============================] - 0s 180us/step - loss: 0.0025 - val_loss: 0.0280\n",
      "Epoch 786/1500\n",
      "28/28 [==============================] - 0s 175us/step - loss: 0.0025 - val_loss: 0.0280\n",
      "Epoch 787/1500\n",
      "28/28 [==============================] - 0s 199us/step - loss: 0.0025 - val_loss: 0.0280\n",
      "Epoch 788/1500\n",
      "28/28 [==============================] - 0s 185us/step - loss: 0.0024 - val_loss: 0.0280\n",
      "Epoch 789/1500\n",
      "28/28 [==============================] - 0s 249us/step - loss: 0.0024 - val_loss: 0.0280\n",
      "Epoch 790/1500\n",
      "28/28 [==============================] - 0s 249us/step - loss: 0.0024 - val_loss: 0.0279\n",
      "Epoch 791/1500\n",
      "28/28 [==============================] - 0s 205us/step - loss: 0.0024 - val_loss: 0.0279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 792/1500\n",
      "28/28 [==============================] - 0s 162us/step - loss: 0.0024 - val_loss: 0.0280\n",
      "Epoch 793/1500\n",
      "28/28 [==============================] - 0s 166us/step - loss: 0.0024 - val_loss: 0.0279\n",
      "Epoch 794/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.0024 - val_loss: 0.0279\n",
      "Epoch 795/1500\n",
      "28/28 [==============================] - 0s 194us/step - loss: 0.0024 - val_loss: 0.0279\n",
      "Epoch 796/1500\n",
      "28/28 [==============================] - 0s 190us/step - loss: 0.0024 - val_loss: 0.0279\n",
      "Epoch 797/1500\n",
      "28/28 [==============================] - 0s 252us/step - loss: 0.0023 - val_loss: 0.0279\n",
      "Epoch 798/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0023 - val_loss: 0.0279\n",
      "Epoch 799/1500\n",
      "28/28 [==============================] - 0s 249us/step - loss: 0.0023 - val_loss: 0.0279\n",
      "Epoch 800/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.0023 - val_loss: 0.0279\n",
      "Epoch 801/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.0023 - val_loss: 0.0279\n",
      "Epoch 802/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.0023 - val_loss: 0.0279\n",
      "Epoch 803/1500\n",
      "28/28 [==============================] - 0s 196us/step - loss: 0.0023 - val_loss: 0.0279\n",
      "Epoch 804/1500\n",
      "28/28 [==============================] - 0s 165us/step - loss: 0.0023 - val_loss: 0.0279\n",
      "Epoch 805/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.0023 - val_loss: 0.0279\n",
      "Epoch 806/1500\n",
      "28/28 [==============================] - 0s 247us/step - loss: 0.0022 - val_loss: 0.0279\n",
      "Epoch 807/1500\n",
      "28/28 [==============================] - 0s 170us/step - loss: 0.0022 - val_loss: 0.0279\n",
      "Epoch 808/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0022 - val_loss: 0.0279\n",
      "Epoch 809/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.0022 - val_loss: 0.0279\n",
      "Epoch 810/1500\n",
      "28/28 [==============================] - 0s 191us/step - loss: 0.0022 - val_loss: 0.0279\n",
      "Epoch 811/1500\n",
      "28/28 [==============================] - 0s 251us/step - loss: 0.0022 - val_loss: 0.0279\n",
      "Epoch 812/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.0022 - val_loss: 0.0279\n",
      "Epoch 813/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.0022 - val_loss: 0.0279\n",
      "Epoch 814/1500\n",
      "28/28 [==============================] - 0s 159us/step - loss: 0.0022 - val_loss: 0.0279\n",
      "Epoch 815/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0022 - val_loss: 0.0279\n",
      "Epoch 816/1500\n",
      "28/28 [==============================] - 0s 226us/step - loss: 0.0021 - val_loss: 0.0279\n",
      "Epoch 817/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.0021 - val_loss: 0.0279\n",
      "Epoch 818/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.0021 - val_loss: 0.0279\n",
      "Epoch 819/1500\n",
      "28/28 [==============================] - 0s 261us/step - loss: 0.0021 - val_loss: 0.0279\n",
      "Epoch 820/1500\n",
      "28/28 [==============================] - 0s 230us/step - loss: 0.0021 - val_loss: 0.0279\n",
      "Epoch 821/1500\n",
      "28/28 [==============================] - 0s 240us/step - loss: 0.0021 - val_loss: 0.0279\n",
      "Epoch 822/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0021 - val_loss: 0.0279\n",
      "Epoch 823/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.0021 - val_loss: 0.0279\n",
      "Epoch 824/1500\n",
      "28/28 [==============================] - 0s 246us/step - loss: 0.0021 - val_loss: 0.0279\n",
      "Epoch 825/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.0021 - val_loss: 0.0279\n",
      "Epoch 826/1500\n",
      "28/28 [==============================] - 0s 236us/step - loss: 0.0021 - val_loss: 0.0279\n",
      "Epoch 827/1500\n",
      "28/28 [==============================] - 0s 189us/step - loss: 0.0021 - val_loss: 0.0279\n",
      "Epoch 828/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.0021 - val_loss: 0.0279\n",
      "Epoch 829/1500\n",
      "28/28 [==============================] - 0s 194us/step - loss: 0.0020 - val_loss: 0.0279\n",
      "Epoch 830/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.0020 - val_loss: 0.0279\n",
      "Epoch 831/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0020 - val_loss: 0.0279\n",
      "Epoch 832/1500\n",
      "28/28 [==============================] - 0s 233us/step - loss: 0.0020 - val_loss: 0.0279\n",
      "Epoch 833/1500\n",
      "28/28 [==============================] - 0s 194us/step - loss: 0.0020 - val_loss: 0.0279\n",
      "Epoch 834/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.0020 - val_loss: 0.0279\n",
      "Epoch 835/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.0020 - val_loss: 0.0279\n",
      "Epoch 836/1500\n",
      "28/28 [==============================] - 0s 189us/step - loss: 0.0020 - val_loss: 0.0279\n",
      "Epoch 837/1500\n",
      "28/28 [==============================] - 0s 277us/step - loss: 0.0020 - val_loss: 0.0279\n",
      "Epoch 838/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.0020 - val_loss: 0.0279\n",
      "Epoch 839/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0020 - val_loss: 0.0279\n",
      "Epoch 840/1500\n",
      "28/28 [==============================] - 0s 159us/step - loss: 0.0020 - val_loss: 0.0279\n",
      "Epoch 841/1500\n",
      "28/28 [==============================] - 0s 226us/step - loss: 0.0020 - val_loss: 0.0280\n",
      "Epoch 842/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0020 - val_loss: 0.0280\n",
      "Epoch 843/1500\n",
      "28/28 [==============================] - 0s 238us/step - loss: 0.0020 - val_loss: 0.0280\n",
      "Epoch 844/1500\n",
      "28/28 [==============================] - 0s 244us/step - loss: 0.0020 - val_loss: 0.0280\n",
      "Epoch 845/1500\n",
      "28/28 [==============================] - 0s 184us/step - loss: 0.0020 - val_loss: 0.0280\n",
      "Epoch 846/1500\n",
      "28/28 [==============================] - 0s 199us/step - loss: 0.0020 - val_loss: 0.0280\n",
      "Epoch 847/1500\n",
      "28/28 [==============================] - 0s 236us/step - loss: 0.0019 - val_loss: 0.0280\n",
      "Epoch 848/1500\n",
      "28/28 [==============================] - 0s 256us/step - loss: 0.0019 - val_loss: 0.0280\n",
      "Epoch 849/1500\n",
      "28/28 [==============================] - 0s 245us/step - loss: 0.0019 - val_loss: 0.0280\n",
      "Epoch 850/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.0019 - val_loss: 0.0281\n",
      "Epoch 851/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0019 - val_loss: 0.0281\n",
      "Epoch 852/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.0019 - val_loss: 0.0281\n",
      "Epoch 853/1500\n",
      "28/28 [==============================] - 0s 248us/step - loss: 0.0019 - val_loss: 0.0281\n",
      "Epoch 854/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0019 - val_loss: 0.0281\n",
      "Epoch 855/1500\n",
      "28/28 [==============================] - 0s 194us/step - loss: 0.0019 - val_loss: 0.0281\n",
      "Epoch 856/1500\n",
      "28/28 [==============================] - 0s 233us/step - loss: 0.0019 - val_loss: 0.0281\n",
      "Epoch 857/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.0019 - val_loss: 0.0281\n",
      "Epoch 858/1500\n",
      "28/28 [==============================] - 0s 200us/step - loss: 0.0019 - val_loss: 0.0282\n",
      "Epoch 859/1500\n",
      "28/28 [==============================] - 0s 236us/step - loss: 0.0019 - val_loss: 0.0282\n",
      "Epoch 860/1500\n",
      "28/28 [==============================] - 0s 253us/step - loss: 0.0019 - val_loss: 0.0282\n",
      "Epoch 861/1500\n",
      "28/28 [==============================] - 0s 238us/step - loss: 0.0019 - val_loss: 0.0282\n",
      "Epoch 862/1500\n",
      "28/28 [==============================] - 0s 281us/step - loss: 0.0019 - val_loss: 0.0283\n",
      "Epoch 863/1500\n",
      "28/28 [==============================] - 0s 250us/step - loss: 0.0019 - val_loss: 0.0281\n",
      "Epoch 864/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0019 - val_loss: 0.0284\n",
      "Epoch 865/1500\n",
      "28/28 [==============================] - 0s 263us/step - loss: 0.0019 - val_loss: 0.0280\n",
      "Epoch 866/1500\n",
      "28/28 [==============================] - 0s 235us/step - loss: 0.0019 - val_loss: 0.0286\n",
      "Epoch 867/1500\n",
      "28/28 [==============================] - 0s 250us/step - loss: 0.0020 - val_loss: 0.0277\n",
      "Epoch 868/1500\n",
      "28/28 [==============================] - 0s 239us/step - loss: 0.0022 - val_loss: 0.0293\n",
      "Epoch 869/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.0025 - val_loss: 0.0272\n",
      "Epoch 870/1500\n",
      "28/28 [==============================] - 0s 263us/step - loss: 0.0031 - val_loss: 0.0302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 871/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.0028 - val_loss: 0.0270\n",
      "Epoch 872/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.0023 - val_loss: 0.0284\n",
      "Epoch 873/1500\n",
      "28/28 [==============================] - 0s 276us/step - loss: 0.0019 - val_loss: 0.0289\n",
      "Epoch 874/1500\n",
      "28/28 [==============================] - 0s 244us/step - loss: 0.0019 - val_loss: 0.0272\n",
      "Epoch 875/1500\n",
      "28/28 [==============================] - 0s 382us/step - loss: 0.0022 - val_loss: 0.0289\n",
      "Epoch 876/1500\n",
      "28/28 [==============================] - 0s 230us/step - loss: 0.0023 - val_loss: 0.0274\n",
      "Epoch 877/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 0.0022 - val_loss: 0.0283\n",
      "Epoch 878/1500\n",
      "28/28 [==============================] - 0s 238us/step - loss: 0.0019 - val_loss: 0.0275\n",
      "Epoch 879/1500\n",
      "28/28 [==============================] - 0s 239us/step - loss: 0.0019 - val_loss: 0.0274\n",
      "Epoch 880/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.0021 - val_loss: 0.0294\n",
      "Epoch 881/1500\n",
      "28/28 [==============================] - 0s 258us/step - loss: 0.0021 - val_loss: 0.0271\n",
      "Epoch 882/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.0020 - val_loss: 0.0280\n",
      "Epoch 883/1500\n",
      "28/28 [==============================] - 0s 207us/step - loss: 0.0019 - val_loss: 0.0287\n",
      "Epoch 884/1500\n",
      "28/28 [==============================] - 0s 264us/step - loss: 0.0019 - val_loss: 0.0269\n",
      "Epoch 885/1500\n",
      "28/28 [==============================] - 0s 291us/step - loss: 0.0020 - val_loss: 0.0281\n",
      "Epoch 886/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.0020 - val_loss: 0.0277\n",
      "Epoch 887/1500\n",
      "28/28 [==============================] - 0s 166us/step - loss: 0.0019 - val_loss: 0.0277\n",
      "Epoch 888/1500\n",
      "28/28 [==============================] - 0s 309us/step - loss: 0.0019 - val_loss: 0.0282\n",
      "Epoch 889/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.0019 - val_loss: 0.0276\n",
      "Epoch 890/1500\n",
      "28/28 [==============================] - 0s 243us/step - loss: 0.0020 - val_loss: 0.0286\n",
      "Epoch 891/1500\n",
      "28/28 [==============================] - 0s 170us/step - loss: 0.0019 - val_loss: 0.0277\n",
      "Epoch 892/1500\n",
      "28/28 [==============================] - 0s 262us/step - loss: 0.0019 - val_loss: 0.0278\n",
      "Epoch 893/1500\n",
      "28/28 [==============================] - 0s 190us/step - loss: 0.0019 - val_loss: 0.0289\n",
      "Epoch 894/1500\n",
      "28/28 [==============================] - 0s 232us/step - loss: 0.0019 - val_loss: 0.0277\n",
      "Epoch 895/1500\n",
      "28/28 [==============================] - 0s 276us/step - loss: 0.0019 - val_loss: 0.0284\n",
      "Epoch 896/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.0019 - val_loss: 0.0288\n",
      "Epoch 897/1500\n",
      "28/28 [==============================] - 0s 291us/step - loss: 0.0019 - val_loss: 0.0281\n",
      "Epoch 898/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.0019 - val_loss: 0.0289\n",
      "Epoch 899/1500\n",
      "28/28 [==============================] - 0s 173us/step - loss: 0.0019 - val_loss: 0.0287\n",
      "Epoch 900/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.0019 - val_loss: 0.0289\n",
      "Epoch 901/1500\n",
      "28/28 [==============================] - 0s 233us/step - loss: 0.0018 - val_loss: 0.0290\n",
      "Epoch 902/1500\n",
      "28/28 [==============================] - 0s 246us/step - loss: 0.0019 - val_loss: 0.0289\n",
      "Epoch 903/1500\n",
      "28/28 [==============================] - 0s 174us/step - loss: 0.0019 - val_loss: 0.0295\n",
      "Epoch 904/1500\n",
      "28/28 [==============================] - 0s 171us/step - loss: 0.0019 - val_loss: 0.0287\n",
      "Epoch 905/1500\n",
      "28/28 [==============================] - 0s 259us/step - loss: 0.0018 - val_loss: 0.0291\n",
      "Epoch 906/1500\n",
      "28/28 [==============================] - 0s 235us/step - loss: 0.0018 - val_loss: 0.0294\n",
      "Epoch 907/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.0018 - val_loss: 0.0287\n",
      "Epoch 908/1500\n",
      "28/28 [==============================] - 0s 190us/step - loss: 0.0019 - val_loss: 0.0293\n",
      "Epoch 909/1500\n",
      "28/28 [==============================] - 0s 196us/step - loss: 0.0019 - val_loss: 0.0292\n",
      "Epoch 910/1500\n",
      "28/28 [==============================] - 0s 244us/step - loss: 0.0018 - val_loss: 0.0291\n",
      "Epoch 911/1500\n",
      "28/28 [==============================] - 0s 236us/step - loss: 0.0018 - val_loss: 0.0292\n",
      "Epoch 912/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.0018 - val_loss: 0.0291\n",
      "Epoch 913/1500\n",
      "28/28 [==============================] - 0s 239us/step - loss: 0.0018 - val_loss: 0.0293\n",
      "Epoch 914/1500\n",
      "28/28 [==============================] - 0s 186us/step - loss: 0.0018 - val_loss: 0.0289\n",
      "Epoch 915/1500\n",
      "28/28 [==============================] - 0s 309us/step - loss: 0.0018 - val_loss: 0.0292\n",
      "Epoch 916/1500\n",
      "28/28 [==============================] - 0s 174us/step - loss: 0.0018 - val_loss: 0.0292\n",
      "Epoch 917/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0018 - val_loss: 0.0289\n",
      "Epoch 918/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0018 - val_loss: 0.0292\n",
      "Epoch 919/1500\n",
      "28/28 [==============================] - 0s 188us/step - loss: 0.0018 - val_loss: 0.0290\n",
      "Epoch 920/1500\n",
      "28/28 [==============================] - 0s 292us/step - loss: 0.0018 - val_loss: 0.0290\n",
      "Epoch 921/1500\n",
      "28/28 [==============================] - 0s 202us/step - loss: 0.0018 - val_loss: 0.0291\n",
      "Epoch 922/1500\n",
      "28/28 [==============================] - 0s 231us/step - loss: 0.0018 - val_loss: 0.0290\n",
      "Epoch 923/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.0018 - val_loss: 0.0291\n",
      "Epoch 924/1500\n",
      "28/28 [==============================] - 0s 176us/step - loss: 0.0018 - val_loss: 0.0289\n",
      "Epoch 925/1500\n",
      "28/28 [==============================] - 0s 195us/step - loss: 0.0018 - val_loss: 0.0291\n",
      "Epoch 926/1500\n",
      "28/28 [==============================] - 0s 241us/step - loss: 0.0018 - val_loss: 0.0289\n",
      "Epoch 927/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0018 - val_loss: 0.0289\n",
      "Epoch 928/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.0018 - val_loss: 0.0291\n",
      "Epoch 929/1500\n",
      "28/28 [==============================] - 0s 199us/step - loss: 0.0018 - val_loss: 0.0289\n",
      "Epoch 930/1500\n",
      "28/28 [==============================] - 0s 190us/step - loss: 0.0018 - val_loss: 0.0291\n",
      "Epoch 931/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.0018 - val_loss: 0.0290\n",
      "Epoch 932/1500\n",
      "28/28 [==============================] - 0s 189us/step - loss: 0.0018 - val_loss: 0.0290\n",
      "Epoch 933/1500\n",
      "28/28 [==============================] - 0s 299us/step - loss: 0.0018 - val_loss: 0.0290\n",
      "Epoch 934/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0018 - val_loss: 0.0290\n",
      "Epoch 935/1500\n",
      "28/28 [==============================] - 0s 169us/step - loss: 0.0018 - val_loss: 0.0291\n",
      "Epoch 936/1500\n",
      "28/28 [==============================] - 0s 185us/step - loss: 0.0018 - val_loss: 0.0289\n",
      "Epoch 937/1500\n",
      "28/28 [==============================] - 0s 194us/step - loss: 0.0018 - val_loss: 0.0291\n",
      "Epoch 938/1500\n",
      "28/28 [==============================] - 0s 348us/step - loss: 0.0018 - val_loss: 0.0290\n",
      "Epoch 939/1500\n",
      "28/28 [==============================] - 0s 183us/step - loss: 0.0018 - val_loss: 0.0290\n",
      "Epoch 940/1500\n",
      "28/28 [==============================] - 0s 239us/step - loss: 0.0018 - val_loss: 0.0291\n",
      "Epoch 941/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.0018 - val_loss: 0.0290\n",
      "Epoch 942/1500\n",
      "28/28 [==============================] - 0s 250us/step - loss: 0.0018 - val_loss: 0.0291\n",
      "Epoch 943/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0018 - val_loss: 0.0291\n",
      "Epoch 944/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.0018 - val_loss: 0.0291\n",
      "Epoch 945/1500\n",
      "28/28 [==============================] - 0s 282us/step - loss: 0.0018 - val_loss: 0.0291\n",
      "Epoch 946/1500\n",
      "28/28 [==============================] - 0s 274us/step - loss: 0.0018 - val_loss: 0.0291\n",
      "Epoch 947/1500\n",
      "28/28 [==============================] - 0s 189us/step - loss: 0.0018 - val_loss: 0.0291\n",
      "Epoch 948/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.0018 - val_loss: 0.0291\n",
      "Epoch 949/1500\n",
      "28/28 [==============================] - 0s 156us/step - loss: 0.0018 - val_loss: 0.0292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 950/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.0018 - val_loss: 0.0291\n",
      "Epoch 951/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0018 - val_loss: 0.0292\n",
      "Epoch 952/1500\n",
      "28/28 [==============================] - 0s 258us/step - loss: 0.0018 - val_loss: 0.0292\n",
      "Epoch 953/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.0018 - val_loss: 0.0292\n",
      "Epoch 954/1500\n",
      "28/28 [==============================] - 0s 209us/step - loss: 0.0018 - val_loss: 0.0292\n",
      "Epoch 955/1500\n",
      "28/28 [==============================] - 0s 183us/step - loss: 0.0018 - val_loss: 0.0292\n",
      "Epoch 956/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.0018 - val_loss: 0.0292\n",
      "Epoch 957/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.0018 - val_loss: 0.0292\n",
      "Epoch 958/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.0018 - val_loss: 0.0292\n",
      "Epoch 959/1500\n",
      "28/28 [==============================] - 0s 241us/step - loss: 0.0018 - val_loss: 0.0292\n",
      "Epoch 960/1500\n",
      "28/28 [==============================] - 0s 242us/step - loss: 0.0018 - val_loss: 0.0292\n",
      "Epoch 961/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0018 - val_loss: 0.0292\n",
      "Epoch 962/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0018 - val_loss: 0.0292\n",
      "Epoch 963/1500\n",
      "28/28 [==============================] - 0s 188us/step - loss: 0.0018 - val_loss: 0.0293\n",
      "Epoch 964/1500\n",
      "28/28 [==============================] - 0s 262us/step - loss: 0.0018 - val_loss: 0.0292\n",
      "Epoch 965/1500\n",
      "28/28 [==============================] - 0s 236us/step - loss: 0.0018 - val_loss: 0.0293\n",
      "Epoch 966/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.0018 - val_loss: 0.0293\n",
      "Epoch 967/1500\n",
      "28/28 [==============================] - 0s 205us/step - loss: 0.0018 - val_loss: 0.0293\n",
      "Epoch 968/1500\n",
      "28/28 [==============================] - 0s 200us/step - loss: 0.0018 - val_loss: 0.0293\n",
      "Epoch 969/1500\n",
      "28/28 [==============================] - 0s 242us/step - loss: 0.0018 - val_loss: 0.0293\n",
      "Epoch 970/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0018 - val_loss: 0.0293\n",
      "Epoch 971/1500\n",
      "28/28 [==============================] - 0s 237us/step - loss: 0.0018 - val_loss: 0.0293\n",
      "Epoch 972/1500\n",
      "28/28 [==============================] - 0s 245us/step - loss: 0.0018 - val_loss: 0.0293\n",
      "Epoch 973/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.0018 - val_loss: 0.0293\n",
      "Epoch 974/1500\n",
      "28/28 [==============================] - 0s 190us/step - loss: 0.0018 - val_loss: 0.0293\n",
      "Epoch 975/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.0018 - val_loss: 0.0293\n",
      "Epoch 976/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.0018 - val_loss: 0.0293\n",
      "Epoch 977/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.0018 - val_loss: 0.0293\n",
      "Epoch 978/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.0018 - val_loss: 0.0293\n",
      "Epoch 979/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0018 - val_loss: 0.0293\n",
      "Epoch 980/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.0018 - val_loss: 0.0293\n",
      "Epoch 981/1500\n",
      "28/28 [==============================] - 0s 240us/step - loss: 0.0018 - val_loss: 0.0293\n",
      "Epoch 982/1500\n",
      "28/28 [==============================] - 0s 207us/step - loss: 0.0018 - val_loss: 0.0293\n",
      "Epoch 983/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.0018 - val_loss: 0.0294\n",
      "Epoch 984/1500\n",
      "28/28 [==============================] - 0s 178us/step - loss: 0.0018 - val_loss: 0.0293\n",
      "Epoch 985/1500\n",
      "28/28 [==============================] - 0s 314us/step - loss: 0.0018 - val_loss: 0.0294\n",
      "Epoch 986/1500\n",
      "28/28 [==============================] - 0s 239us/step - loss: 0.0018 - val_loss: 0.0294\n",
      "Epoch 987/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.0018 - val_loss: 0.0294\n",
      "Epoch 988/1500\n",
      "28/28 [==============================] - 0s 195us/step - loss: 0.0018 - val_loss: 0.0294\n",
      "Epoch 989/1500\n",
      "28/28 [==============================] - 0s 235us/step - loss: 0.0018 - val_loss: 0.0294\n",
      "Epoch 990/1500\n",
      "28/28 [==============================] - 0s 250us/step - loss: 0.0018 - val_loss: 0.0294\n",
      "Epoch 991/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.0018 - val_loss: 0.0294\n",
      "Epoch 992/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.0018 - val_loss: 0.0294\n",
      "Epoch 993/1500\n",
      "28/28 [==============================] - 0s 233us/step - loss: 0.0018 - val_loss: 0.0294\n",
      "Epoch 994/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0018 - val_loss: 0.0294\n",
      "Epoch 995/1500\n",
      "28/28 [==============================] - 0s 240us/step - loss: 0.0018 - val_loss: 0.0294\n",
      "Epoch 996/1500\n",
      "28/28 [==============================] - 0s 226us/step - loss: 0.0018 - val_loss: 0.0294\n",
      "Epoch 997/1500\n",
      "28/28 [==============================] - 0s 247us/step - loss: 0.0018 - val_loss: 0.0294\n",
      "Epoch 998/1500\n",
      "28/28 [==============================] - 0s 199us/step - loss: 0.0018 - val_loss: 0.0294\n",
      "Epoch 999/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.0018 - val_loss: 0.0294\n",
      "Epoch 1000/1500\n",
      "28/28 [==============================] - 0s 191us/step - loss: 0.0018 - val_loss: 0.0294\n",
      "Epoch 1001/1500\n",
      "28/28 [==============================] - 0s 257us/step - loss: 0.0018 - val_loss: 0.0294\n",
      "Epoch 1002/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0018 - val_loss: 0.0294\n",
      "Epoch 1003/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0018 - val_loss: 0.0295\n",
      "Epoch 1004/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.0018 - val_loss: 0.0295\n",
      "Epoch 1005/1500\n",
      "28/28 [==============================] - 0s 233us/step - loss: 0.0018 - val_loss: 0.0295\n",
      "Epoch 1006/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0018 - val_loss: 0.0295\n",
      "Epoch 1007/1500\n",
      "28/28 [==============================] - 0s 254us/step - loss: 0.0018 - val_loss: 0.0295\n",
      "Epoch 1008/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.0018 - val_loss: 0.0295\n",
      "Epoch 1009/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.0018 - val_loss: 0.0295\n",
      "Epoch 1010/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.0018 - val_loss: 0.0295\n",
      "Epoch 1011/1500\n",
      "28/28 [==============================] - 0s 244us/step - loss: 0.0018 - val_loss: 0.0295\n",
      "Epoch 1012/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.0018 - val_loss: 0.0295\n",
      "Epoch 1013/1500\n",
      "28/28 [==============================] - 0s 199us/step - loss: 0.0018 - val_loss: 0.0295\n",
      "Epoch 1014/1500\n",
      "28/28 [==============================] - 0s 256us/step - loss: 0.0018 - val_loss: 0.0295\n",
      "Epoch 1015/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.0018 - val_loss: 0.0295\n",
      "Epoch 1016/1500\n",
      "28/28 [==============================] - 0s 226us/step - loss: 0.0018 - val_loss: 0.0295\n",
      "Epoch 1017/1500\n",
      "28/28 [==============================] - 0s 189us/step - loss: 0.0018 - val_loss: 0.0295\n",
      "Epoch 1018/1500\n",
      "28/28 [==============================] - 0s 187us/step - loss: 0.0018 - val_loss: 0.0295\n",
      "Epoch 1019/1500\n",
      "28/28 [==============================] - 0s 184us/step - loss: 0.0018 - val_loss: 0.0295\n",
      "Epoch 1020/1500\n",
      "28/28 [==============================] - 0s 236us/step - loss: 0.0018 - val_loss: 0.0295\n",
      "Epoch 1021/1500\n",
      "28/28 [==============================] - 0s 243us/step - loss: 0.0018 - val_loss: 0.0295\n",
      "Epoch 1022/1500\n",
      "28/28 [==============================] - 0s 265us/step - loss: 0.0018 - val_loss: 0.0295\n",
      "Epoch 1023/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0018 - val_loss: 0.0295\n",
      "Epoch 1024/1500\n",
      "28/28 [==============================] - 0s 172us/step - loss: 0.0018 - val_loss: 0.0295\n",
      "Epoch 1025/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.0018 - val_loss: 0.0295\n",
      "Epoch 1026/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0018 - val_loss: 0.0295\n",
      "Epoch 1027/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0018 - val_loss: 0.0295\n",
      "Epoch 1028/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0018 - val_loss: 0.0296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1029/1500\n",
      "28/28 [==============================] - 0s 287us/step - loss: 0.0018 - val_loss: 0.0296\n",
      "Epoch 1030/1500\n",
      "28/28 [==============================] - 0s 255us/step - loss: 0.0018 - val_loss: 0.0296\n",
      "Epoch 1031/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.0018 - val_loss: 0.0296\n",
      "Epoch 1032/1500\n",
      "28/28 [==============================] - 0s 176us/step - loss: 0.0018 - val_loss: 0.0296\n",
      "Epoch 1033/1500\n",
      "28/28 [==============================] - 0s 194us/step - loss: 0.0018 - val_loss: 0.0296\n",
      "Epoch 1034/1500\n",
      "28/28 [==============================] - 0s 185us/step - loss: 0.0018 - val_loss: 0.0296\n",
      "Epoch 1035/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.0018 - val_loss: 0.0296\n",
      "Epoch 1036/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0018 - val_loss: 0.0296\n",
      "Epoch 1037/1500\n",
      "28/28 [==============================] - 0s 246us/step - loss: 0.0018 - val_loss: 0.0296\n",
      "Epoch 1038/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0018 - val_loss: 0.0296\n",
      "Epoch 1039/1500\n",
      "28/28 [==============================] - 0s 226us/step - loss: 0.0018 - val_loss: 0.0296\n",
      "Epoch 1040/1500\n",
      "28/28 [==============================] - 0s 232us/step - loss: 0.0018 - val_loss: 0.0296\n",
      "Epoch 1041/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.0018 - val_loss: 0.0296\n",
      "Epoch 1042/1500\n",
      "28/28 [==============================] - 0s 245us/step - loss: 0.0018 - val_loss: 0.0296\n",
      "Epoch 1043/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.0018 - val_loss: 0.0296\n",
      "Epoch 1044/1500\n",
      "28/28 [==============================] - 0s 236us/step - loss: 0.0018 - val_loss: 0.0296\n",
      "Epoch 1045/1500\n",
      "28/28 [==============================] - 0s 196us/step - loss: 0.0018 - val_loss: 0.0296\n",
      "Epoch 1046/1500\n",
      "28/28 [==============================] - 0s 176us/step - loss: 0.0018 - val_loss: 0.0296\n",
      "Epoch 1047/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0018 - val_loss: 0.0296\n",
      "Epoch 1048/1500\n",
      "28/28 [==============================] - 0s 188us/step - loss: 0.0018 - val_loss: 0.0296\n",
      "Epoch 1049/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0018 - val_loss: 0.0296\n",
      "Epoch 1050/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.0018 - val_loss: 0.0296\n",
      "Epoch 1051/1500\n",
      "28/28 [==============================] - 0s 226us/step - loss: 0.0018 - val_loss: 0.0296\n",
      "Epoch 1052/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.0018 - val_loss: 0.0296\n",
      "Epoch 1053/1500\n",
      "28/28 [==============================] - 0s 239us/step - loss: 0.0018 - val_loss: 0.0296\n",
      "Epoch 1054/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.0018 - val_loss: 0.0296\n",
      "Epoch 1055/1500\n",
      "28/28 [==============================] - 0s 207us/step - loss: 0.0018 - val_loss: 0.0296\n",
      "Epoch 1056/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0018 - val_loss: 0.0296\n",
      "Epoch 1057/1500\n",
      "28/28 [==============================] - 0s 291us/step - loss: 0.0018 - val_loss: 0.0296\n",
      "Epoch 1058/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.0018 - val_loss: 0.0296\n",
      "Epoch 1059/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.0018 - val_loss: 0.0296\n",
      "Epoch 1060/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.0018 - val_loss: 0.0297\n",
      "Epoch 1061/1500\n",
      "28/28 [==============================] - 0s 236us/step - loss: 0.0018 - val_loss: 0.0297\n",
      "Epoch 1062/1500\n",
      "28/28 [==============================] - 0s 249us/step - loss: 0.0018 - val_loss: 0.0297\n",
      "Epoch 1063/1500\n",
      "28/28 [==============================] - 0s 247us/step - loss: 0.0018 - val_loss: 0.0297\n",
      "Epoch 1064/1500\n",
      "28/28 [==============================] - 0s 252us/step - loss: 0.0018 - val_loss: 0.0297\n",
      "Epoch 1065/1500\n",
      "28/28 [==============================] - 0s 193us/step - loss: 0.0018 - val_loss: 0.0297\n",
      "Epoch 1066/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0018 - val_loss: 0.0297\n",
      "Epoch 1067/1500\n",
      "28/28 [==============================] - 0s 265us/step - loss: 0.0018 - val_loss: 0.0297\n",
      "Epoch 1068/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0018 - val_loss: 0.0297\n",
      "Epoch 1069/1500\n",
      "28/28 [==============================] - 0s 202us/step - loss: 0.0018 - val_loss: 0.0297\n",
      "Epoch 1070/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0018 - val_loss: 0.0297\n",
      "Epoch 1071/1500\n",
      "28/28 [==============================] - 0s 250us/step - loss: 0.0018 - val_loss: 0.0297\n",
      "Epoch 1072/1500\n",
      "28/28 [==============================] - 0s 209us/step - loss: 0.0018 - val_loss: 0.0297\n",
      "Epoch 1073/1500\n",
      "28/28 [==============================] - 0s 178us/step - loss: 0.0018 - val_loss: 0.0297\n",
      "Epoch 1074/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.0018 - val_loss: 0.0297\n",
      "Epoch 1075/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.0018 - val_loss: 0.0297\n",
      "Epoch 1076/1500\n",
      "28/28 [==============================] - 0s 178us/step - loss: 0.0018 - val_loss: 0.0297\n",
      "Epoch 1077/1500\n",
      "28/28 [==============================] - 0s 237us/step - loss: 0.0018 - val_loss: 0.0297\n",
      "Epoch 1078/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.0018 - val_loss: 0.0297\n",
      "Epoch 1079/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0018 - val_loss: 0.0297\n",
      "Epoch 1080/1500\n",
      "28/28 [==============================] - 0s 175us/step - loss: 0.0017 - val_loss: 0.0297\n",
      "Epoch 1081/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0017 - val_loss: 0.0297\n",
      "Epoch 1082/1500\n",
      "28/28 [==============================] - 0s 263us/step - loss: 0.0017 - val_loss: 0.0297\n",
      "Epoch 1083/1500\n",
      "28/28 [==============================] - 0s 238us/step - loss: 0.0017 - val_loss: 0.0297\n",
      "Epoch 1084/1500\n",
      "28/28 [==============================] - 0s 194us/step - loss: 0.0017 - val_loss: 0.0297\n",
      "Epoch 1085/1500\n",
      "28/28 [==============================] - 0s 195us/step - loss: 0.0017 - val_loss: 0.0297\n",
      "Epoch 1086/1500\n",
      "28/28 [==============================] - 0s 199us/step - loss: 0.0017 - val_loss: 0.0297\n",
      "Epoch 1087/1500\n",
      "28/28 [==============================] - 0s 179us/step - loss: 0.0017 - val_loss: 0.0297\n",
      "Epoch 1088/1500\n",
      "28/28 [==============================] - 0s 280us/step - loss: 0.0017 - val_loss: 0.0297\n",
      "Epoch 1089/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0017 - val_loss: 0.0297\n",
      "Epoch 1090/1500\n",
      "28/28 [==============================] - 0s 254us/step - loss: 0.0017 - val_loss: 0.0298\n",
      "Epoch 1091/1500\n",
      "28/28 [==============================] - 0s 240us/step - loss: 0.0017 - val_loss: 0.0297\n",
      "Epoch 1092/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 0.0017 - val_loss: 0.0298\n",
      "Epoch 1093/1500\n",
      "28/28 [==============================] - 0s 236us/step - loss: 0.0017 - val_loss: 0.0297\n",
      "Epoch 1094/1500\n",
      "28/28 [==============================] - 0s 257us/step - loss: 0.0017 - val_loss: 0.0298\n",
      "Epoch 1095/1500\n",
      "28/28 [==============================] - 0s 238us/step - loss: 0.0017 - val_loss: 0.0296\n",
      "Epoch 1096/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.0017 - val_loss: 0.0298\n",
      "Epoch 1097/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.0017 - val_loss: 0.0296\n",
      "Epoch 1098/1500\n",
      "28/28 [==============================] - 0s 176us/step - loss: 0.0017 - val_loss: 0.0299\n",
      "Epoch 1099/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.0017 - val_loss: 0.0295\n",
      "Epoch 1100/1500\n",
      "28/28 [==============================] - 0s 247us/step - loss: 0.0018 - val_loss: 0.0300\n",
      "Epoch 1101/1500\n",
      "28/28 [==============================] - 0s 230us/step - loss: 0.0018 - val_loss: 0.0294\n",
      "Epoch 1102/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.0018 - val_loss: 0.0302\n",
      "Epoch 1103/1500\n",
      "28/28 [==============================] - 0s 179us/step - loss: 0.0018 - val_loss: 0.0292\n",
      "Epoch 1104/1500\n",
      "28/28 [==============================] - 0s 181us/step - loss: 0.0018 - val_loss: 0.0304\n",
      "Epoch 1105/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.0018 - val_loss: 0.0290\n",
      "Epoch 1106/1500\n",
      "28/28 [==============================] - 0s 153us/step - loss: 0.0018 - val_loss: 0.0308\n",
      "Epoch 1107/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.0019 - val_loss: 0.0286\n",
      "Epoch 1108/1500\n",
      "28/28 [==============================] - 0s 278us/step - loss: 0.0019 - val_loss: 0.0312\n",
      "Epoch 1109/1500\n",
      "28/28 [==============================] - 0s 241us/step - loss: 0.0020 - val_loss: 0.0283\n",
      "Epoch 1110/1500\n",
      "28/28 [==============================] - 0s 150us/step - loss: 0.0020 - val_loss: 0.0313\n",
      "Epoch 1111/1500\n",
      "28/28 [==============================] - 0s 256us/step - loss: 0.0020 - val_loss: 0.0282\n",
      "Epoch 1112/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.0020 - val_loss: 0.0307\n",
      "Epoch 1113/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0019 - val_loss: 0.0286\n",
      "Epoch 1114/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.0018 - val_loss: 0.0295\n",
      "Epoch 1115/1500\n",
      "28/28 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 0.0296\n",
      "Epoch 1116/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.0017 - val_loss: 0.0286\n",
      "Epoch 1117/1500\n",
      "28/28 [==============================] - 0s 277us/step - loss: 0.0018 - val_loss: 0.0304\n",
      "Epoch 1118/1500\n",
      "28/28 [==============================] - 0s 199us/step - loss: 0.0018 - val_loss: 0.0285\n",
      "Epoch 1119/1500\n",
      "28/28 [==============================] - 0s 159us/step - loss: 0.0018 - val_loss: 0.0306\n",
      "Epoch 1120/1500\n",
      "28/28 [==============================] - 0s 275us/step - loss: 0.0018 - val_loss: 0.0289\n",
      "Epoch 1121/1500\n",
      "28/28 [==============================] - 0s 238us/step - loss: 0.0018 - val_loss: 0.0301\n",
      "Epoch 1122/1500\n",
      "28/28 [==============================] - 0s 242us/step - loss: 0.0018 - val_loss: 0.0294\n",
      "Epoch 1123/1500\n",
      "28/28 [==============================] - 0s 183us/step - loss: 0.0017 - val_loss: 0.0293\n",
      "Epoch 1124/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.0017 - val_loss: 0.0301\n",
      "Epoch 1125/1500\n",
      "28/28 [==============================] - 0s 280us/step - loss: 0.0018 - val_loss: 0.0289\n",
      "Epoch 1126/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.0018 - val_loss: 0.0304\n",
      "Epoch 1127/1500\n",
      "28/28 [==============================] - 0s 190us/step - loss: 0.0018 - val_loss: 0.0290\n",
      "Epoch 1128/1500\n",
      "28/28 [==============================] - 0s 235us/step - loss: 0.0018 - val_loss: 0.0302\n",
      "Epoch 1129/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.0018 - val_loss: 0.0296\n",
      "Epoch 1130/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.0017 - val_loss: 0.0297\n",
      "Epoch 1131/1500\n",
      "28/28 [==============================] - 0s 184us/step - loss: 0.0017 - val_loss: 0.0301\n",
      "Epoch 1132/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0017 - val_loss: 0.0294\n",
      "Epoch 1133/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0017 - val_loss: 0.0304\n",
      "Epoch 1134/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.0018 - val_loss: 0.0294\n",
      "Epoch 1135/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.0018 - val_loss: 0.0304\n",
      "Epoch 1136/1500\n",
      "28/28 [==============================] - 0s 250us/step - loss: 0.0018 - val_loss: 0.0297\n",
      "Epoch 1137/1500\n",
      "28/28 [==============================] - 0s 191us/step - loss: 0.0017 - val_loss: 0.0302\n",
      "Epoch 1138/1500\n",
      "28/28 [==============================] - 0s 199us/step - loss: 0.0017 - val_loss: 0.0300\n",
      "Epoch 1139/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.0017 - val_loss: 0.0298\n",
      "Epoch 1140/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.0017 - val_loss: 0.0303\n",
      "Epoch 1141/1500\n",
      "28/28 [==============================] - 0s 245us/step - loss: 0.0017 - val_loss: 0.0296\n",
      "Epoch 1142/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.0017 - val_loss: 0.0304\n",
      "Epoch 1143/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.0017 - val_loss: 0.0297\n",
      "Epoch 1144/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0017 - val_loss: 0.0303\n",
      "Epoch 1145/1500\n",
      "28/28 [==============================] - 0s 190us/step - loss: 0.0017 - val_loss: 0.0298\n",
      "Epoch 1146/1500\n",
      "28/28 [==============================] - 0s 193us/step - loss: 0.0017 - val_loss: 0.0301\n",
      "Epoch 1147/1500\n",
      "28/28 [==============================] - 0s 497us/step - loss: 0.0017 - val_loss: 0.0299\n",
      "Epoch 1148/1500\n",
      "28/28 [==============================] - 0s 272us/step - loss: 0.0017 - val_loss: 0.0299\n",
      "Epoch 1149/1500\n",
      "28/28 [==============================] - 0s 292us/step - loss: 0.0017 - val_loss: 0.0301\n",
      "Epoch 1150/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.0017 - val_loss: 0.0297\n",
      "Epoch 1151/1500\n",
      "28/28 [==============================] - 0s 236us/step - loss: 0.0017 - val_loss: 0.0302\n",
      "Epoch 1152/1500\n",
      "28/28 [==============================] - 0s 263us/step - loss: 0.0017 - val_loss: 0.0297\n",
      "Epoch 1153/1500\n",
      "28/28 [==============================] - 0s 235us/step - loss: 0.0017 - val_loss: 0.0302\n",
      "Epoch 1154/1500\n",
      "28/28 [==============================] - 0s 169us/step - loss: 0.0017 - val_loss: 0.0297\n",
      "Epoch 1155/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0017 - val_loss: 0.0301\n",
      "Epoch 1156/1500\n",
      "28/28 [==============================] - 0s 258us/step - loss: 0.0017 - val_loss: 0.0297\n",
      "Epoch 1157/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 0.0017 - val_loss: 0.0300\n",
      "Epoch 1158/1500\n",
      "28/28 [==============================] - 0s 192us/step - loss: 0.0017 - val_loss: 0.0298\n",
      "Epoch 1159/1500\n",
      "28/28 [==============================] - 0s 205us/step - loss: 0.0017 - val_loss: 0.0299\n",
      "Epoch 1160/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.0017 - val_loss: 0.0299\n",
      "Epoch 1161/1500\n",
      "28/28 [==============================] - 0s 233us/step - loss: 0.0017 - val_loss: 0.0298\n",
      "Epoch 1162/1500\n",
      "28/28 [==============================] - 0s 171us/step - loss: 0.0017 - val_loss: 0.0300\n",
      "Epoch 1163/1500\n",
      "28/28 [==============================] - 0s 196us/step - loss: 0.0017 - val_loss: 0.0297\n",
      "Epoch 1164/1500\n",
      "28/28 [==============================] - 0s 199us/step - loss: 0.0017 - val_loss: 0.0300\n",
      "Epoch 1165/1500\n",
      "28/28 [==============================] - 0s 251us/step - loss: 0.0017 - val_loss: 0.0297\n",
      "Epoch 1166/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0017 - val_loss: 0.0300\n",
      "Epoch 1167/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0017 - val_loss: 0.0297\n",
      "Epoch 1168/1500\n",
      "28/28 [==============================] - 0s 172us/step - loss: 0.0017 - val_loss: 0.0300\n",
      "Epoch 1169/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.0017 - val_loss: 0.0297\n",
      "Epoch 1170/1500\n",
      "28/28 [==============================] - 0s 205us/step - loss: 0.0017 - val_loss: 0.0300\n",
      "Epoch 1171/1500\n",
      "28/28 [==============================] - 0s 233us/step - loss: 0.0017 - val_loss: 0.0298\n",
      "Epoch 1172/1500\n",
      "28/28 [==============================] - 0s 184us/step - loss: 0.0017 - val_loss: 0.0300\n",
      "Epoch 1173/1500\n",
      "28/28 [==============================] - 0s 216us/step - loss: 0.0017 - val_loss: 0.0298\n",
      "Epoch 1174/1500\n",
      "28/28 [==============================] - 0s 185us/step - loss: 0.0017 - val_loss: 0.0299\n",
      "Epoch 1175/1500\n",
      "28/28 [==============================] - 0s 236us/step - loss: 0.0017 - val_loss: 0.0298\n",
      "Epoch 1176/1500\n",
      "28/28 [==============================] - 0s 185us/step - loss: 0.0017 - val_loss: 0.0299\n",
      "Epoch 1177/1500\n",
      "28/28 [==============================] - 0s 233us/step - loss: 0.0017 - val_loss: 0.0299\n",
      "Epoch 1178/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0017 - val_loss: 0.0299\n",
      "Epoch 1179/1500\n",
      "28/28 [==============================] - 0s 207us/step - loss: 0.0017 - val_loss: 0.0299\n",
      "Epoch 1180/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0017 - val_loss: 0.0299\n",
      "Epoch 1181/1500\n",
      "28/28 [==============================] - 0s 237us/step - loss: 0.0017 - val_loss: 0.0299\n",
      "Epoch 1182/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.0017 - val_loss: 0.0299\n",
      "Epoch 1183/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0017 - val_loss: 0.0299\n",
      "Epoch 1184/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.0017 - val_loss: 0.0299\n",
      "Epoch 1185/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 231us/step - loss: 0.0017 - val_loss: 0.0299\n",
      "Epoch 1186/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.0017 - val_loss: 0.0299\n",
      "Epoch 1187/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0017 - val_loss: 0.0299\n",
      "Epoch 1188/1500\n",
      "28/28 [==============================] - 0s 161us/step - loss: 0.0017 - val_loss: 0.0299\n",
      "Epoch 1189/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.0017 - val_loss: 0.0300\n",
      "Epoch 1190/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.0017 - val_loss: 0.0298\n",
      "Epoch 1191/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0017 - val_loss: 0.0300\n",
      "Epoch 1192/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.0017 - val_loss: 0.0298\n",
      "Epoch 1193/1500\n",
      "28/28 [==============================] - 0s 233us/step - loss: 0.0017 - val_loss: 0.0300\n",
      "Epoch 1194/1500\n",
      "28/28 [==============================] - 0s 196us/step - loss: 0.0017 - val_loss: 0.0298\n",
      "Epoch 1195/1500\n",
      "28/28 [==============================] - 0s 179us/step - loss: 0.0017 - val_loss: 0.0300\n",
      "Epoch 1196/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0017 - val_loss: 0.0298\n",
      "Epoch 1197/1500\n",
      "28/28 [==============================] - 0s 159us/step - loss: 0.0017 - val_loss: 0.0300\n",
      "Epoch 1198/1500\n",
      "28/28 [==============================] - 0s 260us/step - loss: 0.0017 - val_loss: 0.0298\n",
      "Epoch 1199/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.0017 - val_loss: 0.0300\n",
      "Epoch 1200/1500\n",
      "28/28 [==============================] - 0s 252us/step - loss: 0.0017 - val_loss: 0.0297\n",
      "Epoch 1201/1500\n",
      "28/28 [==============================] - 0s 194us/step - loss: 0.0017 - val_loss: 0.0301\n",
      "Epoch 1202/1500\n",
      "28/28 [==============================] - 0s 231us/step - loss: 0.0017 - val_loss: 0.0297\n",
      "Epoch 1203/1500\n",
      "28/28 [==============================] - 0s 245us/step - loss: 0.0017 - val_loss: 0.0301\n",
      "Epoch 1204/1500\n",
      "28/28 [==============================] - 0s 235us/step - loss: 0.0017 - val_loss: 0.0296\n",
      "Epoch 1205/1500\n",
      "28/28 [==============================] - 0s 188us/step - loss: 0.0017 - val_loss: 0.0302\n",
      "Epoch 1206/1500\n",
      "28/28 [==============================] - 0s 209us/step - loss: 0.0017 - val_loss: 0.0295\n",
      "Epoch 1207/1500\n",
      "28/28 [==============================] - 0s 200us/step - loss: 0.0017 - val_loss: 0.0303\n",
      "Epoch 1208/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.0017 - val_loss: 0.0294\n",
      "Epoch 1209/1500\n",
      "28/28 [==============================] - 0s 188us/step - loss: 0.0017 - val_loss: 0.0305\n",
      "Epoch 1210/1500\n",
      "28/28 [==============================] - 0s 192us/step - loss: 0.0017 - val_loss: 0.0292\n",
      "Epoch 1211/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.0017 - val_loss: 0.0307\n",
      "Epoch 1212/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.0018 - val_loss: 0.0290\n",
      "Epoch 1213/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.0018 - val_loss: 0.0310\n",
      "Epoch 1214/1500\n",
      "28/28 [==============================] - 0s 181us/step - loss: 0.0018 - val_loss: 0.0287\n",
      "Epoch 1215/1500\n",
      "28/28 [==============================] - 0s 263us/step - loss: 0.0018 - val_loss: 0.0313\n",
      "Epoch 1216/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.0019 - val_loss: 0.0285\n",
      "Epoch 1217/1500\n",
      "28/28 [==============================] - 0s 252us/step - loss: 0.0019 - val_loss: 0.0316\n",
      "Epoch 1218/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.0019 - val_loss: 0.0282\n",
      "Epoch 1219/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.0019 - val_loss: 0.0318\n",
      "Epoch 1220/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0020 - val_loss: 0.0281\n",
      "Epoch 1221/1500\n",
      "28/28 [==============================] - 0s 232us/step - loss: 0.0019 - val_loss: 0.0315\n",
      "Epoch 1222/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.0019 - val_loss: 0.0283\n",
      "Epoch 1223/1500\n",
      "28/28 [==============================] - 0s 230us/step - loss: 0.0018 - val_loss: 0.0308\n",
      "Epoch 1224/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.0018 - val_loss: 0.0289\n",
      "Epoch 1225/1500\n",
      "28/28 [==============================] - 0s 256us/step - loss: 0.0017 - val_loss: 0.0298\n",
      "Epoch 1226/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0017 - val_loss: 0.0298\n",
      "Epoch 1227/1500\n",
      "28/28 [==============================] - 0s 301us/step - loss: 0.0017 - val_loss: 0.0291\n",
      "Epoch 1228/1500\n",
      "28/28 [==============================] - 0s 189us/step - loss: 0.0017 - val_loss: 0.0306\n",
      "Epoch 1229/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0017 - val_loss: 0.0288\n",
      "Epoch 1230/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.0018 - val_loss: 0.0309\n",
      "Epoch 1231/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.0018 - val_loss: 0.0289\n",
      "Epoch 1232/1500\n",
      "28/28 [==============================] - 0s 267us/step - loss: 0.0018 - val_loss: 0.0308\n",
      "Epoch 1233/1500\n",
      "28/28 [==============================] - 0s 205us/step - loss: 0.0017 - val_loss: 0.0291\n",
      "Epoch 1234/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.0017 - val_loss: 0.0303\n",
      "Epoch 1235/1500\n",
      "28/28 [==============================] - 0s 237us/step - loss: 0.0017 - val_loss: 0.0296\n",
      "Epoch 1236/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0017 - val_loss: 0.0299\n",
      "Epoch 1237/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.0017 - val_loss: 0.0302\n",
      "Epoch 1238/1500\n",
      "28/28 [==============================] - 0s 202us/step - loss: 0.0017 - val_loss: 0.0295\n",
      "Epoch 1239/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.0017 - val_loss: 0.0306\n",
      "Epoch 1240/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.0017 - val_loss: 0.0294\n",
      "Epoch 1241/1500\n",
      "28/28 [==============================] - 0s 202us/step - loss: 0.0017 - val_loss: 0.0307\n",
      "Epoch 1242/1500\n",
      "28/28 [==============================] - 0s 200us/step - loss: 0.0017 - val_loss: 0.0295\n",
      "Epoch 1243/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.0017 - val_loss: 0.0306\n",
      "Epoch 1244/1500\n",
      "28/28 [==============================] - 0s 284us/step - loss: 0.0017 - val_loss: 0.0297\n",
      "Epoch 1245/1500\n",
      "28/28 [==============================] - 0s 237us/step - loss: 0.0017 - val_loss: 0.0303\n",
      "Epoch 1246/1500\n",
      "28/28 [==============================] - 0s 237us/step - loss: 0.0017 - val_loss: 0.0299\n",
      "Epoch 1247/1500\n",
      "28/28 [==============================] - 0s 200us/step - loss: 0.0017 - val_loss: 0.0301\n",
      "Epoch 1248/1500\n",
      "28/28 [==============================] - 0s 180us/step - loss: 0.0017 - val_loss: 0.0302\n",
      "Epoch 1249/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.0017 - val_loss: 0.0298\n",
      "Epoch 1250/1500\n",
      "28/28 [==============================] - 0s 233us/step - loss: 0.0017 - val_loss: 0.0303\n",
      "Epoch 1251/1500\n",
      "28/28 [==============================] - 0s 186us/step - loss: 0.0017 - val_loss: 0.0297\n",
      "Epoch 1252/1500\n",
      "28/28 [==============================] - 0s 195us/step - loss: 0.0017 - val_loss: 0.0304\n",
      "Epoch 1253/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.0017 - val_loss: 0.0296\n",
      "Epoch 1254/1500\n",
      "28/28 [==============================] - 0s 199us/step - loss: 0.0017 - val_loss: 0.0304\n",
      "Epoch 1255/1500\n",
      "28/28 [==============================] - 0s 190us/step - loss: 0.0017 - val_loss: 0.0297\n",
      "Epoch 1256/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.0017 - val_loss: 0.0303\n",
      "Epoch 1257/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.0017 - val_loss: 0.0297\n",
      "Epoch 1258/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.0017 - val_loss: 0.0302\n",
      "Epoch 1259/1500\n",
      "28/28 [==============================] - 0s 263us/step - loss: 0.0017 - val_loss: 0.0298\n",
      "Epoch 1260/1500\n",
      "28/28 [==============================] - 0s 250us/step - loss: 0.0017 - val_loss: 0.0301\n",
      "Epoch 1261/1500\n",
      "28/28 [==============================] - 0s 256us/step - loss: 0.0017 - val_loss: 0.0298\n",
      "Epoch 1262/1500\n",
      "28/28 [==============================] - 0s 254us/step - loss: 0.0017 - val_loss: 0.0300\n",
      "Epoch 1263/1500\n",
      "28/28 [==============================] - 0s 191us/step - loss: 0.0017 - val_loss: 0.0299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1264/1500\n",
      "28/28 [==============================] - 0s 256us/step - loss: 0.0017 - val_loss: 0.0299\n",
      "Epoch 1265/1500\n",
      "28/28 [==============================] - 0s 230us/step - loss: 0.0017 - val_loss: 0.0300\n",
      "Epoch 1266/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.0017 - val_loss: 0.0298\n",
      "Epoch 1267/1500\n",
      "28/28 [==============================] - 0s 183us/step - loss: 0.0017 - val_loss: 0.0301\n",
      "Epoch 1268/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0017 - val_loss: 0.0298\n",
      "Epoch 1269/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0017 - val_loss: 0.0301\n",
      "Epoch 1270/1500\n",
      "28/28 [==============================] - 0s 245us/step - loss: 0.0017 - val_loss: 0.0298\n",
      "Epoch 1271/1500\n",
      "28/28 [==============================] - 0s 187us/step - loss: 0.0017 - val_loss: 0.0301\n",
      "Epoch 1272/1500\n",
      "28/28 [==============================] - 0s 259us/step - loss: 0.0017 - val_loss: 0.0297\n",
      "Epoch 1273/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0017 - val_loss: 0.0302\n",
      "Epoch 1274/1500\n",
      "28/28 [==============================] - 0s 248us/step - loss: 0.0017 - val_loss: 0.0297\n",
      "Epoch 1275/1500\n",
      "28/28 [==============================] - 0s 158us/step - loss: 0.0017 - val_loss: 0.0302\n",
      "Epoch 1276/1500\n",
      "28/28 [==============================] - 0s 287us/step - loss: 0.0017 - val_loss: 0.0297\n",
      "Epoch 1277/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.0017 - val_loss: 0.0302\n",
      "Epoch 1278/1500\n",
      "28/28 [==============================] - 0s 194us/step - loss: 0.0017 - val_loss: 0.0296\n",
      "Epoch 1279/1500\n",
      "28/28 [==============================] - 0s 271us/step - loss: 0.0017 - val_loss: 0.0303\n",
      "Epoch 1280/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0017 - val_loss: 0.0296\n",
      "Epoch 1281/1500\n",
      "28/28 [==============================] - 0s 192us/step - loss: 0.0017 - val_loss: 0.0303\n",
      "Epoch 1282/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.0017 - val_loss: 0.0296\n",
      "Epoch 1283/1500\n",
      "28/28 [==============================] - 0s 303us/step - loss: 0.0017 - val_loss: 0.0304\n",
      "Epoch 1284/1500\n",
      "28/28 [==============================] - 0s 275us/step - loss: 0.0017 - val_loss: 0.0295\n",
      "Epoch 1285/1500\n",
      "28/28 [==============================] - 0s 259us/step - loss: 0.0017 - val_loss: 0.0305\n",
      "Epoch 1286/1500\n",
      "28/28 [==============================] - 0s 346us/step - loss: 0.0017 - val_loss: 0.0294\n",
      "Epoch 1287/1500\n",
      "28/28 [==============================] - 0s 278us/step - loss: 0.0017 - val_loss: 0.0306\n",
      "Epoch 1288/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0017 - val_loss: 0.0293\n",
      "Epoch 1289/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.0017 - val_loss: 0.0307\n",
      "Epoch 1290/1500\n",
      "28/28 [==============================] - 0s 207us/step - loss: 0.0017 - val_loss: 0.0291\n",
      "Epoch 1291/1500\n",
      "28/28 [==============================] - 0s 239us/step - loss: 0.0017 - val_loss: 0.0309\n",
      "Epoch 1292/1500\n",
      "28/28 [==============================] - 0s 160us/step - loss: 0.0017 - val_loss: 0.0289\n",
      "Epoch 1293/1500\n",
      "28/28 [==============================] - 0s 237us/step - loss: 0.0017 - val_loss: 0.0312\n",
      "Epoch 1294/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.0017 - val_loss: 0.0287\n",
      "Epoch 1295/1500\n",
      "28/28 [==============================] - 0s 244us/step - loss: 0.0018 - val_loss: 0.0315\n",
      "Epoch 1296/1500\n",
      "28/28 [==============================] - 0s 202us/step - loss: 0.0018 - val_loss: 0.0284\n",
      "Epoch 1297/1500\n",
      "28/28 [==============================] - 0s 202us/step - loss: 0.0018 - val_loss: 0.0319\n",
      "Epoch 1298/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0019 - val_loss: 0.0281\n",
      "Epoch 1299/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.0019 - val_loss: 0.0323\n",
      "Epoch 1300/1500\n",
      "28/28 [==============================] - 0s 241us/step - loss: 0.0019 - val_loss: 0.0279\n",
      "Epoch 1301/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0019 - val_loss: 0.0325\n",
      "Epoch 1302/1500\n",
      "28/28 [==============================] - 0s 196us/step - loss: 0.0020 - val_loss: 0.0278\n",
      "Epoch 1303/1500\n",
      "28/28 [==============================] - 0s 172us/step - loss: 0.0020 - val_loss: 0.0323\n",
      "Epoch 1304/1500\n",
      "28/28 [==============================] - 0s 183us/step - loss: 0.0019 - val_loss: 0.0279\n",
      "Epoch 1305/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.0019 - val_loss: 0.0317\n",
      "Epoch 1306/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.0018 - val_loss: 0.0284\n",
      "Epoch 1307/1500\n",
      "28/28 [==============================] - 0s 207us/step - loss: 0.0018 - val_loss: 0.0307\n",
      "Epoch 1308/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.0017 - val_loss: 0.0293\n",
      "Epoch 1309/1500\n",
      "28/28 [==============================] - 0s 244us/step - loss: 0.0017 - val_loss: 0.0298\n",
      "Epoch 1310/1500\n",
      "28/28 [==============================] - 0s 242us/step - loss: 0.0016 - val_loss: 0.0303\n",
      "Epoch 1311/1500\n",
      "28/28 [==============================] - 0s 216us/step - loss: 0.0017 - val_loss: 0.0291\n",
      "Epoch 1312/1500\n",
      "28/28 [==============================] - 0s 184us/step - loss: 0.0017 - val_loss: 0.0311\n",
      "Epoch 1313/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.0017 - val_loss: 0.0288\n",
      "Epoch 1314/1500\n",
      "28/28 [==============================] - 0s 188us/step - loss: 0.0017 - val_loss: 0.0313\n",
      "Epoch 1315/1500\n",
      "28/28 [==============================] - 0s 243us/step - loss: 0.0017 - val_loss: 0.0289\n",
      "Epoch 1316/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0017 - val_loss: 0.0311\n",
      "Epoch 1317/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.0017 - val_loss: 0.0292\n",
      "Epoch 1318/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.0017 - val_loss: 0.0306\n",
      "Epoch 1319/1500\n",
      "28/28 [==============================] - 0s 180us/step - loss: 0.0017 - val_loss: 0.0298\n",
      "Epoch 1320/1500\n",
      "28/28 [==============================] - 0s 199us/step - loss: 0.0016 - val_loss: 0.0300\n",
      "Epoch 1321/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.0016 - val_loss: 0.0303\n",
      "Epoch 1322/1500\n",
      "28/28 [==============================] - 0s 196us/step - loss: 0.0016 - val_loss: 0.0296\n",
      "Epoch 1323/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.0016 - val_loss: 0.0308\n",
      "Epoch 1324/1500\n",
      "28/28 [==============================] - 0s 199us/step - loss: 0.0017 - val_loss: 0.0294\n",
      "Epoch 1325/1500\n",
      "28/28 [==============================] - 0s 254us/step - loss: 0.0017 - val_loss: 0.0309\n",
      "Epoch 1326/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0017 - val_loss: 0.0294\n",
      "Epoch 1327/1500\n",
      "28/28 [==============================] - 0s 185us/step - loss: 0.0017 - val_loss: 0.0307\n",
      "Epoch 1328/1500\n",
      "28/28 [==============================] - 0s 273us/step - loss: 0.0017 - val_loss: 0.0296\n",
      "Epoch 1329/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.0016 - val_loss: 0.0304\n",
      "Epoch 1330/1500\n",
      "28/28 [==============================] - 0s 240us/step - loss: 0.0016 - val_loss: 0.0298\n",
      "Epoch 1331/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.0016 - val_loss: 0.0301\n",
      "Epoch 1332/1500\n",
      "28/28 [==============================] - 0s 254us/step - loss: 0.0016 - val_loss: 0.0301\n",
      "Epoch 1333/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.0016 - val_loss: 0.0299\n",
      "Epoch 1334/1500\n",
      "28/28 [==============================] - 0s 230us/step - loss: 0.0016 - val_loss: 0.0303\n",
      "Epoch 1335/1500\n",
      "28/28 [==============================] - 0s 230us/step - loss: 0.0016 - val_loss: 0.0297\n",
      "Epoch 1336/1500\n",
      "28/28 [==============================] - 0s 185us/step - loss: 0.0016 - val_loss: 0.0304\n",
      "Epoch 1337/1500\n",
      "28/28 [==============================] - 0s 275us/step - loss: 0.0016 - val_loss: 0.0296\n",
      "Epoch 1338/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.0016 - val_loss: 0.0305\n",
      "Epoch 1339/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0016 - val_loss: 0.0296\n",
      "Epoch 1340/1500\n",
      "28/28 [==============================] - 0s 180us/step - loss: 0.0016 - val_loss: 0.0304\n",
      "Epoch 1341/1500\n",
      "28/28 [==============================] - 0s 191us/step - loss: 0.0016 - val_loss: 0.0297\n",
      "Epoch 1342/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 221us/step - loss: 0.0016 - val_loss: 0.0303\n",
      "Epoch 1343/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.0016 - val_loss: 0.0298\n",
      "Epoch 1344/1500\n",
      "28/28 [==============================] - 0s 264us/step - loss: 0.0016 - val_loss: 0.0302\n",
      "Epoch 1345/1500\n",
      "28/28 [==============================] - 0s 270us/step - loss: 0.0016 - val_loss: 0.0299\n",
      "Epoch 1346/1500\n",
      "28/28 [==============================] - 0s 164us/step - loss: 0.0016 - val_loss: 0.0301\n",
      "Epoch 1347/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0016 - val_loss: 0.0300\n",
      "Epoch 1348/1500\n",
      "28/28 [==============================] - 0s 196us/step - loss: 0.0016 - val_loss: 0.0300\n",
      "Epoch 1349/1500\n",
      "28/28 [==============================] - 0s 183us/step - loss: 0.0016 - val_loss: 0.0301\n",
      "Epoch 1350/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0016 - val_loss: 0.0299\n",
      "Epoch 1351/1500\n",
      "28/28 [==============================] - 0s 239us/step - loss: 0.0016 - val_loss: 0.0302\n",
      "Epoch 1352/1500\n",
      "28/28 [==============================] - 0s 240us/step - loss: 0.0016 - val_loss: 0.0298\n",
      "Epoch 1353/1500\n",
      "28/28 [==============================] - 0s 184us/step - loss: 0.0016 - val_loss: 0.0302\n",
      "Epoch 1354/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0016 - val_loss: 0.0298\n",
      "Epoch 1355/1500\n",
      "28/28 [==============================] - 0s 230us/step - loss: 0.0016 - val_loss: 0.0303\n",
      "Epoch 1356/1500\n",
      "28/28 [==============================] - 0s 181us/step - loss: 0.0016 - val_loss: 0.0298\n",
      "Epoch 1357/1500\n",
      "28/28 [==============================] - 0s 209us/step - loss: 0.0016 - val_loss: 0.0303\n",
      "Epoch 1358/1500\n",
      "28/28 [==============================] - 0s 310us/step - loss: 0.0016 - val_loss: 0.0298\n",
      "Epoch 1359/1500\n",
      "28/28 [==============================] - 0s 232us/step - loss: 0.0016 - val_loss: 0.0303\n",
      "Epoch 1360/1500\n",
      "28/28 [==============================] - 0s 189us/step - loss: 0.0016 - val_loss: 0.0298\n",
      "Epoch 1361/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.0016 - val_loss: 0.0303\n",
      "Epoch 1362/1500\n",
      "28/28 [==============================] - 0s 205us/step - loss: 0.0016 - val_loss: 0.0298\n",
      "Epoch 1363/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.0016 - val_loss: 0.0303\n",
      "Epoch 1364/1500\n",
      "28/28 [==============================] - 0s 262us/step - loss: 0.0016 - val_loss: 0.0298\n",
      "Epoch 1365/1500\n",
      "28/28 [==============================] - 0s 277us/step - loss: 0.0016 - val_loss: 0.0303\n",
      "Epoch 1366/1500\n",
      "28/28 [==============================] - 0s 237us/step - loss: 0.0016 - val_loss: 0.0298\n",
      "Epoch 1367/1500\n",
      "28/28 [==============================] - 0s 278us/step - loss: 0.0016 - val_loss: 0.0303\n",
      "Epoch 1368/1500\n",
      "28/28 [==============================] - 0s 282us/step - loss: 0.0016 - val_loss: 0.0298\n",
      "Epoch 1369/1500\n",
      "28/28 [==============================] - 0s 282us/step - loss: 0.0016 - val_loss: 0.0304\n",
      "Epoch 1370/1500\n",
      "28/28 [==============================] - 0s 306us/step - loss: 0.0016 - val_loss: 0.0297\n",
      "Epoch 1371/1500\n",
      "28/28 [==============================] - 0s 200us/step - loss: 0.0016 - val_loss: 0.0304\n",
      "Epoch 1372/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.0016 - val_loss: 0.0297\n",
      "Epoch 1373/1500\n",
      "28/28 [==============================] - 0s 209us/step - loss: 0.0016 - val_loss: 0.0305\n",
      "Epoch 1374/1500\n",
      "28/28 [==============================] - 0s 232us/step - loss: 0.0016 - val_loss: 0.0296\n",
      "Epoch 1375/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.0016 - val_loss: 0.0306\n",
      "Epoch 1376/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.0016 - val_loss: 0.0295\n",
      "Epoch 1377/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.0016 - val_loss: 0.0308\n",
      "Epoch 1378/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0016 - val_loss: 0.0294\n",
      "Epoch 1379/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.0016 - val_loss: 0.0310\n",
      "Epoch 1380/1500\n",
      "28/28 [==============================] - 0s 207us/step - loss: 0.0016 - val_loss: 0.0291\n",
      "Epoch 1381/1500\n",
      "28/28 [==============================] - 0s 230us/step - loss: 0.0016 - val_loss: 0.0313\n",
      "Epoch 1382/1500\n",
      "28/28 [==============================] - 0s 205us/step - loss: 0.0017 - val_loss: 0.0288\n",
      "Epoch 1383/1500\n",
      "28/28 [==============================] - 0s 202us/step - loss: 0.0017 - val_loss: 0.0318\n",
      "Epoch 1384/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.0017 - val_loss: 0.0285\n",
      "Epoch 1385/1500\n",
      "28/28 [==============================] - 0s 160us/step - loss: 0.0017 - val_loss: 0.0325\n",
      "Epoch 1386/1500\n",
      "28/28 [==============================] - 0s 185us/step - loss: 0.0018 - val_loss: 0.0280\n",
      "Epoch 1387/1500\n",
      "28/28 [==============================] - 0s 289us/step - loss: 0.0019 - val_loss: 0.0335\n",
      "Epoch 1388/1500\n",
      "28/28 [==============================] - 0s 244us/step - loss: 0.0020 - val_loss: 0.0275\n",
      "Epoch 1389/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0021 - val_loss: 0.0347\n",
      "Epoch 1390/1500\n",
      "28/28 [==============================] - 0s 157us/step - loss: 0.0022 - val_loss: 0.0270\n",
      "Epoch 1391/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.0024 - val_loss: 0.0356\n",
      "Epoch 1392/1500\n",
      "28/28 [==============================] - 0s 202us/step - loss: 0.0024 - val_loss: 0.0268\n",
      "Epoch 1393/1500\n",
      "28/28 [==============================] - 0s 281us/step - loss: 0.0025 - val_loss: 0.0353\n",
      "Epoch 1394/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.0024 - val_loss: 0.0270\n",
      "Epoch 1395/1500\n",
      "28/28 [==============================] - 0s 237us/step - loss: 0.0022 - val_loss: 0.0332\n",
      "Epoch 1396/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.0020 - val_loss: 0.0283\n",
      "Epoch 1397/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.0017 - val_loss: 0.0304\n",
      "Epoch 1398/1500\n",
      "28/28 [==============================] - 0s 240us/step - loss: 0.0016 - val_loss: 0.0306\n",
      "Epoch 1399/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0016 - val_loss: 0.0286\n",
      "Epoch 1400/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0017 - val_loss: 0.0327\n",
      "Epoch 1401/1500\n",
      "28/28 [==============================] - 0s 245us/step - loss: 0.0018 - val_loss: 0.0280\n",
      "Epoch 1402/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0019 - val_loss: 0.0328\n",
      "Epoch 1403/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.0018 - val_loss: 0.0287\n",
      "Epoch 1404/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0017 - val_loss: 0.0312\n",
      "Epoch 1405/1500\n",
      "28/28 [==============================] - 0s 256us/step - loss: 0.0016 - val_loss: 0.0303\n",
      "Epoch 1406/1500\n",
      "28/28 [==============================] - 0s 246us/step - loss: 0.0016 - val_loss: 0.0295\n",
      "Epoch 1407/1500\n",
      "28/28 [==============================] - 0s 235us/step - loss: 0.0016 - val_loss: 0.0320\n",
      "Epoch 1408/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.0017 - val_loss: 0.0289\n",
      "Epoch 1409/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0017 - val_loss: 0.0322\n",
      "Epoch 1410/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.0017 - val_loss: 0.0293\n",
      "Epoch 1411/1500\n",
      "28/28 [==============================] - 0s 249us/step - loss: 0.0016 - val_loss: 0.0310\n",
      "Epoch 1412/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.0016 - val_loss: 0.0305\n",
      "Epoch 1413/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0016 - val_loss: 0.0297\n",
      "Epoch 1414/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.0016 - val_loss: 0.0316\n",
      "Epoch 1415/1500\n",
      "28/28 [==============================] - 0s 235us/step - loss: 0.0016 - val_loss: 0.0292\n",
      "Epoch 1416/1500\n",
      "28/28 [==============================] - 0s 186us/step - loss: 0.0016 - val_loss: 0.0315\n",
      "Epoch 1417/1500\n",
      "28/28 [==============================] - 0s 209us/step - loss: 0.0016 - val_loss: 0.0296\n",
      "Epoch 1418/1500\n",
      "28/28 [==============================] - 0s 216us/step - loss: 0.0016 - val_loss: 0.0306\n",
      "Epoch 1419/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.0016 - val_loss: 0.0305\n",
      "Epoch 1420/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.0016 - val_loss: 0.0298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1421/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.0016 - val_loss: 0.0312\n",
      "Epoch 1422/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.0016 - val_loss: 0.0295\n",
      "Epoch 1423/1500\n",
      "28/28 [==============================] - 0s 154us/step - loss: 0.0016 - val_loss: 0.0311\n",
      "Epoch 1424/1500\n",
      "28/28 [==============================] - 0s 231us/step - loss: 0.0016 - val_loss: 0.0299\n",
      "Epoch 1425/1500\n",
      "28/28 [==============================] - 0s 209us/step - loss: 0.0016 - val_loss: 0.0305\n",
      "Epoch 1426/1500\n",
      "28/28 [==============================] - 0s 261us/step - loss: 0.0016 - val_loss: 0.0305\n",
      "Epoch 1427/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.0016 - val_loss: 0.0299\n",
      "Epoch 1428/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0016 - val_loss: 0.0310\n",
      "Epoch 1429/1500\n",
      "28/28 [==============================] - 0s 184us/step - loss: 0.0016 - val_loss: 0.0298\n",
      "Epoch 1430/1500\n",
      "28/28 [==============================] - 0s 200us/step - loss: 0.0016 - val_loss: 0.0309\n",
      "Epoch 1431/1500\n",
      "28/28 [==============================] - 0s 186us/step - loss: 0.0016 - val_loss: 0.0301\n",
      "Epoch 1432/1500\n",
      "28/28 [==============================] - 0s 235us/step - loss: 0.0016 - val_loss: 0.0305\n",
      "Epoch 1433/1500\n",
      "28/28 [==============================] - 0s 248us/step - loss: 0.0016 - val_loss: 0.0305\n",
      "Epoch 1434/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0016 - val_loss: 0.0302\n",
      "Epoch 1435/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.0016 - val_loss: 0.0308\n",
      "Epoch 1436/1500\n",
      "28/28 [==============================] - 0s 193us/step - loss: 0.0016 - val_loss: 0.0300\n",
      "Epoch 1437/1500\n",
      "28/28 [==============================] - 0s 293us/step - loss: 0.0016 - val_loss: 0.0308\n",
      "Epoch 1438/1500\n",
      "28/28 [==============================] - 0s 192us/step - loss: 0.0016 - val_loss: 0.0301\n",
      "Epoch 1439/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.0016 - val_loss: 0.0306\n",
      "Epoch 1440/1500\n",
      "28/28 [==============================] - 0s 185us/step - loss: 0.0015 - val_loss: 0.0304\n",
      "Epoch 1441/1500\n",
      "28/28 [==============================] - 0s 194us/step - loss: 0.0015 - val_loss: 0.0303\n",
      "Epoch 1442/1500\n",
      "28/28 [==============================] - 0s 280us/step - loss: 0.0015 - val_loss: 0.0307\n",
      "Epoch 1443/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0015 - val_loss: 0.0302\n",
      "Epoch 1444/1500\n",
      "28/28 [==============================] - 0s 226us/step - loss: 0.0015 - val_loss: 0.0307\n",
      "Epoch 1445/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.0015 - val_loss: 0.0302\n",
      "Epoch 1446/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.0015 - val_loss: 0.0307\n",
      "Epoch 1447/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.0015 - val_loss: 0.0304\n",
      "Epoch 1448/1500\n",
      "28/28 [==============================] - 0s 182us/step - loss: 0.0015 - val_loss: 0.0305\n",
      "Epoch 1449/1500\n",
      "28/28 [==============================] - 0s 239us/step - loss: 0.0015 - val_loss: 0.0306\n",
      "Epoch 1450/1500\n",
      "28/28 [==============================] - 0s 232us/step - loss: 0.0015 - val_loss: 0.0304\n",
      "Epoch 1451/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.0015 - val_loss: 0.0307\n",
      "Epoch 1452/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 0.0015 - val_loss: 0.0304\n",
      "Epoch 1453/1500\n",
      "28/28 [==============================] - 0s 195us/step - loss: 0.0015 - val_loss: 0.0307\n",
      "Epoch 1454/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.0015 - val_loss: 0.0304\n",
      "Epoch 1455/1500\n",
      "28/28 [==============================] - 0s 194us/step - loss: 0.0015 - val_loss: 0.0307\n",
      "Epoch 1456/1500\n",
      "28/28 [==============================] - 0s 173us/step - loss: 0.0015 - val_loss: 0.0305\n",
      "Epoch 1457/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.0015 - val_loss: 0.0306\n",
      "Epoch 1458/1500\n",
      "28/28 [==============================] - 0s 240us/step - loss: 0.0015 - val_loss: 0.0306\n",
      "Epoch 1459/1500\n",
      "28/28 [==============================] - 0s 191us/step - loss: 0.0015 - val_loss: 0.0306\n",
      "Epoch 1460/1500\n",
      "28/28 [==============================] - 0s 191us/step - loss: 0.0015 - val_loss: 0.0307\n",
      "Epoch 1461/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.0015 - val_loss: 0.0306\n",
      "Epoch 1462/1500\n",
      "28/28 [==============================] - 0s 196us/step - loss: 0.0015 - val_loss: 0.0307\n",
      "Epoch 1463/1500\n",
      "28/28 [==============================] - 0s 247us/step - loss: 0.0015 - val_loss: 0.0306\n",
      "Epoch 1464/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.0015 - val_loss: 0.0307\n",
      "Epoch 1465/1500\n",
      "28/28 [==============================] - 0s 185us/step - loss: 0.0015 - val_loss: 0.0306\n",
      "Epoch 1466/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0015 - val_loss: 0.0308\n",
      "Epoch 1467/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.0015 - val_loss: 0.0306\n",
      "Epoch 1468/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.0015 - val_loss: 0.0308\n",
      "Epoch 1469/1500\n",
      "28/28 [==============================] - 0s 264us/step - loss: 0.0015 - val_loss: 0.0307\n",
      "Epoch 1470/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0015 - val_loss: 0.0307\n",
      "Epoch 1471/1500\n",
      "28/28 [==============================] - 0s 187us/step - loss: 0.0015 - val_loss: 0.0307\n",
      "Epoch 1472/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.0015 - val_loss: 0.0307\n",
      "Epoch 1473/1500\n",
      "28/28 [==============================] - 0s 156us/step - loss: 0.0015 - val_loss: 0.0308\n",
      "Epoch 1474/1500\n",
      "28/28 [==============================] - 0s 245us/step - loss: 0.0015 - val_loss: 0.0307\n",
      "Epoch 1475/1500\n",
      "28/28 [==============================] - 0s 260us/step - loss: 0.0015 - val_loss: 0.0308\n",
      "Epoch 1476/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.0015 - val_loss: 0.0307\n",
      "Epoch 1477/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0015 - val_loss: 0.0309\n",
      "Epoch 1478/1500\n",
      "28/28 [==============================] - 0s 192us/step - loss: 0.0015 - val_loss: 0.0307\n",
      "Epoch 1479/1500\n",
      "28/28 [==============================] - 0s 205us/step - loss: 0.0015 - val_loss: 0.0309\n",
      "Epoch 1480/1500\n",
      "28/28 [==============================] - 0s 185us/step - loss: 0.0015 - val_loss: 0.0308\n",
      "Epoch 1481/1500\n",
      "28/28 [==============================] - 0s 236us/step - loss: 0.0015 - val_loss: 0.0309\n",
      "Epoch 1482/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0015 - val_loss: 0.0308\n",
      "Epoch 1483/1500\n",
      "28/28 [==============================] - 0s 239us/step - loss: 0.0015 - val_loss: 0.0309\n",
      "Epoch 1484/1500\n",
      "28/28 [==============================] - 0s 207us/step - loss: 0.0015 - val_loss: 0.0308\n",
      "Epoch 1485/1500\n",
      "28/28 [==============================] - 0s 193us/step - loss: 0.0015 - val_loss: 0.0310\n",
      "Epoch 1486/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.0015 - val_loss: 0.0308\n",
      "Epoch 1487/1500\n",
      "28/28 [==============================] - 0s 275us/step - loss: 0.0015 - val_loss: 0.0310\n",
      "Epoch 1488/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.0015 - val_loss: 0.0308\n",
      "Epoch 1489/1500\n",
      "28/28 [==============================] - 0s 195us/step - loss: 0.0015 - val_loss: 0.0310\n",
      "Epoch 1490/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.0015 - val_loss: 0.0309\n",
      "Epoch 1491/1500\n",
      "28/28 [==============================] - 0s 183us/step - loss: 0.0015 - val_loss: 0.0311\n",
      "Epoch 1492/1500\n",
      "28/28 [==============================] - 0s 193us/step - loss: 0.0015 - val_loss: 0.0309\n",
      "Epoch 1493/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.0015 - val_loss: 0.0311\n",
      "Epoch 1494/1500\n",
      "28/28 [==============================] - 0s 263us/step - loss: 0.0015 - val_loss: 0.0308\n",
      "Epoch 1495/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0015 - val_loss: 0.0312\n",
      "Epoch 1496/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0015 - val_loss: 0.0308\n",
      "Epoch 1497/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.0015 - val_loss: 0.0313\n",
      "Epoch 1498/1500\n",
      "28/28 [==============================] - 0s 193us/step - loss: 0.0015 - val_loss: 0.0308\n",
      "Epoch 1499/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 407us/step - loss: 0.0015 - val_loss: 0.0314\n",
      "Epoch 1500/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.0015 - val_loss: 0.0307\n"
     ]
    }
   ],
   "source": [
    "# fit the model - INTENSIVE\n",
    "model4_history = model4.fit(X_train, Y_train, batch_size=256, epochs=1500, verbose=1, \\\n",
    "                            shuffle = True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use our model to predict in the range we want\n",
    "num_epochs = f'{len(model4_history.epoch)}'\n",
    "\n",
    "X_range = np.linspace(-10, 10, 500)\n",
    "y_pred = model4.predict(X_range)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,6))\n",
    "ax.scatter(X_train, Y_train, label='Training data')\n",
    "ax.plot(X_range, y_pred, lw=4, color='r', label=f'NN ({num_epochs} epochs)')\n",
    "\n",
    "ax.set_xlabel(r'$X$', fontsize=20)\n",
    "ax.set_ylabel(r'$Y$', fontsize=20)\n",
    "ax.set_title(f'NN with {len(model4_history.model.layers)} layers, {H} nodes in each layer', fontsize=LABEL_SIZE)\n",
    "ax.tick_params(labelsize=20)\n",
    "\n",
    "ax.legend(loc=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
    "ax.plot(np.sqrt(model4_history.history['loss']), 'r')\n",
    "ax.plot(np.sqrt(model4_history.history['val_loss']), 'b' ,label='Val')\n",
    "ax.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax.set_ylabel(r'Loss', fontsize=20)\n",
    "ax.legend()\n",
    "ax.tick_params(labelsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization\n",
    "\n",
    "Let's try adding a regularizer in our model: `kernel_regularizer=regularizers.l2(l2)`. Also let's create a function that takes the number of layers and the l2 value as the input and creates the model.\n",
    "\n",
    "Usage: `def create_dense([10, 20], l2=0.01)` will create a model with two hidden layers of 10 and 20 nodes each, l2=0.01 regularization and num_classes output nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "H =  100  # number of hidden nodes\n",
    "input_dim = 1\n",
    "\n",
    "model5 = models.Sequential()\n",
    "\n",
    "# Input layer of the neural network with ReLU activation function and L2 regularization\n",
    "model5.add(layers.Dense(H, input_dim=input_dim,  \n",
    "                activation='tanh', \n",
    "                kernel_regularizer=regularizers.l2(0.01)))\n",
    "           \n",
    "# hidden layers\n",
    "model5.add(layers.Dense(H,   \n",
    "                activation='tanh', \n",
    "                kernel_regularizer=regularizers.l2(0.01)))\n",
    "model5.add(layers.Dense(H,   \n",
    "                activation='tanh', \n",
    "                kernel_regularizer=regularizers.l2(0.01)))\n",
    "model5.add(layers.Dense(H,   \n",
    "                activation='tanh', \n",
    "                kernel_regularizer=regularizers.l2(0.01)))\n",
    "model5.add(layers.Dense(H,   \n",
    "                activation='tanh', \n",
    "                kernel_regularizer=regularizers.l2(0.01)))\n",
    "model5.add(layers.Dense(H,   \n",
    "                activation='tanh', \n",
    "                kernel_regularizer=regularizers.l2(0.01)))\n",
    "model5.add(layers.Dense(H,   \n",
    "                activation='tanh', \n",
    "                kernel_regularizer=regularizers.l2(0.01)))\n",
    "# output layer\n",
    "model5.add(layers.Dense(1, \n",
    "                activation='linear')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the model\n",
    "model5.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28 samples, validate on 7 samples\n",
      "Epoch 1/1500\n",
      "28/28 [==============================] - 1s 44ms/step - loss: 6.5774 - val_loss: 6.1298\n",
      "Epoch 2/1500\n",
      "28/28 [==============================] - 0s 172us/step - loss: 6.2509 - val_loss: 6.2109\n",
      "Epoch 3/1500\n",
      "28/28 [==============================] - 0s 193us/step - loss: 6.3529 - val_loss: 5.9970\n",
      "Epoch 4/1500\n",
      "28/28 [==============================] - 0s 192us/step - loss: 6.0514 - val_loss: 5.9759\n",
      "Epoch 5/1500\n",
      "28/28 [==============================] - 0s 182us/step - loss: 5.9873 - val_loss: 6.0607\n",
      "Epoch 6/1500\n",
      "28/28 [==============================] - 0s 183us/step - loss: 6.0666 - val_loss: 6.0436\n",
      "Epoch 7/1500\n",
      "28/28 [==============================] - 0s 189us/step - loss: 6.0396 - val_loss: 5.9471\n",
      "Epoch 8/1500\n",
      "28/28 [==============================] - 0s 179us/step - loss: 5.9312 - val_loss: 5.8721\n",
      "Epoch 9/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 5.8613 - val_loss: 5.8573\n",
      "Epoch 10/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 5.8686 - val_loss: 5.8528\n",
      "Epoch 11/1500\n",
      "28/28 [==============================] - 0s 169us/step - loss: 5.8791 - val_loss: 5.8173\n",
      "Epoch 12/1500\n",
      "28/28 [==============================] - 0s 161us/step - loss: 5.8362 - val_loss: 5.7690\n",
      "Epoch 13/1500\n",
      "28/28 [==============================] - 0s 195us/step - loss: 5.7672 - val_loss: 5.7389\n",
      "Epoch 14/1500\n",
      "28/28 [==============================] - 0s 199us/step - loss: 5.7175 - val_loss: 5.7306\n",
      "Epoch 15/1500\n",
      "28/28 [==============================] - 0s 160us/step - loss: 5.6977 - val_loss: 5.7239\n",
      "Epoch 16/1500\n",
      "28/28 [==============================] - 0s 181us/step - loss: 5.6865 - val_loss: 5.6989\n",
      "Epoch 17/1500\n",
      "28/28 [==============================] - 0s 163us/step - loss: 5.6610 - val_loss: 5.6531\n",
      "Epoch 18/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 5.6176 - val_loss: 5.5987\n",
      "Epoch 19/1500\n",
      "28/28 [==============================] - 0s 216us/step - loss: 5.5692 - val_loss: 5.5499\n",
      "Epoch 20/1500\n",
      "28/28 [==============================] - 0s 168us/step - loss: 5.5301 - val_loss: 5.5111\n",
      "Epoch 21/1500\n",
      "28/28 [==============================] - 0s 174us/step - loss: 5.5029 - val_loss: 5.4792\n",
      "Epoch 22/1500\n",
      "28/28 [==============================] - 0s 193us/step - loss: 5.4803 - val_loss: 5.4474\n",
      "Epoch 23/1500\n",
      "28/28 [==============================] - 0s 163us/step - loss: 5.4517 - val_loss: 5.4140\n",
      "Epoch 24/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 5.4147 - val_loss: 5.3813\n",
      "Epoch 25/1500\n",
      "28/28 [==============================] - 0s 189us/step - loss: 5.3735 - val_loss: 5.3539\n",
      "Epoch 26/1500\n",
      "28/28 [==============================] - 0s 260us/step - loss: 5.3363 - val_loss: 5.3312\n",
      "Epoch 27/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 5.3049 - val_loss: 5.3092\n",
      "Epoch 28/1500\n",
      "28/28 [==============================] - 0s 178us/step - loss: 5.2767 - val_loss: 5.2827\n",
      "Epoch 29/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 5.2466 - val_loss: 5.2494\n",
      "Epoch 30/1500\n",
      "28/28 [==============================] - 0s 185us/step - loss: 5.2121 - val_loss: 5.2108\n",
      "Epoch 31/1500\n",
      "28/28 [==============================] - 0s 174us/step - loss: 5.1747 - val_loss: 5.1711\n",
      "Epoch 32/1500\n",
      "28/28 [==============================] - 0s 182us/step - loss: 5.1382 - val_loss: 5.1336\n",
      "Epoch 33/1500\n",
      "28/28 [==============================] - 0s 257us/step - loss: 5.1048 - val_loss: 5.0993\n",
      "Epoch 34/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 5.0740 - val_loss: 5.0672\n",
      "Epoch 35/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 5.0430 - val_loss: 5.0361\n",
      "Epoch 36/1500\n",
      "28/28 [==============================] - 0s 194us/step - loss: 5.0097 - val_loss: 5.0061\n",
      "Epoch 37/1500\n",
      "28/28 [==============================] - 0s 160us/step - loss: 4.9745 - val_loss: 4.9779\n",
      "Epoch 38/1500\n",
      "28/28 [==============================] - 0s 241us/step - loss: 4.9395 - val_loss: 4.9517\n",
      "Epoch 39/1500\n",
      "28/28 [==============================] - 0s 183us/step - loss: 4.9066 - val_loss: 4.9257\n",
      "Epoch 40/1500\n",
      "28/28 [==============================] - 0s 284us/step - loss: 4.8754 - val_loss: 4.8975\n",
      "Epoch 41/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 4.8441 - val_loss: 4.8653\n",
      "Epoch 42/1500\n",
      "28/28 [==============================] - 0s 248us/step - loss: 4.8112 - val_loss: 4.8301\n",
      "Epoch 43/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 4.7777 - val_loss: 4.7932\n",
      "Epoch 44/1500\n",
      "28/28 [==============================] - 0s 175us/step - loss: 4.7441 - val_loss: 4.7573\n",
      "Epoch 45/1500\n",
      "28/28 [==============================] - 0s 168us/step - loss: 4.7120 - val_loss: 4.7228\n",
      "Epoch 46/1500\n",
      "28/28 [==============================] - 0s 185us/step - loss: 4.6806 - val_loss: 4.6903\n",
      "Epoch 47/1500\n",
      "28/28 [==============================] - 0s 245us/step - loss: 4.6490 - val_loss: 4.6596\n",
      "Epoch 48/1500\n",
      "28/28 [==============================] - 0s 276us/step - loss: 4.6167 - val_loss: 4.6307\n",
      "Epoch 49/1500\n",
      "28/28 [==============================] - 0s 165us/step - loss: 4.5839 - val_loss: 4.6034\n",
      "Epoch 50/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 4.5518 - val_loss: 4.5767\n",
      "Epoch 51/1500\n",
      "28/28 [==============================] - 0s 175us/step - loss: 4.5206 - val_loss: 4.5491\n",
      "Epoch 52/1500\n",
      "28/28 [==============================] - 0s 207us/step - loss: 4.4899 - val_loss: 4.5190\n",
      "Epoch 53/1500\n",
      "28/28 [==============================] - 0s 184us/step - loss: 4.4586 - val_loss: 4.4868\n",
      "Epoch 54/1500\n",
      "28/28 [==============================] - 0s 192us/step - loss: 4.4270 - val_loss: 4.4536\n",
      "Epoch 55/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 4.3956 - val_loss: 4.4209\n",
      "Epoch 56/1500\n",
      "28/28 [==============================] - 0s 267us/step - loss: 4.3649 - val_loss: 4.3895\n",
      "Epoch 57/1500\n",
      "28/28 [==============================] - 0s 250us/step - loss: 4.3346 - val_loss: 4.3596\n",
      "Epoch 58/1500\n",
      "28/28 [==============================] - 0s 335us/step - loss: 4.3041 - val_loss: 4.3313\n",
      "Epoch 59/1500\n",
      "28/28 [==============================] - 0s 255us/step - loss: 4.2735 - val_loss: 4.3043\n",
      "Epoch 60/1500\n",
      "28/28 [==============================] - 0s 307us/step - loss: 4.2433 - val_loss: 4.2775\n",
      "Epoch 61/1500\n",
      "28/28 [==============================] - 0s 336us/step - loss: 4.2133 - val_loss: 4.2502\n",
      "Epoch 62/1500\n",
      "28/28 [==============================] - 0s 196us/step - loss: 4.1839 - val_loss: 4.2212\n",
      "Epoch 63/1500\n",
      "28/28 [==============================] - 0s 195us/step - loss: 4.1545 - val_loss: 4.1905\n",
      "Epoch 64/1500\n",
      "28/28 [==============================] - 0s 167us/step - loss: 4.1248 - val_loss: 4.1592\n",
      "Epoch 65/1500\n",
      "28/28 [==============================] - 0s 191us/step - loss: 4.0954 - val_loss: 4.1279\n",
      "Epoch 66/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 4.0663 - val_loss: 4.0977\n",
      "Epoch 67/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 4.0374 - val_loss: 4.0689\n",
      "Epoch 68/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 4.0085 - val_loss: 4.0414\n",
      "Epoch 69/1500\n",
      "28/28 [==============================] - 0s 290us/step - loss: 3.9796 - val_loss: 4.0148\n",
      "Epoch 70/1500\n",
      "28/28 [==============================] - 0s 195us/step - loss: 3.9510 - val_loss: 3.9882\n",
      "Epoch 71/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 3.9226 - val_loss: 3.9611\n",
      "Epoch 72/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 3.8945 - val_loss: 3.9329\n",
      "Epoch 73/1500\n",
      "28/28 [==============================] - 0s 188us/step - loss: 3.8664 - val_loss: 3.9040\n",
      "Epoch 74/1500\n",
      "28/28 [==============================] - 0s 199us/step - loss: 3.8384 - val_loss: 3.8750\n",
      "Epoch 75/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 3.8106 - val_loss: 3.8468\n",
      "Epoch 76/1500\n",
      "28/28 [==============================] - 0s 199us/step - loss: 3.7833 - val_loss: 3.8195\n",
      "Epoch 77/1500\n",
      "28/28 [==============================] - 0s 231us/step - loss: 3.7561 - val_loss: 3.7931\n",
      "Epoch 78/1500\n",
      "28/28 [==============================] - 0s 244us/step - loss: 3.7290 - val_loss: 3.7673\n",
      "Epoch 79/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 3.7018 - val_loss: 3.7415\n",
      "Epoch 80/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 3.6749 - val_loss: 3.7154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/1500\n",
      "28/28 [==============================] - 0s 188us/step - loss: 3.6482 - val_loss: 3.6887\n",
      "Epoch 82/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 3.6216 - val_loss: 3.6614\n",
      "Epoch 83/1500\n",
      "28/28 [==============================] - 0s 192us/step - loss: 3.5952 - val_loss: 3.6341\n",
      "Epoch 84/1500\n",
      "28/28 [==============================] - 0s 171us/step - loss: 3.5690 - val_loss: 3.6072\n",
      "Epoch 85/1500\n",
      "28/28 [==============================] - 0s 160us/step - loss: 3.5429 - val_loss: 3.5809\n",
      "Epoch 86/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 3.5170 - val_loss: 3.5555\n",
      "Epoch 87/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 3.4913 - val_loss: 3.5305\n",
      "Epoch 88/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 3.4657 - val_loss: 3.5058\n",
      "Epoch 89/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 3.4403 - val_loss: 3.4810\n",
      "Epoch 90/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 3.4151 - val_loss: 3.4558\n",
      "Epoch 91/1500\n",
      "28/28 [==============================] - 0s 175us/step - loss: 3.3900 - val_loss: 3.4304\n",
      "Epoch 92/1500\n",
      "28/28 [==============================] - 0s 235us/step - loss: 3.3651 - val_loss: 3.4051\n",
      "Epoch 93/1500\n",
      "28/28 [==============================] - 0s 189us/step - loss: 3.3404 - val_loss: 3.3801\n",
      "Epoch 94/1500\n",
      "28/28 [==============================] - 0s 282us/step - loss: 3.3159 - val_loss: 3.3557\n",
      "Epoch 95/1500\n",
      "28/28 [==============================] - 0s 238us/step - loss: 3.2915 - val_loss: 3.3318\n",
      "Epoch 96/1500\n",
      "28/28 [==============================] - 0s 294us/step - loss: 3.2673 - val_loss: 3.3082\n",
      "Epoch 97/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 3.2432 - val_loss: 3.2848\n",
      "Epoch 98/1500\n",
      "28/28 [==============================] - 0s 271us/step - loss: 3.2194 - val_loss: 3.2612\n",
      "Epoch 99/1500\n",
      "28/28 [==============================] - 0s 265us/step - loss: 3.1957 - val_loss: 3.2376\n",
      "Epoch 100/1500\n",
      "28/28 [==============================] - 0s 226us/step - loss: 3.1722 - val_loss: 3.2138\n",
      "Epoch 101/1500\n",
      "28/28 [==============================] - 0s 207us/step - loss: 3.1488 - val_loss: 3.1903\n",
      "Epoch 102/1500\n",
      "28/28 [==============================] - 0s 278us/step - loss: 3.1257 - val_loss: 3.1670\n",
      "Epoch 103/1500\n",
      "28/28 [==============================] - 0s 300us/step - loss: 3.1028 - val_loss: 3.1441\n",
      "Epoch 104/1500\n",
      "28/28 [==============================] - 0s 254us/step - loss: 3.0799 - val_loss: 3.1216\n",
      "Epoch 105/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 3.0572 - val_loss: 3.0993\n",
      "Epoch 106/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 3.0346 - val_loss: 3.0772\n",
      "Epoch 107/1500\n",
      "28/28 [==============================] - 0s 202us/step - loss: 3.0122 - val_loss: 3.0550\n",
      "Epoch 108/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 2.9900 - val_loss: 3.0328\n",
      "Epoch 109/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 2.9679 - val_loss: 3.0107\n",
      "Epoch 110/1500\n",
      "28/28 [==============================] - 0s 249us/step - loss: 2.9460 - val_loss: 2.9887\n",
      "Epoch 111/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 2.9243 - val_loss: 2.9671\n",
      "Epoch 112/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 2.9027 - val_loss: 2.9458\n",
      "Epoch 113/1500\n",
      "28/28 [==============================] - 0s 226us/step - loss: 2.8812 - val_loss: 2.9247\n",
      "Epoch 114/1500\n",
      "28/28 [==============================] - 0s 226us/step - loss: 2.8600 - val_loss: 2.9039\n",
      "Epoch 115/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 2.8389 - val_loss: 2.8831\n",
      "Epoch 116/1500\n",
      "28/28 [==============================] - 0s 274us/step - loss: 2.8180 - val_loss: 2.8624\n",
      "Epoch 117/1500\n",
      "28/28 [==============================] - 0s 331us/step - loss: 2.7973 - val_loss: 2.8416\n",
      "Epoch 118/1500\n",
      "28/28 [==============================] - 0s 255us/step - loss: 2.7766 - val_loss: 2.8210\n",
      "Epoch 119/1500\n",
      "28/28 [==============================] - 0s 169us/step - loss: 2.7561 - val_loss: 2.8005\n",
      "Epoch 120/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 2.7358 - val_loss: 2.7804\n",
      "Epoch 121/1500\n",
      "28/28 [==============================] - 0s 202us/step - loss: 2.7156 - val_loss: 2.7604\n",
      "Epoch 122/1500\n",
      "28/28 [==============================] - 0s 202us/step - loss: 2.6955 - val_loss: 2.7407\n",
      "Epoch 123/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 2.6756 - val_loss: 2.7211\n",
      "Epoch 124/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 2.6559 - val_loss: 2.7017\n",
      "Epoch 125/1500\n",
      "28/28 [==============================] - 0s 194us/step - loss: 2.6364 - val_loss: 2.6823\n",
      "Epoch 126/1500\n",
      "28/28 [==============================] - 0s 235us/step - loss: 2.6170 - val_loss: 2.6629\n",
      "Epoch 127/1500\n",
      "28/28 [==============================] - 0s 233us/step - loss: 2.5977 - val_loss: 2.6437\n",
      "Epoch 128/1500\n",
      "28/28 [==============================] - 0s 188us/step - loss: 2.5786 - val_loss: 2.6248\n",
      "Epoch 129/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 2.5596 - val_loss: 2.6060\n",
      "Epoch 130/1500\n",
      "28/28 [==============================] - 0s 245us/step - loss: 2.5407 - val_loss: 2.5874\n",
      "Epoch 131/1500\n",
      "28/28 [==============================] - 0s 181us/step - loss: 2.5220 - val_loss: 2.5690\n",
      "Epoch 132/1500\n",
      "28/28 [==============================] - 0s 178us/step - loss: 2.5035 - val_loss: 2.5508\n",
      "Epoch 133/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 2.4851 - val_loss: 2.5326\n",
      "Epoch 134/1500\n",
      "28/28 [==============================] - 0s 205us/step - loss: 2.4669 - val_loss: 2.5145\n",
      "Epoch 135/1500\n",
      "28/28 [==============================] - 0s 256us/step - loss: 2.4488 - val_loss: 2.4964\n",
      "Epoch 136/1500\n",
      "28/28 [==============================] - 0s 242us/step - loss: 2.4308 - val_loss: 2.4786\n",
      "Epoch 137/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 2.4130 - val_loss: 2.4609\n",
      "Epoch 138/1500\n",
      "28/28 [==============================] - 0s 168us/step - loss: 2.3953 - val_loss: 2.4435\n",
      "Epoch 139/1500\n",
      "28/28 [==============================] - 0s 269us/step - loss: 2.3778 - val_loss: 2.4261\n",
      "Epoch 140/1500\n",
      "28/28 [==============================] - 0s 171us/step - loss: 2.3603 - val_loss: 2.4088\n",
      "Epoch 141/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 2.3430 - val_loss: 2.3917\n",
      "Epoch 142/1500\n",
      "28/28 [==============================] - 0s 199us/step - loss: 2.3258 - val_loss: 2.3747\n",
      "Epoch 143/1500\n",
      "28/28 [==============================] - 0s 216us/step - loss: 2.3088 - val_loss: 2.3578\n",
      "Epoch 144/1500\n",
      "28/28 [==============================] - 0s 257us/step - loss: 2.2919 - val_loss: 2.3411\n",
      "Epoch 145/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 2.2752 - val_loss: 2.3245\n",
      "Epoch 146/1500\n",
      "28/28 [==============================] - 0s 239us/step - loss: 2.2586 - val_loss: 2.3081\n",
      "Epoch 147/1500\n",
      "28/28 [==============================] - 0s 250us/step - loss: 2.2421 - val_loss: 2.2918\n",
      "Epoch 148/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 2.2257 - val_loss: 2.2756\n",
      "Epoch 149/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 2.2095 - val_loss: 2.2595\n",
      "Epoch 150/1500\n",
      "28/28 [==============================] - 0s 185us/step - loss: 2.1933 - val_loss: 2.2434\n",
      "Epoch 151/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 2.1773 - val_loss: 2.2275\n",
      "Epoch 152/1500\n",
      "28/28 [==============================] - 0s 236us/step - loss: 2.1614 - val_loss: 2.2118\n",
      "Epoch 153/1500\n",
      "28/28 [==============================] - 0s 247us/step - loss: 2.1457 - val_loss: 2.1961\n",
      "Epoch 154/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 2.1300 - val_loss: 2.1807\n",
      "Epoch 155/1500\n",
      "28/28 [==============================] - 0s 202us/step - loss: 2.1145 - val_loss: 2.1653\n",
      "Epoch 156/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 2.0991 - val_loss: 2.1501\n",
      "Epoch 157/1500\n",
      "28/28 [==============================] - 0s 267us/step - loss: 2.0839 - val_loss: 2.1350\n",
      "Epoch 158/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 2.0688 - val_loss: 2.1201\n",
      "Epoch 159/1500\n",
      "28/28 [==============================] - 0s 265us/step - loss: 2.0538 - val_loss: 2.1052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 2.0389 - val_loss: 2.0904\n",
      "Epoch 161/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 2.0241 - val_loss: 2.0757\n",
      "Epoch 162/1500\n",
      "28/28 [==============================] - 0s 194us/step - loss: 2.0095 - val_loss: 2.0612\n",
      "Epoch 163/1500\n",
      "28/28 [==============================] - 0s 205us/step - loss: 1.9949 - val_loss: 2.0468\n",
      "Epoch 164/1500\n",
      "28/28 [==============================] - 0s 185us/step - loss: 1.9804 - val_loss: 2.0325\n",
      "Epoch 165/1500\n",
      "28/28 [==============================] - 0s 188us/step - loss: 1.9661 - val_loss: 2.0183\n",
      "Epoch 166/1500\n",
      "28/28 [==============================] - 0s 257us/step - loss: 1.9519 - val_loss: 2.0042\n",
      "Epoch 167/1500\n",
      "28/28 [==============================] - 0s 168us/step - loss: 1.9378 - val_loss: 1.9902\n",
      "Epoch 168/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 1.9238 - val_loss: 1.9763\n",
      "Epoch 169/1500\n",
      "28/28 [==============================] - 0s 181us/step - loss: 1.9099 - val_loss: 1.9626\n",
      "Epoch 170/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 1.8962 - val_loss: 1.9489\n",
      "Epoch 171/1500\n",
      "28/28 [==============================] - 0s 195us/step - loss: 1.8825 - val_loss: 1.9354\n",
      "Epoch 172/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 1.8690 - val_loss: 1.9219\n",
      "Epoch 173/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 1.8555 - val_loss: 1.9087\n",
      "Epoch 174/1500\n",
      "28/28 [==============================] - 0s 241us/step - loss: 1.8422 - val_loss: 1.8954\n",
      "Epoch 175/1500\n",
      "28/28 [==============================] - 0s 190us/step - loss: 1.8290 - val_loss: 1.8823\n",
      "Epoch 176/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 1.8159 - val_loss: 1.8693\n",
      "Epoch 177/1500\n",
      "28/28 [==============================] - 0s 245us/step - loss: 1.8029 - val_loss: 1.8564\n",
      "Epoch 178/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 1.7900 - val_loss: 1.8436\n",
      "Epoch 179/1500\n",
      "28/28 [==============================] - 0s 202us/step - loss: 1.7771 - val_loss: 1.8309\n",
      "Epoch 180/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 1.7644 - val_loss: 1.8183\n",
      "Epoch 181/1500\n",
      "28/28 [==============================] - 0s 262us/step - loss: 1.7518 - val_loss: 1.8058\n",
      "Epoch 182/1500\n",
      "28/28 [==============================] - 0s 202us/step - loss: 1.7393 - val_loss: 1.7934\n",
      "Epoch 183/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 1.7269 - val_loss: 1.7811\n",
      "Epoch 184/1500\n",
      "28/28 [==============================] - 0s 235us/step - loss: 1.7145 - val_loss: 1.7689\n",
      "Epoch 185/1500\n",
      "28/28 [==============================] - 0s 250us/step - loss: 1.7023 - val_loss: 1.7567\n",
      "Epoch 186/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 1.6902 - val_loss: 1.7447\n",
      "Epoch 187/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 1.6782 - val_loss: 1.7328\n",
      "Epoch 188/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 1.6662 - val_loss: 1.7210\n",
      "Epoch 189/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 1.6544 - val_loss: 1.7093\n",
      "Epoch 190/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 1.6427 - val_loss: 1.6976\n",
      "Epoch 191/1500\n",
      "28/28 [==============================] - 0s 282us/step - loss: 1.6310 - val_loss: 1.6861\n",
      "Epoch 192/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 1.6195 - val_loss: 1.6746\n",
      "Epoch 193/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 1.6080 - val_loss: 1.6632\n",
      "Epoch 194/1500\n",
      "28/28 [==============================] - 0s 209us/step - loss: 1.5966 - val_loss: 1.6520\n",
      "Epoch 195/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 1.5853 - val_loss: 1.6408\n",
      "Epoch 196/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 1.5742 - val_loss: 1.6297\n",
      "Epoch 197/1500\n",
      "28/28 [==============================] - 0s 267us/step - loss: 1.5630 - val_loss: 1.6187\n",
      "Epoch 198/1500\n",
      "28/28 [==============================] - 0s 199us/step - loss: 1.5520 - val_loss: 1.6077\n",
      "Epoch 199/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 1.5411 - val_loss: 1.5969\n",
      "Epoch 200/1500\n",
      "28/28 [==============================] - 0s 205us/step - loss: 1.5303 - val_loss: 1.5862\n",
      "Epoch 201/1500\n",
      "28/28 [==============================] - 0s 207us/step - loss: 1.5195 - val_loss: 1.5755\n",
      "Epoch 202/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 1.5088 - val_loss: 1.5649\n",
      "Epoch 203/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 1.4982 - val_loss: 1.5544\n",
      "Epoch 204/1500\n",
      "28/28 [==============================] - 0s 279us/step - loss: 1.4877 - val_loss: 1.5440\n",
      "Epoch 205/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 1.4773 - val_loss: 1.5337\n",
      "Epoch 206/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 1.4670 - val_loss: 1.5234\n",
      "Epoch 207/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 1.4567 - val_loss: 1.5133\n",
      "Epoch 208/1500\n",
      "28/28 [==============================] - 0s 238us/step - loss: 1.4466 - val_loss: 1.5032\n",
      "Epoch 209/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 1.4365 - val_loss: 1.4932\n",
      "Epoch 210/1500\n",
      "28/28 [==============================] - 0s 261us/step - loss: 1.4265 - val_loss: 1.4832\n",
      "Epoch 211/1500\n",
      "28/28 [==============================] - 0s 205us/step - loss: 1.4165 - val_loss: 1.4734\n",
      "Epoch 212/1500\n",
      "28/28 [==============================] - 0s 189us/step - loss: 1.4067 - val_loss: 1.4636\n",
      "Epoch 213/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 1.3969 - val_loss: 1.4539\n",
      "Epoch 214/1500\n",
      "28/28 [==============================] - 0s 244us/step - loss: 1.3872 - val_loss: 1.4443\n",
      "Epoch 215/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 1.3776 - val_loss: 1.4347\n",
      "Epoch 216/1500\n",
      "28/28 [==============================] - 0s 158us/step - loss: 1.3680 - val_loss: 1.4253\n",
      "Epoch 217/1500\n",
      "28/28 [==============================] - 0s 193us/step - loss: 1.3585 - val_loss: 1.4159\n",
      "Epoch 218/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 1.3491 - val_loss: 1.4066\n",
      "Epoch 219/1500\n",
      "28/28 [==============================] - 0s 260us/step - loss: 1.3398 - val_loss: 1.3973\n",
      "Epoch 220/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 1.3306 - val_loss: 1.3881\n",
      "Epoch 221/1500\n",
      "28/28 [==============================] - 0s 277us/step - loss: 1.3214 - val_loss: 1.3790\n",
      "Epoch 222/1500\n",
      "28/28 [==============================] - 0s 268us/step - loss: 1.3123 - val_loss: 1.3700\n",
      "Epoch 223/1500\n",
      "28/28 [==============================] - 0s 299us/step - loss: 1.3033 - val_loss: 1.3611\n",
      "Epoch 224/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 1.2943 - val_loss: 1.3522\n",
      "Epoch 225/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 1.2854 - val_loss: 1.3434\n",
      "Epoch 226/1500\n",
      "28/28 [==============================] - 0s 173us/step - loss: 1.2766 - val_loss: 1.3346\n",
      "Epoch 227/1500\n",
      "28/28 [==============================] - 0s 158us/step - loss: 1.2679 - val_loss: 1.3260\n",
      "Epoch 228/1500\n",
      "28/28 [==============================] - 0s 207us/step - loss: 1.2592 - val_loss: 1.3173\n",
      "Epoch 229/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 1.2506 - val_loss: 1.3088\n",
      "Epoch 230/1500\n",
      "28/28 [==============================] - 0s 172us/step - loss: 1.2420 - val_loss: 1.3003\n",
      "Epoch 231/1500\n",
      "28/28 [==============================] - 0s 282us/step - loss: 1.2335 - val_loss: 1.2919\n",
      "Epoch 232/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 1.2251 - val_loss: 1.2836\n",
      "Epoch 233/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 1.2168 - val_loss: 1.2753\n",
      "Epoch 234/1500\n",
      "28/28 [==============================] - 0s 248us/step - loss: 1.2085 - val_loss: 1.2671\n",
      "Epoch 235/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 1.2003 - val_loss: 1.2589\n",
      "Epoch 236/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 1.1921 - val_loss: 1.2508\n",
      "Epoch 237/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 1.1840 - val_loss: 1.2428\n",
      "Epoch 238/1500\n",
      "28/28 [==============================] - 0s 202us/step - loss: 1.1760 - val_loss: 1.2348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239/1500\n",
      "28/28 [==============================] - 0s 205us/step - loss: 1.1680 - val_loss: 1.2270\n",
      "Epoch 240/1500\n",
      "28/28 [==============================] - 0s 254us/step - loss: 1.1601 - val_loss: 1.2191\n",
      "Epoch 241/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 1.1523 - val_loss: 1.2113\n",
      "Epoch 242/1500\n",
      "28/28 [==============================] - 0s 237us/step - loss: 1.1445 - val_loss: 1.2036\n",
      "Epoch 243/1500\n",
      "28/28 [==============================] - 0s 258us/step - loss: 1.1368 - val_loss: 1.1960\n",
      "Epoch 244/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 1.1291 - val_loss: 1.1884\n",
      "Epoch 245/1500\n",
      "28/28 [==============================] - 0s 236us/step - loss: 1.1215 - val_loss: 1.1808\n",
      "Epoch 246/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 1.1140 - val_loss: 1.1734\n",
      "Epoch 247/1500\n",
      "28/28 [==============================] - 0s 205us/step - loss: 1.1065 - val_loss: 1.1659\n",
      "Epoch 248/1500\n",
      "28/28 [==============================] - 0s 260us/step - loss: 1.0990 - val_loss: 1.1586\n",
      "Epoch 249/1500\n",
      "28/28 [==============================] - 0s 257us/step - loss: 1.0917 - val_loss: 1.1513\n",
      "Epoch 250/1500\n",
      "28/28 [==============================] - 0s 207us/step - loss: 1.0844 - val_loss: 1.1440\n",
      "Epoch 251/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 1.0771 - val_loss: 1.1368\n",
      "Epoch 252/1500\n",
      "28/28 [==============================] - 0s 273us/step - loss: 1.0699 - val_loss: 1.1297\n",
      "Epoch 253/1500\n",
      "28/28 [==============================] - 0s 232us/step - loss: 1.0628 - val_loss: 1.1226\n",
      "Epoch 254/1500\n",
      "28/28 [==============================] - 0s 235us/step - loss: 1.0557 - val_loss: 1.1156\n",
      "Epoch 255/1500\n",
      "28/28 [==============================] - 0s 233us/step - loss: 1.0486 - val_loss: 1.1086\n",
      "Epoch 256/1500\n",
      "28/28 [==============================] - 0s 246us/step - loss: 1.0417 - val_loss: 1.1017\n",
      "Epoch 257/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 1.0347 - val_loss: 1.0948\n",
      "Epoch 258/1500\n",
      "28/28 [==============================] - 0s 192us/step - loss: 1.0279 - val_loss: 1.0880\n",
      "Epoch 259/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 1.0210 - val_loss: 1.0812\n",
      "Epoch 260/1500\n",
      "28/28 [==============================] - 0s 257us/step - loss: 1.0143 - val_loss: 1.0745\n",
      "Epoch 261/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 1.0075 - val_loss: 1.0679\n",
      "Epoch 262/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 1.0009 - val_loss: 1.0612\n",
      "Epoch 263/1500\n",
      "28/28 [==============================] - 0s 216us/step - loss: 0.9943 - val_loss: 1.0547\n",
      "Epoch 264/1500\n",
      "28/28 [==============================] - 0s 293us/step - loss: 0.9877 - val_loss: 1.0482\n",
      "Epoch 265/1500\n",
      "28/28 [==============================] - 0s 195us/step - loss: 0.9812 - val_loss: 1.0417\n",
      "Epoch 266/1500\n",
      "28/28 [==============================] - 0s 247us/step - loss: 0.9747 - val_loss: 1.0353\n",
      "Epoch 267/1500\n",
      "28/28 [==============================] - 0s 313us/step - loss: 0.9683 - val_loss: 1.0290\n",
      "Epoch 268/1500\n",
      "28/28 [==============================] - 0s 226us/step - loss: 0.9620 - val_loss: 1.0227\n",
      "Epoch 269/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.9556 - val_loss: 1.0164\n",
      "Epoch 270/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.9494 - val_loss: 1.0102\n",
      "Epoch 271/1500\n",
      "28/28 [==============================] - 0s 248us/step - loss: 0.9431 - val_loss: 1.0040\n",
      "Epoch 272/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.9370 - val_loss: 0.9979\n",
      "Epoch 273/1500\n",
      "28/28 [==============================] - 0s 194us/step - loss: 0.9308 - val_loss: 0.9918\n",
      "Epoch 274/1500\n",
      "28/28 [==============================] - 0s 153us/step - loss: 0.9248 - val_loss: 0.9858\n",
      "Epoch 275/1500\n",
      "28/28 [==============================] - 0s 231us/step - loss: 0.9187 - val_loss: 0.9798\n",
      "Epoch 276/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.9127 - val_loss: 0.9739\n",
      "Epoch 277/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.9068 - val_loss: 0.9680\n",
      "Epoch 278/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.9009 - val_loss: 0.9622\n",
      "Epoch 279/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.8950 - val_loss: 0.9564\n",
      "Epoch 280/1500\n",
      "28/28 [==============================] - 0s 299us/step - loss: 0.8892 - val_loss: 0.9506\n",
      "Epoch 281/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.8835 - val_loss: 0.9449\n",
      "Epoch 282/1500\n",
      "28/28 [==============================] - 0s 261us/step - loss: 0.8777 - val_loss: 0.9392\n",
      "Epoch 283/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.8721 - val_loss: 0.9336\n",
      "Epoch 284/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.8664 - val_loss: 0.9280\n",
      "Epoch 285/1500\n",
      "28/28 [==============================] - 0s 239us/step - loss: 0.8608 - val_loss: 0.9225\n",
      "Epoch 286/1500\n",
      "28/28 [==============================] - 0s 233us/step - loss: 0.8553 - val_loss: 0.9170\n",
      "Epoch 287/1500\n",
      "28/28 [==============================] - 0s 267us/step - loss: 0.8497 - val_loss: 0.9115\n",
      "Epoch 288/1500\n",
      "28/28 [==============================] - 0s 207us/step - loss: 0.8443 - val_loss: 0.9061\n",
      "Epoch 289/1500\n",
      "28/28 [==============================] - 0s 272us/step - loss: 0.8389 - val_loss: 0.9007\n",
      "Epoch 290/1500\n",
      "28/28 [==============================] - 0s 259us/step - loss: 0.8335 - val_loss: 0.8954\n",
      "Epoch 291/1500\n",
      "28/28 [==============================] - 0s 240us/step - loss: 0.8281 - val_loss: 0.8901\n",
      "Epoch 292/1500\n",
      "28/28 [==============================] - 0s 247us/step - loss: 0.8228 - val_loss: 0.8848\n",
      "Epoch 293/1500\n",
      "28/28 [==============================] - 0s 311us/step - loss: 0.8175 - val_loss: 0.8796\n",
      "Epoch 294/1500\n",
      "28/28 [==============================] - 0s 253us/step - loss: 0.8123 - val_loss: 0.8744\n",
      "Epoch 295/1500\n",
      "28/28 [==============================] - 0s 257us/step - loss: 0.8071 - val_loss: 0.8693\n",
      "Epoch 296/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.8020 - val_loss: 0.8642\n",
      "Epoch 297/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.7968 - val_loss: 0.8591\n",
      "Epoch 298/1500\n",
      "28/28 [==============================] - 0s 207us/step - loss: 0.7918 - val_loss: 0.8541\n",
      "Epoch 299/1500\n",
      "28/28 [==============================] - 0s 325us/step - loss: 0.7867 - val_loss: 0.8491\n",
      "Epoch 300/1500\n",
      "28/28 [==============================] - 0s 260us/step - loss: 0.7817 - val_loss: 0.8441\n",
      "Epoch 301/1500\n",
      "28/28 [==============================] - 0s 273us/step - loss: 0.7768 - val_loss: 0.8392\n",
      "Epoch 302/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.7718 - val_loss: 0.8344\n",
      "Epoch 303/1500\n",
      "28/28 [==============================] - 0s 284us/step - loss: 0.7670 - val_loss: 0.8295\n",
      "Epoch 304/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.7621 - val_loss: 0.8247\n",
      "Epoch 305/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.7573 - val_loss: 0.8199\n",
      "Epoch 306/1500\n",
      "28/28 [==============================] - 0s 437us/step - loss: 0.7525 - val_loss: 0.8152\n",
      "Epoch 307/1500\n",
      "28/28 [==============================] - 0s 238us/step - loss: 0.7478 - val_loss: 0.8105\n",
      "Epoch 308/1500\n",
      "28/28 [==============================] - 0s 256us/step - loss: 0.7431 - val_loss: 0.8058\n",
      "Epoch 309/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.7384 - val_loss: 0.8012\n",
      "Epoch 310/1500\n",
      "28/28 [==============================] - 0s 182us/step - loss: 0.7337 - val_loss: 0.7966\n",
      "Epoch 311/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.7291 - val_loss: 0.7921\n",
      "Epoch 312/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.7246 - val_loss: 0.7875\n",
      "Epoch 313/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.7200 - val_loss: 0.7830\n",
      "Epoch 314/1500\n",
      "28/28 [==============================] - 0s 192us/step - loss: 0.7155 - val_loss: 0.7786\n",
      "Epoch 315/1500\n",
      "28/28 [==============================] - 0s 233us/step - loss: 0.7110 - val_loss: 0.7742\n",
      "Epoch 316/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.7066 - val_loss: 0.7698\n",
      "Epoch 317/1500\n",
      "28/28 [==============================] - 0s 256us/step - loss: 0.7022 - val_loss: 0.7654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 318/1500\n",
      "28/28 [==============================] - 0s 263us/step - loss: 0.6978 - val_loss: 0.7611\n",
      "Epoch 319/1500\n",
      "28/28 [==============================] - 0s 184us/step - loss: 0.6935 - val_loss: 0.7568\n",
      "Epoch 320/1500\n",
      "28/28 [==============================] - 0s 160us/step - loss: 0.6891 - val_loss: 0.7525\n",
      "Epoch 321/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.6849 - val_loss: 0.7483\n",
      "Epoch 322/1500\n",
      "28/28 [==============================] - 0s 184us/step - loss: 0.6806 - val_loss: 0.7441\n",
      "Epoch 323/1500\n",
      "28/28 [==============================] - 0s 191us/step - loss: 0.6764 - val_loss: 0.7399\n",
      "Epoch 324/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.6722 - val_loss: 0.7357\n",
      "Epoch 325/1500\n",
      "28/28 [==============================] - 0s 258us/step - loss: 0.6680 - val_loss: 0.7316\n",
      "Epoch 326/1500\n",
      "28/28 [==============================] - 0s 238us/step - loss: 0.6639 - val_loss: 0.7275\n",
      "Epoch 327/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.6598 - val_loss: 0.7235\n",
      "Epoch 328/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.6558 - val_loss: 0.7195\n",
      "Epoch 329/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.6517 - val_loss: 0.7155\n",
      "Epoch 330/1500\n",
      "28/28 [==============================] - 0s 202us/step - loss: 0.6477 - val_loss: 0.7115\n",
      "Epoch 331/1500\n",
      "28/28 [==============================] - 0s 184us/step - loss: 0.6437 - val_loss: 0.7076\n",
      "Epoch 332/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.6398 - val_loss: 0.7037\n",
      "Epoch 333/1500\n",
      "28/28 [==============================] - 0s 240us/step - loss: 0.6359 - val_loss: 0.6998\n",
      "Epoch 334/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.6320 - val_loss: 0.6959\n",
      "Epoch 335/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.6281 - val_loss: 0.6921\n",
      "Epoch 336/1500\n",
      "28/28 [==============================] - 0s 272us/step - loss: 0.6243 - val_loss: 0.6883\n",
      "Epoch 337/1500\n",
      "28/28 [==============================] - 0s 253us/step - loss: 0.6204 - val_loss: 0.6845\n",
      "Epoch 338/1500\n",
      "28/28 [==============================] - 0s 274us/step - loss: 0.6167 - val_loss: 0.6808\n",
      "Epoch 339/1500\n",
      "28/28 [==============================] - 0s 194us/step - loss: 0.6129 - val_loss: 0.6771\n",
      "Epoch 340/1500\n",
      "28/28 [==============================] - 0s 188us/step - loss: 0.6092 - val_loss: 0.6734\n",
      "Epoch 341/1500\n",
      "28/28 [==============================] - 0s 250us/step - loss: 0.6055 - val_loss: 0.6698\n",
      "Epoch 342/1500\n",
      "28/28 [==============================] - 0s 247us/step - loss: 0.6018 - val_loss: 0.6661\n",
      "Epoch 343/1500\n",
      "28/28 [==============================] - 0s 282us/step - loss: 0.5982 - val_loss: 0.6625\n",
      "Epoch 344/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.5945 - val_loss: 0.6589\n",
      "Epoch 345/1500\n",
      "28/28 [==============================] - 0s 240us/step - loss: 0.5909 - val_loss: 0.6554\n",
      "Epoch 346/1500\n",
      "28/28 [==============================] - 0s 207us/step - loss: 0.5874 - val_loss: 0.6519\n",
      "Epoch 347/1500\n",
      "28/28 [==============================] - 0s 174us/step - loss: 0.5838 - val_loss: 0.6484\n",
      "Epoch 348/1500\n",
      "28/28 [==============================] - 0s 192us/step - loss: 0.5803 - val_loss: 0.6449\n",
      "Epoch 349/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.5768 - val_loss: 0.6414\n",
      "Epoch 350/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.5734 - val_loss: 0.6380\n",
      "Epoch 351/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.5699 - val_loss: 0.6346\n",
      "Epoch 352/1500\n",
      "28/28 [==============================] - 0s 176us/step - loss: 0.5665 - val_loss: 0.6312\n",
      "Epoch 353/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.5631 - val_loss: 0.6279\n",
      "Epoch 354/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.5597 - val_loss: 0.6245\n",
      "Epoch 355/1500\n",
      "28/28 [==============================] - 0s 209us/step - loss: 0.5564 - val_loss: 0.6212\n",
      "Epoch 356/1500\n",
      "28/28 [==============================] - 0s 196us/step - loss: 0.5531 - val_loss: 0.6180\n",
      "Epoch 357/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.5498 - val_loss: 0.6147\n",
      "Epoch 358/1500\n",
      "28/28 [==============================] - 0s 237us/step - loss: 0.5465 - val_loss: 0.6115\n",
      "Epoch 359/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.5432 - val_loss: 0.6083\n",
      "Epoch 360/1500\n",
      "28/28 [==============================] - 0s 216us/step - loss: 0.5400 - val_loss: 0.6051\n",
      "Epoch 361/1500\n",
      "28/28 [==============================] - 0s 195us/step - loss: 0.5368 - val_loss: 0.6019\n",
      "Epoch 362/1500\n",
      "28/28 [==============================] - 0s 175us/step - loss: 0.5336 - val_loss: 0.5988\n",
      "Epoch 363/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.5305 - val_loss: 0.5956\n",
      "Epoch 364/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 0.5273 - val_loss: 0.5925\n",
      "Epoch 365/1500\n",
      "28/28 [==============================] - 0s 205us/step - loss: 0.5242 - val_loss: 0.5895\n",
      "Epoch 366/1500\n",
      "28/28 [==============================] - 0s 249us/step - loss: 0.5211 - val_loss: 0.5864\n",
      "Epoch 367/1500\n",
      "28/28 [==============================] - 0s 251us/step - loss: 0.5180 - val_loss: 0.5834\n",
      "Epoch 368/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.5150 - val_loss: 0.5804\n",
      "Epoch 369/1500\n",
      "28/28 [==============================] - 0s 251us/step - loss: 0.5120 - val_loss: 0.5774\n",
      "Epoch 370/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.5090 - val_loss: 0.5744\n",
      "Epoch 371/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.5060 - val_loss: 0.5715\n",
      "Epoch 372/1500\n",
      "28/28 [==============================] - 0s 260us/step - loss: 0.5030 - val_loss: 0.5685\n",
      "Epoch 373/1500\n",
      "28/28 [==============================] - 0s 287us/step - loss: 0.5001 - val_loss: 0.5656\n",
      "Epoch 374/1500\n",
      "28/28 [==============================] - 0s 216us/step - loss: 0.4971 - val_loss: 0.5627\n",
      "Epoch 375/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.4942 - val_loss: 0.5599\n",
      "Epoch 376/1500\n",
      "28/28 [==============================] - 0s 209us/step - loss: 0.4914 - val_loss: 0.5570\n",
      "Epoch 377/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.4885 - val_loss: 0.5542\n",
      "Epoch 378/1500\n",
      "28/28 [==============================] - 0s 194us/step - loss: 0.4857 - val_loss: 0.5514\n",
      "Epoch 379/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.4828 - val_loss: 0.5486\n",
      "Epoch 380/1500\n",
      "28/28 [==============================] - 0s 247us/step - loss: 0.4800 - val_loss: 0.5459\n",
      "Epoch 381/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.4773 - val_loss: 0.5431\n",
      "Epoch 382/1500\n",
      "28/28 [==============================] - 0s 233us/step - loss: 0.4745 - val_loss: 0.5404\n",
      "Epoch 383/1500\n",
      "28/28 [==============================] - 0s 232us/step - loss: 0.4718 - val_loss: 0.5377\n",
      "Epoch 384/1500\n",
      "28/28 [==============================] - 0s 230us/step - loss: 0.4690 - val_loss: 0.5350\n",
      "Epoch 385/1500\n",
      "28/28 [==============================] - 0s 258us/step - loss: 0.4663 - val_loss: 0.5323\n",
      "Epoch 386/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.4636 - val_loss: 0.5297\n",
      "Epoch 387/1500\n",
      "28/28 [==============================] - 0s 287us/step - loss: 0.4610 - val_loss: 0.5271\n",
      "Epoch 388/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.4583 - val_loss: 0.5245\n",
      "Epoch 389/1500\n",
      "28/28 [==============================] - 0s 190us/step - loss: 0.4557 - val_loss: 0.5219\n",
      "Epoch 390/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.4531 - val_loss: 0.5193\n",
      "Epoch 391/1500\n",
      "28/28 [==============================] - 0s 175us/step - loss: 0.4505 - val_loss: 0.5167\n",
      "Epoch 392/1500\n",
      "28/28 [==============================] - 0s 254us/step - loss: 0.4479 - val_loss: 0.5142\n",
      "Epoch 393/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.4454 - val_loss: 0.5117\n",
      "Epoch 394/1500\n",
      "28/28 [==============================] - 0s 248us/step - loss: 0.4428 - val_loss: 0.5092\n",
      "Epoch 395/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.4403 - val_loss: 0.5067\n",
      "Epoch 396/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.4378 - val_loss: 0.5042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 397/1500\n",
      "28/28 [==============================] - 0s 209us/step - loss: 0.4353 - val_loss: 0.5018\n",
      "Epoch 398/1500\n",
      "28/28 [==============================] - 0s 209us/step - loss: 0.4329 - val_loss: 0.4994\n",
      "Epoch 399/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.4304 - val_loss: 0.4969\n",
      "Epoch 400/1500\n",
      "28/28 [==============================] - 0s 189us/step - loss: 0.4280 - val_loss: 0.4945\n",
      "Epoch 401/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.4256 - val_loss: 0.4922\n",
      "Epoch 402/1500\n",
      "28/28 [==============================] - 0s 315us/step - loss: 0.4232 - val_loss: 0.4898\n",
      "Epoch 403/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.4208 - val_loss: 0.4874\n",
      "Epoch 404/1500\n",
      "28/28 [==============================] - 0s 183us/step - loss: 0.4184 - val_loss: 0.4851\n",
      "Epoch 405/1500\n",
      "28/28 [==============================] - 0s 185us/step - loss: 0.4161 - val_loss: 0.4828\n",
      "Epoch 406/1500\n",
      "28/28 [==============================] - 0s 154us/step - loss: 0.4137 - val_loss: 0.4805\n",
      "Epoch 407/1500\n",
      "28/28 [==============================] - 0s 176us/step - loss: 0.4114 - val_loss: 0.4782\n",
      "Epoch 408/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.4091 - val_loss: 0.4760\n",
      "Epoch 409/1500\n",
      "28/28 [==============================] - 0s 174us/step - loss: 0.4069 - val_loss: 0.4737\n",
      "Epoch 410/1500\n",
      "28/28 [==============================] - 0s 177us/step - loss: 0.4046 - val_loss: 0.4715\n",
      "Epoch 411/1500\n",
      "28/28 [==============================] - 0s 164us/step - loss: 0.4023 - val_loss: 0.4693\n",
      "Epoch 412/1500\n",
      "28/28 [==============================] - 0s 190us/step - loss: 0.4001 - val_loss: 0.4671\n",
      "Epoch 413/1500\n",
      "28/28 [==============================] - 0s 173us/step - loss: 0.3979 - val_loss: 0.4649\n",
      "Epoch 414/1500\n",
      "28/28 [==============================] - 0s 162us/step - loss: 0.3957 - val_loss: 0.4627\n",
      "Epoch 415/1500\n",
      "28/28 [==============================] - 0s 192us/step - loss: 0.3935 - val_loss: 0.4605\n",
      "Epoch 416/1500\n",
      "28/28 [==============================] - 0s 178us/step - loss: 0.3913 - val_loss: 0.4584\n",
      "Epoch 417/1500\n",
      "28/28 [==============================] - 0s 209us/step - loss: 0.3891 - val_loss: 0.4563\n",
      "Epoch 418/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.3870 - val_loss: 0.4542\n",
      "Epoch 419/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.3849 - val_loss: 0.4521\n",
      "Epoch 420/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.3828 - val_loss: 0.4500\n",
      "Epoch 421/1500\n",
      "28/28 [==============================] - 0s 289us/step - loss: 0.3806 - val_loss: 0.4479\n",
      "Epoch 422/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.3786 - val_loss: 0.4459\n",
      "Epoch 423/1500\n",
      "28/28 [==============================] - 0s 268us/step - loss: 0.3765 - val_loss: 0.4438\n",
      "Epoch 424/1500\n",
      "28/28 [==============================] - 0s 269us/step - loss: 0.3744 - val_loss: 0.4418\n",
      "Epoch 425/1500\n",
      "28/28 [==============================] - 0s 237us/step - loss: 0.3724 - val_loss: 0.4398\n",
      "Epoch 426/1500\n",
      "28/28 [==============================] - 0s 226us/step - loss: 0.3704 - val_loss: 0.4378\n",
      "Epoch 427/1500\n",
      "28/28 [==============================] - 0s 252us/step - loss: 0.3683 - val_loss: 0.4358\n",
      "Epoch 428/1500\n",
      "28/28 [==============================] - 0s 271us/step - loss: 0.3663 - val_loss: 0.4338\n",
      "Epoch 429/1500\n",
      "28/28 [==============================] - 0s 283us/step - loss: 0.3643 - val_loss: 0.4319\n",
      "Epoch 430/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.3624 - val_loss: 0.4299\n",
      "Epoch 431/1500\n",
      "28/28 [==============================] - 0s 290us/step - loss: 0.3604 - val_loss: 0.4280\n",
      "Epoch 432/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.3585 - val_loss: 0.4261\n",
      "Epoch 433/1500\n",
      "28/28 [==============================] - 0s 200us/step - loss: 0.3565 - val_loss: 0.4242\n",
      "Epoch 434/1500\n",
      "28/28 [==============================] - 0s 290us/step - loss: 0.3546 - val_loss: 0.4223\n",
      "Epoch 435/1500\n",
      "28/28 [==============================] - 0s 226us/step - loss: 0.3527 - val_loss: 0.4204\n",
      "Epoch 436/1500\n",
      "28/28 [==============================] - 0s 245us/step - loss: 0.3508 - val_loss: 0.4186\n",
      "Epoch 437/1500\n",
      "28/28 [==============================] - 0s 235us/step - loss: 0.3489 - val_loss: 0.4167\n",
      "Epoch 438/1500\n",
      "28/28 [==============================] - 0s 189us/step - loss: 0.3470 - val_loss: 0.4149\n",
      "Epoch 439/1500\n",
      "28/28 [==============================] - 0s 257us/step - loss: 0.3452 - val_loss: 0.4130\n",
      "Epoch 440/1500\n",
      "28/28 [==============================] - 0s 188us/step - loss: 0.3433 - val_loss: 0.4112\n",
      "Epoch 441/1500\n",
      "28/28 [==============================] - 0s 183us/step - loss: 0.3415 - val_loss: 0.4094\n",
      "Epoch 442/1500\n",
      "28/28 [==============================] - 0s 193us/step - loss: 0.3397 - val_loss: 0.4076\n",
      "Epoch 443/1500\n",
      "28/28 [==============================] - 0s 230us/step - loss: 0.3379 - val_loss: 0.4059\n",
      "Epoch 444/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.3361 - val_loss: 0.4041\n",
      "Epoch 445/1500\n",
      "28/28 [==============================] - 0s 236us/step - loss: 0.3343 - val_loss: 0.4023\n",
      "Epoch 446/1500\n",
      "28/28 [==============================] - 0s 242us/step - loss: 0.3325 - val_loss: 0.4006\n",
      "Epoch 447/1500\n",
      "28/28 [==============================] - 0s 252us/step - loss: 0.3308 - val_loss: 0.3989\n",
      "Epoch 448/1500\n",
      "28/28 [==============================] - 0s 191us/step - loss: 0.3290 - val_loss: 0.3972\n",
      "Epoch 449/1500\n",
      "28/28 [==============================] - 0s 281us/step - loss: 0.3273 - val_loss: 0.3955\n",
      "Epoch 450/1500\n",
      "28/28 [==============================] - 0s 200us/step - loss: 0.3256 - val_loss: 0.3938\n",
      "Epoch 451/1500\n",
      "28/28 [==============================] - 0s 240us/step - loss: 0.3239 - val_loss: 0.3921\n",
      "Epoch 452/1500\n",
      "28/28 [==============================] - 0s 231us/step - loss: 0.3222 - val_loss: 0.3904\n",
      "Epoch 453/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.3205 - val_loss: 0.3888\n",
      "Epoch 454/1500\n",
      "28/28 [==============================] - 0s 189us/step - loss: 0.3188 - val_loss: 0.3871\n",
      "Epoch 455/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.3172 - val_loss: 0.3855\n",
      "Epoch 456/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.3155 - val_loss: 0.3839\n",
      "Epoch 457/1500\n",
      "28/28 [==============================] - 0s 180us/step - loss: 0.3139 - val_loss: 0.3823\n",
      "Epoch 458/1500\n",
      "28/28 [==============================] - 0s 177us/step - loss: 0.3122 - val_loss: 0.3807\n",
      "Epoch 459/1500\n",
      "28/28 [==============================] - 0s 184us/step - loss: 0.3106 - val_loss: 0.3791\n",
      "Epoch 460/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.3090 - val_loss: 0.3775\n",
      "Epoch 461/1500\n",
      "28/28 [==============================] - 0s 263us/step - loss: 0.3074 - val_loss: 0.3759\n",
      "Epoch 462/1500\n",
      "28/28 [==============================] - 0s 207us/step - loss: 0.3058 - val_loss: 0.3744\n",
      "Epoch 463/1500\n",
      "28/28 [==============================] - 0s 188us/step - loss: 0.3042 - val_loss: 0.3728\n",
      "Epoch 464/1500\n",
      "28/28 [==============================] - 0s 257us/step - loss: 0.3027 - val_loss: 0.3713\n",
      "Epoch 465/1500\n",
      "28/28 [==============================] - 0s 251us/step - loss: 0.3011 - val_loss: 0.3698\n",
      "Epoch 466/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.2996 - val_loss: 0.3683\n",
      "Epoch 467/1500\n",
      "28/28 [==============================] - 0s 200us/step - loss: 0.2981 - val_loss: 0.3668\n",
      "Epoch 468/1500\n",
      "28/28 [==============================] - 0s 254us/step - loss: 0.2965 - val_loss: 0.3653\n",
      "Epoch 469/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.2950 - val_loss: 0.3638\n",
      "Epoch 470/1500\n",
      "28/28 [==============================] - 0s 287us/step - loss: 0.2935 - val_loss: 0.3623\n",
      "Epoch 471/1500\n",
      "28/28 [==============================] - 0s 235us/step - loss: 0.2920 - val_loss: 0.3608\n",
      "Epoch 472/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.2905 - val_loss: 0.3594\n",
      "Epoch 473/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.2891 - val_loss: 0.3580\n",
      "Epoch 474/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.2876 - val_loss: 0.3565\n",
      "Epoch 475/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.2862 - val_loss: 0.3551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 476/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.2847 - val_loss: 0.3537\n",
      "Epoch 477/1500\n",
      "28/28 [==============================] - 0s 181us/step - loss: 0.2833 - val_loss: 0.3523\n",
      "Epoch 478/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.2819 - val_loss: 0.3509\n",
      "Epoch 479/1500\n",
      "28/28 [==============================] - 0s 233us/step - loss: 0.2805 - val_loss: 0.3495\n",
      "Epoch 480/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.2790 - val_loss: 0.3481\n",
      "Epoch 481/1500\n",
      "28/28 [==============================] - 0s 189us/step - loss: 0.2777 - val_loss: 0.3468\n",
      "Epoch 482/1500\n",
      "28/28 [==============================] - 0s 238us/step - loss: 0.2763 - val_loss: 0.3454\n",
      "Epoch 483/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.2749 - val_loss: 0.3441\n",
      "Epoch 484/1500\n",
      "28/28 [==============================] - 0s 236us/step - loss: 0.2735 - val_loss: 0.3427\n",
      "Epoch 485/1500\n",
      "28/28 [==============================] - 0s 262us/step - loss: 0.2722 - val_loss: 0.3414\n",
      "Epoch 486/1500\n",
      "28/28 [==============================] - 0s 207us/step - loss: 0.2708 - val_loss: 0.3401\n",
      "Epoch 487/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.2695 - val_loss: 0.3388\n",
      "Epoch 488/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.2682 - val_loss: 0.3375\n",
      "Epoch 489/1500\n",
      "28/28 [==============================] - 0s 249us/step - loss: 0.2668 - val_loss: 0.3362\n",
      "Epoch 490/1500\n",
      "28/28 [==============================] - 0s 205us/step - loss: 0.2655 - val_loss: 0.3349\n",
      "Epoch 491/1500\n",
      "28/28 [==============================] - 0s 235us/step - loss: 0.2642 - val_loss: 0.3336\n",
      "Epoch 492/1500\n",
      "28/28 [==============================] - 0s 247us/step - loss: 0.2629 - val_loss: 0.3324\n",
      "Epoch 493/1500\n",
      "28/28 [==============================] - 0s 191us/step - loss: 0.2616 - val_loss: 0.3311\n",
      "Epoch 494/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.2604 - val_loss: 0.3298\n",
      "Epoch 495/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.2591 - val_loss: 0.3286\n",
      "Epoch 496/1500\n",
      "28/28 [==============================] - 0s 196us/step - loss: 0.2578 - val_loss: 0.3274\n",
      "Epoch 497/1500\n",
      "28/28 [==============================] - 0s 171us/step - loss: 0.2566 - val_loss: 0.3262\n",
      "Epoch 498/1500\n",
      "28/28 [==============================] - 0s 207us/step - loss: 0.2554 - val_loss: 0.3249\n",
      "Epoch 499/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.2541 - val_loss: 0.3237\n",
      "Epoch 500/1500\n",
      "28/28 [==============================] - 0s 226us/step - loss: 0.2529 - val_loss: 0.3225\n",
      "Epoch 501/1500\n",
      "28/28 [==============================] - 0s 194us/step - loss: 0.2517 - val_loss: 0.3213\n",
      "Epoch 502/1500\n",
      "28/28 [==============================] - 0s 251us/step - loss: 0.2505 - val_loss: 0.3202\n",
      "Epoch 503/1500\n",
      "28/28 [==============================] - 0s 209us/step - loss: 0.2493 - val_loss: 0.3190\n",
      "Epoch 504/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.2481 - val_loss: 0.3178\n",
      "Epoch 505/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.2469 - val_loss: 0.3167\n",
      "Epoch 506/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.2457 - val_loss: 0.3155\n",
      "Epoch 507/1500\n",
      "28/28 [==============================] - 0s 184us/step - loss: 0.2445 - val_loss: 0.3144\n",
      "Epoch 508/1500\n",
      "28/28 [==============================] - 0s 254us/step - loss: 0.2434 - val_loss: 0.3132\n",
      "Epoch 509/1500\n",
      "28/28 [==============================] - 0s 267us/step - loss: 0.2422 - val_loss: 0.3121\n",
      "Epoch 510/1500\n",
      "28/28 [==============================] - 0s 195us/step - loss: 0.2411 - val_loss: 0.3110\n",
      "Epoch 511/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.2399 - val_loss: 0.3099\n",
      "Epoch 512/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.2388 - val_loss: 0.3088\n",
      "Epoch 513/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.2377 - val_loss: 0.3077\n",
      "Epoch 514/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.2366 - val_loss: 0.3066\n",
      "Epoch 515/1500\n",
      "28/28 [==============================] - 0s 249us/step - loss: 0.2355 - val_loss: 0.3055\n",
      "Epoch 516/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 0.2344 - val_loss: 0.3044\n",
      "Epoch 517/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.2333 - val_loss: 0.3034\n",
      "Epoch 518/1500\n",
      "28/28 [==============================] - 0s 361us/step - loss: 0.2322 - val_loss: 0.3023\n",
      "Epoch 519/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.2311 - val_loss: 0.3013\n",
      "Epoch 520/1500\n",
      "28/28 [==============================] - 0s 271us/step - loss: 0.2300 - val_loss: 0.3002\n",
      "Epoch 521/1500\n",
      "28/28 [==============================] - 0s 233us/step - loss: 0.2290 - val_loss: 0.2992\n",
      "Epoch 522/1500\n",
      "28/28 [==============================] - 0s 179us/step - loss: 0.2279 - val_loss: 0.2981\n",
      "Epoch 523/1500\n",
      "28/28 [==============================] - 0s 252us/step - loss: 0.2269 - val_loss: 0.2971\n",
      "Epoch 524/1500\n",
      "28/28 [==============================] - 0s 233us/step - loss: 0.2258 - val_loss: 0.2961\n",
      "Epoch 525/1500\n",
      "28/28 [==============================] - 0s 247us/step - loss: 0.2248 - val_loss: 0.2951\n",
      "Epoch 526/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.2238 - val_loss: 0.2941\n",
      "Epoch 527/1500\n",
      "28/28 [==============================] - 0s 236us/step - loss: 0.2227 - val_loss: 0.2931\n",
      "Epoch 528/1500\n",
      "28/28 [==============================] - 0s 193us/step - loss: 0.2217 - val_loss: 0.2921\n",
      "Epoch 529/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.2207 - val_loss: 0.2911\n",
      "Epoch 530/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.2197 - val_loss: 0.2901\n",
      "Epoch 531/1500\n",
      "28/28 [==============================] - 0s 241us/step - loss: 0.2187 - val_loss: 0.2892\n",
      "Epoch 532/1500\n",
      "28/28 [==============================] - 0s 235us/step - loss: 0.2177 - val_loss: 0.2882\n",
      "Epoch 533/1500\n",
      "28/28 [==============================] - 0s 241us/step - loss: 0.2167 - val_loss: 0.2873\n",
      "Epoch 534/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.2158 - val_loss: 0.2863\n",
      "Epoch 535/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.2148 - val_loss: 0.2854\n",
      "Epoch 536/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.2138 - val_loss: 0.2844\n",
      "Epoch 537/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.2129 - val_loss: 0.2835\n",
      "Epoch 538/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.2119 - val_loss: 0.2826\n",
      "Epoch 539/1500\n",
      "28/28 [==============================] - 0s 260us/step - loss: 0.2110 - val_loss: 0.2817\n",
      "Epoch 540/1500\n",
      "28/28 [==============================] - 0s 235us/step - loss: 0.2101 - val_loss: 0.2807\n",
      "Epoch 541/1500\n",
      "28/28 [==============================] - 0s 289us/step - loss: 0.2091 - val_loss: 0.2798\n",
      "Epoch 542/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.2082 - val_loss: 0.2789\n",
      "Epoch 543/1500\n",
      "28/28 [==============================] - 0s 230us/step - loss: 0.2073 - val_loss: 0.2780\n",
      "Epoch 544/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.2064 - val_loss: 0.2772\n",
      "Epoch 545/1500\n",
      "28/28 [==============================] - 0s 264us/step - loss: 0.2055 - val_loss: 0.2763\n",
      "Epoch 546/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.2046 - val_loss: 0.2754\n",
      "Epoch 547/1500\n",
      "28/28 [==============================] - 0s 230us/step - loss: 0.2037 - val_loss: 0.2745\n",
      "Epoch 548/1500\n",
      "28/28 [==============================] - 0s 246us/step - loss: 0.2028 - val_loss: 0.2737\n",
      "Epoch 549/1500\n",
      "28/28 [==============================] - 0s 260us/step - loss: 0.2019 - val_loss: 0.2728\n",
      "Epoch 550/1500\n",
      "28/28 [==============================] - 0s 263us/step - loss: 0.2010 - val_loss: 0.2720\n",
      "Epoch 551/1500\n",
      "28/28 [==============================] - 0s 205us/step - loss: 0.2002 - val_loss: 0.2711\n",
      "Epoch 552/1500\n",
      "28/28 [==============================] - 0s 243us/step - loss: 0.1993 - val_loss: 0.2703\n",
      "Epoch 553/1500\n",
      "28/28 [==============================] - 0s 205us/step - loss: 0.1984 - val_loss: 0.2694\n",
      "Epoch 554/1500\n",
      "28/28 [==============================] - 0s 256us/step - loss: 0.1976 - val_loss: 0.2686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 555/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.1967 - val_loss: 0.2678\n",
      "Epoch 556/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.1959 - val_loss: 0.2670\n",
      "Epoch 557/1500\n",
      "28/28 [==============================] - 0s 199us/step - loss: 0.1951 - val_loss: 0.2661\n",
      "Epoch 558/1500\n",
      "28/28 [==============================] - 0s 337us/step - loss: 0.1942 - val_loss: 0.2653\n",
      "Epoch 559/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.1934 - val_loss: 0.2645\n",
      "Epoch 560/1500\n",
      "28/28 [==============================] - 0s 261us/step - loss: 0.1926 - val_loss: 0.2637\n",
      "Epoch 561/1500\n",
      "28/28 [==============================] - 0s 238us/step - loss: 0.1918 - val_loss: 0.2629\n",
      "Epoch 562/1500\n",
      "28/28 [==============================] - 0s 242us/step - loss: 0.1910 - val_loss: 0.2622\n",
      "Epoch 563/1500\n",
      "28/28 [==============================] - 0s 256us/step - loss: 0.1902 - val_loss: 0.2614\n",
      "Epoch 564/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.1894 - val_loss: 0.2606\n",
      "Epoch 565/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.1886 - val_loss: 0.2598\n",
      "Epoch 566/1500\n",
      "28/28 [==============================] - 0s 205us/step - loss: 0.1878 - val_loss: 0.2591\n",
      "Epoch 567/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.1870 - val_loss: 0.2583\n",
      "Epoch 568/1500\n",
      "28/28 [==============================] - 0s 292us/step - loss: 0.1862 - val_loss: 0.2576\n",
      "Epoch 569/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.1855 - val_loss: 0.2568\n",
      "Epoch 570/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.1847 - val_loss: 0.2561\n",
      "Epoch 571/1500\n",
      "28/28 [==============================] - 0s 209us/step - loss: 0.1839 - val_loss: 0.2553\n",
      "Epoch 572/1500\n",
      "28/28 [==============================] - 0s 276us/step - loss: 0.1832 - val_loss: 0.2546\n",
      "Epoch 573/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.1824 - val_loss: 0.2539\n",
      "Epoch 574/1500\n",
      "28/28 [==============================] - 0s 230us/step - loss: 0.1817 - val_loss: 0.2531\n",
      "Epoch 575/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.1809 - val_loss: 0.2524\n",
      "Epoch 576/1500\n",
      "28/28 [==============================] - 0s 205us/step - loss: 0.1802 - val_loss: 0.2517\n",
      "Epoch 577/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.1795 - val_loss: 0.2510\n",
      "Epoch 578/1500\n",
      "28/28 [==============================] - 0s 231us/step - loss: 0.1787 - val_loss: 0.2503\n",
      "Epoch 579/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.1780 - val_loss: 0.2496\n",
      "Epoch 580/1500\n",
      "28/28 [==============================] - 0s 250us/step - loss: 0.1773 - val_loss: 0.2489\n",
      "Epoch 581/1500\n",
      "28/28 [==============================] - 0s 205us/step - loss: 0.1766 - val_loss: 0.2482\n",
      "Epoch 582/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.1759 - val_loss: 0.2475\n",
      "Epoch 583/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.1752 - val_loss: 0.2468\n",
      "Epoch 584/1500\n",
      "28/28 [==============================] - 0s 226us/step - loss: 0.1745 - val_loss: 0.2462\n",
      "Epoch 585/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.1738 - val_loss: 0.2455\n",
      "Epoch 586/1500\n",
      "28/28 [==============================] - 0s 216us/step - loss: 0.1731 - val_loss: 0.2448\n",
      "Epoch 587/1500\n",
      "28/28 [==============================] - 0s 251us/step - loss: 0.1724 - val_loss: 0.2441\n",
      "Epoch 588/1500\n",
      "28/28 [==============================] - 0s 238us/step - loss: 0.1717 - val_loss: 0.2435\n",
      "Epoch 589/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.1711 - val_loss: 0.2428\n",
      "Epoch 590/1500\n",
      "28/28 [==============================] - 0s 245us/step - loss: 0.1704 - val_loss: 0.2422\n",
      "Epoch 591/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.1697 - val_loss: 0.2415\n",
      "Epoch 592/1500\n",
      "28/28 [==============================] - 0s 194us/step - loss: 0.1691 - val_loss: 0.2409\n",
      "Epoch 593/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.1684 - val_loss: 0.2403\n",
      "Epoch 594/1500\n",
      "28/28 [==============================] - 0s 226us/step - loss: 0.1677 - val_loss: 0.2396\n",
      "Epoch 595/1500\n",
      "28/28 [==============================] - 0s 199us/step - loss: 0.1671 - val_loss: 0.2390\n",
      "Epoch 596/1500\n",
      "28/28 [==============================] - 0s 233us/step - loss: 0.1664 - val_loss: 0.2384\n",
      "Epoch 597/1500\n",
      "28/28 [==============================] - 0s 183us/step - loss: 0.1658 - val_loss: 0.2377\n",
      "Epoch 598/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.1652 - val_loss: 0.2371\n",
      "Epoch 599/1500\n",
      "28/28 [==============================] - 0s 270us/step - loss: 0.1645 - val_loss: 0.2365\n",
      "Epoch 600/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.1639 - val_loss: 0.2359\n",
      "Epoch 601/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.1633 - val_loss: 0.2353\n",
      "Epoch 602/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.1627 - val_loss: 0.2347\n",
      "Epoch 603/1500\n",
      "28/28 [==============================] - 0s 258us/step - loss: 0.1621 - val_loss: 0.2341\n",
      "Epoch 604/1500\n",
      "28/28 [==============================] - 0s 207us/step - loss: 0.1614 - val_loss: 0.2335\n",
      "Epoch 605/1500\n",
      "28/28 [==============================] - 0s 245us/step - loss: 0.1608 - val_loss: 0.2329\n",
      "Epoch 606/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.1602 - val_loss: 0.2323\n",
      "Epoch 607/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.1596 - val_loss: 0.2318\n",
      "Epoch 608/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.1590 - val_loss: 0.2312\n",
      "Epoch 609/1500\n",
      "28/28 [==============================] - 0s 239us/step - loss: 0.1584 - val_loss: 0.2306\n",
      "Epoch 610/1500\n",
      "28/28 [==============================] - 0s 242us/step - loss: 0.1579 - val_loss: 0.2300\n",
      "Epoch 611/1500\n",
      "28/28 [==============================] - 0s 216us/step - loss: 0.1573 - val_loss: 0.2295\n",
      "Epoch 612/1500\n",
      "28/28 [==============================] - 0s 190us/step - loss: 0.1567 - val_loss: 0.2289\n",
      "Epoch 613/1500\n",
      "28/28 [==============================] - 0s 196us/step - loss: 0.1561 - val_loss: 0.2284\n",
      "Epoch 614/1500\n",
      "28/28 [==============================] - 0s 233us/step - loss: 0.1555 - val_loss: 0.2278\n",
      "Epoch 615/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 0.1550 - val_loss: 0.2273\n",
      "Epoch 616/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.1544 - val_loss: 0.2267\n",
      "Epoch 617/1500\n",
      "28/28 [==============================] - 0s 209us/step - loss: 0.1539 - val_loss: 0.2262\n",
      "Epoch 618/1500\n",
      "28/28 [==============================] - 0s 236us/step - loss: 0.1533 - val_loss: 0.2256\n",
      "Epoch 619/1500\n",
      "28/28 [==============================] - 0s 185us/step - loss: 0.1527 - val_loss: 0.2251\n",
      "Epoch 620/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.1522 - val_loss: 0.2246\n",
      "Epoch 621/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.1516 - val_loss: 0.2240\n",
      "Epoch 622/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.1511 - val_loss: 0.2235\n",
      "Epoch 623/1500\n",
      "28/28 [==============================] - 0s 254us/step - loss: 0.1506 - val_loss: 0.2230\n",
      "Epoch 624/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.1500 - val_loss: 0.2225\n",
      "Epoch 625/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.1495 - val_loss: 0.2220\n",
      "Epoch 626/1500\n",
      "28/28 [==============================] - 0s 231us/step - loss: 0.1490 - val_loss: 0.2214\n",
      "Epoch 627/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.1484 - val_loss: 0.2209\n",
      "Epoch 628/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.1479 - val_loss: 0.2204\n",
      "Epoch 629/1500\n",
      "28/28 [==============================] - 0s 181us/step - loss: 0.1474 - val_loss: 0.2199\n",
      "Epoch 630/1500\n",
      "28/28 [==============================] - 0s 161us/step - loss: 0.1469 - val_loss: 0.2194\n",
      "Epoch 631/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.1464 - val_loss: 0.2189\n",
      "Epoch 632/1500\n",
      "28/28 [==============================] - 0s 209us/step - loss: 0.1459 - val_loss: 0.2185\n",
      "Epoch 633/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.1454 - val_loss: 0.2180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 634/1500\n",
      "28/28 [==============================] - 0s 182us/step - loss: 0.1449 - val_loss: 0.2175\n",
      "Epoch 635/1500\n",
      "28/28 [==============================] - 0s 202us/step - loss: 0.1444 - val_loss: 0.2170\n",
      "Epoch 636/1500\n",
      "28/28 [==============================] - 0s 183us/step - loss: 0.1439 - val_loss: 0.2165\n",
      "Epoch 637/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.1434 - val_loss: 0.2160\n",
      "Epoch 638/1500\n",
      "28/28 [==============================] - 0s 241us/step - loss: 0.1429 - val_loss: 0.2156\n",
      "Epoch 639/1500\n",
      "28/28 [==============================] - 0s 189us/step - loss: 0.1424 - val_loss: 0.2151\n",
      "Epoch 640/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.1419 - val_loss: 0.2146\n",
      "Epoch 641/1500\n",
      "28/28 [==============================] - 0s 169us/step - loss: 0.1415 - val_loss: 0.2142\n",
      "Epoch 642/1500\n",
      "28/28 [==============================] - 0s 181us/step - loss: 0.1410 - val_loss: 0.2137\n",
      "Epoch 643/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.1405 - val_loss: 0.2133\n",
      "Epoch 644/1500\n",
      "28/28 [==============================] - 0s 194us/step - loss: 0.1400 - val_loss: 0.2128\n",
      "Epoch 645/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.1396 - val_loss: 0.2124\n",
      "Epoch 646/1500\n",
      "28/28 [==============================] - 0s 253us/step - loss: 0.1391 - val_loss: 0.2119\n",
      "Epoch 647/1500\n",
      "28/28 [==============================] - 0s 266us/step - loss: 0.1386 - val_loss: 0.2115\n",
      "Epoch 648/1500\n",
      "28/28 [==============================] - 0s 209us/step - loss: 0.1382 - val_loss: 0.2110\n",
      "Epoch 649/1500\n",
      "28/28 [==============================] - 0s 247us/step - loss: 0.1377 - val_loss: 0.2106\n",
      "Epoch 650/1500\n",
      "28/28 [==============================] - 0s 273us/step - loss: 0.1373 - val_loss: 0.2102\n",
      "Epoch 651/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.1368 - val_loss: 0.2097\n",
      "Epoch 652/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.1364 - val_loss: 0.2093\n",
      "Epoch 653/1500\n",
      "28/28 [==============================] - 0s 235us/step - loss: 0.1360 - val_loss: 0.2089\n",
      "Epoch 654/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.1355 - val_loss: 0.2084\n",
      "Epoch 655/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.1351 - val_loss: 0.2080\n",
      "Epoch 656/1500\n",
      "28/28 [==============================] - 0s 163us/step - loss: 0.1346 - val_loss: 0.2076\n",
      "Epoch 657/1500\n",
      "28/28 [==============================] - 0s 292us/step - loss: 0.1342 - val_loss: 0.2072\n",
      "Epoch 658/1500\n",
      "28/28 [==============================] - 0s 172us/step - loss: 0.1338 - val_loss: 0.2068\n",
      "Epoch 659/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 0.1334 - val_loss: 0.2064\n",
      "Epoch 660/1500\n",
      "28/28 [==============================] - 0s 199us/step - loss: 0.1329 - val_loss: 0.2060\n",
      "Epoch 661/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1325 - val_loss: 0.2056\n",
      "Epoch 662/1500\n",
      "28/28 [==============================] - 0s 155us/step - loss: 0.1321 - val_loss: 0.2052\n",
      "Epoch 663/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.1317 - val_loss: 0.2048\n",
      "Epoch 664/1500\n",
      "28/28 [==============================] - 0s 243us/step - loss: 0.1313 - val_loss: 0.2044\n",
      "Epoch 665/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.1309 - val_loss: 0.2040\n",
      "Epoch 666/1500\n",
      "28/28 [==============================] - 0s 193us/step - loss: 0.1305 - val_loss: 0.2036\n",
      "Epoch 667/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.1301 - val_loss: 0.2032\n",
      "Epoch 668/1500\n",
      "28/28 [==============================] - 0s 283us/step - loss: 0.1297 - val_loss: 0.2028\n",
      "Epoch 669/1500\n",
      "28/28 [==============================] - 0s 182us/step - loss: 0.1293 - val_loss: 0.2024\n",
      "Epoch 670/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 0.1289 - val_loss: 0.2020\n",
      "Epoch 671/1500\n",
      "28/28 [==============================] - 0s 186us/step - loss: 0.1285 - val_loss: 0.2017\n",
      "Epoch 672/1500\n",
      "28/28 [==============================] - 0s 190us/step - loss: 0.1281 - val_loss: 0.2013\n",
      "Epoch 673/1500\n",
      "28/28 [==============================] - 0s 240us/step - loss: 0.1277 - val_loss: 0.2009\n",
      "Epoch 674/1500\n",
      "28/28 [==============================] - 0s 216us/step - loss: 0.1273 - val_loss: 0.2006\n",
      "Epoch 675/1500\n",
      "28/28 [==============================] - 0s 194us/step - loss: 0.1269 - val_loss: 0.2002\n",
      "Epoch 676/1500\n",
      "28/28 [==============================] - 0s 216us/step - loss: 0.1266 - val_loss: 0.1998\n",
      "Epoch 677/1500\n",
      "28/28 [==============================] - 0s 232us/step - loss: 0.1262 - val_loss: 0.1995\n",
      "Epoch 678/1500\n",
      "28/28 [==============================] - 0s 235us/step - loss: 0.1258 - val_loss: 0.1991\n",
      "Epoch 679/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.1254 - val_loss: 0.1987\n",
      "Epoch 680/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.1251 - val_loss: 0.1984\n",
      "Epoch 681/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.1247 - val_loss: 0.1980\n",
      "Epoch 682/1500\n",
      "28/28 [==============================] - 0s 251us/step - loss: 0.1243 - val_loss: 0.1977\n",
      "Epoch 683/1500\n",
      "28/28 [==============================] - 0s 249us/step - loss: 0.1240 - val_loss: 0.1973\n",
      "Epoch 684/1500\n",
      "28/28 [==============================] - 0s 272us/step - loss: 0.1236 - val_loss: 0.1970\n",
      "Epoch 685/1500\n",
      "28/28 [==============================] - 0s 253us/step - loss: 0.1232 - val_loss: 0.1966\n",
      "Epoch 686/1500\n",
      "28/28 [==============================] - 0s 401us/step - loss: 0.1229 - val_loss: 0.1963\n",
      "Epoch 687/1500\n",
      "28/28 [==============================] - 0s 287us/step - loss: 0.1225 - val_loss: 0.1960\n",
      "Epoch 688/1500\n",
      "28/28 [==============================] - 0s 186us/step - loss: 0.1222 - val_loss: 0.1956\n",
      "Epoch 689/1500\n",
      "28/28 [==============================] - 0s 247us/step - loss: 0.1218 - val_loss: 0.1953\n",
      "Epoch 690/1500\n",
      "28/28 [==============================] - 0s 191us/step - loss: 0.1215 - val_loss: 0.1950\n",
      "Epoch 691/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.1211 - val_loss: 0.1946\n",
      "Epoch 692/1500\n",
      "28/28 [==============================] - 0s 253us/step - loss: 0.1208 - val_loss: 0.1943\n",
      "Epoch 693/1500\n",
      "28/28 [==============================] - 0s 235us/step - loss: 0.1205 - val_loss: 0.1940\n",
      "Epoch 694/1500\n",
      "28/28 [==============================] - 0s 244us/step - loss: 0.1201 - val_loss: 0.1936\n",
      "Epoch 695/1500\n",
      "28/28 [==============================] - 0s 250us/step - loss: 0.1198 - val_loss: 0.1933\n",
      "Epoch 696/1500\n",
      "28/28 [==============================] - 0s 249us/step - loss: 0.1195 - val_loss: 0.1930\n",
      "Epoch 697/1500\n",
      "28/28 [==============================] - 0s 253us/step - loss: 0.1191 - val_loss: 0.1927\n",
      "Epoch 698/1500\n",
      "28/28 [==============================] - 0s 254us/step - loss: 0.1188 - val_loss: 0.1924\n",
      "Epoch 699/1500\n",
      "28/28 [==============================] - 0s 241us/step - loss: 0.1185 - val_loss: 0.1921\n",
      "Epoch 700/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.1181 - val_loss: 0.1917\n",
      "Epoch 701/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.1178 - val_loss: 0.1914\n",
      "Epoch 702/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.1175 - val_loss: 0.1911\n",
      "Epoch 703/1500\n",
      "28/28 [==============================] - 0s 242us/step - loss: 0.1172 - val_loss: 0.1908\n",
      "Epoch 704/1500\n",
      "28/28 [==============================] - 0s 244us/step - loss: 0.1169 - val_loss: 0.1905\n",
      "Epoch 705/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.1166 - val_loss: 0.1902\n",
      "Epoch 706/1500\n",
      "28/28 [==============================] - 0s 245us/step - loss: 0.1162 - val_loss: 0.1899\n",
      "Epoch 707/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.1159 - val_loss: 0.1896\n",
      "Epoch 708/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.1156 - val_loss: 0.1893\n",
      "Epoch 709/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 0.1153 - val_loss: 0.1890\n",
      "Epoch 710/1500\n",
      "28/28 [==============================] - 0s 196us/step - loss: 0.1150 - val_loss: 0.1887\n",
      "Epoch 711/1500\n",
      "28/28 [==============================] - 0s 216us/step - loss: 0.1147 - val_loss: 0.1885\n",
      "Epoch 712/1500\n",
      "28/28 [==============================] - 0s 239us/step - loss: 0.1144 - val_loss: 0.1882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 713/1500\n",
      "28/28 [==============================] - 0s 233us/step - loss: 0.1141 - val_loss: 0.1879\n",
      "Epoch 714/1500\n",
      "28/28 [==============================] - 0s 248us/step - loss: 0.1138 - val_loss: 0.1876\n",
      "Epoch 715/1500\n",
      "28/28 [==============================] - 0s 190us/step - loss: 0.1135 - val_loss: 0.1873\n",
      "Epoch 716/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.1132 - val_loss: 0.1870\n",
      "Epoch 717/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.1129 - val_loss: 0.1868\n",
      "Epoch 718/1500\n",
      "28/28 [==============================] - 0s 196us/step - loss: 0.1127 - val_loss: 0.1865\n",
      "Epoch 719/1500\n",
      "28/28 [==============================] - 0s 195us/step - loss: 0.1124 - val_loss: 0.1862\n",
      "Epoch 720/1500\n",
      "28/28 [==============================] - 0s 171us/step - loss: 0.1121 - val_loss: 0.1859\n",
      "Epoch 721/1500\n",
      "28/28 [==============================] - 0s 195us/step - loss: 0.1118 - val_loss: 0.1857\n",
      "Epoch 722/1500\n",
      "28/28 [==============================] - 0s 196us/step - loss: 0.1115 - val_loss: 0.1854\n",
      "Epoch 723/1500\n",
      "28/28 [==============================] - 0s 184us/step - loss: 0.1112 - val_loss: 0.1851\n",
      "Epoch 724/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.1110 - val_loss: 0.1849\n",
      "Epoch 725/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.1107 - val_loss: 0.1846\n",
      "Epoch 726/1500\n",
      "28/28 [==============================] - 0s 185us/step - loss: 0.1104 - val_loss: 0.1843\n",
      "Epoch 727/1500\n",
      "28/28 [==============================] - 0s 244us/step - loss: 0.1101 - val_loss: 0.1841\n",
      "Epoch 728/1500\n",
      "28/28 [==============================] - 0s 192us/step - loss: 0.1099 - val_loss: 0.1838\n",
      "Epoch 729/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.1096 - val_loss: 0.1836\n",
      "Epoch 730/1500\n",
      "28/28 [==============================] - 0s 169us/step - loss: 0.1093 - val_loss: 0.1833\n",
      "Epoch 731/1500\n",
      "28/28 [==============================] - 0s 216us/step - loss: 0.1091 - val_loss: 0.1831\n",
      "Epoch 732/1500\n",
      "28/28 [==============================] - 0s 172us/step - loss: 0.1088 - val_loss: 0.1828\n",
      "Epoch 733/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.1086 - val_loss: 0.1826\n",
      "Epoch 734/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 0.1083 - val_loss: 0.1823\n",
      "Epoch 735/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.1080 - val_loss: 0.1821\n",
      "Epoch 736/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.1078 - val_loss: 0.1818\n",
      "Epoch 737/1500\n",
      "28/28 [==============================] - 0s 188us/step - loss: 0.1075 - val_loss: 0.1816\n",
      "Epoch 738/1500\n",
      "28/28 [==============================] - 0s 180us/step - loss: 0.1073 - val_loss: 0.1813\n",
      "Epoch 739/1500\n",
      "28/28 [==============================] - 0s 189us/step - loss: 0.1070 - val_loss: 0.1811\n",
      "Epoch 740/1500\n",
      "28/28 [==============================] - 0s 205us/step - loss: 0.1068 - val_loss: 0.1809\n",
      "Epoch 741/1500\n",
      "28/28 [==============================] - 0s 161us/step - loss: 0.1065 - val_loss: 0.1806\n",
      "Epoch 742/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.1063 - val_loss: 0.1804\n",
      "Epoch 743/1500\n",
      "28/28 [==============================] - 0s 252us/step - loss: 0.1060 - val_loss: 0.1802\n",
      "Epoch 744/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.1058 - val_loss: 0.1799\n",
      "Epoch 745/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.1055 - val_loss: 0.1797\n",
      "Epoch 746/1500\n",
      "28/28 [==============================] - 0s 173us/step - loss: 0.1053 - val_loss: 0.1795\n",
      "Epoch 747/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.1051 - val_loss: 0.1792\n",
      "Epoch 748/1500\n",
      "28/28 [==============================] - 0s 185us/step - loss: 0.1048 - val_loss: 0.1790\n",
      "Epoch 749/1500\n",
      "28/28 [==============================] - 0s 266us/step - loss: 0.1046 - val_loss: 0.1788\n",
      "Epoch 750/1500\n",
      "28/28 [==============================] - 0s 207us/step - loss: 0.1044 - val_loss: 0.1786\n",
      "Epoch 751/1500\n",
      "28/28 [==============================] - 0s 183us/step - loss: 0.1041 - val_loss: 0.1784\n",
      "Epoch 752/1500\n",
      "28/28 [==============================] - 0s 185us/step - loss: 0.1039 - val_loss: 0.1781\n",
      "Epoch 753/1500\n",
      "28/28 [==============================] - 0s 205us/step - loss: 0.1037 - val_loss: 0.1779\n",
      "Epoch 754/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.1034 - val_loss: 0.1777\n",
      "Epoch 755/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.1032 - val_loss: 0.1775\n",
      "Epoch 756/1500\n",
      "28/28 [==============================] - 0s 178us/step - loss: 0.1030 - val_loss: 0.1773\n",
      "Epoch 757/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.1028 - val_loss: 0.1771\n",
      "Epoch 758/1500\n",
      "28/28 [==============================] - 0s 181us/step - loss: 0.1025 - val_loss: 0.1768\n",
      "Epoch 759/1500\n",
      "28/28 [==============================] - 0s 175us/step - loss: 0.1023 - val_loss: 0.1766\n",
      "Epoch 760/1500\n",
      "28/28 [==============================] - 0s 190us/step - loss: 0.1021 - val_loss: 0.1764\n",
      "Epoch 761/1500\n",
      "28/28 [==============================] - 0s 171us/step - loss: 0.1019 - val_loss: 0.1762\n",
      "Epoch 762/1500\n",
      "28/28 [==============================] - 0s 187us/step - loss: 0.1017 - val_loss: 0.1760\n",
      "Epoch 763/1500\n",
      "28/28 [==============================] - 0s 170us/step - loss: 0.1015 - val_loss: 0.1758\n",
      "Epoch 764/1500\n",
      "28/28 [==============================] - 0s 200us/step - loss: 0.1012 - val_loss: 0.1756\n",
      "Epoch 765/1500\n",
      "28/28 [==============================] - 0s 209us/step - loss: 0.1010 - val_loss: 0.1754\n",
      "Epoch 766/1500\n",
      "28/28 [==============================] - 0s 417us/step - loss: 0.1008 - val_loss: 0.1752\n",
      "Epoch 767/1500\n",
      "28/28 [==============================] - 0s 186us/step - loss: 0.1006 - val_loss: 0.1750\n",
      "Epoch 768/1500\n",
      "28/28 [==============================] - 0s 177us/step - loss: 0.1004 - val_loss: 0.1748\n",
      "Epoch 769/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.1002 - val_loss: 0.1746\n",
      "Epoch 770/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.1000 - val_loss: 0.1744\n",
      "Epoch 771/1500\n",
      "28/28 [==============================] - 0s 241us/step - loss: 0.0998 - val_loss: 0.1742\n",
      "Epoch 772/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.0996 - val_loss: 0.1740\n",
      "Epoch 773/1500\n",
      "28/28 [==============================] - 0s 243us/step - loss: 0.0994 - val_loss: 0.1738\n",
      "Epoch 774/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.0992 - val_loss: 0.1737\n",
      "Epoch 775/1500\n",
      "28/28 [==============================] - 0s 191us/step - loss: 0.0990 - val_loss: 0.1735\n",
      "Epoch 776/1500\n",
      "28/28 [==============================] - 0s 238us/step - loss: 0.0988 - val_loss: 0.1733\n",
      "Epoch 777/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0986 - val_loss: 0.1731\n",
      "Epoch 778/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.0984 - val_loss: 0.1729\n",
      "Epoch 779/1500\n",
      "28/28 [==============================] - 0s 191us/step - loss: 0.0982 - val_loss: 0.1727\n",
      "Epoch 780/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.0980 - val_loss: 0.1725\n",
      "Epoch 781/1500\n",
      "28/28 [==============================] - 0s 172us/step - loss: 0.0978 - val_loss: 0.1724\n",
      "Epoch 782/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0976 - val_loss: 0.1722\n",
      "Epoch 783/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.0974 - val_loss: 0.1720\n",
      "Epoch 784/1500\n",
      "28/28 [==============================] - 0s 231us/step - loss: 0.0972 - val_loss: 0.1718\n",
      "Epoch 785/1500\n",
      "28/28 [==============================] - 0s 175us/step - loss: 0.0971 - val_loss: 0.1717\n",
      "Epoch 786/1500\n",
      "28/28 [==============================] - 0s 242us/step - loss: 0.0969 - val_loss: 0.1715\n",
      "Epoch 787/1500\n",
      "28/28 [==============================] - 0s 226us/step - loss: 0.0967 - val_loss: 0.1713\n",
      "Epoch 788/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 0.0965 - val_loss: 0.1711\n",
      "Epoch 789/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.0963 - val_loss: 0.1710\n",
      "Epoch 790/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.0961 - val_loss: 0.1708\n",
      "Epoch 791/1500\n",
      "28/28 [==============================] - 0s 252us/step - loss: 0.0960 - val_loss: 0.1706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 792/1500\n",
      "28/28 [==============================] - 0s 231us/step - loss: 0.0958 - val_loss: 0.1705\n",
      "Epoch 793/1500\n",
      "28/28 [==============================] - 0s 200us/step - loss: 0.0956 - val_loss: 0.1703\n",
      "Epoch 794/1500\n",
      "28/28 [==============================] - 0s 232us/step - loss: 0.0954 - val_loss: 0.1701\n",
      "Epoch 795/1500\n",
      "28/28 [==============================] - 0s 226us/step - loss: 0.0953 - val_loss: 0.1700\n",
      "Epoch 796/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0951 - val_loss: 0.1698\n",
      "Epoch 797/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0949 - val_loss: 0.1696\n",
      "Epoch 798/1500\n",
      "28/28 [==============================] - 0s 241us/step - loss: 0.0947 - val_loss: 0.1695\n",
      "Epoch 799/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0946 - val_loss: 0.1693\n",
      "Epoch 800/1500\n",
      "28/28 [==============================] - 0s 232us/step - loss: 0.0944 - val_loss: 0.1692\n",
      "Epoch 801/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.0942 - val_loss: 0.1690\n",
      "Epoch 802/1500\n",
      "28/28 [==============================] - 0s 195us/step - loss: 0.0941 - val_loss: 0.1688\n",
      "Epoch 803/1500\n",
      "28/28 [==============================] - 0s 154us/step - loss: 0.0939 - val_loss: 0.1687\n",
      "Epoch 804/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.0937 - val_loss: 0.1685\n",
      "Epoch 805/1500\n",
      "28/28 [==============================] - 0s 190us/step - loss: 0.0936 - val_loss: 0.1684\n",
      "Epoch 806/1500\n",
      "28/28 [==============================] - 0s 181us/step - loss: 0.0934 - val_loss: 0.1682\n",
      "Epoch 807/1500\n",
      "28/28 [==============================] - 0s 191us/step - loss: 0.0933 - val_loss: 0.1681\n",
      "Epoch 808/1500\n",
      "28/28 [==============================] - 0s 202us/step - loss: 0.0931 - val_loss: 0.1679\n",
      "Epoch 809/1500\n",
      "28/28 [==============================] - 0s 230us/step - loss: 0.0929 - val_loss: 0.1678\n",
      "Epoch 810/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.0928 - val_loss: 0.1676\n",
      "Epoch 811/1500\n",
      "28/28 [==============================] - 0s 165us/step - loss: 0.0926 - val_loss: 0.1675\n",
      "Epoch 812/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0925 - val_loss: 0.1673\n",
      "Epoch 813/1500\n",
      "28/28 [==============================] - 0s 190us/step - loss: 0.0923 - val_loss: 0.1672\n",
      "Epoch 814/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.0921 - val_loss: 0.1670\n",
      "Epoch 815/1500\n",
      "28/28 [==============================] - 0s 192us/step - loss: 0.0920 - val_loss: 0.1669\n",
      "Epoch 816/1500\n",
      "28/28 [==============================] - 0s 207us/step - loss: 0.0918 - val_loss: 0.1668\n",
      "Epoch 817/1500\n",
      "28/28 [==============================] - 0s 180us/step - loss: 0.0917 - val_loss: 0.1666\n",
      "Epoch 818/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0915 - val_loss: 0.1665\n",
      "Epoch 819/1500\n",
      "28/28 [==============================] - 0s 167us/step - loss: 0.0914 - val_loss: 0.1663\n",
      "Epoch 820/1500\n",
      "28/28 [==============================] - 0s 268us/step - loss: 0.0912 - val_loss: 0.1662\n",
      "Epoch 821/1500\n",
      "28/28 [==============================] - 0s 232us/step - loss: 0.0911 - val_loss: 0.1661\n",
      "Epoch 822/1500\n",
      "28/28 [==============================] - 0s 246us/step - loss: 0.0909 - val_loss: 0.1659\n",
      "Epoch 823/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.0908 - val_loss: 0.1658\n",
      "Epoch 824/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.0907 - val_loss: 0.1656\n",
      "Epoch 825/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.0905 - val_loss: 0.1655\n",
      "Epoch 826/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.0904 - val_loss: 0.1654\n",
      "Epoch 827/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0902 - val_loss: 0.1652\n",
      "Epoch 828/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.0901 - val_loss: 0.1651\n",
      "Epoch 829/1500\n",
      "28/28 [==============================] - 0s 317us/step - loss: 0.0899 - val_loss: 0.1650\n",
      "Epoch 830/1500\n",
      "28/28 [==============================] - 0s 205us/step - loss: 0.0898 - val_loss: 0.1649\n",
      "Epoch 831/1500\n",
      "28/28 [==============================] - 0s 180us/step - loss: 0.0897 - val_loss: 0.1647\n",
      "Epoch 832/1500\n",
      "28/28 [==============================] - 0s 154us/step - loss: 0.0895 - val_loss: 0.1646\n",
      "Epoch 833/1500\n",
      "28/28 [==============================] - 0s 192us/step - loss: 0.0894 - val_loss: 0.1645\n",
      "Epoch 834/1500\n",
      "28/28 [==============================] - 0s 246us/step - loss: 0.0893 - val_loss: 0.1643\n",
      "Epoch 835/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0891 - val_loss: 0.1642\n",
      "Epoch 836/1500\n",
      "28/28 [==============================] - 0s 199us/step - loss: 0.0890 - val_loss: 0.1641\n",
      "Epoch 837/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.0889 - val_loss: 0.1640\n",
      "Epoch 838/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0887 - val_loss: 0.1638\n",
      "Epoch 839/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0886 - val_loss: 0.1637\n",
      "Epoch 840/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0885 - val_loss: 0.1636\n",
      "Epoch 841/1500\n",
      "28/28 [==============================] - 0s 235us/step - loss: 0.0883 - val_loss: 0.1635\n",
      "Epoch 842/1500\n",
      "28/28 [==============================] - 0s 232us/step - loss: 0.0882 - val_loss: 0.1634\n",
      "Epoch 843/1500\n",
      "28/28 [==============================] - 0s 269us/step - loss: 0.0881 - val_loss: 0.1632\n",
      "Epoch 844/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.0879 - val_loss: 0.1631\n",
      "Epoch 845/1500\n",
      "28/28 [==============================] - 0s 250us/step - loss: 0.0878 - val_loss: 0.1630\n",
      "Epoch 846/1500\n",
      "28/28 [==============================] - 0s 207us/step - loss: 0.0877 - val_loss: 0.1629\n",
      "Epoch 847/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0876 - val_loss: 0.1628\n",
      "Epoch 848/1500\n",
      "28/28 [==============================] - 0s 216us/step - loss: 0.0874 - val_loss: 0.1627\n",
      "Epoch 849/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.0873 - val_loss: 0.1625\n",
      "Epoch 850/1500\n",
      "28/28 [==============================] - 0s 209us/step - loss: 0.0872 - val_loss: 0.1624\n",
      "Epoch 851/1500\n",
      "28/28 [==============================] - 0s 199us/step - loss: 0.0871 - val_loss: 0.1623\n",
      "Epoch 852/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.0870 - val_loss: 0.1622\n",
      "Epoch 853/1500\n",
      "28/28 [==============================] - 0s 238us/step - loss: 0.0868 - val_loss: 0.1621\n",
      "Epoch 854/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.0867 - val_loss: 0.1620\n",
      "Epoch 855/1500\n",
      "28/28 [==============================] - 0s 271us/step - loss: 0.0866 - val_loss: 0.1619\n",
      "Epoch 856/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0865 - val_loss: 0.1618\n",
      "Epoch 857/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 0.0864 - val_loss: 0.1617\n",
      "Epoch 858/1500\n",
      "28/28 [==============================] - 0s 253us/step - loss: 0.0862 - val_loss: 0.1615\n",
      "Epoch 859/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.0861 - val_loss: 0.1614\n",
      "Epoch 860/1500\n",
      "28/28 [==============================] - 0s 194us/step - loss: 0.0860 - val_loss: 0.1613\n",
      "Epoch 861/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0859 - val_loss: 0.1612\n",
      "Epoch 862/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0858 - val_loss: 0.1611\n",
      "Epoch 863/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.0857 - val_loss: 0.1610\n",
      "Epoch 864/1500\n",
      "28/28 [==============================] - 0s 261us/step - loss: 0.0856 - val_loss: 0.1609\n",
      "Epoch 865/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0855 - val_loss: 0.1608\n",
      "Epoch 866/1500\n",
      "28/28 [==============================] - 0s 252us/step - loss: 0.0853 - val_loss: 0.1607\n",
      "Epoch 867/1500\n",
      "28/28 [==============================] - 0s 231us/step - loss: 0.0852 - val_loss: 0.1606\n",
      "Epoch 868/1500\n",
      "28/28 [==============================] - 0s 233us/step - loss: 0.0851 - val_loss: 0.1605\n",
      "Epoch 869/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0850 - val_loss: 0.1604\n",
      "Epoch 870/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.0849 - val_loss: 0.1603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 871/1500\n",
      "28/28 [==============================] - 0s 202us/step - loss: 0.0848 - val_loss: 0.1602\n",
      "Epoch 872/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.0847 - val_loss: 0.1601\n",
      "Epoch 873/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.0846 - val_loss: 0.1600\n",
      "Epoch 874/1500\n",
      "28/28 [==============================] - 0s 271us/step - loss: 0.0845 - val_loss: 0.1599\n",
      "Epoch 875/1500\n",
      "28/28 [==============================] - 0s 255us/step - loss: 0.0844 - val_loss: 0.1598\n",
      "Epoch 876/1500\n",
      "28/28 [==============================] - 0s 253us/step - loss: 0.0843 - val_loss: 0.1597\n",
      "Epoch 877/1500\n",
      "28/28 [==============================] - 0s 269us/step - loss: 0.0842 - val_loss: 0.1596\n",
      "Epoch 878/1500\n",
      "28/28 [==============================] - 0s 257us/step - loss: 0.0841 - val_loss: 0.1595\n",
      "Epoch 879/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.0840 - val_loss: 0.1595\n",
      "Epoch 880/1500\n",
      "28/28 [==============================] - 0s 207us/step - loss: 0.0839 - val_loss: 0.1594\n",
      "Epoch 881/1500\n",
      "28/28 [==============================] - 0s 194us/step - loss: 0.0838 - val_loss: 0.1593\n",
      "Epoch 882/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.0837 - val_loss: 0.1592\n",
      "Epoch 883/1500\n",
      "28/28 [==============================] - 0s 185us/step - loss: 0.0836 - val_loss: 0.1591\n",
      "Epoch 884/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.0835 - val_loss: 0.1590\n",
      "Epoch 885/1500\n",
      "28/28 [==============================] - 0s 175us/step - loss: 0.0834 - val_loss: 0.1589\n",
      "Epoch 886/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.0833 - val_loss: 0.1588\n",
      "Epoch 887/1500\n",
      "28/28 [==============================] - 0s 243us/step - loss: 0.0832 - val_loss: 0.1587\n",
      "Epoch 888/1500\n",
      "28/28 [==============================] - 0s 265us/step - loss: 0.0831 - val_loss: 0.1586\n",
      "Epoch 889/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.0830 - val_loss: 0.1586\n",
      "Epoch 890/1500\n",
      "28/28 [==============================] - 0s 195us/step - loss: 0.0829 - val_loss: 0.1585\n",
      "Epoch 891/1500\n",
      "28/28 [==============================] - 0s 237us/step - loss: 0.0828 - val_loss: 0.1584\n",
      "Epoch 892/1500\n",
      "28/28 [==============================] - 0s 305us/step - loss: 0.0827 - val_loss: 0.1583\n",
      "Epoch 893/1500\n",
      "28/28 [==============================] - 0s 282us/step - loss: 0.0826 - val_loss: 0.1582\n",
      "Epoch 894/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0825 - val_loss: 0.1581\n",
      "Epoch 895/1500\n",
      "28/28 [==============================] - 0s 209us/step - loss: 0.0824 - val_loss: 0.1580\n",
      "Epoch 896/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0823 - val_loss: 0.1580\n",
      "Epoch 897/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.0822 - val_loss: 0.1579\n",
      "Epoch 898/1500\n",
      "28/28 [==============================] - 0s 302us/step - loss: 0.0821 - val_loss: 0.1578\n",
      "Epoch 899/1500\n",
      "28/28 [==============================] - 0s 199us/step - loss: 0.0821 - val_loss: 0.1577\n",
      "Epoch 900/1500\n",
      "28/28 [==============================] - 0s 202us/step - loss: 0.0820 - val_loss: 0.1576\n",
      "Epoch 901/1500\n",
      "28/28 [==============================] - 0s 188us/step - loss: 0.0819 - val_loss: 0.1575\n",
      "Epoch 902/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.0818 - val_loss: 0.1575\n",
      "Epoch 903/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.0817 - val_loss: 0.1574\n",
      "Epoch 904/1500\n",
      "28/28 [==============================] - 0s 253us/step - loss: 0.0816 - val_loss: 0.1573\n",
      "Epoch 905/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.0815 - val_loss: 0.1572\n",
      "Epoch 906/1500\n",
      "28/28 [==============================] - 0s 180us/step - loss: 0.0814 - val_loss: 0.1572\n",
      "Epoch 907/1500\n",
      "28/28 [==============================] - 0s 216us/step - loss: 0.0814 - val_loss: 0.1571\n",
      "Epoch 908/1500\n",
      "28/28 [==============================] - 0s 243us/step - loss: 0.0813 - val_loss: 0.1570\n",
      "Epoch 909/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.0812 - val_loss: 0.1569\n",
      "Epoch 910/1500\n",
      "28/28 [==============================] - 0s 246us/step - loss: 0.0811 - val_loss: 0.1569\n",
      "Epoch 911/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.0810 - val_loss: 0.1568\n",
      "Epoch 912/1500\n",
      "28/28 [==============================] - 0s 216us/step - loss: 0.0809 - val_loss: 0.1567\n",
      "Epoch 913/1500\n",
      "28/28 [==============================] - 0s 232us/step - loss: 0.0809 - val_loss: 0.1566\n",
      "Epoch 914/1500\n",
      "28/28 [==============================] - 0s 262us/step - loss: 0.0808 - val_loss: 0.1566\n",
      "Epoch 915/1500\n",
      "28/28 [==============================] - 0s 272us/step - loss: 0.0807 - val_loss: 0.1565\n",
      "Epoch 916/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.0806 - val_loss: 0.1564\n",
      "Epoch 917/1500\n",
      "28/28 [==============================] - 0s 182us/step - loss: 0.0805 - val_loss: 0.1563\n",
      "Epoch 918/1500\n",
      "28/28 [==============================] - 0s 241us/step - loss: 0.0805 - val_loss: 0.1563\n",
      "Epoch 919/1500\n",
      "28/28 [==============================] - 0s 289us/step - loss: 0.0804 - val_loss: 0.1562\n",
      "Epoch 920/1500\n",
      "28/28 [==============================] - 0s 250us/step - loss: 0.0803 - val_loss: 0.1561\n",
      "Epoch 921/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.0802 - val_loss: 0.1561\n",
      "Epoch 922/1500\n",
      "28/28 [==============================] - 0s 240us/step - loss: 0.0801 - val_loss: 0.1560\n",
      "Epoch 923/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0801 - val_loss: 0.1559\n",
      "Epoch 924/1500\n",
      "28/28 [==============================] - 0s 233us/step - loss: 0.0800 - val_loss: 0.1558\n",
      "Epoch 925/1500\n",
      "28/28 [==============================] - 0s 242us/step - loss: 0.0799 - val_loss: 0.1558\n",
      "Epoch 926/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0798 - val_loss: 0.1557\n",
      "Epoch 927/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.0798 - val_loss: 0.1556\n",
      "Epoch 928/1500\n",
      "28/28 [==============================] - 0s 240us/step - loss: 0.0797 - val_loss: 0.1556\n",
      "Epoch 929/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.0796 - val_loss: 0.1555\n",
      "Epoch 930/1500\n",
      "28/28 [==============================] - 0s 249us/step - loss: 0.0795 - val_loss: 0.1554\n",
      "Epoch 931/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.0795 - val_loss: 0.1554\n",
      "Epoch 932/1500\n",
      "28/28 [==============================] - 0s 295us/step - loss: 0.0794 - val_loss: 0.1553\n",
      "Epoch 933/1500\n",
      "28/28 [==============================] - 0s 237us/step - loss: 0.0793 - val_loss: 0.1552\n",
      "Epoch 934/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.0792 - val_loss: 0.1552\n",
      "Epoch 935/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.0792 - val_loss: 0.1551\n",
      "Epoch 936/1500\n",
      "28/28 [==============================] - 0s 231us/step - loss: 0.0791 - val_loss: 0.1551\n",
      "Epoch 937/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.0790 - val_loss: 0.1550\n",
      "Epoch 938/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0790 - val_loss: 0.1549\n",
      "Epoch 939/1500\n",
      "28/28 [==============================] - 0s 236us/step - loss: 0.0789 - val_loss: 0.1549\n",
      "Epoch 940/1500\n",
      "28/28 [==============================] - 0s 242us/step - loss: 0.0788 - val_loss: 0.1548\n",
      "Epoch 941/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.0788 - val_loss: 0.1547\n",
      "Epoch 942/1500\n",
      "28/28 [==============================] - 0s 281us/step - loss: 0.0787 - val_loss: 0.1547\n",
      "Epoch 943/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.0786 - val_loss: 0.1546\n",
      "Epoch 944/1500\n",
      "28/28 [==============================] - 0s 205us/step - loss: 0.0785 - val_loss: 0.1546\n",
      "Epoch 945/1500\n",
      "28/28 [==============================] - 0s 230us/step - loss: 0.0785 - val_loss: 0.1545\n",
      "Epoch 946/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0784 - val_loss: 0.1544\n",
      "Epoch 947/1500\n",
      "28/28 [==============================] - 0s 185us/step - loss: 0.0783 - val_loss: 0.1544\n",
      "Epoch 948/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.0783 - val_loss: 0.1543\n",
      "Epoch 949/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 0.0782 - val_loss: 0.1543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 950/1500\n",
      "28/28 [==============================] - 0s 209us/step - loss: 0.0782 - val_loss: 0.1542\n",
      "Epoch 951/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.0781 - val_loss: 0.1542\n",
      "Epoch 952/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.0780 - val_loss: 0.1541\n",
      "Epoch 953/1500\n",
      "28/28 [==============================] - 0s 256us/step - loss: 0.0780 - val_loss: 0.1540\n",
      "Epoch 954/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0779 - val_loss: 0.1540\n",
      "Epoch 955/1500\n",
      "28/28 [==============================] - 0s 269us/step - loss: 0.0778 - val_loss: 0.1539\n",
      "Epoch 956/1500\n",
      "28/28 [==============================] - 0s 284us/step - loss: 0.0778 - val_loss: 0.1539\n",
      "Epoch 957/1500\n",
      "28/28 [==============================] - 0s 190us/step - loss: 0.0777 - val_loss: 0.1538\n",
      "Epoch 958/1500\n",
      "28/28 [==============================] - 0s 259us/step - loss: 0.0776 - val_loss: 0.1538\n",
      "Epoch 959/1500\n",
      "28/28 [==============================] - 0s 235us/step - loss: 0.0776 - val_loss: 0.1537\n",
      "Epoch 960/1500\n",
      "28/28 [==============================] - 0s 235us/step - loss: 0.0775 - val_loss: 0.1537\n",
      "Epoch 961/1500\n",
      "28/28 [==============================] - 0s 179us/step - loss: 0.0775 - val_loss: 0.1536\n",
      "Epoch 962/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.0774 - val_loss: 0.1535\n",
      "Epoch 963/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.0773 - val_loss: 0.1535\n",
      "Epoch 964/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.0773 - val_loss: 0.1534\n",
      "Epoch 965/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.0772 - val_loss: 0.1534\n",
      "Epoch 966/1500\n",
      "28/28 [==============================] - 0s 311us/step - loss: 0.0772 - val_loss: 0.1533\n",
      "Epoch 967/1500\n",
      "28/28 [==============================] - 0s 272us/step - loss: 0.0771 - val_loss: 0.1533\n",
      "Epoch 968/1500\n",
      "28/28 [==============================] - 0s 240us/step - loss: 0.0770 - val_loss: 0.1532\n",
      "Epoch 969/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0770 - val_loss: 0.1532\n",
      "Epoch 970/1500\n",
      "28/28 [==============================] - 0s 196us/step - loss: 0.0769 - val_loss: 0.1531\n",
      "Epoch 971/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0769 - val_loss: 0.1531\n",
      "Epoch 972/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0768 - val_loss: 0.1530\n",
      "Epoch 973/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0768 - val_loss: 0.1530\n",
      "Epoch 974/1500\n",
      "28/28 [==============================] - 0s 338us/step - loss: 0.0767 - val_loss: 0.1529\n",
      "Epoch 975/1500\n",
      "28/28 [==============================] - 0s 290us/step - loss: 0.0766 - val_loss: 0.1529\n",
      "Epoch 976/1500\n",
      "28/28 [==============================] - 0s 264us/step - loss: 0.0766 - val_loss: 0.1528\n",
      "Epoch 977/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.0765 - val_loss: 0.1528\n",
      "Epoch 978/1500\n",
      "28/28 [==============================] - 0s 311us/step - loss: 0.0765 - val_loss: 0.1527\n",
      "Epoch 979/1500\n",
      "28/28 [==============================] - 0s 239us/step - loss: 0.0764 - val_loss: 0.1527\n",
      "Epoch 980/1500\n",
      "28/28 [==============================] - 0s 341us/step - loss: 0.0764 - val_loss: 0.1527\n",
      "Epoch 981/1500\n",
      "28/28 [==============================] - 0s 192us/step - loss: 0.0763 - val_loss: 0.1526\n",
      "Epoch 982/1500\n",
      "28/28 [==============================] - 0s 162us/step - loss: 0.0763 - val_loss: 0.1526\n",
      "Epoch 983/1500\n",
      "28/28 [==============================] - 0s 195us/step - loss: 0.0762 - val_loss: 0.1525\n",
      "Epoch 984/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.0762 - val_loss: 0.1525\n",
      "Epoch 985/1500\n",
      "28/28 [==============================] - 0s 249us/step - loss: 0.0761 - val_loss: 0.1524\n",
      "Epoch 986/1500\n",
      "28/28 [==============================] - 0s 232us/step - loss: 0.0761 - val_loss: 0.1524\n",
      "Epoch 987/1500\n",
      "28/28 [==============================] - 0s 236us/step - loss: 0.0760 - val_loss: 0.1523\n",
      "Epoch 988/1500\n",
      "28/28 [==============================] - 0s 256us/step - loss: 0.0760 - val_loss: 0.1523\n",
      "Epoch 989/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0759 - val_loss: 0.1522\n",
      "Epoch 990/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.0758 - val_loss: 0.1522\n",
      "Epoch 991/1500\n",
      "28/28 [==============================] - 0s 187us/step - loss: 0.0758 - val_loss: 0.1522\n",
      "Epoch 992/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.0757 - val_loss: 0.1521\n",
      "Epoch 993/1500\n",
      "28/28 [==============================] - 0s 226us/step - loss: 0.0757 - val_loss: 0.1521\n",
      "Epoch 994/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.0756 - val_loss: 0.1520\n",
      "Epoch 995/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.0756 - val_loss: 0.1520\n",
      "Epoch 996/1500\n",
      "28/28 [==============================] - 0s 171us/step - loss: 0.0755 - val_loss: 0.1519\n",
      "Epoch 997/1500\n",
      "28/28 [==============================] - 0s 243us/step - loss: 0.0755 - val_loss: 0.1519\n",
      "Epoch 998/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.0755 - val_loss: 0.1519\n",
      "Epoch 999/1500\n",
      "28/28 [==============================] - 0s 268us/step - loss: 0.0754 - val_loss: 0.1518\n",
      "Epoch 1000/1500\n",
      "28/28 [==============================] - 0s 216us/step - loss: 0.0754 - val_loss: 0.1518\n",
      "Epoch 1001/1500\n",
      "28/28 [==============================] - 0s 239us/step - loss: 0.0753 - val_loss: 0.1517\n",
      "Epoch 1002/1500\n",
      "28/28 [==============================] - 0s 205us/step - loss: 0.0753 - val_loss: 0.1517\n",
      "Epoch 1003/1500\n",
      "28/28 [==============================] - 0s 189us/step - loss: 0.0752 - val_loss: 0.1517\n",
      "Epoch 1004/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.0752 - val_loss: 0.1516\n",
      "Epoch 1005/1500\n",
      "28/28 [==============================] - 0s 259us/step - loss: 0.0751 - val_loss: 0.1516\n",
      "Epoch 1006/1500\n",
      "28/28 [==============================] - 0s 207us/step - loss: 0.0751 - val_loss: 0.1515\n",
      "Epoch 1007/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0750 - val_loss: 0.1515\n",
      "Epoch 1008/1500\n",
      "28/28 [==============================] - 0s 199us/step - loss: 0.0750 - val_loss: 0.1515\n",
      "Epoch 1009/1500\n",
      "28/28 [==============================] - 0s 161us/step - loss: 0.0749 - val_loss: 0.1514\n",
      "Epoch 1010/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.0749 - val_loss: 0.1514\n",
      "Epoch 1011/1500\n",
      "28/28 [==============================] - 0s 171us/step - loss: 0.0748 - val_loss: 0.1513\n",
      "Epoch 1012/1500\n",
      "28/28 [==============================] - 0s 249us/step - loss: 0.0748 - val_loss: 0.1513\n",
      "Epoch 1013/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.0748 - val_loss: 0.1513\n",
      "Epoch 1014/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.0747 - val_loss: 0.1512\n",
      "Epoch 1015/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.0747 - val_loss: 0.1512\n",
      "Epoch 1016/1500\n",
      "28/28 [==============================] - 0s 249us/step - loss: 0.0746 - val_loss: 0.1512\n",
      "Epoch 1017/1500\n",
      "28/28 [==============================] - 0s 196us/step - loss: 0.0746 - val_loss: 0.1511\n",
      "Epoch 1018/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0745 - val_loss: 0.1511\n",
      "Epoch 1019/1500\n",
      "28/28 [==============================] - 0s 246us/step - loss: 0.0745 - val_loss: 0.1511\n",
      "Epoch 1020/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.0745 - val_loss: 0.1510\n",
      "Epoch 1021/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.0744 - val_loss: 0.1510\n",
      "Epoch 1022/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.0744 - val_loss: 0.1509\n",
      "Epoch 1023/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.0743 - val_loss: 0.1509\n",
      "Epoch 1024/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.0743 - val_loss: 0.1509\n",
      "Epoch 1025/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.0742 - val_loss: 0.1508\n",
      "Epoch 1026/1500\n",
      "28/28 [==============================] - 0s 191us/step - loss: 0.0742 - val_loss: 0.1508\n",
      "Epoch 1027/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.0742 - val_loss: 0.1508\n",
      "Epoch 1028/1500\n",
      "28/28 [==============================] - 0s 187us/step - loss: 0.0741 - val_loss: 0.1507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1029/1500\n",
      "28/28 [==============================] - 0s 191us/step - loss: 0.0741 - val_loss: 0.1507\n",
      "Epoch 1030/1500\n",
      "28/28 [==============================] - 0s 192us/step - loss: 0.0740 - val_loss: 0.1507\n",
      "Epoch 1031/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.0740 - val_loss: 0.1506\n",
      "Epoch 1032/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.0740 - val_loss: 0.1506\n",
      "Epoch 1033/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.0739 - val_loss: 0.1506\n",
      "Epoch 1034/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.0739 - val_loss: 0.1505\n",
      "Epoch 1035/1500\n",
      "28/28 [==============================] - 0s 226us/step - loss: 0.0738 - val_loss: 0.1505\n",
      "Epoch 1036/1500\n",
      "28/28 [==============================] - 0s 200us/step - loss: 0.0738 - val_loss: 0.1505\n",
      "Epoch 1037/1500\n",
      "28/28 [==============================] - 0s 266us/step - loss: 0.0738 - val_loss: 0.1505\n",
      "Epoch 1038/1500\n",
      "28/28 [==============================] - 0s 238us/step - loss: 0.0737 - val_loss: 0.1504\n",
      "Epoch 1039/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.0737 - val_loss: 0.1504\n",
      "Epoch 1040/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.0737 - val_loss: 0.1504\n",
      "Epoch 1041/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 0.0736 - val_loss: 0.1503\n",
      "Epoch 1042/1500\n",
      "28/28 [==============================] - 0s 232us/step - loss: 0.0736 - val_loss: 0.1503\n",
      "Epoch 1043/1500\n",
      "28/28 [==============================] - 0s 246us/step - loss: 0.0735 - val_loss: 0.1503\n",
      "Epoch 1044/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.0735 - val_loss: 0.1502\n",
      "Epoch 1045/1500\n",
      "28/28 [==============================] - 0s 244us/step - loss: 0.0735 - val_loss: 0.1502\n",
      "Epoch 1046/1500\n",
      "28/28 [==============================] - 0s 247us/step - loss: 0.0734 - val_loss: 0.1502\n",
      "Epoch 1047/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.0734 - val_loss: 0.1501\n",
      "Epoch 1048/1500\n",
      "28/28 [==============================] - 0s 200us/step - loss: 0.0734 - val_loss: 0.1501\n",
      "Epoch 1049/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.0733 - val_loss: 0.1501\n",
      "Epoch 1050/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.0733 - val_loss: 0.1501\n",
      "Epoch 1051/1500\n",
      "28/28 [==============================] - 0s 191us/step - loss: 0.0733 - val_loss: 0.1500\n",
      "Epoch 1052/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.0732 - val_loss: 0.1500\n",
      "Epoch 1053/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0732 - val_loss: 0.1500\n",
      "Epoch 1054/1500\n",
      "28/28 [==============================] - 0s 196us/step - loss: 0.0732 - val_loss: 0.1499\n",
      "Epoch 1055/1500\n",
      "28/28 [==============================] - 0s 247us/step - loss: 0.0731 - val_loss: 0.1499\n",
      "Epoch 1056/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.0731 - val_loss: 0.1499\n",
      "Epoch 1057/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.0731 - val_loss: 0.1499\n",
      "Epoch 1058/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.0730 - val_loss: 0.1498\n",
      "Epoch 1059/1500\n",
      "28/28 [==============================] - 0s 195us/step - loss: 0.0730 - val_loss: 0.1498\n",
      "Epoch 1060/1500\n",
      "28/28 [==============================] - 0s 181us/step - loss: 0.0730 - val_loss: 0.1498\n",
      "Epoch 1061/1500\n",
      "28/28 [==============================] - 0s 189us/step - loss: 0.0729 - val_loss: 0.1498\n",
      "Epoch 1062/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0729 - val_loss: 0.1497\n",
      "Epoch 1063/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 0.0729 - val_loss: 0.1497\n",
      "Epoch 1064/1500\n",
      "28/28 [==============================] - 0s 191us/step - loss: 0.0728 - val_loss: 0.1497\n",
      "Epoch 1065/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.0728 - val_loss: 0.1496\n",
      "Epoch 1066/1500\n",
      "28/28 [==============================] - 0s 239us/step - loss: 0.0728 - val_loss: 0.1496\n",
      "Epoch 1067/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.0727 - val_loss: 0.1496\n",
      "Epoch 1068/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.0727 - val_loss: 0.1496\n",
      "Epoch 1069/1500\n",
      "28/28 [==============================] - 0s 292us/step - loss: 0.0727 - val_loss: 0.1495\n",
      "Epoch 1070/1500\n",
      "28/28 [==============================] - 0s 205us/step - loss: 0.0726 - val_loss: 0.1495\n",
      "Epoch 1071/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.0726 - val_loss: 0.1495\n",
      "Epoch 1072/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0726 - val_loss: 0.1495\n",
      "Epoch 1073/1500\n",
      "28/28 [==============================] - 0s 235us/step - loss: 0.0725 - val_loss: 0.1494\n",
      "Epoch 1074/1500\n",
      "28/28 [==============================] - 0s 249us/step - loss: 0.0725 - val_loss: 0.1494\n",
      "Epoch 1075/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.0725 - val_loss: 0.1494\n",
      "Epoch 1076/1500\n",
      "28/28 [==============================] - 0s 236us/step - loss: 0.0724 - val_loss: 0.1494\n",
      "Epoch 1077/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0724 - val_loss: 0.1494\n",
      "Epoch 1078/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0724 - val_loss: 0.1493\n",
      "Epoch 1079/1500\n",
      "28/28 [==============================] - 0s 216us/step - loss: 0.0724 - val_loss: 0.1493\n",
      "Epoch 1080/1500\n",
      "28/28 [==============================] - 0s 308us/step - loss: 0.0723 - val_loss: 0.1493\n",
      "Epoch 1081/1500\n",
      "28/28 [==============================] - 0s 301us/step - loss: 0.0723 - val_loss: 0.1493\n",
      "Epoch 1082/1500\n",
      "28/28 [==============================] - 0s 233us/step - loss: 0.0723 - val_loss: 0.1492\n",
      "Epoch 1083/1500\n",
      "28/28 [==============================] - 0s 249us/step - loss: 0.0722 - val_loss: 0.1492\n",
      "Epoch 1084/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.0722 - val_loss: 0.1492\n",
      "Epoch 1085/1500\n",
      "28/28 [==============================] - 0s 200us/step - loss: 0.0722 - val_loss: 0.1492\n",
      "Epoch 1086/1500\n",
      "28/28 [==============================] - 0s 193us/step - loss: 0.0721 - val_loss: 0.1491\n",
      "Epoch 1087/1500\n",
      "28/28 [==============================] - 0s 185us/step - loss: 0.0721 - val_loss: 0.1491\n",
      "Epoch 1088/1500\n",
      "28/28 [==============================] - 0s 256us/step - loss: 0.0721 - val_loss: 0.1491\n",
      "Epoch 1089/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0721 - val_loss: 0.1491\n",
      "Epoch 1090/1500\n",
      "28/28 [==============================] - 0s 260us/step - loss: 0.0720 - val_loss: 0.1491\n",
      "Epoch 1091/1500\n",
      "28/28 [==============================] - 0s 187us/step - loss: 0.0720 - val_loss: 0.1490\n",
      "Epoch 1092/1500\n",
      "28/28 [==============================] - 0s 183us/step - loss: 0.0720 - val_loss: 0.1490\n",
      "Epoch 1093/1500\n",
      "28/28 [==============================] - 0s 268us/step - loss: 0.0720 - val_loss: 0.1490\n",
      "Epoch 1094/1500\n",
      "28/28 [==============================] - 0s 244us/step - loss: 0.0719 - val_loss: 0.1490\n",
      "Epoch 1095/1500\n",
      "28/28 [==============================] - 0s 196us/step - loss: 0.0719 - val_loss: 0.1489\n",
      "Epoch 1096/1500\n",
      "28/28 [==============================] - 0s 271us/step - loss: 0.0719 - val_loss: 0.1489\n",
      "Epoch 1097/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.0718 - val_loss: 0.1489\n",
      "Epoch 1098/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0718 - val_loss: 0.1489\n",
      "Epoch 1099/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0718 - val_loss: 0.1489\n",
      "Epoch 1100/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0718 - val_loss: 0.1488\n",
      "Epoch 1101/1500\n",
      "28/28 [==============================] - 0s 242us/step - loss: 0.0717 - val_loss: 0.1488\n",
      "Epoch 1102/1500\n",
      "28/28 [==============================] - 0s 265us/step - loss: 0.0717 - val_loss: 0.1488\n",
      "Epoch 1103/1500\n",
      "28/28 [==============================] - 0s 238us/step - loss: 0.0717 - val_loss: 0.1488\n",
      "Epoch 1104/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.0717 - val_loss: 0.1488\n",
      "Epoch 1105/1500\n",
      "28/28 [==============================] - 0s 252us/step - loss: 0.0716 - val_loss: 0.1487\n",
      "Epoch 1106/1500\n",
      "28/28 [==============================] - 0s 252us/step - loss: 0.0716 - val_loss: 0.1487\n",
      "Epoch 1107/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 208us/step - loss: 0.0716 - val_loss: 0.1487\n",
      "Epoch 1108/1500\n",
      "28/28 [==============================] - 0s 277us/step - loss: 0.0716 - val_loss: 0.1487\n",
      "Epoch 1109/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.0715 - val_loss: 0.1487\n",
      "Epoch 1110/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.0715 - val_loss: 0.1486\n",
      "Epoch 1111/1500\n",
      "28/28 [==============================] - 0s 226us/step - loss: 0.0715 - val_loss: 0.1486\n",
      "Epoch 1112/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0715 - val_loss: 0.1486\n",
      "Epoch 1113/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.0714 - val_loss: 0.1486\n",
      "Epoch 1114/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0714 - val_loss: 0.1486\n",
      "Epoch 1115/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.0714 - val_loss: 0.1486\n",
      "Epoch 1116/1500\n",
      "28/28 [==============================] - 0s 322us/step - loss: 0.0714 - val_loss: 0.1485\n",
      "Epoch 1117/1500\n",
      "28/28 [==============================] - 0s 230us/step - loss: 0.0713 - val_loss: 0.1485\n",
      "Epoch 1118/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0713 - val_loss: 0.1485\n",
      "Epoch 1119/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 0.0713 - val_loss: 0.1485\n",
      "Epoch 1120/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.0713 - val_loss: 0.1485\n",
      "Epoch 1121/1500\n",
      "28/28 [==============================] - 0s 232us/step - loss: 0.0712 - val_loss: 0.1484\n",
      "Epoch 1122/1500\n",
      "28/28 [==============================] - 0s 237us/step - loss: 0.0712 - val_loss: 0.1484\n",
      "Epoch 1123/1500\n",
      "28/28 [==============================] - 0s 209us/step - loss: 0.0712 - val_loss: 0.1484\n",
      "Epoch 1124/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0712 - val_loss: 0.1484\n",
      "Epoch 1125/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.0711 - val_loss: 0.1484\n",
      "Epoch 1126/1500\n",
      "28/28 [==============================] - 0s 250us/step - loss: 0.0711 - val_loss: 0.1484\n",
      "Epoch 1127/1500\n",
      "28/28 [==============================] - 0s 248us/step - loss: 0.0711 - val_loss: 0.1483\n",
      "Epoch 1128/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0711 - val_loss: 0.1483\n",
      "Epoch 1129/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.0711 - val_loss: 0.1483\n",
      "Epoch 1130/1500\n",
      "28/28 [==============================] - 0s 237us/step - loss: 0.0710 - val_loss: 0.1483\n",
      "Epoch 1131/1500\n",
      "28/28 [==============================] - 0s 226us/step - loss: 0.0710 - val_loss: 0.1483\n",
      "Epoch 1132/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.0710 - val_loss: 0.1483\n",
      "Epoch 1133/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0710 - val_loss: 0.1482\n",
      "Epoch 1134/1500\n",
      "28/28 [==============================] - 0s 268us/step - loss: 0.0709 - val_loss: 0.1482\n",
      "Epoch 1135/1500\n",
      "28/28 [==============================] - 0s 193us/step - loss: 0.0709 - val_loss: 0.1482\n",
      "Epoch 1136/1500\n",
      "28/28 [==============================] - 0s 189us/step - loss: 0.0709 - val_loss: 0.1482\n",
      "Epoch 1137/1500\n",
      "28/28 [==============================] - 0s 193us/step - loss: 0.0709 - val_loss: 0.1482\n",
      "Epoch 1138/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0709 - val_loss: 0.1482\n",
      "Epoch 1139/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.0708 - val_loss: 0.1482\n",
      "Epoch 1140/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.0708 - val_loss: 0.1481\n",
      "Epoch 1141/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.0708 - val_loss: 0.1481\n",
      "Epoch 1142/1500\n",
      "28/28 [==============================] - 0s 257us/step - loss: 0.0708 - val_loss: 0.1481\n",
      "Epoch 1143/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.0708 - val_loss: 0.1481\n",
      "Epoch 1144/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.0707 - val_loss: 0.1481\n",
      "Epoch 1145/1500\n",
      "28/28 [==============================] - 0s 199us/step - loss: 0.0707 - val_loss: 0.1481\n",
      "Epoch 1146/1500\n",
      "28/28 [==============================] - 0s 165us/step - loss: 0.0707 - val_loss: 0.1481\n",
      "Epoch 1147/1500\n",
      "28/28 [==============================] - 0s 193us/step - loss: 0.0707 - val_loss: 0.1480\n",
      "Epoch 1148/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.0706 - val_loss: 0.1480\n",
      "Epoch 1149/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.0706 - val_loss: 0.1480\n",
      "Epoch 1150/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0706 - val_loss: 0.1480\n",
      "Epoch 1151/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.0706 - val_loss: 0.1480\n",
      "Epoch 1152/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.0706 - val_loss: 0.1480\n",
      "Epoch 1153/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.0706 - val_loss: 0.1480\n",
      "Epoch 1154/1500\n",
      "28/28 [==============================] - 0s 232us/step - loss: 0.0705 - val_loss: 0.1479\n",
      "Epoch 1155/1500\n",
      "28/28 [==============================] - 0s 191us/step - loss: 0.0705 - val_loss: 0.1479\n",
      "Epoch 1156/1500\n",
      "28/28 [==============================] - 0s 193us/step - loss: 0.0705 - val_loss: 0.1479\n",
      "Epoch 1157/1500\n",
      "28/28 [==============================] - 0s 190us/step - loss: 0.0705 - val_loss: 0.1479\n",
      "Epoch 1158/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.0705 - val_loss: 0.1479\n",
      "Epoch 1159/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.0704 - val_loss: 0.1479\n",
      "Epoch 1160/1500\n",
      "28/28 [==============================] - 0s 186us/step - loss: 0.0704 - val_loss: 0.1479\n",
      "Epoch 1161/1500\n",
      "28/28 [==============================] - 0s 185us/step - loss: 0.0704 - val_loss: 0.1478\n",
      "Epoch 1162/1500\n",
      "28/28 [==============================] - 0s 179us/step - loss: 0.0704 - val_loss: 0.1478\n",
      "Epoch 1163/1500\n",
      "28/28 [==============================] - 0s 183us/step - loss: 0.0704 - val_loss: 0.1478\n",
      "Epoch 1164/1500\n",
      "28/28 [==============================] - 0s 178us/step - loss: 0.0703 - val_loss: 0.1478\n",
      "Epoch 1165/1500\n",
      "28/28 [==============================] - 0s 205us/step - loss: 0.0703 - val_loss: 0.1478\n",
      "Epoch 1166/1500\n",
      "28/28 [==============================] - 0s 236us/step - loss: 0.0703 - val_loss: 0.1478\n",
      "Epoch 1167/1500\n",
      "28/28 [==============================] - 0s 202us/step - loss: 0.0703 - val_loss: 0.1478\n",
      "Epoch 1168/1500\n",
      "28/28 [==============================] - 0s 196us/step - loss: 0.0703 - val_loss: 0.1478\n",
      "Epoch 1169/1500\n",
      "28/28 [==============================] - 0s 189us/step - loss: 0.0702 - val_loss: 0.1477\n",
      "Epoch 1170/1500\n",
      "28/28 [==============================] - 0s 185us/step - loss: 0.0702 - val_loss: 0.1477\n",
      "Epoch 1171/1500\n",
      "28/28 [==============================] - 0s 202us/step - loss: 0.0702 - val_loss: 0.1477\n",
      "Epoch 1172/1500\n",
      "28/28 [==============================] - 0s 183us/step - loss: 0.0702 - val_loss: 0.1477\n",
      "Epoch 1173/1500\n",
      "28/28 [==============================] - 0s 187us/step - loss: 0.0702 - val_loss: 0.1477\n",
      "Epoch 1174/1500\n",
      "28/28 [==============================] - 0s 188us/step - loss: 0.0702 - val_loss: 0.1477\n",
      "Epoch 1175/1500\n",
      "28/28 [==============================] - 0s 184us/step - loss: 0.0701 - val_loss: 0.1477\n",
      "Epoch 1176/1500\n",
      "28/28 [==============================] - 0s 171us/step - loss: 0.0701 - val_loss: 0.1477\n",
      "Epoch 1177/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.0701 - val_loss: 0.1476\n",
      "Epoch 1178/1500\n",
      "28/28 [==============================] - 0s 173us/step - loss: 0.0701 - val_loss: 0.1476\n",
      "Epoch 1179/1500\n",
      "28/28 [==============================] - 0s 173us/step - loss: 0.0701 - val_loss: 0.1476\n",
      "Epoch 1180/1500\n",
      "28/28 [==============================] - 0s 190us/step - loss: 0.0701 - val_loss: 0.1476\n",
      "Epoch 1181/1500\n",
      "28/28 [==============================] - 0s 170us/step - loss: 0.0700 - val_loss: 0.1476\n",
      "Epoch 1182/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.0700 - val_loss: 0.1476\n",
      "Epoch 1183/1500\n",
      "28/28 [==============================] - 0s 190us/step - loss: 0.0700 - val_loss: 0.1476\n",
      "Epoch 1184/1500\n",
      "28/28 [==============================] - 0s 192us/step - loss: 0.0700 - val_loss: 0.1476\n",
      "Epoch 1185/1500\n",
      "28/28 [==============================] - 0s 192us/step - loss: 0.0700 - val_loss: 0.1476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1186/1500\n",
      "28/28 [==============================] - 0s 189us/step - loss: 0.0700 - val_loss: 0.1475\n",
      "Epoch 1187/1500\n",
      "28/28 [==============================] - 0s 182us/step - loss: 0.0699 - val_loss: 0.1475\n",
      "Epoch 1188/1500\n",
      "28/28 [==============================] - 0s 194us/step - loss: 0.0699 - val_loss: 0.1475\n",
      "Epoch 1189/1500\n",
      "28/28 [==============================] - 0s 182us/step - loss: 0.0699 - val_loss: 0.1475\n",
      "Epoch 1190/1500\n",
      "28/28 [==============================] - 0s 192us/step - loss: 0.0699 - val_loss: 0.1475\n",
      "Epoch 1191/1500\n",
      "28/28 [==============================] - 0s 175us/step - loss: 0.0699 - val_loss: 0.1475\n",
      "Epoch 1192/1500\n",
      "28/28 [==============================] - 0s 186us/step - loss: 0.0699 - val_loss: 0.1475\n",
      "Epoch 1193/1500\n",
      "28/28 [==============================] - 0s 200us/step - loss: 0.0698 - val_loss: 0.1475\n",
      "Epoch 1194/1500\n",
      "28/28 [==============================] - 0s 182us/step - loss: 0.0698 - val_loss: 0.1475\n",
      "Epoch 1195/1500\n",
      "28/28 [==============================] - 0s 200us/step - loss: 0.0698 - val_loss: 0.1474\n",
      "Epoch 1196/1500\n",
      "28/28 [==============================] - 0s 359us/step - loss: 0.0698 - val_loss: 0.1474\n",
      "Epoch 1197/1500\n",
      "28/28 [==============================] - 0s 255us/step - loss: 0.0698 - val_loss: 0.1474\n",
      "Epoch 1198/1500\n",
      "28/28 [==============================] - 0s 277us/step - loss: 0.0698 - val_loss: 0.1474\n",
      "Epoch 1199/1500\n",
      "28/28 [==============================] - 0s 175us/step - loss: 0.0697 - val_loss: 0.1474\n",
      "Epoch 1200/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.0697 - val_loss: 0.1474\n",
      "Epoch 1201/1500\n",
      "28/28 [==============================] - 0s 175us/step - loss: 0.0697 - val_loss: 0.1474\n",
      "Epoch 1202/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.0697 - val_loss: 0.1474\n",
      "Epoch 1203/1500\n",
      "28/28 [==============================] - 0s 230us/step - loss: 0.0697 - val_loss: 0.1474\n",
      "Epoch 1204/1500\n",
      "28/28 [==============================] - 0s 244us/step - loss: 0.0697 - val_loss: 0.1474\n",
      "Epoch 1205/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0697 - val_loss: 0.1474\n",
      "Epoch 1206/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.0696 - val_loss: 0.1473\n",
      "Epoch 1207/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0696 - val_loss: 0.1473\n",
      "Epoch 1208/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.0696 - val_loss: 0.1473\n",
      "Epoch 1209/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.0696 - val_loss: 0.1473\n",
      "Epoch 1210/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.0696 - val_loss: 0.1473\n",
      "Epoch 1211/1500\n",
      "28/28 [==============================] - 0s 325us/step - loss: 0.0696 - val_loss: 0.1473\n",
      "Epoch 1212/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0696 - val_loss: 0.1473\n",
      "Epoch 1213/1500\n",
      "28/28 [==============================] - 0s 273us/step - loss: 0.0695 - val_loss: 0.1473\n",
      "Epoch 1214/1500\n",
      "28/28 [==============================] - 0s 271us/step - loss: 0.0695 - val_loss: 0.1473\n",
      "Epoch 1215/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0695 - val_loss: 0.1473\n",
      "Epoch 1216/1500\n",
      "28/28 [==============================] - 0s 231us/step - loss: 0.0695 - val_loss: 0.1473\n",
      "Epoch 1217/1500\n",
      "28/28 [==============================] - 0s 274us/step - loss: 0.0695 - val_loss: 0.1472\n",
      "Epoch 1218/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0695 - val_loss: 0.1472\n",
      "Epoch 1219/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0695 - val_loss: 0.1472\n",
      "Epoch 1220/1500\n",
      "28/28 [==============================] - 0s 267us/step - loss: 0.0694 - val_loss: 0.1472\n",
      "Epoch 1221/1500\n",
      "28/28 [==============================] - 0s 273us/step - loss: 0.0694 - val_loss: 0.1472\n",
      "Epoch 1222/1500\n",
      "28/28 [==============================] - 0s 194us/step - loss: 0.0694 - val_loss: 0.1472\n",
      "Epoch 1223/1500\n",
      "28/28 [==============================] - 0s 269us/step - loss: 0.0694 - val_loss: 0.1472\n",
      "Epoch 1224/1500\n",
      "28/28 [==============================] - 0s 254us/step - loss: 0.0694 - val_loss: 0.1472\n",
      "Epoch 1225/1500\n",
      "28/28 [==============================] - 0s 262us/step - loss: 0.0694 - val_loss: 0.1472\n",
      "Epoch 1226/1500\n",
      "28/28 [==============================] - 0s 209us/step - loss: 0.0694 - val_loss: 0.1472\n",
      "Epoch 1227/1500\n",
      "28/28 [==============================] - 0s 281us/step - loss: 0.0693 - val_loss: 0.1472\n",
      "Epoch 1228/1500\n",
      "28/28 [==============================] - 0s 245us/step - loss: 0.0693 - val_loss: 0.1471\n",
      "Epoch 1229/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.0693 - val_loss: 0.1471\n",
      "Epoch 1230/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0693 - val_loss: 0.1471\n",
      "Epoch 1231/1500\n",
      "28/28 [==============================] - 0s 246us/step - loss: 0.0693 - val_loss: 0.1471\n",
      "Epoch 1232/1500\n",
      "28/28 [==============================] - 0s 179us/step - loss: 0.0693 - val_loss: 0.1471\n",
      "Epoch 1233/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.0693 - val_loss: 0.1471\n",
      "Epoch 1234/1500\n",
      "28/28 [==============================] - 0s 273us/step - loss: 0.0693 - val_loss: 0.1471\n",
      "Epoch 1235/1500\n",
      "28/28 [==============================] - 0s 264us/step - loss: 0.0692 - val_loss: 0.1471\n",
      "Epoch 1236/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.0692 - val_loss: 0.1471\n",
      "Epoch 1237/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.0692 - val_loss: 0.1471\n",
      "Epoch 1238/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.0692 - val_loss: 0.1471\n",
      "Epoch 1239/1500\n",
      "28/28 [==============================] - 0s 246us/step - loss: 0.0692 - val_loss: 0.1471\n",
      "Epoch 1240/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.0692 - val_loss: 0.1471\n",
      "Epoch 1241/1500\n",
      "28/28 [==============================] - 0s 247us/step - loss: 0.0692 - val_loss: 0.1471\n",
      "Epoch 1242/1500\n",
      "28/28 [==============================] - 0s 216us/step - loss: 0.0691 - val_loss: 0.1470\n",
      "Epoch 1243/1500\n",
      "28/28 [==============================] - 0s 270us/step - loss: 0.0691 - val_loss: 0.1470\n",
      "Epoch 1244/1500\n",
      "28/28 [==============================] - 0s 196us/step - loss: 0.0691 - val_loss: 0.1470\n",
      "Epoch 1245/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.0691 - val_loss: 0.1470\n",
      "Epoch 1246/1500\n",
      "28/28 [==============================] - 0s 230us/step - loss: 0.0691 - val_loss: 0.1470\n",
      "Epoch 1247/1500\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.0691 - val_loss: 0.1470\n",
      "Epoch 1248/1500\n",
      "28/28 [==============================] - 0s 235us/step - loss: 0.0691 - val_loss: 0.1470\n",
      "Epoch 1249/1500\n",
      "28/28 [==============================] - 0s 251us/step - loss: 0.0691 - val_loss: 0.1470\n",
      "Epoch 1250/1500\n",
      "28/28 [==============================] - 0s 244us/step - loss: 0.0691 - val_loss: 0.1470\n",
      "Epoch 1251/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.0690 - val_loss: 0.1470\n",
      "Epoch 1252/1500\n",
      "28/28 [==============================] - 0s 252us/step - loss: 0.0690 - val_loss: 0.1470\n",
      "Epoch 1253/1500\n",
      "28/28 [==============================] - 0s 262us/step - loss: 0.0690 - val_loss: 0.1470\n",
      "Epoch 1254/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.0690 - val_loss: 0.1470\n",
      "Epoch 1255/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.0690 - val_loss: 0.1470\n",
      "Epoch 1256/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.0690 - val_loss: 0.1469\n",
      "Epoch 1257/1500\n",
      "28/28 [==============================] - 0s 200us/step - loss: 0.0690 - val_loss: 0.1469\n",
      "Epoch 1258/1500\n",
      "28/28 [==============================] - 0s 243us/step - loss: 0.0690 - val_loss: 0.1469\n",
      "Epoch 1259/1500\n",
      "28/28 [==============================] - 0s 243us/step - loss: 0.0689 - val_loss: 0.1469\n",
      "Epoch 1260/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.0689 - val_loss: 0.1469\n",
      "Epoch 1261/1500\n",
      "28/28 [==============================] - 0s 240us/step - loss: 0.0689 - val_loss: 0.1469\n",
      "Epoch 1262/1500\n",
      "28/28 [==============================] - 0s 216us/step - loss: 0.0689 - val_loss: 0.1469\n",
      "Epoch 1263/1500\n",
      "28/28 [==============================] - 0s 247us/step - loss: 0.0689 - val_loss: 0.1469\n",
      "Epoch 1264/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 251us/step - loss: 0.0689 - val_loss: 0.1469\n",
      "Epoch 1265/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.0689 - val_loss: 0.1469\n",
      "Epoch 1266/1500\n",
      "28/28 [==============================] - 0s 237us/step - loss: 0.0689 - val_loss: 0.1469\n",
      "Epoch 1267/1500\n",
      "28/28 [==============================] - 0s 248us/step - loss: 0.0689 - val_loss: 0.1469\n",
      "Epoch 1268/1500\n",
      "28/28 [==============================] - 0s 205us/step - loss: 0.0688 - val_loss: 0.1469\n",
      "Epoch 1269/1500\n",
      "28/28 [==============================] - 0s 242us/step - loss: 0.0688 - val_loss: 0.1469\n",
      "Epoch 1270/1500\n",
      "28/28 [==============================] - 0s 177us/step - loss: 0.0688 - val_loss: 0.1469\n",
      "Epoch 1271/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0688 - val_loss: 0.1469\n",
      "Epoch 1272/1500\n",
      "28/28 [==============================] - 0s 259us/step - loss: 0.0688 - val_loss: 0.1469\n",
      "Epoch 1273/1500\n",
      "28/28 [==============================] - 0s 239us/step - loss: 0.0688 - val_loss: 0.1468\n",
      "Epoch 1274/1500\n",
      "28/28 [==============================] - 0s 192us/step - loss: 0.0688 - val_loss: 0.1468\n",
      "Epoch 1275/1500\n",
      "28/28 [==============================] - 0s 207us/step - loss: 0.0688 - val_loss: 0.1468\n",
      "Epoch 1276/1500\n",
      "28/28 [==============================] - 0s 273us/step - loss: 0.0688 - val_loss: 0.1468\n",
      "Epoch 1277/1500\n",
      "28/28 [==============================] - 0s 238us/step - loss: 0.0687 - val_loss: 0.1468\n",
      "Epoch 1278/1500\n",
      "28/28 [==============================] - 0s 282us/step - loss: 0.0687 - val_loss: 0.1468\n",
      "Epoch 1279/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.0687 - val_loss: 0.1468\n",
      "Epoch 1280/1500\n",
      "28/28 [==============================] - 0s 375us/step - loss: 0.0687 - val_loss: 0.1468\n",
      "Epoch 1281/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0687 - val_loss: 0.1468\n",
      "Epoch 1282/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.0687 - val_loss: 0.1468\n",
      "Epoch 1283/1500\n",
      "28/28 [==============================] - 0s 238us/step - loss: 0.0687 - val_loss: 0.1468\n",
      "Epoch 1284/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0687 - val_loss: 0.1468\n",
      "Epoch 1285/1500\n",
      "28/28 [==============================] - 0s 252us/step - loss: 0.0687 - val_loss: 0.1468\n",
      "Epoch 1286/1500\n",
      "28/28 [==============================] - 0s 216us/step - loss: 0.0687 - val_loss: 0.1468\n",
      "Epoch 1287/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.0686 - val_loss: 0.1468\n",
      "Epoch 1288/1500\n",
      "28/28 [==============================] - 0s 184us/step - loss: 0.0686 - val_loss: 0.1468\n",
      "Epoch 1289/1500\n",
      "28/28 [==============================] - 0s 241us/step - loss: 0.0686 - val_loss: 0.1468\n",
      "Epoch 1290/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 0.0686 - val_loss: 0.1468\n",
      "Epoch 1291/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.0686 - val_loss: 0.1467\n",
      "Epoch 1292/1500\n",
      "28/28 [==============================] - 0s 194us/step - loss: 0.0686 - val_loss: 0.1467\n",
      "Epoch 1293/1500\n",
      "28/28 [==============================] - 0s 194us/step - loss: 0.0686 - val_loss: 0.1467\n",
      "Epoch 1294/1500\n",
      "28/28 [==============================] - 0s 249us/step - loss: 0.0686 - val_loss: 0.1467\n",
      "Epoch 1295/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.0686 - val_loss: 0.1467\n",
      "Epoch 1296/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.0686 - val_loss: 0.1467\n",
      "Epoch 1297/1500\n",
      "28/28 [==============================] - 0s 184us/step - loss: 0.0685 - val_loss: 0.1467\n",
      "Epoch 1298/1500\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.0685 - val_loss: 0.1467\n",
      "Epoch 1299/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.0685 - val_loss: 0.1467\n",
      "Epoch 1300/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.0685 - val_loss: 0.1467\n",
      "Epoch 1301/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0685 - val_loss: 0.1467\n",
      "Epoch 1302/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.0685 - val_loss: 0.1467\n",
      "Epoch 1303/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.0685 - val_loss: 0.1467\n",
      "Epoch 1304/1500\n",
      "28/28 [==============================] - 0s 260us/step - loss: 0.0685 - val_loss: 0.1467\n",
      "Epoch 1305/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.0685 - val_loss: 0.1467\n",
      "Epoch 1306/1500\n",
      "28/28 [==============================] - 0s 157us/step - loss: 0.0685 - val_loss: 0.1467\n",
      "Epoch 1307/1500\n",
      "28/28 [==============================] - 0s 202us/step - loss: 0.0684 - val_loss: 0.1467\n",
      "Epoch 1308/1500\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0684 - val_loss: 0.1467\n",
      "Epoch 1309/1500\n",
      "28/28 [==============================] - 0s 277us/step - loss: 0.0684 - val_loss: 0.1467\n",
      "Epoch 1310/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.0684 - val_loss: 0.1467\n",
      "Epoch 1311/1500\n",
      "28/28 [==============================] - 0s 263us/step - loss: 0.0684 - val_loss: 0.1467\n",
      "Epoch 1312/1500\n",
      "28/28 [==============================] - 0s 187us/step - loss: 0.0684 - val_loss: 0.1467\n",
      "Epoch 1313/1500\n",
      "28/28 [==============================] - 0s 179us/step - loss: 0.0684 - val_loss: 0.1466\n",
      "Epoch 1314/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0684 - val_loss: 0.1466\n",
      "Epoch 1315/1500\n",
      "28/28 [==============================] - 0s 246us/step - loss: 0.0684 - val_loss: 0.1466\n",
      "Epoch 1316/1500\n",
      "28/28 [==============================] - 0s 186us/step - loss: 0.0684 - val_loss: 0.1466\n",
      "Epoch 1317/1500\n",
      "28/28 [==============================] - 0s 194us/step - loss: 0.0684 - val_loss: 0.1466\n",
      "Epoch 1318/1500\n",
      "28/28 [==============================] - 0s 192us/step - loss: 0.0683 - val_loss: 0.1466\n",
      "Epoch 1319/1500\n",
      "28/28 [==============================] - 0s 207us/step - loss: 0.0683 - val_loss: 0.1466\n",
      "Epoch 1320/1500\n",
      "28/28 [==============================] - 0s 241us/step - loss: 0.0683 - val_loss: 0.1466\n",
      "Epoch 1321/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.0683 - val_loss: 0.1466\n",
      "Epoch 1322/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.0683 - val_loss: 0.1466\n",
      "Epoch 1323/1500\n",
      "28/28 [==============================] - 0s 268us/step - loss: 0.0683 - val_loss: 0.1466\n",
      "Epoch 1324/1500\n",
      "28/28 [==============================] - 0s 240us/step - loss: 0.0683 - val_loss: 0.1466\n",
      "Epoch 1325/1500\n",
      "28/28 [==============================] - 0s 297us/step - loss: 0.0683 - val_loss: 0.1466\n",
      "Epoch 1326/1500\n",
      "28/28 [==============================] - 0s 312us/step - loss: 0.0683 - val_loss: 0.1466\n",
      "Epoch 1327/1500\n",
      "28/28 [==============================] - 0s 247us/step - loss: 0.0683 - val_loss: 0.1466\n",
      "Epoch 1328/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0683 - val_loss: 0.1466\n",
      "Epoch 1329/1500\n",
      "28/28 [==============================] - 0s 176us/step - loss: 0.0683 - val_loss: 0.1466\n",
      "Epoch 1330/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0682 - val_loss: 0.1466\n",
      "Epoch 1331/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.0682 - val_loss: 0.1466\n",
      "Epoch 1332/1500\n",
      "28/28 [==============================] - 0s 302us/step - loss: 0.0682 - val_loss: 0.1466\n",
      "Epoch 1333/1500\n",
      "28/28 [==============================] - 0s 230us/step - loss: 0.0682 - val_loss: 0.1466\n",
      "Epoch 1334/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0682 - val_loss: 0.1466\n",
      "Epoch 1335/1500\n",
      "28/28 [==============================] - 0s 233us/step - loss: 0.0682 - val_loss: 0.1466\n",
      "Epoch 1336/1500\n",
      "28/28 [==============================] - 0s 226us/step - loss: 0.0682 - val_loss: 0.1466\n",
      "Epoch 1337/1500\n",
      "28/28 [==============================] - 0s 216us/step - loss: 0.0682 - val_loss: 0.1466\n",
      "Epoch 1338/1500\n",
      "28/28 [==============================] - 0s 254us/step - loss: 0.0682 - val_loss: 0.1466\n",
      "Epoch 1339/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.0682 - val_loss: 0.1465\n",
      "Epoch 1340/1500\n",
      "28/28 [==============================] - 0s 269us/step - loss: 0.0682 - val_loss: 0.1465\n",
      "Epoch 1341/1500\n",
      "28/28 [==============================] - 0s 249us/step - loss: 0.0682 - val_loss: 0.1465\n",
      "Epoch 1342/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.0681 - val_loss: 0.1465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1343/1500\n",
      "28/28 [==============================] - 0s 267us/step - loss: 0.0681 - val_loss: 0.1465\n",
      "Epoch 1344/1500\n",
      "28/28 [==============================] - 0s 279us/step - loss: 0.0681 - val_loss: 0.1465\n",
      "Epoch 1345/1500\n",
      "28/28 [==============================] - 0s 233us/step - loss: 0.0681 - val_loss: 0.1465\n",
      "Epoch 1346/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0681 - val_loss: 0.1465\n",
      "Epoch 1347/1500\n",
      "28/28 [==============================] - 0s 226us/step - loss: 0.0681 - val_loss: 0.1465\n",
      "Epoch 1348/1500\n",
      "28/28 [==============================] - 0s 205us/step - loss: 0.0681 - val_loss: 0.1465\n",
      "Epoch 1349/1500\n",
      "28/28 [==============================] - 0s 263us/step - loss: 0.0681 - val_loss: 0.1465\n",
      "Epoch 1350/1500\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.0681 - val_loss: 0.1465\n",
      "Epoch 1351/1500\n",
      "28/28 [==============================] - 0s 235us/step - loss: 0.0681 - val_loss: 0.1465\n",
      "Epoch 1352/1500\n",
      "28/28 [==============================] - 0s 380us/step - loss: 0.0681 - val_loss: 0.1465\n",
      "Epoch 1353/1500\n",
      "28/28 [==============================] - 0s 187us/step - loss: 0.0681 - val_loss: 0.1465\n",
      "Epoch 1354/1500\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.0680 - val_loss: 0.1465\n",
      "Epoch 1355/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.0680 - val_loss: 0.1465\n",
      "Epoch 1356/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0680 - val_loss: 0.1465\n",
      "Epoch 1357/1500\n",
      "28/28 [==============================] - 0s 190us/step - loss: 0.0680 - val_loss: 0.1465\n",
      "Epoch 1358/1500\n",
      "28/28 [==============================] - 0s 249us/step - loss: 0.0680 - val_loss: 0.1465\n",
      "Epoch 1359/1500\n",
      "28/28 [==============================] - 0s 293us/step - loss: 0.0680 - val_loss: 0.1465\n",
      "Epoch 1360/1500\n",
      "28/28 [==============================] - 0s 251us/step - loss: 0.0680 - val_loss: 0.1465\n",
      "Epoch 1361/1500\n",
      "28/28 [==============================] - 0s 274us/step - loss: 0.0680 - val_loss: 0.1465\n",
      "Epoch 1362/1500\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.0680 - val_loss: 0.1465\n",
      "Epoch 1363/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.0680 - val_loss: 0.1465\n",
      "Epoch 1364/1500\n",
      "28/28 [==============================] - 0s 231us/step - loss: 0.0680 - val_loss: 0.1465\n",
      "Epoch 1365/1500\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.0680 - val_loss: 0.1465\n",
      "Epoch 1366/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.0680 - val_loss: 0.1465\n",
      "Epoch 1367/1500\n",
      "28/28 [==============================] - 0s 230us/step - loss: 0.0679 - val_loss: 0.1465\n",
      "Epoch 1368/1500\n",
      "28/28 [==============================] - 0s 235us/step - loss: 0.0679 - val_loss: 0.1465\n",
      "Epoch 1369/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0679 - val_loss: 0.1465\n",
      "Epoch 1370/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.0679 - val_loss: 0.1465\n",
      "Epoch 1371/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.0679 - val_loss: 0.1465\n",
      "Epoch 1372/1500\n",
      "28/28 [==============================] - 0s 281us/step - loss: 0.0679 - val_loss: 0.1464\n",
      "Epoch 1373/1500\n",
      "28/28 [==============================] - 0s 237us/step - loss: 0.0679 - val_loss: 0.1464\n",
      "Epoch 1374/1500\n",
      "28/28 [==============================] - 0s 241us/step - loss: 0.0679 - val_loss: 0.1464\n",
      "Epoch 1375/1500\n",
      "28/28 [==============================] - 0s 251us/step - loss: 0.0679 - val_loss: 0.1464\n",
      "Epoch 1376/1500\n",
      "28/28 [==============================] - 0s 243us/step - loss: 0.0679 - val_loss: 0.1464\n",
      "Epoch 1377/1500\n",
      "28/28 [==============================] - 0s 278us/step - loss: 0.0679 - val_loss: 0.1464\n",
      "Epoch 1378/1500\n",
      "28/28 [==============================] - 0s 199us/step - loss: 0.0679 - val_loss: 0.1464\n",
      "Epoch 1379/1500\n",
      "28/28 [==============================] - 0s 216us/step - loss: 0.0679 - val_loss: 0.1464\n",
      "Epoch 1380/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.0679 - val_loss: 0.1464\n",
      "Epoch 1381/1500\n",
      "28/28 [==============================] - 0s 251us/step - loss: 0.0678 - val_loss: 0.1464\n",
      "Epoch 1382/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.0678 - val_loss: 0.1464\n",
      "Epoch 1383/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.0678 - val_loss: 0.1464\n",
      "Epoch 1384/1500\n",
      "28/28 [==============================] - 0s 192us/step - loss: 0.0678 - val_loss: 0.1464\n",
      "Epoch 1385/1500\n",
      "28/28 [==============================] - 0s 249us/step - loss: 0.0678 - val_loss: 0.1464\n",
      "Epoch 1386/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.0678 - val_loss: 0.1464\n",
      "Epoch 1387/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0678 - val_loss: 0.1464\n",
      "Epoch 1388/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.0678 - val_loss: 0.1464\n",
      "Epoch 1389/1500\n",
      "28/28 [==============================] - 0s 209us/step - loss: 0.0678 - val_loss: 0.1464\n",
      "Epoch 1390/1500\n",
      "28/28 [==============================] - 0s 293us/step - loss: 0.0678 - val_loss: 0.1464\n",
      "Epoch 1391/1500\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0678 - val_loss: 0.1464\n",
      "Epoch 1392/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.0678 - val_loss: 0.1464\n",
      "Epoch 1393/1500\n",
      "28/28 [==============================] - 0s 268us/step - loss: 0.0678 - val_loss: 0.1464\n",
      "Epoch 1394/1500\n",
      "28/28 [==============================] - 0s 277us/step - loss: 0.0678 - val_loss: 0.1464\n",
      "Epoch 1395/1500\n",
      "28/28 [==============================] - 0s 200us/step - loss: 0.0678 - val_loss: 0.1464\n",
      "Epoch 1396/1500\n",
      "28/28 [==============================] - 0s 263us/step - loss: 0.0677 - val_loss: 0.1464\n",
      "Epoch 1397/1500\n",
      "28/28 [==============================] - 0s 274us/step - loss: 0.0677 - val_loss: 0.1464\n",
      "Epoch 1398/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.0677 - val_loss: 0.1464\n",
      "Epoch 1399/1500\n",
      "28/28 [==============================] - 0s 205us/step - loss: 0.0677 - val_loss: 0.1464\n",
      "Epoch 1400/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.0677 - val_loss: 0.1464\n",
      "Epoch 1401/1500\n",
      "28/28 [==============================] - 0s 235us/step - loss: 0.0677 - val_loss: 0.1464\n",
      "Epoch 1402/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.0677 - val_loss: 0.1464\n",
      "Epoch 1403/1500\n",
      "28/28 [==============================] - 0s 240us/step - loss: 0.0677 - val_loss: 0.1464\n",
      "Epoch 1404/1500\n",
      "28/28 [==============================] - 0s 268us/step - loss: 0.0677 - val_loss: 0.1464\n",
      "Epoch 1405/1500\n",
      "28/28 [==============================] - 0s 232us/step - loss: 0.0677 - val_loss: 0.1464\n",
      "Epoch 1406/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.0677 - val_loss: 0.1464\n",
      "Epoch 1407/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.0677 - val_loss: 0.1464\n",
      "Epoch 1408/1500\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.0677 - val_loss: 0.1464\n",
      "Epoch 1409/1500\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.0677 - val_loss: 0.1464\n",
      "Epoch 1410/1500\n",
      "28/28 [==============================] - 0s 257us/step - loss: 0.0677 - val_loss: 0.1464\n",
      "Epoch 1411/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.0676 - val_loss: 0.1464\n",
      "Epoch 1412/1500\n",
      "28/28 [==============================] - 0s 242us/step - loss: 0.0676 - val_loss: 0.1464\n",
      "Epoch 1413/1500\n",
      "28/28 [==============================] - 0s 235us/step - loss: 0.0676 - val_loss: 0.1464\n",
      "Epoch 1414/1500\n",
      "28/28 [==============================] - 0s 231us/step - loss: 0.0676 - val_loss: 0.1464\n",
      "Epoch 1415/1500\n",
      "28/28 [==============================] - 0s 238us/step - loss: 0.0676 - val_loss: 0.1464\n",
      "Epoch 1416/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.0676 - val_loss: 0.1464\n",
      "Epoch 1417/1500\n",
      "28/28 [==============================] - 0s 194us/step - loss: 0.0676 - val_loss: 0.1463\n",
      "Epoch 1418/1500\n",
      "28/28 [==============================] - 0s 187us/step - loss: 0.0676 - val_loss: 0.1463\n",
      "Epoch 1419/1500\n",
      "28/28 [==============================] - 0s 172us/step - loss: 0.0676 - val_loss: 0.1463\n",
      "Epoch 1420/1500\n",
      "28/28 [==============================] - 0s 290us/step - loss: 0.0676 - val_loss: 0.1463\n",
      "Epoch 1421/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 234us/step - loss: 0.0676 - val_loss: 0.1463\n",
      "Epoch 1422/1500\n",
      "28/28 [==============================] - 0s 263us/step - loss: 0.0676 - val_loss: 0.1463\n",
      "Epoch 1423/1500\n",
      "28/28 [==============================] - 0s 238us/step - loss: 0.0676 - val_loss: 0.1463\n",
      "Epoch 1424/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 0.0676 - val_loss: 0.1463\n",
      "Epoch 1425/1500\n",
      "28/28 [==============================] - 0s 207us/step - loss: 0.0676 - val_loss: 0.1463\n",
      "Epoch 1426/1500\n",
      "28/28 [==============================] - 0s 260us/step - loss: 0.0676 - val_loss: 0.1463\n",
      "Epoch 1427/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0675 - val_loss: 0.1463\n",
      "Epoch 1428/1500\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.0675 - val_loss: 0.1463\n",
      "Epoch 1429/1500\n",
      "28/28 [==============================] - 0s 231us/step - loss: 0.0675 - val_loss: 0.1463\n",
      "Epoch 1430/1500\n",
      "28/28 [==============================] - 0s 263us/step - loss: 0.0675 - val_loss: 0.1463\n",
      "Epoch 1431/1500\n",
      "28/28 [==============================] - 0s 252us/step - loss: 0.0675 - val_loss: 0.1463\n",
      "Epoch 1432/1500\n",
      "28/28 [==============================] - 0s 238us/step - loss: 0.0675 - val_loss: 0.1463\n",
      "Epoch 1433/1500\n",
      "28/28 [==============================] - 0s 187us/step - loss: 0.0675 - val_loss: 0.1463\n",
      "Epoch 1434/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0675 - val_loss: 0.1463\n",
      "Epoch 1435/1500\n",
      "28/28 [==============================] - 0s 193us/step - loss: 0.0675 - val_loss: 0.1463\n",
      "Epoch 1436/1500\n",
      "28/28 [==============================] - 0s 238us/step - loss: 0.0675 - val_loss: 0.1463\n",
      "Epoch 1437/1500\n",
      "28/28 [==============================] - 0s 243us/step - loss: 0.0675 - val_loss: 0.1463\n",
      "Epoch 1438/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.0675 - val_loss: 0.1463\n",
      "Epoch 1439/1500\n",
      "28/28 [==============================] - 0s 209us/step - loss: 0.0675 - val_loss: 0.1463\n",
      "Epoch 1440/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.0675 - val_loss: 0.1463\n",
      "Epoch 1441/1500\n",
      "28/28 [==============================] - 0s 254us/step - loss: 0.0675 - val_loss: 0.1463\n",
      "Epoch 1442/1500\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.0675 - val_loss: 0.1463\n",
      "Epoch 1443/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0675 - val_loss: 0.1463\n",
      "Epoch 1444/1500\n",
      "28/28 [==============================] - 0s 209us/step - loss: 0.0674 - val_loss: 0.1463\n",
      "Epoch 1445/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0674 - val_loss: 0.1463\n",
      "Epoch 1446/1500\n",
      "28/28 [==============================] - 0s 252us/step - loss: 0.0674 - val_loss: 0.1463\n",
      "Epoch 1447/1500\n",
      "28/28 [==============================] - 0s 240us/step - loss: 0.0674 - val_loss: 0.1463\n",
      "Epoch 1448/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.0674 - val_loss: 0.1463\n",
      "Epoch 1449/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.0674 - val_loss: 0.1463\n",
      "Epoch 1450/1500\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.0674 - val_loss: 0.1463\n",
      "Epoch 1451/1500\n",
      "28/28 [==============================] - 0s 241us/step - loss: 0.0674 - val_loss: 0.1463\n",
      "Epoch 1452/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.0674 - val_loss: 0.1463\n",
      "Epoch 1453/1500\n",
      "28/28 [==============================] - 0s 190us/step - loss: 0.0674 - val_loss: 0.1463\n",
      "Epoch 1454/1500\n",
      "28/28 [==============================] - 0s 185us/step - loss: 0.0674 - val_loss: 0.1463\n",
      "Epoch 1455/1500\n",
      "28/28 [==============================] - 0s 278us/step - loss: 0.0674 - val_loss: 0.1463\n",
      "Epoch 1456/1500\n",
      "28/28 [==============================] - 0s 216us/step - loss: 0.0674 - val_loss: 0.1463\n",
      "Epoch 1457/1500\n",
      "28/28 [==============================] - 0s 216us/step - loss: 0.0674 - val_loss: 0.1463\n",
      "Epoch 1458/1500\n",
      "28/28 [==============================] - 0s 188us/step - loss: 0.0674 - val_loss: 0.1463\n",
      "Epoch 1459/1500\n",
      "28/28 [==============================] - 0s 205us/step - loss: 0.0674 - val_loss: 0.1463\n",
      "Epoch 1460/1500\n",
      "28/28 [==============================] - 0s 166us/step - loss: 0.0674 - val_loss: 0.1463\n",
      "Epoch 1461/1500\n",
      "28/28 [==============================] - 0s 262us/step - loss: 0.0673 - val_loss: 0.1463\n",
      "Epoch 1462/1500\n",
      "28/28 [==============================] - 0s 193us/step - loss: 0.0673 - val_loss: 0.1463\n",
      "Epoch 1463/1500\n",
      "28/28 [==============================] - 0s 166us/step - loss: 0.0673 - val_loss: 0.1463\n",
      "Epoch 1464/1500\n",
      "28/28 [==============================] - 0s 192us/step - loss: 0.0673 - val_loss: 0.1463\n",
      "Epoch 1465/1500\n",
      "28/28 [==============================] - 0s 251us/step - loss: 0.0673 - val_loss: 0.1463\n",
      "Epoch 1466/1500\n",
      "28/28 [==============================] - 0s 265us/step - loss: 0.0673 - val_loss: 0.1463\n",
      "Epoch 1467/1500\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.0673 - val_loss: 0.1463\n",
      "Epoch 1468/1500\n",
      "28/28 [==============================] - 0s 250us/step - loss: 0.0673 - val_loss: 0.1463\n",
      "Epoch 1469/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.0673 - val_loss: 0.1463\n",
      "Epoch 1470/1500\n",
      "28/28 [==============================] - 0s 254us/step - loss: 0.0673 - val_loss: 0.1463\n",
      "Epoch 1471/1500\n",
      "28/28 [==============================] - 0s 263us/step - loss: 0.0673 - val_loss: 0.1463\n",
      "Epoch 1472/1500\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0673 - val_loss: 0.1463\n",
      "Epoch 1473/1500\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.0673 - val_loss: 0.1463\n",
      "Epoch 1474/1500\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.0673 - val_loss: 0.1463\n",
      "Epoch 1475/1500\n",
      "28/28 [==============================] - 0s 263us/step - loss: 0.0673 - val_loss: 0.1463\n",
      "Epoch 1476/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.0673 - val_loss: 0.1463\n",
      "Epoch 1477/1500\n",
      "28/28 [==============================] - 0s 186us/step - loss: 0.0673 - val_loss: 0.1463\n",
      "Epoch 1478/1500\n",
      "28/28 [==============================] - 0s 178us/step - loss: 0.0673 - val_loss: 0.1463\n",
      "Epoch 1479/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.0673 - val_loss: 0.1463\n",
      "Epoch 1480/1500\n",
      "28/28 [==============================] - 0s 275us/step - loss: 0.0672 - val_loss: 0.1463\n",
      "Epoch 1481/1500\n",
      "28/28 [==============================] - 0s 252us/step - loss: 0.0672 - val_loss: 0.1463\n",
      "Epoch 1482/1500\n",
      "28/28 [==============================] - 0s 290us/step - loss: 0.0672 - val_loss: 0.1463\n",
      "Epoch 1483/1500\n",
      "28/28 [==============================] - 0s 181us/step - loss: 0.0672 - val_loss: 0.1463\n",
      "Epoch 1484/1500\n",
      "28/28 [==============================] - 0s 231us/step - loss: 0.0672 - val_loss: 0.1463\n",
      "Epoch 1485/1500\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.0672 - val_loss: 0.1462\n",
      "Epoch 1486/1500\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.0672 - val_loss: 0.1462\n",
      "Epoch 1487/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 0.0672 - val_loss: 0.1462\n",
      "Epoch 1488/1500\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.0672 - val_loss: 0.1462\n",
      "Epoch 1489/1500\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.0672 - val_loss: 0.1462\n",
      "Epoch 1490/1500\n",
      "28/28 [==============================] - 0s 242us/step - loss: 0.0672 - val_loss: 0.1462\n",
      "Epoch 1491/1500\n",
      "28/28 [==============================] - 0s 249us/step - loss: 0.0672 - val_loss: 0.1462\n",
      "Epoch 1492/1500\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.0672 - val_loss: 0.1462\n",
      "Epoch 1493/1500\n",
      "28/28 [==============================] - 0s 242us/step - loss: 0.0672 - val_loss: 0.1462\n",
      "Epoch 1494/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 0.0672 - val_loss: 0.1462\n",
      "Epoch 1495/1500\n",
      "28/28 [==============================] - 0s 199us/step - loss: 0.0672 - val_loss: 0.1462\n",
      "Epoch 1496/1500\n",
      "28/28 [==============================] - 0s 219us/step - loss: 0.0672 - val_loss: 0.1462\n",
      "Epoch 1497/1500\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.0672 - val_loss: 0.1462\n",
      "Epoch 1498/1500\n",
      "28/28 [==============================] - 0s 190us/step - loss: 0.0672 - val_loss: 0.1462\n",
      "Epoch 1499/1500\n",
      "28/28 [==============================] - 0s 254us/step - loss: 0.0671 - val_loss: 0.1462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500/1500\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.0671 - val_loss: 0.1462\n"
     ]
    }
   ],
   "source": [
    "# fit the model - INTENSIVE\n",
    "model5_history = model5.fit(X_train, Y_train, batch_size=256, epochs=1500, verbose=1, \\\n",
    "                            shuffle = True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAo4AAAGXCAYAAAA9P9EuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3Xuc1mP+x/HXp4OaTiYUmqxKGqdUTFaiyG4lpyShlMoph/Vbh8g6hV21YkVaQuTQllOyRDmUJCydiKik0BRSppIpTV2/P657Zu77nntm7pm5Z+7DvJ+Pxzzuvtf3ur/fz33fM81nrqM55xARERERKU2NeAcgIiIiIslBiaOIiIiIREWJo4iIiIhERYmjiIiIiERFiaOIiIiIREWJo4iIiIhERYmjSAWY2Ugzc2Y2K8K5F83s3aDjEwN1fzazBmF1rzKzmK6NZWYtAvc7LajsBjM7MUJdZ2ZXlfM+55nZIjP71cyyzexpM2tWynMGB+7ZoKR6ycrMrjCzGWa2MfA6Tyym3mFm9o6Z/WZm68zsTjOrGVbHzOxvZva9meWa2Xtm1r5KXkgJzOxeM1tTBfcZaWY/V/Z9YinSz14Znvuumb1YGXGJxIISR5HY6G5mHaOsuzdweWUGE7Ae6AS8H1R2A3BirG5gZmcAU4APgDOBG4EuwGtmVp3/fxkE7AUU+YMin5k1Bt4GHP69uxO4DrgjrOoI4Fbgn8DpwK/A22a2X+zDTkiPAz3iHYSIeLXiHYBICtgErAVuBnpHUf9d4DozG+ec215ZQTnndgAfVdb1A/oDi5xzBa2VZrYFeAXIBL6s5PvHhJnVBnY753bF6JLHOed2m9kRwPnF1BkGpAF9nHNbgLfMrBEw0szucc5tMbO6+MRxlHPuoUCsHwJrgKuAW2IUb8Jyzq3F/3xJHJhZmnMuN95xSOKozi0CIrHigLuBM8ysbRT17wEaAxdHewMzq2tmO8ysf1DZqEB32BlBZePMbH7g3yHdZYFuxb2B2wPl4V2oNc3sbjPbYGY/mdl4M6tTSmi1gc1hZTn54UT7+gLxjTazpYEu77VmNjm4Vc3MxpjZN2ZmYc8bYma/m9k+geMaZjbCzL4OvGcrzOzCsOe8GxhKcKmZrQK2A83MrLmZPR94/blmtsrM7irL6wBwzu2OotopwKxA0phvKj6Z7Bo4Pg5oBDwfdO1twKuB5xfLzNYEupOvCbyfv5jZVDNLD6vX0symm9kWM9tqZq+aWeuwOulm9h8z22Zm683s5mLu+YfAPTYFut9nmVlmWJ2bAp/NdjP70cxmltR6Gt5VbYVDPk40sxcC3y/fmNkVJb0fQc+/2My+CHxvfGtmN4Sd72Rm/zU/dGCbmS0xswERrnOgmU0xP/TkNzP7LPjnM6CemU0ws82Bz+COsrbEm9khgff0+8B9vjCzv+Zfx8xqBWK9PcJz55rZtKDjEj+foP8zBpgfcpKD/14TKaDEUSQ2XgBW4FsdS/M98DRwg/mWrlIFWiY/AU4IKu6CT3jCy+YVc5mz8EneRHwXdidgUdD564BmwAXAGOAy4P9KCe0J4AQzG2RmjcysDfB3YI5zblkULy1YU3wCfirwV6AVMNsKx/w9DrSkMKnKNxh41TmXn1yMw7fEPRq41svAE1Z0vFln/JCBG/FdwJvxn8sBwKX4xOwfQGnJc3kdAnwVXOCc+w74LXAuv84uYGXYc78MqlOSfsDJ+NdzI3Aa/j0GIPCHwTvAocAl+PeyJTDXzPYKus6T+Pfjr4FrdQfOC75RoP77+JbmYYF718d3q6cF6gwC/gb8C9/9fDnwdaBeWT0GfIr/vn4XGG9mx5T0BDMbDjwMTMe/Fw8Dd1no+N4Dgfn4P+xOB14CnjSz84Ou0xT4EOgIXB+oNxH/vRPsHvzQgr7As8BtgX+XRQawHLgC6IV/3XfgP0+cc3nAU8Dg4D+qzKwV/v+GJwPHpX4+Qe4FtgLnEPT9IgKAc05f+tJXOb+AkcDPgX8Pxv+SbxM4fhF4N6juifjWySOAg4A84KLAuav8j2OJ9xoFfB74d11gB/AQ8FGgLD1w/1MDxy0C9zst6Bo/AyMjXNsB74WVTc+/dilxDcAnsC7wNR9IL+U5gwN1GxRzvib+F6YDugSVvw88FXTcCtid/xqB1oHjC8Ou9zTwSdDxu0AusF9YvV+B02P4/XFE4DWcGOHcTuCvEcrXAncH/n0zkBOhzsWB6+5Rwr3XAKuAWkFlY4Efgo6HBb4PWwWVNQd+B24KHB8euNe5QXUa4IdorAkquwvYCOwVVNYYn5BfGTh+CHipvD9jYT9HdwaV1QY2AKNLuE6jwOd7e1j5ncAPQM0IzzH8kK4JwOywn8VtwP7F3KtFIManw8qXAFNLeb3vAi8Wcy4/nr8B3wSVHxy430kRXletMnw++XG/HKufAX2l3pdaHEVi51ngO+Cm0io651bhuyVHWNgs2hLMAw4LtBwci//F9TBwlJnVA44P1Jtf1sAD3gw7XoZPIoplZicBjwAPACfhW6H2Al4uw+vKv9YpZvaBmW3GJzP549raBFWbCJxthbOxBwM/AjMDxyfjE8eXA114tcysFr5VrX1YTAudcz+EhbEEGGV+1vcfyhJ/OUWaSW9h5cXVKe5csDnOt0jlWwY0NbM9AsfH4MeoflNwMz+mcD6F30/5k77+G1TnV+CtsHv9KVC2Jeh93wosBLICdZYAvQJdtseU9XskTMH3q3NuJ75VtqTv1074FrYXwr43ZgP75j/XzBqb2YNm9i0+ud+Jb2UN/j7sBsx0zq2PNsaAUn+mwpkfpnKHmX2N/2NxJ74lvGUgfpxzK4H38D8PBFoeBwHPBH3+0Xw++WaUJUapXpQ4isRI4D/oe4ALzOzAKJ5yN77l8dwobzEfnygcj++Cet859wW+xeDYQNnnzrmc4i9RovDn/Y5v2SzJfcB/nXM3Oufedc49h58gdCJ+pnBUzM9I/y8+WRyI/yV/bOB0cAzP4xPDfkG/HJ8O+uW4D761cjOFv/R3ApPwLTX7B13rxwihnAssAO4Hvg2Mbzs52tdRRr/gW4nD7UnhZ/EL0DBCgpUO/BZImEoS6TM1ID9x3J/I78OP+D8AAPYDtrqiEyR+CjveB//+7Qz7OonCLtwn8K1l/YD/AT+a2V3lTCDL+v26T+Dxi7D45gTK82OcFHgdY/Bd8h0DcQdfe2/8qgWxjjGSf+K7wx/Fd1V3xA8HIexaE4G+ZtYQn9geSKCbOiCazydfpO8JEUCzqkVi7Qn8+LobS6vonFtmZi/jf5FOiKL+ZjP7DJ8gtqdwqZf3A2UljW+sLIfgl+Mp4Jxbbma5+KQ4WmfhuxrPdc75PrkIybdzbpuZTcW3rHyL/+U4KajKJnxrZWd8ghkuONkp0lrnnMvGjxWrgW+NGwn818z+4JzbWIbXE42vCBunaGYH4FvFvgqqUxPfBb88qGqR8ZHltB7fFR1uX/x7Cb67s6EVnV3bNOw5m/DJf6TJRFuhYNLQ/cD9gdc6AN96lo1vua5M+a/nNCInRsvNz2I/FbjKOVcQT4QJLRsJ/SOkMp0DjHPO3RMUz6kR6r0APBiofxLwPxc6zrjUzydITNeUldSixFEkhpxzO8zsXvwYqIX4v+hL8nf8BJWzorzFPPwvhUMonIjzHv6XxdH4MWwlKU+LR0m+BY4KLjCzQ/Ezg9eU4TppwM78pDGgyEzWgIn4ZYZG4sdgBi/5MxufaO3pnAvvSo1aIMH5yMzuwK9ReSA+WYilN4DhZtbQOZf/i/tc/NjLuYHjD4At+M/37wCBYQmn41ugKup/wCAza+mcWx24fgZ+NvfIQJ1PAo9nAM8F6jQA/hyILd87+JbELyK0ThbhnPseGG1mQ4DDKv5SSvUh/r1t5pyL2BVrZnviv392BJU1xL/24O/Nd4CrzWxf51xlt86lhcVTk7CJSQDOuVwzmwJcif//4dqwKmX6fESKo8RRJPYm4FsRj6MwAYjIObfYzN6glKVVgrwH/AU/yD9/RvQ8/CxVCF3sO5KvgFPNbGbgGsuDkpbyeATferQOnwjti585ugZ4vQzXeQv4q5mNxS//cRx+dncRzrn/mdkX+C77y8LOLTezR4CpZnYPvtu5Lr5VrY1zrtglkAJJwyz8RJoV+NnU1+Fb3L4M1DkR37V5knPu3RKulYWfaJDfBdjV/HJBa5xzCwJljwBXA9PM7J/4iT4jgX+5wBI9zrntZjYauNXMfsF/ftfihxmNK+7+ZTAJ3zr+hpndhp9cNRI/iWpCIIYvzOy/wMPm15lcDwzHz/4O9i/8ZzbbzMbhWxH3xc+Cf985N8XMJuBbvj7CDyc4CT+xo9QW+opyzuWY2UjggUBr9nv497EN/vM8K9Cq/wlwm/n1SHfj19HcjJ9ck+9+/DCJeWb2D/xKCYcC9YNbBmPkLeDKwBjHTfjEsLiZ/hPxE55y8WOog5X6+cQ4bklRShxFYsw595uZ3Y/vgovG34k+cczviv4waFzfYnxX08+BrtaSDAfG4we/18P/4n43yntH8iC+FfNy/C+sHHzyepPz6w1GxTn3upndiE+KL8G3Dp2GT+AimY5PtMJ/OYL/xboicJ078a1iy/C/VEuyHViKX4LoAHxi9BHQPaiFpl7gMXx8X7irgOC1I0cGHp8iMIHBOfdLYPzkQ/hkOQefkIwk1Gh8gnMTfmzdAuDPsWjpCrSQ/wmfVEzEj398F78o+aagqoPxE7HG4v/gGI9viewbdK2fzexY/Pf9/fhxmOvx3w+fBap9iP9cLsMn9F8Dlzjnplf0tUTDOXdP4I+ca/B/FGzHf688F1StP74192l8K/ND+M/9qqDrbDCzzvgxzWPxidxKfE9DrP0F/0fGeHxC+BR+iakiLc7OuQVmlo1fzWFz2LloPh+RUlloz5CISOIzs4/xraUDq/i+d+CXBzqpKu8rEg0zOww/+edPzrl34h2PpCa1OIpI0gh0AXfDzyy9Mg4hHEfhsACRhGBme+MX9r4L+Bw/1lekUihxFJFk8gm+S/cm59wnpVWONefcn6v6niJROB2/osNXwECnrkSpROqqFhEREZGoaAFwEREREYmKEkcRERERiYrGOFaSffbZx7Vo0SLeYYiIiIiUauHChT8755qUVk+JYyVp0aIFCxYsKL2iiIiISJyZ2bfR1FNXtYiIiIhERYmjiIiIiERFiaOIiIiIREVjHEVERKqpnTt3snbtWrZv3x7vUKSK1K1bl+bNm1O7du1yPV+Jo4iISDW1du1aGjZsSIsWLTCzeIcjlcw5x8aNG1m7di0tW7Ys1zXUVS0iIlJNbd++nb333ltJYzVhZuy9994VamFW4igiIlKNKWmsXir6eStxFBERkbgxM6677rqC43vvvZeRI0cCMHLkSOrVq8dPP/1UcL5BgwYRr+Oco1u3bmzZsgWAoUOH0rRpU4444oiQeiNHjiQjI4P27dvTvn17Xn/99YJzo0aNonXr1mRmZjJr1qyC8pkzZ5KZmUnr1q0ZPXp0hV9zebRo0YKff/45qrobNmygZ8+elRKHEkcRERGJmzp16jBt2rRik6J99tmH++67r9TrvP7667Rr145GjRoBMHjwYGbOnBmx7jXXXMOSJUtYsmQJvXr1AmDZsmVMnTqVL774gpkzZ3LFFVewa9cudu3axZVXXskbb7zBsmXLmDJlCsuWLSvnq60aTZo0Yf/992f+/Pkxv7YSRxERkerOrHK/SlCrVi0uvfRS7r///ojnhw4dynPPPcemTZtKvM7kyZM588wzC467dOnCXnvtFfVb8Morr3DeeedRp04dWrZsSevWrfn444/5+OOPad26Na1atWKPPfbgvPPO45VXXiny/FWrVtGzZ0+OPvpoTjjhBL766ivAJ7DDhg3jhBNOoE2bNrz22muAH186ZMgQ2rZtS4cOHZgzZw4Au3bt4vrrr6dt27YceeSRjBs3ruAe48aN46ijjqJt27YF1587d25B62mHDh3YunUrAL1792by5MlRv/5oKXEUERGRuLryyiuZPHkymzdvLnKuQYMGDB06lAceeKDEa8yfP5+jjz46qvs99NBDHHnkkQwdOpRffvkFgOzsbA444ICCOs2bNyc7O7vY8nCXXnop48aNY+HChdx7771cccUVBefWrFnD3LlzmTFjBsOGDWP79u2MHz8egKVLlzJlyhQuvPBCtm/fzqOPPsrq1atZvHgxn332GQMGDCi4zj777MOiRYu4/PLLuffeewHftT9+/HiWLFnCvHnzSEtLAyArK4t58+ZF9X6UhRJHERERiatGjRoxaNAgHnzwwYjnr776ap566qmC8YuRbNq0iYYNG5Z6r8svv5xVq1axZMkS9t9//4Lxlc65InXNrNjyYL/++isffPAB55xzDu3bt+eyyy5j/fr1Bef79etHjRo1OPjgg2nVqhVfffUV77//PgMHDgTgkEMO4cADD2TFihW8/fbbDBs2jFq1/IqJwa2mffr0AeDoo49mzZo1AHTu3Jlrr72WBx98kJycnILnNW3alHXr1pX6fpSV1nEUEUkw0xdnM2bWctbl5NIsPY3hPTLp3SEj3mGJVKq//vWvHHXUUQwZMqTIufT0dPr378+///3vYp9fq1Ytdu/eTY0aJbeJ7bvvvgX/vuSSSzjttNMA35L4/fffF5xbu3YtzZo1Ayi2PN/u3btJT09nyZIlEe8ZnmgWl5CCT2CLm/lcp04dAGrWrEleXh4AI0aM4NRTT+X111/n2GOP5e233+aQQw5h+/btBa2PsaQWRxGRBDJ9cTY3TVtKdk4uDsjOyeWmaUuZvrho15hIzDhXuV9R2GuvvejXrx8TJ06MeP7aa69lwoQJBQlTuMzMTL755ptS7xPcEvjyyy8XzLo+44wzmDp1Kjt27GD16tWsXLmSY445ho4dO7Jy5UpWr17N77//ztSpUznjjDNCrtmoUSNatmzJCy+8EHg7HZ9++mnB+RdeeIHdu3ezatUqvvnmGzIzM+nSpUvBGMQVK1bw3XffkZmZSffu3XnkkUcKXmdpYztXrVpF27ZtufHGG8nKyioY+7hixYoiM8pjQYmjiEgCGTNrObk7d4WU5e7cxZhZy+MUkUjVue6660qcXX3WWWexY8eOiOdPPfVU3n333YLj888/n06dOrF8+XKaN29ekJDecMMNBRNP5syZUzAp5/DDD6dfv34cdthh9OzZk/Hjx1OzZk1q1arFQw89RI8ePTj00EPp168fhx9+eJH7T548mYkTJ9KuXTsOP/zwkAk0mZmZdO3alVNOOYVHHnmEunXrFszabtu2Leeeey6TJk2iTp06XHzxxfzhD3/gyCOPpF27dvznP/8p8T0bO3YsRxxxBO3atSMtLY1TTjkFgDlz5nDqqaeW+NzysOKaSqVisrKy3IIFC+IdhogkmZYjZhDpf2UDVo+O/S8Bqd6+/PJLDj300HiHERPr169n0KBBvPXWW/EOJcTgwYM57bTT6Nu3b5Xet0uXLrzyyis0bty4yLlIn7uZLXTOZZV2XbU4iogkkGbpkcckFVcuIt7+++/PJZdcUuIEmupiw4YNXHvttRGTxorS5BgRkQQyvEcmN01bGtJdnVa7JsN7ZMYxKpHk0K9fv3iHUMSkSZOq/J5NmjShd+/elXLtlGlxNLPmZvaEma0zsx1mtsbMxppZmdJtMzvezF4JPH+7mX1nZq+bWeXs3SMiEqR3hwxG9WlLRnoaBmSkpzGqT1vNqhaRhJASLY5mdhDwAdAUeAX4CjgG+D+gp5l1ds5tjOI6lwP/BrYBLwNrgeZAH+AUM7vFOfePynkVIiJe7w4ZShRFJCGlROKIT/aaAlc75wr25jGzfwHXAP8AhpV0ATOrDYwCtgNHO+eWB527G1gM3Gxm9zrnIk/pEhEREUlhSd9VbWatgO7AGmB82Onb8a2HA82sfimX2gvYE1gRnDQCOOe+BFYAaUCDGIQtIiIiknSSPnEEugUe33TO7Q4+4ZzbCswH6gHHlnKdn4ANQBszOzj4hJm1AQ4GlkTT5S0iIiKl27hxI+3bt6d9+/bst99+ZGRkFBz//vvvUV1jyJAhLF9e8jqn48ePL1hsO5befvvtUiehLFq0iJkzZ8b83vGSCl3V+VMNVxRzfiW+RbIN8E5xF3HOOTO7EngWWGhmLwPrgAzgLOAL4LxYBS0iIlLd7b333gXb9I0cOZIGDRpw/fXXh9RxzuGcK3YrwSeffLLU+1x55ZUVD7acFi1axOeff07PnqkxxzYVWhz3DDxuLuZ8fnl6aRdyzr2Ab8HMAQYBI4CB+O7uJ4ES9zIys0vNbIGZLdiwYUMUoYuIiCSP6Yuz6Tx6Ni1HzKDz6NmVthXm119/zRFHHMGwYcM46qijWL9+PZdeeilZWVkcfvjh3HnnnQV1jz/+eJYsWUJeXh7p6emMGDGCdu3a0alTJ3766ScAbrnlFsaOHVtQf8SIERxzzDFkZmbywQcfALBt2zbOPvts2rVrx/nnn09WVlbEvadnzJhBZmYmxx9/fMjuMB999BGdOnWiQ4cOdO7cmZUrV5Kbm8udd97J5MmTad++PS+++GLEeskkFRLH0uTvFF7qFjlmdgHwNjAPOBTfxX0ovqXyIWBqSc93zj3qnMtyzmU1adKkQkGLiIgkkqreR33ZsmVcdNFFLF68mIyMDEaPHs2CBQv49NNPeeutt1i2bFmR52zevJmuXbvy6aef0qlTJ5544omI13bO8fHHHzNmzJiCJHTcuHHst99+fPrpp4wYMYLFixcXed5vv/3GZZddxuuvv868efNYt25dwblDDz2U999/n8WLF3Prrbdyyy23kJaWxm233caAAQNYsmQJffv2jVgvmaRCV3V+i+KexZxvFFYvosA4xieAz4CBQeMlvzKzgfgu8XPM7ETn3LsVC1lERCS5lLSPemUsH3XQQQfRsWPHguMpU6YwceJE8vLyWLduHcuWLeOwww4LeU7wXs1HH3008+bNi3jtPn36FNRZs2YNAO+//z433ngjQMF+0+GWLVtGmzZtOOiggwAYMGAATz/9NAA5OTkMGjSIVatWlfi6oq2XqFKhxTF/RGybYs7nT3Qpbgxkvu5AbWBuhEk2u4H3AodHlydIERGRZLYuJ7dM5RVVv37hYigrV67kgQceYPbs2Xz22Wf07NmT7du3F3nOHnvsUfDvmjVrkpeXF/HaderUKVLHuVI7JgEws4jlN998Mz169ODzzz9n+vTpEeMrS71ElQqJ45zAY3czC3k9ZtYQ6AzkAh+Vcp06gcfi+pjzy6Ob5iUiIpJC4rmP+pYtW2jYsCGNGjVi/fr1zJo1K+b3OP7443n++ecBWLp0acSu8MMOO4wVK1awevVqnHNMmTKl4NzmzZvJyPAtr8HbDDZs2JCtW7eWWi9ZJH3i6JxbBbwJtADCp03dAdQHnnbObcsvNLNDzOyQsLr57dl9zezI4BNm1h7oix8nOTt20YuIlF9VTVQQAb+PelrtmiFlVbWP+lFHHcVhhx3GEUccwSWXXELnzp1jfo+//OUvZGdnc+SRR3LfffdxxBFHsOeeoaPg6tWrxyOPPMIpp5zCCSecQKtWrQrO3XjjjQwfPrxIbN26dePTTz+lQ4cOvPjii8XWSxYWbdNsIouw5eCXwB+Bk/Bd1McFr79oZg7AOWdh13kCGIJvVXwZ+BafkPYG9gDGOueuiSamrKwst2DBggq9LhGR4uRPVAgec5ZWu6b2tZYy+fLLLzn00EOjrj99cTZjZi1nXU4uzdLTGN4jM2W+3/Ly8sjLy6Nu3bqsXLmS7t27s3LlSmrVSoXpIKEife5mttA5l1Xac1Pi3XDOrTKzLOBOoCfQC1gPPAjc4ZzbFOWlLsKPZRwM9AAaAluA94HHnHMlzqoWEakqVT1RQQRSex/1X3/9lZNPPpm8vDycc0yYMCElk8aKSpl3xDn3Pb61MJq6EUe2Ot/8OinwJSKSsKp6ooJIqktPT2fhwoXxDiPhJf0YRxGR6iieExVEpPpS4igikoTiOVFBUksqzHWQ6FX081biKCKShHp3yGBUn7ZkpKdhQEZ6mibGSJnVrVuXjRs3KnmsJpxzbNy4kbp165b7GikzxlFEpLpJ5YkKUjWaN2/O2rVr2bBhQ7xDkSpSt25dmjdvXu7nK3EUEUlxqbyEilRM7dq1admyZbzDkCSixFFEJIWFr/eYnZPLTdOWAih5FJEy0xhHEZEUVtJ6jyIiZaXEUUQkhWm9RxGJJSWOIiIpTOs9ikgsKXEUEUlhWu9RRGJJk2NERFJY/gQYzaoWkVhQ4igikuK03qOIxIq6qkVEREQkKkocRURERCQqShxFREREJCpKHEVEREQkKkocRURERCQqShxFREREJCpKHEVEREQkKkocRURERCQqShxFREREJCpKHEVEREQkKkocRURERCQqShxFREREJCpKHEVEREQkKkocRURERCQqShxFREREJCpKHEVEREQkKkocRURERCQqteIdgIhIdTB9cTZjZi1nXU4uzdLTGN4jk94dMuIdlohImShxFBGpZNMXZ3PTtKXk7twFQHZOLjdNWwqg5FFEkoq6qkVEKtmYWcsLksZ8uTt3MWbW8jhFJCJSPkocRUQq2bqc3DKVi4gkKiWOIiKVrFl6WpnKRUQSlRJHEZFKNrxHJmm1a4aUpdWuyfAemXGKSESkfDQ5RkSkkuVPgNGsahFJdkocRUSqQO8OGUoURSTpqataRERERKKixFFEREREoqLEUURERESiosRRRERERKKixFFEREREoqLEUURERESikjKJo5k1N7MnzGydme0wszVmNtbMGpfjWm3N7Gkz+z5wrZ/MbK6ZDaqM2EVERESSQUqs42hmBwEfAE2BV4CvgGOA/wN6mlln59zGKK81GHgc+A14DVgDpANHAL2Ap2McvoiIiEhSSInEEfg3Pmm82jk3Lr/QzP4FXAP8AxhW2kXM7Fh80vg50NM590PY+dqxDFpEREQkmSR9V7WZtQK641sGx4edvh3YBgw0s/pRXO4eoCZwQXjSCOCc21mxaEVERESSVyq0OHYLPL7pnNsdfMI5t9XM5uMTy2OBd4q7iJk1B04AFgCPPcZ1AAAgAElEQVRfmNlJwNGAA5YAc8KvLyIiIlKdpELimBl4XFHM+ZX4xLENJSSOQMeg+rOBE8POLzWzPs65r8sZp4iIiEhSS/quamDPwOPmYs7nl6eXcp2mgcd+wKFAn8C1WwPPAG2BGWa2R3EXMLNLzWyBmS3YsGFDNLGLiIiIJI1USBxLY4FHV0q9mkGPFzvnXnbObXHOrQIuxHdhtwHOLu4CzrlHnXNZzrmsJk2aVDRuERERkYSSColjfovinsWcbxRWrzi/BB53AK8Hn3DOOfwyP+CX+RERERGpdlIhcVweeGxTzPmDA4/FjYEMv87WYibB5CeWaWWITURERCRlpMLkmDmBx+5mViM46TOzhkBnIBf4qJTrfAb8DOxjZvs6534MO39E4HFNxUMWESmnTZvg3Xdh6VL47jvYuBFq1YK0NGjVCjIzoXNnOPDAeEcqIiko6RNH59wqM3sTP3P6SmBc0Ok7gPrABOfctvxCMzsk8Nyvgq6TZ2YTgJuBe8xsSH4SamZtgcFAHvBi5b4iEZEwubnw/PPw6KPw4YfgShuyDRx8MJx9NgwZAm2K65ARESkbc9H8B5TgImw5+CXwR+AkfBf1ccFbDpqZA3DOWdh16uGX7DkWWAy8CzTBT4hJA65zzv0rmpiysrLcggULKvS6RKSay8uDCRNg5Ej4+efyX+dPf4JbboGuXWMWmoikFjNb6JzLKq1eKoxxJDDzOQuYhE8YrwMOAh4EOkW7T7Vz7jfgZHxLZT18C+YZ+KS0V7RJo4hIhX3yCbRrB1ddVbGkEeDtt+HEE6FbN/jss5iEJyLVU0q0OCYitTiKSLns3g3/+hfcdJNvcYzkyCPhpJN8F/S++/rn5OTAihXw8cfwwQfFP7dGDbjiChg1Cho0qLzXISJJJdoWx6Qf4ygikjJ27PBjEqdMKXqufn0YNgwuu8yPXyzJ1q3w0kvw+OMwf37oud274aGHYOZMeOYZOPbY2MUvIikvJbqqRUSS3pYt0KtX5KTxwgt9a+K995aeNAI0bAiDB8P77/uvP/2paJ2vv/azr2+/HXbtqnD4IlI9KHEUEYm3bdt80jh7dmh548YwbRpMmgTNmpXv2p07w5tvwn//65frCbZ7N9x5J5x2GvzyS+Tni4gEUeIoIhJPO3ZAnz5Fu5QPPhgWLoSzzqr4Pczg9NP9xJjLLy96fuZM+OMf4csvK34vEUlpShxFROLFObjoIt8iGKxjR59ItmwZ2/vVrw///je8/rqfVBNs5UqfPL7zTmzvKSIpRYmjiEi83HcfTJ4cWta+vU8kmzSpvPuecgosWlR0YszWrb7L/IUXKu/eIpLUlDiKiMTDm2/CjTeGlrVpA7NmQXp65d+/WTO/deGQIaHlv/8O554LDz9c+TGISNJR4igiUtV++AEuuMBPTsmXng4zZkDTplUXR506MHEijBkTWu6cX+vxnnuqLhYRSQpKHEVEqpJzvpVvw4bCsho1YOpUaN266uMxg+uvh6eegpo1Q8/deCP8859VH5OIJCwljiIiVSl/8e1gI0dCjx5xCafAoEF+yZ60tNDyESOUPIpIASWOIiJVZfVqn4gFO/54+Nvf4hNPuF694I03oF690PIRI/w2iCJS7SlxFBGpCvnjBn/7rbCsUSO/7V94F3E8de3ql+sJTx6vuw6efDI+MYlIwlDiKCJSFaZMKdpFfd990KJFXMIpUdeuvuWxfv3Q8osvhpdfjk9MIpIQlDiKiFS2LVvg2mtDy7p29Yt/J6ouXeCVV2CPPQrLdu+G887TIuEi1ZgSRxGRyvaPf8CPPxYe16kDEyb4Gc2J7OST/WzvGkG/Kn7/Hc48Ez75JH5xiUjcKHEUEalMq1bB2LGhZTfcAJmZ8YmnrM46Cx57LLRs2zY47TRYsyYuIYlI/ChxFBGpTDfc4Fvp8mVkFN0xJtENHQr33hta9tNPfhZ2Tk58YhKRuFDiKCJSWT7+GKZNCy0bPbropJNkcN11PgkO9uWXcPbZoYmxiKQ0JY4iIpXltttCjzt2hP794xNLLIwaBeecE1o2ezZcdplfbkhEUp4SRxGRyjBvHsyaFVp2992hE02STY0afmvCTp1CyydN8hOARCTlJfH/YCIiCco5uPXW0LKuXf0s5WSXluaX6WnVKrT81lv9WpUiktKUOIqIxNrs2TB3bmjZXXcl/vI70WrSxO8u07hxaPnQoVqmRyTFKXEUEYmlSK2N3bvDCSfEJ57KkpkJ06eHLhC+fTv07g3r18cvLhGpVEocRURiae5c+PDD0LK77opPLJWtS5eiazyuW+fXfty+PT4xiUilUuIoIhJL99wTenzqqXDMMfGJpSoMGuSX6gn2v//BsGGaaS2SgpQ4iojEymefwRtvhJaNGBGfWKrSP/8JPXuGlj31VNEdc0Qk6SlxFBGJlfDdVTp1gs6d4xNLVapZ08+obtMmtPz664suSSQiSU2Jo4hILHz3XdHlaG64IXVmUpcmPR3++1/Yc8/Cst274dxzYcWK+MUlIjGlxFFEJBbGjoW8vMLjNm3gjDPiF088ZGb65Dl4kfPNm+HMM2Hr1vjFJSIxo8RRRKSiNm8uOrt4+PDk3iWmvE45pegEoa++gsGDNVlGJAVUw//VRERi7Kmn4NdfC4/32w8uuCB+8cTbtdfCwIGhZdOmwejR8YlHRGJGiaOISEXs3g3jx4eWXXEF1K0bn3gSgRlMmAAdOoSW33yzJsuIJDkljiIiFfH226GTP2rXhksuiV88iSItzbcy7r13YZlzcP75sHp1/OISkQpR4igiUhEPPRR6fM45vqtaoEWLopNlfvnF7yzz229xC0tEyk+Jo4hIea1eDa+9Flp21VXxiSVR/fnPcPfdoWWffgqXXqrJMiJJSImjiEh5PfxwaPLToQMce2z84klUN9wAffuGlk2eDA8+GJ94RKTclDiKiJRHbi5MnBhadtVV1WfB77IwgyeegMMOCy2/7jqYOzc+MYlIuShxFBEpj2nTYNOmwuO99vITPySyhg3h5ZehUaPCsl27oF8/WLs2fnGJSJkocRQRKY/w1sYLL/QziaV4bdrAM8+Elv30k+/G3rEjPjGJSJkocRQRKatVq2DOnNCyiy+OTyzJ5owz4LbbQsv+9z/4y1/iE4+IlIkSRxGRsnriidDjTp2Kjt+T4t1+O/TqFVr22GNFt20UkYSjxFFEpCzy8uDJJ0PLLrooPrEkqxo14Nln4aCDQsuvusq3PopIwlLiKCJSFjNnwvr1hccNGsC558YvnmTVuDFMnw716hWW/f47nH02/Phj/OISkRIpcRQRKYvHHw89PvdcnzxK2R1xRNFu/+xsv/vO77/HJyYRKVHKJI5m1tzMnjCzdWa2w8zWmNlYM2tcgWt2MbNdZubM7O+xjFdEktD69UV3itGkmIo591y4/vrQsnnz/BqPIpJwUiJxNLODgIXAEOBj4H7gG+D/gA/NbO9yXLMh8BSgDVVFxHv6ab/2YL7DDmP6Hs3pPHo2LUfMoPPo2UxfnB2/+JLVqFFw8smhZQ89BJMmxSUcESleSiSOwL+BpsDVzrnezrkRzrlu+AQyE/hHOa75ALAnMCp2YYpI0nKuyNqNS3uew00vf052Ti4OyM7J5aZpS5U8llWtWjB1Khx4YGj5sGHwySfxiUlEIkr6xNHMWgHdgTXA+LDTtwPbgIFmVr8M1zwT33p5NbAuNpGKSFL74ANYubLwuHZtbqzXjtydu0Kq5e7cxZhZy6s4uBSwzz5+skzwIuo7dsBZZ2myjEgCSfrEEegWeHzTObc7+IRzbiswH6gHHBvNxcysKfAYMN0592wsAxWRJPaf/4Qen3EGX+7cI2LVdTm5VRBQCmrfvujko+xsvy3hzp3xiUlEQqRC4pgZeFxRzPn8JoI2UV7vUfz7MqwiQYlICtm5E55/PrRs4ECapUfeYrC4colC//5w7bWhZe+9p8kyIgkiFRLHPQOPm4s5n1+eXtqFzGwocCZwhXOuzH0jZnapmS0wswUbNmwo69NFJFG99Rb8/HPhcXo69OzJ8B6ZpNWuGVI1rXZNhvfIRCrgn/+Ebt1Cy8aN02QZkQSQColjaSzw6EqsZNYCGAu84Jx7vqS6xXHOPeqcy3LOZTVp0qQ8lxCRRBTeTd23L9SpQ+8OGYzq05aM9DQMyEhPY1SftvTukBGXMFNGrVrw3HORJ8ssWBCfmEQEgFrxDiAG8lsU9yzmfKOwesV5AsgFrohFUCKSIrZt85M2gg0YUPDP3h0ylChWhn32gZdfhuOOg+3bfVn+ZJmFC6Fp0/jGJ1JNpUKLY/70xeLGMB4ceCxuDGS+o/BL+mwILPjtzMwB+ZvS3hwom178JUQk5bz6qk8e82VkwAknxC+e6qRDh6KTZdau1WQZkThKhRbHOYHH7mZWI3hmdWAR7874lsSPSrnO0/jZ1+EOBroAS/CLjC+ucMQikjwmTw49Pu88qFkzcl2JvQEDfAvj/fcXls2d63ebeeCB+MUlUk0lfeLonFtlZm/i13K8EhgXdPoOoD4wwTlX0GRgZocEnvtV0HWujnR9MxuMTxxnOOduifkLEJHEtXEjzJwZWta/f3xiqc7uuQeWLIE5cwrLHnwQjjwSLroofnGJVEOp0FUNflziT8CDZjbdzEaZ2WzgGnwX9c1h9b8MfImIFO/FFyEvr/D4kEN896lUrfzJMn/4Q2j55ZfD++/HJyaRaiolEkfn3CogC5gE/BG4DjgIeBDo5JzbGL/oRCRphc+m7t8fzCLXlcrVpEnRnWV27oQ+fWDNmriFJVLdmHMlrlIj5ZSVleUWaNkIkeT13XdFl4NZuRJat45PPOK98IKfHBOsbVu/JWSDBvGJSSQFmNlC51xWafVSosVRRCTmpk4NPT7mGCWNieCcc+D220PLli6FCy6A3bsjP0dEYkaJo4hIJJG6qSUx3HabX4Q92CuvwK23xicekWpEiaOISLgvvoBPPy08rlEDzj03fvFIqBo1/PaD4ROV7r67aMIvIjGlxFFEJNyUKaHHJ58M++0Xn1gksvr1fSvjvvuGlg8dCh9/HJ+YRKoBJY4iIsGcUzd1sjjgAD/Tuk6dwrIdO+DMM+H77+MXl0gKKzFxNLODqioQEZGE8NFHsHp14XGdOn5/ZElMxx4Ljz0WWvbDD3DqqbBlS3xiEklhpbU4zjezo6okEhGRRBDe2nj66bDnnvGJRaIzcCDccENo2dKl2tNapBKUljjWB+aY2Z+rIhgRkbjKy/M7lARTN3VyuPvuoi3Ds2bBlVf64QciEhOlJY4nAtuB18xsQOWHIyISR++8Axs2FB7vuSecckr84pHo1awJzz4LHTuGlj/2mN/rWkRiosTE0Tm3EOgMrAWeNrPrqiQqEZF4mDw59Pjss6Fu3fjEImVXrx68+iq0aBFaPmIEPP98XEISSTWlzqp2zn0NdAI+Be4xs/sqPSoRkar222/w8suhZQPU0ZJ09t0XZswoOi510CCYPz8+MYmkkKiW43HO/QR0AeYA15jZZDOrVamRiYhUpddeg19/LTzef3/o2jV+8Uj5HXYYTJsGtYJ+TeUv0/P11/GLSyQFRL2Oo3PuV+AUYBpwHrDKzJ43sxvMrJuZadqhiCSv8NnU553nx81JcurWDR5/PLRs40bo1Qt+/jk+MYmkgKgTRzPbC7gFOAkw4ACgLzAKeAvYZGYrzUz7PYlIctm0CV5/PbRMs6mT34UX+n2tg61c6dd43LYtPjGJJLlSE0cza2Zm/wK+BfJ3kL8dyAT6AHcDbwIbgYMAbegqIsnlpZdC1/s7+GA4+uj4xSOxM3IkXHBBaNnHH8M552iNR5FyKHGcopk9CgwE6gC/APcAY51zWwNVVgLTg+r/AdD/tiKSXMK7qQcMALP4xCKxZea7rNetg9mzC8vfeAMuuggmTYIa2n1XJFql/bRcDPwG3Aa0cM7dFZQ0FuGc+84593Jx50VEEs7atTB3bmjZ+efHJxapHHXq+Bnz7duHlj/zjF+qR0SiVlrimJ8w/r2khFFEJGk991zoziJZWdCmTfzikcrRqJFvZWzVKrR8zBi4T6vMiUSrtAXAlTCKSGoLX/Rbk2JS1377+W0ImzYNLb/+er/rjIiUSmsxikj19eWXsHhx4bGZX4anGpu+OJsxs5azLieXZulpDO+RSe8OGfEOK3Zat/Ytj127hq7bOWQING7sZ1yLSLE0IlhEqq8pU0KPu3XzC39XU9MXZ3PTtKVk5+TigOycXG6atpTpi7PjHVpsHXUUTJ8OtWsXluXl+S0mgyfQiEgRShxFpHpyruhs6mreTT1m1nJyd+4KKcvduYsxs5bHKaJKdPLJvns6ePb8jh1wxhnw4Yfxi0skwSlxFJHq6ZNPYNWqwuM99oA+feIXTwJYl5NbpvKk168f/PvfoWXbtsEpp4QOYRCRAkocRaR6Cp8Uc+qpkJ4en1gSRLP0tDKVp4Rhw+Dee0PLNm+G7t39GFgRCaHEUUSqn7w8vwxPsAED4hNLAhneI5O02qH7c6fVrsnwHplxiqiKXHcd3H57aNnPP/vu7OBWaRFR4igi1dCcOfDjj4XHjRpBr17xiydB9O6Qwag+bclIT8OAjPQ0RvVpm1qzqotz++0+gQy2fr1PHr//Pj4xiSQgLccjItVP+KSYPn0gLYW7Y8ugd4eM6pEohjPzi4Fv2waPPFJY/u23cOKJ/o+NP/whbuGJJAq1OIpI9ZKbCy+9FFpWzWdTS4AZjB8PF1wQWv7NNz55/O67uIQlkkiUOIpI9TJjBmwN2hBr3339+o0iADVqwJNPQt++oeWrV/vk8dtv4xKWSKJQ4igi1Ut4N/V550HNmpHrSvVUq5b/PlHyKFKEEkcRqT5ycnyLYzB1U0sktWv75PGcc0LL16zxyeOaNXEISiT+lDiKSPXx0kvw+++FxwcdBB07xi8eSWy1a/v1PotLHlevjkdUInGlxFFEqo9nnw097t8/dMs5kXD5LY/9+oWWf/stnHACfPVVfOISiRMljiJSPXz3Hbz7bmiZFv2WaNSq5Vsezz03tDw72yePixbFJy6ROFDiKCLVw5QpoccdO0Jmiu+IIrFTq5ZvsT7//NDyn3+Gk06C99+PT1wiVUyJo4ikPufgmWdCy8LX6hMpTa1a/vvokktCy7ds8Xtbz5oVn7hEqpASRxFJfZ99Bl98UXhcs6ZfhkekrGrWhAkT4PrrQ8tzc+H004suLi+SYpQ4ikjqC58U06MHNG0an1gk+ZnBPffAXXeFlu/c6SfRPPFEfOISqQJKHEUkte3aVXTRb3VTS0WZwS23wAMPhJbv3g0XXeSTSufiE5tIJVLiKCKp7d13Yd26wuMGDeDMM+MWjqSYq6/2WxTWCPt1etttcNllkJcXn7hEKokSRxFJbeHd1H36QL168YlFUtPgwfDii1CnTmj5Y4/BWWfBtm1xCUukMihxFJHU9dtvRScrqJtaKsNZZ8Hbb0PjxqHlr70G3brBTz/FJy6RGFPiKCKp69VXYevWwuP99vO/xEUqw/HHw/z5cOCBoeUffwzHHQdffx2fuERiKGUSRzNrbmZPmNk6M9thZmvMbKyZNS792WBm9c1sgJn9x8y+MrNtZrbVzBaY2XVmtkdlvwYRibHwtRv79/fLqYhUlkMPhQ8/hPbtQ8tXrYI//hHmzo1PXCIxkhKJo5kdBCwEhgAfA/cD3wD/B3xoZntHcZkTgGeBHsDnwDhgCpAB3AvMMbO6sY9eRCrFhg0wc2ZombqppSrsv79PEP/0p9DyTZt82eOPxycukRhIicQR+DfQFLjaOdfbOTfCOdcNn0BmAv+I4ho/ABcA+zvn+gaucSnQBlgEHAdcWTnhi0jMTZ3ql+LJd/jhRVuBRCpLo0YwYwYMHBhanpfnd5655prQ70+RJJH0iaOZtQK6A2uA8WGnbwe2AQPNrH5J13HOLXHOTXbO/R5WvhW4L3B4YixiFpEqMGlS6PGAAX7tPZGqssce8NRT8Pe/Fz03dqzfaWbLlqqPS6QCkj5xBPJHur/pnNsdfCKQ9M0H6gHHVuAeOwOPWpBLJBksWQKLFhUemxVt+RGpCmZw881+uZ60tNBzb7wBnTrBN9/EJzaRckiFxDEz8LiimPMrA49tKnCPoYHHmSXWEpHE8OSTocfdu0Pz5vGJReJm+uJsOo+eTcsRM+g8ejbTF2fHL5izz4b334eMjNDyZcsgK6voeFyRBJUKieOegcfNxZzPL08vz8XN7CqgJ7AEKHEDUjO7NDALe8GGDRvKczsRqagdO2Dy5NCyoUMj15WUNX1xNjdNW0p2Ti4OyM7J5aZpS+ObPB51FHzyCXTsGFr+yy/Qq5ffpnD37sjPFUkQqZA4liZ/UFOZNw01sz7AWPzEmbOdcztLqu+ce9Q5l+Wcy2rSpEnZIxWRinv1Vdi4sfB4r720xWA1NGbWcnJ3hk4+yd25izGzlscpooD8GdfnnRda7pzfpvDMMyEnJz6xiUQhFRLH/BbFPYs53yisXlTMrDcwFfgJONE5p0EoIsngibCOgf79i24FJylvXU5umcqrVFoa/Oc/cM89Rfe4fu0133X92WfxiU2kFKmQOOb/+VjcGMaDA4/FjYEswszOAV4AfgS6Oufi/CeqiEQlOxtmzQotUzd1tdQsPa1M5VXODIYPh7fegn32CT23ahUce2zRfdZFEkAqJI5zAo/dzSzk9ZhZQ6AzkAt8FM3FzKw/fuHvdfikcWUpTxGRRPH006FjxNq3hw4d4hePxM3wHpmk1Q7dJSitdk2G98gs5hlx0q2bXwHgmGNCy3Nz/UoAQ4fCtm3xiU0qRUJN2iqHpE8cnXOrgDeBFhRdoPsOoD7wtHOu4CfPzA4xs0PCr2VmFwLPAN8BXdQ9LZJEnCvaTa3Wxmqrd4cMRvVpS0Z6GgZkpKcxqk9benfIKPW5Ve6AA+C99+Cyy4qee/JJdV2nkISctFVG5lyZ54wknMCWgx/gd495BfgS+CNwEr6L+jjn3Mag+g7AOWdBZScBb+OT6SeA7yPcKsc5NzaamLKystyCBQvK9XpEpBzmzYMuXQqP99gD1q2DvaPZcVQkQTz5JFx+uV8dIFidOnD//TBsmBayT2KdR88mO8I424z0NOaP6BbhGVXHzBY657JKq1erKoKpbM65VWaWBdyJXzqnF7AeeBC4wzm3KYrLHEhhC2xxzRTf4mdZi0iiCd//98wzlTRK8hkyxLcw9usHX31VWL5jB1xxBbzzjv9eTy/XCnMSZwk9aStKSd9Vnc85971zbohzbn/n3B7OuQOdc/8XKWl0zllwa2OgbFJ+eQlfLarsBYlI9DZtgueeCy0bMiQ+sYhUVNu2sGBB5KEWL70ERx4Js2dXfVxSYQk/aSsKKZM4SmTJPghXJCpPPRXatdeihd8tRiRZ1a8PEyf6xewbNAg99/33cPLJcM01fhKNJI2kmbRVAiWOKSwVBuGKlMo5eOSR0LJLL4WaNSPXF0km/fvD4sV+15lwY8fC0UfDwoVVH5eUS1JN2ipGSkyOSUSJMDkmkQfhisTMnDl+SZN8tWv7Fpl9941fTCKxtmMH3HIL3Hef/2MpWK1afteZm27y/xYph2gnx6jFMYWlwiBckVI9/HDocZ8+MUkaNcxDEkqdOjBmjP9D6cADQ8/l5fnE8bjj4PPP4xOfVBtKHFNYKgzCFSnRDz/Ayy+Hlg0bVuHLapiHJKyuXf2ajpEmf33yie/Svv32osv5iMSIEscUlgqDcEVKNHGib23Jl5npf7FW0JhZy8nduSukLHfnLsbM0u6jkgAaNfKL3U+fDk2ahJ7buRPuvNMnkB9FtWGaSJkocUxhqTAIV6RYO3cW7aaO0eLIGuYhSeHMM33XdJ8+Rc8tW+a7rv/6V/j116qPTVKWRtGmuN4dMpQoSmp66SXIDuo6rlcPLrwwJpdulp4WcWKZhnlIwmna1P8svPQSXHkl/Phj4Tnn4IEHfMvkAw/AGWdo1xmpMLU4ikhyeuCB0OMLL4TGjWNyaQ3zkKRz9tm+lTHS2Mdvv4XeveH00+Gbb6o+NkkpShxFJPn8739Fx29dfXXMLq9hHpKU9trLj318802/CH64GTPg8MP9GMjt26s8PEkNWsexkiTCOo4iKat/f5gypfC4Z0944434xSOSaLZtg1tvhQcfhF27ip5v3dqfO+WUqo9NEpLWcRSR1JSdDS+8EFL0wakDtOaiSLD69eFf/4JFi6Bz56Lnv/4aevXyX19+WfXxSdJS4igiyWX8+JAleLa2OIiLf9hLay6KRHLkkfDee/Dkk0WX7gHfUt+2LfzlL7BxY9XHJ0lHiaNUa9odJHaifS8r9J5v2VJkCZ5H2p3Gb3mhQ2605qJIkBo1YPBgWL4crrii6MzqXbvgoYd89/X998Pvv8clTEkOShyl2tLuILET7XtZ4fd8wgTIySk83msvnmx1QsSqWnNRJEzjxr7F/pNP4IQIPzc5OXDttX4CzfPPw+7dVR+jJDwljlJtaXeQ2In2vazQe759ux+zFezqq2ncNPISPFpzUaQYRx8Nc+f6scItWxY9//XXcO65kJUFM2f69SBFApQ4SrWl3UFiJ9r3skLv+TPP+L2p89WvD1ddpTUXRcrDDPr29Ws//vOf0LBh0TqLF/tZ1yeeCB98UOUhSmJS4ijVVnEtUmqpKrto38tyv+e7dsE994SWXXop7L231lwUqYi6deGGG2DlSv8zVSNCWvDee35m9hlnwNKlVR+jJBQljlJtqaUqdqJ9L8v9nr/0ku8+y1e7th+LFdC7QwbzR3Rj9ehTmT+im5JGkbLad18/hnjZMjjnnMh1Xn0V2rXz5z/9tGrjk4ShxFGqLbVUxU6072W53vPdu+Hvfw8tGzgQmjeP+esQqfYyM/3EmAULoEePouedgxdfhPbt4cwzfT2pVrRzTCXRzjEiMfLcc3Deef0JNv4AACAASURBVIXHZr5V5JBD4heTSAxNX5zNmFnLWZeTS7P0NIb3yEycP2DnzoWbboIPPyy+Ts+efpea444r06UT+nVXQ9o5RkSSX14e3H57aNn55ytplJSR8MuCde0K8+fDK6/4VsZIZs70YyBPPhneeiuqWdgJ/7qlWEock9HChTBtGnz7rZZJkNT2n//4RYvz1ahRNJEUSWJJsSyYmZ8Ys2iRH+d4zDGR682eDd27+wTzmWdKXEg8KV63RKTEMRlNnAhnnw0tWkDTpn4cys03VyiZ1A4qknB27oQ77ggtGzQI2rSJTzwilSCplgUzg9NOg48+glmzIu+BDfDZZzBoEOv3bsb4Xpfx2ntF98JOqtctIZQ4JqNFiwr//fPP8OabcPfdhclkkyY+mfzb3/xs1DVrSkwm1WUgCempp+CbbwqPa9WC226LXzwilSAplwUz8y2L8+b5VsaTTopYbf9fN3LlG49y4p+P5uuBl8Hq1QXnkvJ1C6DEMfnk5ZW+DMLGjT6ZHDXKL/DasqVPJrt39wOYZ8zwCWeAugwk4WzbVrRLeujQyLtciCSxpF4WzMwnjbNn+8kzffuyy4qmFQ1+z6X1s4/CQQfB6afDrFkM//PByfu6qznNqq4klTarevNm3+qycKFf1f+338p/rYMPhmOP5dYfGrCoWSbLm7Qgr2atgtMGrB59asVjFimrkSNDu6n32MOv43jAAXELSaSypNLs4q6XPc6QBa/Qb+lb1Nu5o/iKrVuz9MwLuL5+B1bsqJn0rzsVRDurWoljJamS5Xh27fITBxYuLPxavNi31pRDbq06fLZfaxZnHMLiZpmsP6Q9/727mIVgRSpLdrb/oyY3aKzTDTf4bdFEJKF1Hj2b7Jxc0nO3MGDxGwxe9CpNtuUU/4R69eCCC+Cyy+Coo6ouUClCiWOcxW0dx127YMWKosnkr7+W73otWsAJJ0CXLv6xTRvfPSFSWS68EJ5+uvC4SRO/Hdqee8YvJhGJSv6Y+fzhT3Xyfqfv8vcY/vU7pH9VynaF7dv7ISkDBsBee1VBtBJMiWOcJdQC4Lt3+2Tyk0/8bLgPP/Sz3nbtKv254Zo29Qlk/le7dlCzZunPE4nGggXQsWNo2cMPw7Bh8YlHRMosYtd7+2bwv//BQw/5nWl27iz+AnXqQJ8+cNFFfgxlpP2zy3LvJO3+rurXosQxzhIqcYxk2zbfGvnRR4XJ5A8/lP06DRv63QK6dPELxXbs6MejSalS6T+4mNi9G44/PnSHisMPhyVL/IxqEUkNP/4Ijz8OjzwCa9eWXLdlSxgyxC/FdeCBJVYNb+0EP+GmIlvJxuv/6cp4LaVR4hhnCZ84hnMO/r+9O4+Xoy7zPf55EshCJCtbCEIAIQFFcIwQEkdCogQiW1SUGWXES1RQBFG5A1fZ1OvlvlQcEJRFFGaAwWELe8IaAiJLRpZB9khYwpJAAiSQEJI888dTPafT6T5dfbq6q/v09/161auT6q7f+dWpPtVP/5bn98ILXYHkffdFYNndt8JyBg2KlsgpU2DyZLVIVpDHTaHlnXsuHHXUuvtmz45sACLS+6xeHQnFL7wQbr45vjx255OfjG7sQw6BESPWe7owvrLUqKED+dMJk2uuXp736azPJQ0Fjjlru8CxnBUr4IEHIlfX3XfDvffWPlZy2LDoapg8ObaxYzVGknxuCi3tlVdgp50ia0DBAQfAddflVycRaZ6FC+Gii+D3v183f2s5G24Y62N/+ctxn9hoIwC2PeFGykU0Pc0Qkud9OutzSSNt4Kj+H6ls4MDoft5rr/j/6tXRbVgIJO++e518kGUtXRor2lx9dfx/5MgIIKdMiZakUZ3ZuqZVE0oce+y6QeOgQTEWSkQ6w6hRsQLaiSfCXXdFV/ZVV8F7ZVL6vP9+tFRefz184AMxHvLQQ9n6Axvw/PLV6728p0nF87xPbzl0YNmgtRUSpCsBuKS3wQYwbhwcd1wEgosWwRNPwPnnxze/kSOrl/HKK3DppTFzbqutYJdd4Ac/gNtug5UrG38OLUKrJhS58Ua44op19/30p7D11vnUR0Ty06dP9FJdeml8Xpx9NowfX/n1y5dHFoZp07jt/3+RM2/6FZ9+5n76r451sutJKp7nfbqVE8Orq7pBekVXda3cI6/k7bfHSgJ33hktjmkNHAiTJkUXxNSpvTr1j8Y4JpYsgY9+NLqpCj7+8Zh9qbGxIlIwfz5cdlkElE9VX9Vseb+B/HnseIYcdii7f+sr/9OdXYu879OaVd1hOjJwLLVmTSyPWAgk586tbaWbbbbpCiI//emYwd2LdPysanf44hfhyiu79vXpE2mjlAhYRMpxh7/8JQLIyy+PVslqBg6Mz5EDDoDPfhY23zz1j+uk+7QCx5wpcCxj1aqYbHPbbbGW9v33V59FV9CvX7RG7r9//PGPHt3ImkozXHwxHH74uvtOOCHWWBcRqWbNmujZuuIKuOYaWLw43XG77x6fIwccED0evbRnq1YKHHOmwDGFpUsjiJw9O7Zq+byKffjDXUHk+PHq1mw3f/tbpGoqnqX/d38XORyVB1REarV6NdxzT/RgXHVV+rzEH/xg12fJ3nvDgAGNrWcLU+CYMwWONXKHxx+PAHLWrOjWLjebrpwRI2C//eIPf+rU3Jem66SujR5ZuTJm6j/wQNe+gQOj+2ns2PzqJSK9w9q1kT6uEESmbZQYMCAWs9hnn9g+8pGOao1U4JgzBY51evfdCB5nzYIbboiB0WlssEEkID/oIDj44KorDWQt78HULc8dZsyIXG3FfvOb9ZN/i4jUa+1aeOihSN1zww2xsEVaW2wRAeRnPhNbDWMj25ECx5wpcMxQYbb2DTfEds896dfZ/tjHYPr0CCKb8O1Rib2rOOccOProdfcdeCDMnNlR3+xFJCcLF8JNN0UgedttsdBFWrvuGhM1J02KBoqce7eypsAxZwocG2jp0q6WyJtvTp/yZ/vtu4LIPfeMGbwZyyPbf9uYOzcSv68uStC7444xSWro0PzqJSKdacWKyPhx/fURTL74Yvpj+/SB3XaLILIQSLb5fazjAkcz2wr4MbAvMAJ4BZgJnObuqZMJmtlw4GTgYGAk8AYwCzjZ3VPP3lDg2CSrV8dYlkJr5BNPpDtu8827urMnT4b+/TOpjlocK3jssRg7VBzkb7xxBI077ZRfvUREIHq2nn46Mn7cckvM1n7nnfTHm0UgWVhtbcIE2GyzxtW3AToqcDSz7YF7gc2Aa4Engd2BvYGngInu/kaKckYk5ewI3AE8CIwFDgIWAXu6e5VFNIMCx5zMnw/XXhupGf70p7gZVLPxxpHb6+CDYdq0uvJFaoxjGc89BxMnrp9vbebMCN5FRFrNqlWR5eHWWyOQnDcv3edJsQ99KALIwrbzzi2dAaTTAsfZwD7AMe7+66L9ZwDHAee5+5EpyjkP+AbwK3f/XtH+Y4Azgdnuvm+aOilwbAGvvRZdENdcE2NZVq2qfky/fjGGZfr0GHvXg2+MmlVd5LXX4JOfhGefXXf/T34CP/pRPnUSEanVG29Et/Zdd8GcOfDXv9ZexuDBkT6uEEjusUfsaxEdEzia2XbAfGABsL27ry16bmOiy9qAzdy9YruzmQ0CFgNrgZHuvqzouT7Jzxid/IyqrY4KHFvM22/HeMiZM2Nt5GXLqh/Tp0+0lE2fHpuSjtfm1VdjJuJjj627/+ij4ayzNBlGRNrX4sUxbnvOnNhK73NpmMGYMfCJT8C4cfG4226RniwHnRQ4zgAuAM5392+Web7QGvlpd7+9m3I+DdwK3OLuU8s8X2iNnOHuF1arlwLHFvbee/HNcebM6NZ+7bV0x+22W1cQ2WH5vWr24osxEeaZZ9bd/w//AJdc0pCJSSIiuXn99Qgk77orxt0/9FD67B/F+vaNz5dCIDluHOyyS1MWRkgbOPaGu/eY5PHpCs8XPrl2bFI50ur694+E4eedF6kZ7rkHvv992G677o97+GE45ZRYomqHHeD44+MGkXbZxE7xyCPRDVMaNO67L1x0kYJGEel9NtkEPvc5OPNMePBBeOutaIn82c9iZZrhw9OVs2ZN3EMvvBCOPDICx403jmUSL7igoaeQVm+4gxcSKb1V4fnC/mrz5Osux8y+YWbzzGze4rRrZkq++vaN7uhf/CLG4T36KJx2WrQudmf+/Dhm4kQYNSqSV99yS7pxlL3ZDTfEmMbSlRqmTYOrr9ZygiLSGQYNitnVJ54YY+1ffx2efDIWP5gxIybKpO21WrUqgtHXX29snVPaIO8KNEHhytTbJ1+1HHc/Hzgfoqu6zp8nzWYWXQK77AInnxyzgWfOjMk199xTeUbdq6/CuefGNmRIfLucPj1a2AYNau455OX99+GHP4Sf/3z95z7/ebjsMgWNIk2iCXotqDCeccwY+NrXYt/bb0eX9oMPxqztefO6XyXtE59oTl2r6A2BY6ElsFIK98Elr2t0OdJbbLstHHdcbIsWwXXXVZ+h/dZbcOmlsQ0YEMtVTZ8e62iPGNGjarT8h8CCBfCP/xipK0odcwyccUZLp6AQ6U1KU4ItfHMFJ179XwCtdd+QmFFdyPtYsGRJLItYCCYffLCrB+fjH8+nniV6Q+D4VPJYaezhDsljpbGLWZcjvdFmm0X3wowZXTO0r7kmZmgvX17+mJUrI9i87roY1zd+fIyt3G+/WAoxxVi/lv4QeP/9GM9zyimxtnixvn0jYDzmmHzqJtKhfj77qXXyyAKseH8NP5/9VP73DKlu+PCutbELXn01Zm0PG5ZfvYr0hlnV2wPP0n06nj7AplXS8XyASPKtdDyS3nvvwe23RxB57bWRoiGNzTePruxp0+IGUeGG0LIr0cyZA8ceG2NCS40aBZdfHmMdRaSptOyp9FTHzKp29/nALURQ9+2Sp08DBgH/Whw0mtlYMxtbUs5y4N+S159aUs7RSfmz064cI9mb+dBCJp5+B9uecCMTT7+DmQ8tzLtKMUN72rSY7fbKK5GO4bjjqud8fO01uPhi+NKXYNNNI8g6+eRIE7SiK1B8uUzQ2N3+hps7F/beO7ZyQeO0aTH7XEGjSC62HFo+B2Cl/SK1avsWRyi75OATwB7EkoNPAxOKlxw0Mwdwdyspp3TJwQeAnehacnBCEqhWpRbHbLXdUn7ukVLhmmtigk25IKuSfv1gzz1h0iSOfnkwt39gG1b0G7DOS5ra4rh8ebQgXnABPPBA+dcMHQqnnw5f/7rS7YjkqO3uldIyOiYBeIGZfRD4MbAvMILoop4JnObuS0peWzZwTJ4bDpwCHAyMBN4AbgZOdveXSl9fiQLHbLVsl21aL70Es2bF2Mhbb023ck1ijfXh6U225qEtx/DwyDE8ufVYjjhiXw7afdvG1Xfp0qjv9dfHVmkcJ8Bhh0Vqoh4szygi2Wv5CXXSkjoucGw1Chyzlfe4nUxvxKtWReLwm26KQLInS1VtsEEkId9559h22gm22Qa22gq23DKeT8M91mCdPz9yjN1/f2yPPFJ91YPPfCZyXu65Z+31FxGRlqLAMWcKHLOVZ4tjw7t+XnwR7ryza3v++frK69MnJt8MGRLpHjbeuCuf5Jo1MRv6zTcj7cOiRTFLvBZTp8JJJ0XycxER6RUUOOZMgWO28hy30/SgdcGCCCDnzInciKVL9+Vh5MhIWnvEEdWXZsyIuttERJonbeDYG/I4SgcoBAx5BBJNn9k8enQEaYXVBZYsiSSwhW7kRx9df0m/Rth550hcfsABkYOyiUm8Wzp/pYhIB1PgKG3j4I+NyiVo2HLowLItjk1LbzF8eHQPT53ate/tt+Hxx2P7619jne2XXopt0aLayh84MFoRt98edt0V9tgjlrbKcbKLkhiLiLQmBY4iVRw/dUzZbvLjp47Jr1KDB0cr4Pjx6z+3cmUEj8uWRYC5bBm8806MfezTJ1oOhw2LbfjwyCNp6yUYyFXL5a8UERFAgaNIVXl2k/fIgAGw9dZ516IuubfyiohIWQocRVLIq5u8U7VkK6+IiChwFJHW03atvFJRI2bHa8a9SH4UOIpIS1Irb/trxOx4zbgXyZcWlRURkYbobnZ8K5UpIukpcBQRkYZoxOx4zbgXyZe6qkU6kMaISTM0Yna8ZtyL5EstjiIdpjBGbOGbK3C6xojNfGhh3lWTXub4qWMYuOG6Kw7VOzu+EWWKSHoKHEU6jMaISbMc/LFR/L/P7cKooQMxYn33eteXb0SZIpKeuqpFOkwtY8TUpS31asTseM24F8mPWhxFOkylsWCl+9WlLSIipRQ4Su5mPrSQiaffwbYn3MjE0+9QYNJgaceIqUtbRERKqatacqVkvs2XdlUWpT0REZFSChwlV921ailwbJw0Y8SU9kREREqpq1pypVat1qW0JyIiUkqBo+Qq7UQNaT6lPRERkVLqqpZcHT91zDpjHEGtWq1EaU9ERKSYAkfJVdqJGiIiIpI/BY6SO7VqiYiItAeNcRQRERGRVNTiKCIiIt3S8qNSoMBRREREKtJCDVJMXdUiIiJSkZYflWIKHEVERKQiLdQgxRQ4ioiISEVaqEGKKXAUERGRirT8qBTT5BgRERGpSAs1SDEFjiIiItItLdQgBeqqFhEREZFUFDiKiIiISCoKHEVEREQkFQWOIiIiIpKKJseISMfQersiIvVR4CgiHUHr7YqI1E9d1SLSEbTerohI/RQ4ikhH0Hq7IiL1U+AoIh1B6+2KiNRPgaOIdASttysiUj9NjhGRjqD1dkVE6tcrAkczmwD8CBgPDACeBX4P/Nrd13R3bFEZo4DPAdOAnYCRwHLgL8Bv3f3qBlRdRJpI6+2KiNSn7buqzewgYC7wKeAa4BygH/Ar4PIaivoOcBYwBrgTOAOYDfw9cJWZnZFhtUVERETaTlu3OJrZYOACYA0wyd3nJftPAu4AvmBmh7p7mgDygaSMu0p+xk7AfcBxZnapu/9npichIiIi0ibavcXxC8CmwOWFoBHA3VcSXdcAR6UpyN2vLg0ak/1PAH9M/juprtqKiIiItLF2DxwnJ4+zyjw3F3gXmGBm/ev8Oe8nj6vrLEdERESkbbV74FjIo/F06RPuvhp4juiO366nPyDpDv884MAtPS1HREREpN21e+A4JHl8q8Lzhf1De1K4mRnwO2BzYmb1E1Ve/w0zm2dm8xYvXtyTHykiIiLSsnIPHM1sgZl5DdsltRSfPHoPq/dL4BDgbuB71V7s7ue7+zh3H7fpppv28EeKiIiItKZWmFU9H1hZw+tfLvp3oUVxSLkXAoNLXpeamf0cOI4YK/lZd3+v1jJEREREepPcA0d3n1LH4U8B44AdgXXS5JjZBsC2xISWv9VSqJn9Cvgukc9xf3d/t446ioiIiPQKuXdV1+mO5HHfMs99CtgIuDdta6GFc4ig8VaipVFBo4iIiAjtHzheCbwOHGpm4wo7zWwA8NPkv78tPsDMNjKzsWa2dcl+A84HvgXcDBzo7isaWXkRERGRdpJ7V3U93P1tM/s6EUDOMbPLgSXAgUSqnivpSt5dsDvRBX0X6yb0PhmYAawAHgZOiFhyHQ+7+8yMT0NERESkLbR14Ajg7jPNbC/gh0S+xQHAs8Qs6LPcPe2M6m2Tx4HAiRVeczGgwFFEREQ6kqWPq6QWZrYYeL7BP2YToqu+U3Xy+evcO1cnn38nnzt09vnr3BtvG3evmktQgWMbM7N57j6u+it7p04+f517Z547dPb5d/K5Q2efv869dc693SfHiIiIiEiTKHAUERERkVQUOLa38/OuQM46+fx17p2rk8+/k88dOvv8de4tQmMcRURERCQVtTiKiIiISCoKHEVEREQkFQWOLcLMNjSzY83sD2b2sJmtMjM3sxkpjv2qmT1gZsvN7C0zm2Nm+/ewHvsnx7+VlHe/mX21J2XVy8wuSn4H3W23pyxrdJVyLm/0+dSqEXU2swlmdpOZLTGzd83sUTP7rpn1bcQ59JSZ7WBm/2xmd5jZi8nfw2tmdq2Z7V1jWS177c1sKzP7vZm9bGbvmdkCM/sXMxtWYznDk+MWJOW8nJS7VaPqXg8zG2FmM8zsGjN71sxWJPece8zsCDNL/dmUnHOla/tqI8+jp7Ksc1bvoWYxs8NT3NfXpCyrJa+9mX3BzH5tZneb2dtJfS6pckxm92Yz29nM/sPMFpnZSjN7ysxOM7OBPT+rLm2/ckwvMgj4l+TfrwGvAh+sdpCZ/QL4PvAScAHQDzgUuN7MvuPuZ6etgJkdDfwaeAO4BFgFfAG4yMx2cfcfpD+dTMwEFlR47jBgO2Jd8Vo8QvnVfx6rsZxmyqTOZnYQcBWwkliKcwlwAPArYCJwSH3VzNRPgC8BjwM3EXUdQywneqCZHevuZ9VYZktdezPbHrgX2Ay4FniSWBL1WGBfM5vo7m+kKGdEUs6OwB3A5cBY4GvAZ81sT3f/W2POoscOAX4LvEIsAfsCsDnwOeB3wH5mdkgNK3+9Rdf9s9jyDOraKHXXOav3UJM9DJxW4bm/ByZT2329Fa/9j4Bdkzq8RPw9VpTlvdnM9iDuAxsSyy6/SPxOTwammNkUd3+vxvNZl7tra4GNCPj2A0Ym/z8VcGBGN8dMSF7zLDCsaP9oIvhbCYxO+fNHJ69/o/gYYFhSvgN75v17Suo0FHgXeA/YpIbzc+CivOtfw3lmVmdgMLAo+Z2NK9o/gPjgceDQvM+5qF6HAx8rs38v4gvNe4W/lXa99sDspF7fKdl/RrL/3JTlnJe8/oyS/cck+2flfa5l6jyZ+GDsU7J/CyKIdODzKctaACzI+5xqPP9M6pzVe6hVNuDPSb0PbOdrD+wN7AAYMCk5p0sqvDazezPQl/iyvc7vkOhdvjLZf0K956eu6hbh7qvc/WZ3f6WGw45MHv+vuy8tKmsBcA7Qn2h1SON/Ja8/Ozm+UNZS4GclPy9vhxFril/t7p26BFWtvgBsClzu7vMKO919JfHtGOCoPCpWjrtf5O4Pldl/FzCH+KI1odn1yoqZbQfsQ3zwnVPy9CnAO8BhZjaoSjmDiL+Hd5Ljip2dlD81+Xktw93vcPfr3X1tyf5XgXOT/05qesXaSFbvoVZhZh8BxgMLgRtzrk5d3P1Od3/Gk6itiizvzXsBOwFz3f26orLWAv87+e+RZmYpyytLXdXtbXLyOKvMczcDJyWvKf1A6UlZxa/J29eTx57kttrSzL4JjCBaV//s7o9mVrPGyKLO3V3fuUQL7gQz6+/1dmM03vvJ4+oaj2ula1+4HreUCZ6WmdmfiKBgPNDdON49iS9Rt7j7spJy1prZLcA3iBaQVuuurqQn17e/mX0F2JoImB4lPjxTjZXLSb11zuo91Cq+mTxeWON1a8drXyzLe3PFstz9b2b2NDGkZTtgfg/rq8CxXSXfIkcByyu0Uj6TPO6YssgxyePTpU+4+ytm9g6wlZlt5O7v1lzhjJjZnsAuwNPufmcPivhMshWXOQf4qru/UH8NGyKLOnd3fVeb2XPAh4kbyhM9r2pjmdk2wBTiZjq3xsNb6dpXvB6JZ4gP/R3p/kM/TTmQ/j6QKzPbAPin5L/lPkgr2QL4t5J9z5nZ15JW6lZUb52zeg/lLpm08RVgLTHGtRbteO2LZXlvTvOe2DHZehw4qqu6fQ1JHt+q8Hxh/9CMyxtS4flm+UbyeEGNx71LTLj4ODFucxjRrH8n0SV2ewt26WRZ56zfL01nZv2BS4khFacWD8+oohWvfVbXo+2va4nTgY8AN7n77JTH/IH4MrEFMclwF2Lc52jgZjPbtQH1rFcWde5N1/6LRD1vdvcXaziuHa99qSyvY1PeEwocM1QlNUC5rdvp+RnJammgwpiImsrL8ndiZkOIG8wq4KJa6uHui9z9ZHf/i7u/mWxziW/k9wMfAqqmPqpVPeff5Dr36Pp2W2C2174v0aowkZh1+Iu09cjr2tcpq+uR+XVtFDM7hsgQ8SQxbjMVdz8tGTP5mru/6+6PufuRxASRgcREw5bSpDq3zbWnq0HgvFoOasdr3wNZXsdMylJXdbbmEzOT03q5jp9VrQWw2jePcuVtkhxXLn3D4OTx7ZTlFWT5O/kKsBExiDiTSTFJV8DvgD2ATwFnZlFukczfEz2sc7X3y+CS12Uhk3NPgsZLiJQU/wF8JeWg82414dp3J6vrkcd1zZyZfZv4/T8OTHH3JRkUey4RiH4qg7KapZY695ZrvzMx0e0lIvVWFtrp2md5HZvynlDgmCF3n9LEn/WOmS0ERpnZyDLjHHdIHiuNdSj1FBE47kikRPgfZjaS6AZ4qdbxjRn/TgqTYmr6VprC4uQx8+7KBr4naq3zU8A44vr+Z/ETybiybYnJCJlNoMji3JO6XUYEjZcB/5TxoPeGXfsqnkoeK409TPv3m1U5uTGz7xL56h4jgsZFGRVdKKfVhqB0p5Y6t/21T/R0Ukx32unaZ3lvbsp7Ql3V7e2O5HHfMs/tV/KaZpaVuSSp6a7EpJg5GRc/Pnlsl1mnUHudu7u+nyJacu9tpRnVZtaPyD12CPCvwGENmCmZ17UvTOzax0pWSTGzjYku+RXAfVXKuS953cTkuOJy+hDd8cU/r6WY2T8TQePDwN4ZBo0QM86hvf6ua6lzVu+h3JjZAGJYwlrgwgyLbqdrn+W9uWJZSfqmHYHnqff3kjbho7bmbjQoATjRqjiWksTZxLealk0ATtxUHPh+ldcNSc5vZMn+PYB+ZV4/OTlvBybkfd3rrXM35z+YaF1rlwTg/Ylcbk7MsuyT4pi2uvbUmLw5ObexZcopJAD/Zcn+lk0AntTvpKR+84DhVV67YXL+25fs/3C5Y4FtiBmkDvyfvM+1njpXOveevIdabSOCRgeu763XnnQJwGu6NxPB5Fhg65L93SUAv4KMEoBbUqi0ADM7ga6liXYjWtjupSulxj3u/ruSY34JHaOzBQAABGhJREFUfI8YH3IlkRj5S0SuuvWWHDSzU4m8jqe5+6klz30HOIsIHv9I15KDWxEfSs1ecrBQr8HE+LcNgVHezfhGMzucmGl3sbsfXrR/DnGjmUP8rgA+Slfeq5Pc/acZV70uPalzpfNPnjuYeI+sJJalW0Is4Tcm2f9Fb5Ebgpn9gVg95nXgN5QfzD3Hi1qf2+3a2/rLxT1BBLl7E11JE7xouTgzcwB3t5JySpccfIBIAnwQ0WU3wd17nHqjEczsq8QEtzXEMqflxlwtcPeLktePBp4Dnnf30UXlnAqcQLS+PQcsA7YHPkt88N4ETHf3VY04j56otc6Vzj15rqb3UKsxs7uBTxJBzvUVXjOaNrv2yb324OS/WwBTiVa+u5N9rxd/ntZ6bzazScR53+Xuk0p+dumSgy8QM8/HAX8ihoNoycHeshEfbN7NdlGF474KPEgkP10G3AXsX+G1pyZlnVrh+QOS45cl5T1I5LnL8/dyVFLnf0/x2sPL/a6AI4AbiFUWlhPf7l4gAuS/z/vaVziXmutc6fyLnp9I3FCXEt1Y/wUcB/TN+3xL6lntb2G993A7XntiPfo/EGs2ryK6kc6kfEuKxy27bDnDk+OeT8p5Bfg9sFXe17JCfQv3oe62OUWvH53sW1BSzl7AvxMzsd8kkocvBm4l8kFa3uda5txrqnOlc+/Je6iVNuLLjRNrKVe8/7TjtU/x/l7vWlLDvZmuVsw5FX7+zkQL4+vJ/e5pYn3wgVmcn1ocRURERCQVTY4RERERkVQUOIqIiIhIKgocRURERCQVBY4iIiIikooCRxERERFJRYGjiIiIiKSiwFFEREREUlHgKCIiIiKpKHAUEWlBZjbUzN40szfMbOMyz/cxsyvNzM3sd+XKEBHJmgJHEZEW5O5vEmvHDweOLvOSs4DPE8spfrOJVRORDqYlB0VEWpSZDSPW2H4fGO3uy5P9PwR+CtwHTHH3d3OrpIh0FLU4ioi0KHdfCvwaGAF8G8DMvkYEjU8B+ytoFJFmUoujiEgLM7PhwPPASiJ4vBRYDExw9wU5Vk1EOpBaHEVEWpi7LwHOBjYB/gi8C+ynoFFE8qDAUUSk9d1Q9O8vu/sjudVERDqaAkcRkRZmZlsS3dMFO+dVFxERBY4iIi3KzIYCs4BtgJOBd4AfmNmgXCsmIh1LgaOISAsyswHAtcAuwI/d/SfAb4FNgaPyrJuIdC7NqhYRaTFm1he4ApgOnO/u30z2b0rkdVwObKtUPCLSbGpxFBFpPecQQeNM4FuFne6+GPgNsBlwZD5VE5FOphZHEZEWYmanEeMZ7wb2cfeVJc9vBjwHLCNaHVc0v5Yi0qnU4igi0iLM7EgiaHwMOLA0aARw90XEWMfN0RrVItJkanEUERERkVTU4igiIiIiqShwFBEREZFUFDiKiIiISCoKHEVEREQkFQWOIiIiIpKKAkcRERERSUWBo4iIiIikosBRRERERFJR4CgiIiIiqShwFBEREZFU/hsemTnqmp8uPgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use our model to predict in the range we want\n",
    "num_epochs = f'{len(model5_history.epoch)}'\n",
    "\n",
    "X_range = np.linspace(-10, 10, 500)\n",
    "y_pred = model5.predict(X_range)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,6))\n",
    "ax.scatter(X_train, Y_train, label='Training data')\n",
    "ax.plot(X_range, y_pred, lw=4, color='r', label=f'NN ({num_epochs} epochs)')\n",
    "\n",
    "ax.set_xlabel(r'$X$', fontsize=20)\n",
    "ax.set_ylabel(r'$Y$', fontsize=20)\n",
    "ax.set_title(f'NN with {len(model5_history.model.layers)} layers, {H} nodes in each layer', fontsize=LABEL_SIZE)\n",
    "ax.tick_params(labelsize=20)\n",
    "\n",
    "ax.legend(loc=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems very good. Let's see the $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score as r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 428us/step\n",
      "Test loss: 0.09021387249231339\n",
      "Test R2: -2.2482520675821482\n"
     ]
    }
   ],
   "source": [
    "score = model5.evaluate(X_test, Y_test, verbose=1)\n",
    "print('Test loss:', score)\n",
    "print('Test R2:', r2(Y_test, model5.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
    "ax.plot(np.sqrt(model5_history.history['loss']), 'r')\n",
    "ax.plot(np.sqrt(model5_history.history['val_loss']), 'b' ,label='Val')\n",
    "ax.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax.set_ylabel(r'Loss', fontsize=20)\n",
    "ax.legend()\n",
    "ax.tick_params(labelsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
